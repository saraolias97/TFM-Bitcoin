{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense intervalos - datos 1 hora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run 1hora-porintervalos1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix,balanced_accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subida(list):\n",
    "    resultado = []\n",
    "    for i in range(1,len(list)):\n",
    "        if  (list)[i] > (list)[i-1]:\n",
    "            resultado.append(1)\n",
    "        else:\n",
    "            resultado.append(0)\n",
    "    return resultado\n",
    "\n",
    "def acierto(list1,list2):\n",
    "    sum = 0\n",
    "    for i in range(0,len(list1)):\n",
    "        if(list1[i]==list2[i]):\n",
    "            sum = sum +1\n",
    "    a = sum/len(list1)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 11, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 25)                850       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,965\n",
      "Trainable params: 8,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 4s 3ms/step - loss: 44.4530 - accuracy: 0.4996\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 4.0642 - accuracy: 0.4939\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4637 - accuracy: 0.5006\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9010 - accuracy: 0.5007\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.0390 - accuracy: 0.5047\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4582 - accuracy: 0.5057\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.8468 - accuracy: 0.5034\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7528 - accuracy: 0.5054\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.8537 - accuracy: 0.5088\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7304 - accuracy: 0.5094\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5102\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5108\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7271 - accuracy: 0.5095\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5108\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5084\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5097\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5075\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5072\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5077\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5055\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5093\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7274 - accuracy: 0.5052\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5050\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5067\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5088\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5053\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5076\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5086\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7275 - accuracy: 0.5051\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7273 - accuracy: 0.5077\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5101\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5061\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7275 - accuracy: 0.5067\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5094\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5085\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5084\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5077\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5073\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5070\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5077\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5077\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5066\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5084\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5091\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5088\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7274 - accuracy: 0.5065\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5074\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5074\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5065\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5072\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5081\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7274 - accuracy: 0.5075\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5068\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5091\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5068\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5088\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5092\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5086\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5082\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5086\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5105\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5088\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5051\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5072\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5100\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5059\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5097\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7273 - accuracy: 0.5091\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5099\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5089\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7271 - accuracy: 0.5086\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5074\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7271 - accuracy: 0.5089\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5105\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5092\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5071\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5094\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5080\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5109\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 0.7272 - accuracy: 0.5080\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 0.7272 - accuracy: 0.5085\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 0.7271 - accuracy: 0.5089\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5070\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5094\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7271 - accuracy: 0.5087\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5089\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7270 - accuracy: 0.5086\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5095\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5103\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5100\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7271 - accuracy: 0.5090\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5112\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5090\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7271 - accuracy: 0.5093\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5106\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5082\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7271 - accuracy: 0.5100\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 0.7271 - accuracy: 0.5111\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7271 - accuracy: 0.5111\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179b3348648>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4944970283953335\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4493    0    0    0]\n",
      " [   0 4588    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      1.00      0.66      4493\n",
      "         4.0       0.00      0.00      0.00      4588\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9086\n",
      "   macro avg       0.10      0.20      0.13      9086\n",
      "weighted avg       0.24      0.49      0.33      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 64)                768       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 21)                693       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                352       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,012\n",
      "Trainable params: 4,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 37.5358 - accuracy: 0.4998\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.5714 - accuracy: 0.5015\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.9120 - accuracy: 0.4997\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.2952 - accuracy: 0.4994\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1123 - accuracy: 0.4970\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.9660 - accuracy: 0.5013\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3825 - accuracy: 0.5043\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7534 - accuracy: 0.5046\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7504 - accuracy: 0.5054\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7275 - accuracy: 0.5086\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7277 - accuracy: 0.5067\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5100\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5065\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5079\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5065\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5051\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7275 - accuracy: 0.5078\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5084\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5072\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5076\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7276 - accuracy: 0.5054\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5099\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7275 - accuracy: 0.5064\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5077\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5061\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5097\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5072\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5091\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5041\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5088\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5089\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5089\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5089\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5104\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5087\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5098\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5067\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5071\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5056\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5081\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5079\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5088\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5091\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5094\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5050\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5055\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5100\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5081\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5087\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5071\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5076\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5096\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5091\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5083\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7274 - accuracy: 0.5060\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5095\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.5095\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5077\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5078\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5076\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5080\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5097\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5092\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5111\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5089\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5066\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5102\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5066\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5099\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5098\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5092\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5095\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5084\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5098\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5100\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5084\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5102\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5099\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5072\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5078\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5086\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5098\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5100\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5087\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5088\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5085\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5102\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5094\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5112\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5088\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5082\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5099\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5102\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5092\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5087\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5115\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5103\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5059\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5104\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179b4b56488>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4944970283953335\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4493    0    0    0]\n",
      " [   0 4588    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      1.00      0.66      4493\n",
      "         4.0       0.00      0.00      0.00      4588\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9086\n",
      "   macro avg       0.10      0.20      0.13      9086\n",
      "weighted avg       0.24      0.49      0.33      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 11)                187       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,258\n",
      "Trainable params: 1,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.8209 - accuracy: 0.5014\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.9851 - accuracy: 0.4981\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6039 - accuracy: 0.4965\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4108 - accuracy: 0.4958\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2228 - accuracy: 0.4982\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.0948 - accuracy: 0.5010\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.0067 - accuracy: 0.5055\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.9297 - accuracy: 0.5086\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7642 - accuracy: 0.5113\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7513 - accuracy: 0.5117\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7315 - accuracy: 0.5115\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7284 - accuracy: 0.5115\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7325 - accuracy: 0.5092\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5104\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5113\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7267 - accuracy: 0.5113\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7628 - accuracy: 0.5056\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7354 - accuracy: 0.5115\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7305 - accuracy: 0.5115\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7286 - accuracy: 0.5115\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7278 - accuracy: 0.5115\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5115\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5115\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5115\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5115\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5092\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179b5c43808>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4944970283953335\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4493    0    0    0]\n",
      " [   0 4588    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      1.00      0.66      4493\n",
      "         4.0       0.00      0.00      0.00      4588\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9086\n",
      "   macro avg       0.10      0.20      0.13      9086\n",
      "weighted avg       0.24      0.49      0.33      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 11, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,257\n",
      "Trainable params: 19,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 4s 2ms/step - loss: 9.1304 - accuracy: 0.0022\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0572 - accuracy: 0.0022\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0571 - accuracy: 0.0022\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.0571 - accuracy: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179b4c0ed88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00022011886418666079\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    2    0]\n",
      " [   0    0    0 4493    0]\n",
      " [   0    0    0 4588    0]\n",
      " [   0    0    0    2    0]\n",
      " [   0    0    0    1    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4493\n",
      "         4.0       0.00      0.00      0.00      4588\n",
      "         5.0       0.00      1.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9086\n",
      "   macro avg       0.00      0.20      0.00      9086\n",
      "weighted avg       0.00      0.00      0.00      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,295\n",
      "Trainable params: 8,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 4s 2ms/step - loss: 17.2231 - accuracy: 1.3757e-04\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 17.4580 - accuracy: 2.7515e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179b3959148>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0]\n",
      " [   2    0    0    0    0    0    0]\n",
      " [4486    7    0    0    0    0    0]\n",
      " [4576   12    0    0    0    0    0]\n",
      " [   2    0    0    0    0    0    0]\n",
      " [   1    0    0    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00       2.0\n",
      "         3.0       0.00      0.00      0.00    4493.0\n",
      "         4.0       0.00      0.00      0.00    4588.0\n",
      "         5.0       0.00      0.00      0.00       2.0\n",
      "         6.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00    9086.0\n",
      "   macro avg       0.00      0.00      0.00    9086.0\n",
      "weighted avg       0.00      0.00      0.00    9086.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,359\n",
      "Trainable params: 2,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.3873 - accuracy: 0.0096\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.3954 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179bbc3b088>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    2    0]\n",
      " [   0    0    0 4493    0]\n",
      " [   0    0    0 4588    0]\n",
      " [   0    0    0    2    0]\n",
      " [   0    0    0    1    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00       2.0\n",
      "         3.0       0.00      0.00      0.00    4493.0\n",
      "         4.0       0.00      0.00      0.00    4588.0\n",
      "         5.0       0.00      0.00      0.00       2.0\n",
      "         6.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00    9086.0\n",
      "   macro avg       0.00      0.00      0.00    9086.0\n",
      "weighted avg       0.00      0.00      0.00    9086.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 11, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 25)                850       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 20)                520       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 17)                357       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 14)                252       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 12)                180       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 11)                143       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,319\n",
      "Trainable params: 10,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 4s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.4308 - accuracy: 0.0022\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.4308 - accuracy: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179bc3a1a08>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00022011886418666079\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    2    0]\n",
      " [   0    0    0 4493    0]\n",
      " [   0    0    0 4588    0]\n",
      " [   0    0    0    2    0]\n",
      " [   0    0    0    1    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4493\n",
      "         4.0       0.00      0.00      0.00      4588\n",
      "         5.0       0.00      1.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9086\n",
      "   macro avg       0.00      0.20      0.00      9086\n",
      "weighted avg       0.00      0.00      0.00      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 21)                693       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 16)                352       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 13)                221       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 11)                154       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,575\n",
      "Trainable params: 4,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 4s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6378 - accuracy: 2.4763e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179cdc83908>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0    0]\n",
      " [   2    0    0    0    0    0]\n",
      " [4493    0    0    0    0    0]\n",
      " [4588    0    0    0    0    0]\n",
      " [   2    0    0    0    0    0]\n",
      " [   1    0    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00       2.0\n",
      "         3.0       0.00      0.00      0.00    4493.0\n",
      "         4.0       0.00      0.00      0.00    4588.0\n",
      "         5.0       0.00      0.00      0.00       2.0\n",
      "         6.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00    9086.0\n",
      "   macro avg       0.00      0.00      0.00    9086.0\n",
      "weighted avg       0.00      0.00      0.00    9086.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 11)                187       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 4s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.2214 - accuracy: 0.5115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179b6e49948>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4944970283953335\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    2    0]\n",
      " [   0    0    0 4493    0]\n",
      " [   0    0    0 4588    0]\n",
      " [   0    0    0    2    0]\n",
      " [   0    0    0    1    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      1.00      0.66      4493\n",
      "         4.0       0.00      0.00      0.00      4588\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9086\n",
      "   macro avg       0.10      0.20      0.13      9086\n",
      "weighted avg       0.24      0.49      0.33      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 25)                850       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,965\n",
      "Trainable params: 8,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 33.5036 - accuracy: 0.4879\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 13.3295 - accuracy: 0.4870\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 10.7390 - accuracy: 0.5004\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0020 - accuracy: 0.4891\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 7.4427 - accuracy: 0.4905\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 6.3048 - accuracy: 0.4889\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.4117 - accuracy: 0.4881\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.7331 - accuracy: 0.4839\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.0774 - accuracy: 0.4883\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.5233 - accuracy: 0.4865\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.0923 - accuracy: 0.4890\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.7320 - accuracy: 0.4965\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.4852 - accuracy: 0.4904\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.2858 - accuracy: 0.4909\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.1191 - accuracy: 0.4929\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.0779 - accuracy: 0.4906\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9822 - accuracy: 0.4913\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.8992 - accuracy: 0.4953\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.8739 - accuracy: 0.4955\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.8593 - accuracy: 0.4940\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.8298 - accuracy: 0.4930\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.8082 - accuracy: 0.4913\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.4922\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.7196 - accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6965 - accuracy: 0.4932\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6890 - accuracy: 0.4927\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6709 - accuracy: 0.4921\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6439 - accuracy: 0.4880\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6303 - accuracy: 0.4913\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5994 - accuracy: 0.4906\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5841 - accuracy: 0.4903\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5543 - accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5264 - accuracy: 0.4952\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5288 - accuracy: 0.4928\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5107 - accuracy: 0.4933\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5052 - accuracy: 0.4914\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4804 - accuracy: 0.4905\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4729 - accuracy: 0.4886\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4784 - accuracy: 0.4904\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4425 - accuracy: 0.4922\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4341 - accuracy: 0.4941\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4351 - accuracy: 0.4941\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4232 - accuracy: 0.4906\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4061 - accuracy: 0.4913\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3903 - accuracy: 0.4960\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3838 - accuracy: 0.4948\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3503 - accuracy: 0.4949\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3706 - accuracy: 0.4901\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3518 - accuracy: 0.4927\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3424 - accuracy: 0.4947\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3466 - accuracy: 0.4910\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3390 - accuracy: 0.4919\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3127 - accuracy: 0.4964\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3052 - accuracy: 0.4936\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3094 - accuracy: 0.4925\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2973 - accuracy: 0.4921\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2814 - accuracy: 0.4984\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2790 - accuracy: 0.4931\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2819 - accuracy: 0.4928\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2784 - accuracy: 0.4934\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2882 - accuracy: 0.4922\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2897 - accuracy: 0.4880\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2572 - accuracy: 0.4922\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2518 - accuracy: 0.4910\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2346 - accuracy: 0.4987\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2551 - accuracy: 0.4938\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2526 - accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2357 - accuracy: 0.4956\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2310 - accuracy: 0.4921\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2304 - accuracy: 0.4931\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2125 - accuracy: 0.4975\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2368 - accuracy: 0.4882\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2176 - accuracy: 0.4909\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2068 - accuracy: 0.4938\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2034 - accuracy: 0.4989\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1982 - accuracy: 0.4974\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1983 - accuracy: 0.4969\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1818 - accuracy: 0.4934\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1951 - accuracy: 0.4912\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1797 - accuracy: 0.4921\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1820 - accuracy: 0.4947\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1756 - accuracy: 0.4968\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1852 - accuracy: 0.4919\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1753 - accuracy: 0.4906\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1670 - accuracy: 0.4960\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1642 - accuracy: 0.4916\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1536 - accuracy: 0.4947\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1596 - accuracy: 0.4932\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1606 - accuracy: 0.4888\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1520 - accuracy: 0.4927\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1575 - accuracy: 0.4942\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1339 - accuracy: 0.4947\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1385 - accuracy: 0.4984\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1335 - accuracy: 0.4973\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1367 - accuracy: 0.4922\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1310 - accuracy: 0.4950\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1362 - accuracy: 0.4926\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1311 - accuracy: 0.4937\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1237 - accuracy: 0.4966\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.1168 - accuracy: 0.4957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179c37f2188>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4953775038520801\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    1    1    0    0]\n",
      " [   0 1377 3089   27    0]\n",
      " [   2 1434 3124   28    0]\n",
      " [   0    1    1    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      0.31      0.38      4493\n",
      "         4.0       0.50      0.68      0.58      4588\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50      9086\n",
      "   macro avg       0.20      0.20      0.19      9086\n",
      "weighted avg       0.50      0.50      0.48      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_65 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 21)                693       \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 16)                352       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,012\n",
      "Trainable params: 4,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 257.4811 - accuracy: 0.3888\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.4468 - accuracy: 0.4882\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 12.3252 - accuracy: 0.4908\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 11.0462 - accuracy: 0.4939\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 10.1934 - accuracy: 0.4942\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.4787 - accuracy: 0.4984\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.1348 - accuracy: 0.4955\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 8.8412 - accuracy: 0.4938\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 8.5211 - accuracy: 0.4971\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 8.2376 - accuracy: 0.4969\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 7.9665 - accuracy: 0.4952\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 7.6557 - accuracy: 0.4977\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 7.5478 - accuracy: 0.4938\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 7.3775 - accuracy: 0.4964\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 7.2871 - accuracy: 0.4943\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 7.0706 - accuracy: 0.4957\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 7.0451 - accuracy: 0.4982\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 6.7922 - accuracy: 0.4926\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 6.6985 - accuracy: 0.4993\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 6.6449 - accuracy: 0.4934\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 6.4677 - accuracy: 0.4959\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 6.4748 - accuracy: 0.4960\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 6.3124 - accuracy: 0.4969\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 6.2787 - accuracy: 0.4947\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 6.2265 - accuracy: 0.4945\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 6.1511 - accuracy: 0.4975\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 6.0235 - accuracy: 0.4982\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 6.0115 - accuracy: 0.4923\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.8465 - accuracy: 0.4976\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.7494 - accuracy: 0.5021\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.7616 - accuracy: 0.4987\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.7100 - accuracy: 0.4963\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.6298 - accuracy: 0.4988\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.5749 - accuracy: 0.4962\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.3822 - accuracy: 0.4973\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.4046 - accuracy: 0.5012\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.4428 - accuracy: 0.4979\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.2515 - accuracy: 0.5045\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.2240 - accuracy: 0.5023\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.2012 - accuracy: 0.4998\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.1394 - accuracy: 0.5046\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.0693 - accuracy: 0.5055\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.0131 - accuracy: 0.5040\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.0411 - accuracy: 0.5051\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.9771 - accuracy: 0.4990\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.9045 - accuracy: 0.5018\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.9398 - accuracy: 0.5031\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.8896 - accuracy: 0.5001\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.8373 - accuracy: 0.5033\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.7907 - accuracy: 0.4994\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.7165 - accuracy: 0.5027\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.6692 - accuracy: 0.4994\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.6512 - accuracy: 0.5022\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.5662 - accuracy: 0.5012\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.5753 - accuracy: 0.4973\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.4670 - accuracy: 0.4954\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.4333 - accuracy: 0.4972\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.3401 - accuracy: 0.4957\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.2924 - accuracy: 0.4982\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.2086 - accuracy: 0.5007\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.2024 - accuracy: 0.5002\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.1335 - accuracy: 0.5019\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.1218 - accuracy: 0.5020\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.0738 - accuracy: 0.5012\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.0536 - accuracy: 0.5021\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 4.0094 - accuracy: 0.5022\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.9997 - accuracy: 0.5010\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.9793 - accuracy: 0.5018\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.9283 - accuracy: 0.5037\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.8955 - accuracy: 0.5032\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.8605 - accuracy: 0.5039\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.8634 - accuracy: 0.4979\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.8357 - accuracy: 0.5039\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.7881 - accuracy: 0.5039\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.8145 - accuracy: 0.5013\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.7416 - accuracy: 0.5021\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.7266 - accuracy: 0.5024\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.7313 - accuracy: 0.5072\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.6702 - accuracy: 0.5031\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.6679 - accuracy: 0.5002\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.6809 - accuracy: 0.5012\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.6424 - accuracy: 0.5043\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.6529 - accuracy: 0.4991\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.6392 - accuracy: 0.4985\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.5829 - accuracy: 0.5019\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.5713 - accuracy: 0.4998\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.5698 - accuracy: 0.4990\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.5506 - accuracy: 0.4995\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.5235 - accuracy: 0.4978\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.5274 - accuracy: 0.5007\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.5117 - accuracy: 0.5021\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.4890 - accuracy: 0.4999\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.4564 - accuracy: 0.5038\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.4542 - accuracy: 0.5004\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.4184 - accuracy: 0.5015\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.4320 - accuracy: 0.4994\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.4210 - accuracy: 0.4986\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.4400 - accuracy: 0.5005\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.4091 - accuracy: 0.5030\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 3.3417 - accuracy: 0.5017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179c9a5a848>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5062733876293198\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0]\n",
      " [   0    0    0    1    1    0    0]\n",
      " [   1    1    0 1811 2678    2    0]\n",
      " [   0    0    1 1795 2789    3    0]\n",
      " [   0    0    0    0    2    0    0]\n",
      " [   0    0    0    0    1    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.50      0.40      0.45      4493\n",
      "         4.0       0.51      0.61      0.55      4588\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51      9086\n",
      "   macro avg       0.14      0.14      0.14      9086\n",
      "weighted avg       0.51      0.51      0.50      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_70 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 11)                187       \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,258\n",
      "Trainable params: 1,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 294.3656 - accuracy: 0.3800\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.1692 - accuracy: 0.4667\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.0016 - accuracy: 0.4754\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9321 - accuracy: 0.4791\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.8849 - accuracy: 0.4803\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.8479 - accuracy: 0.4814\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.8150 - accuracy: 0.4822\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.7874 - accuracy: 0.4824\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.7673 - accuracy: 0.4829\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.7503 - accuracy: 0.4830\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.7351 - accuracy: 0.4829\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.7211 - accuracy: 0.4831\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.7084 - accuracy: 0.4832\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6963 - accuracy: 0.4833\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6845 - accuracy: 0.4835\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6731 - accuracy: 0.4835\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6621 - accuracy: 0.4836\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6520 - accuracy: 0.4835\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6423 - accuracy: 0.4836\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6329 - accuracy: 0.4836\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6238 - accuracy: 0.4836\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6149 - accuracy: 0.4836\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6065 - accuracy: 0.4836\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5985 - accuracy: 0.4836\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5907 - accuracy: 0.4837\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5832 - accuracy: 0.4837\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5757 - accuracy: 0.4837\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5683 - accuracy: 0.4837\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5610 - accuracy: 0.4837\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5538 - accuracy: 0.4837\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5469 - accuracy: 0.4836\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5402 - accuracy: 0.4837\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5338 - accuracy: 0.4837\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5275 - accuracy: 0.4837\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5214 - accuracy: 0.4837\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5154 - accuracy: 0.4837\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5095 - accuracy: 0.4837\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5037 - accuracy: 0.4837\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4980 - accuracy: 0.4837\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4924 - accuracy: 0.4837\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4869 - accuracy: 0.4837\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4816 - accuracy: 0.4837\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4767 - accuracy: 0.4837\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4719 - accuracy: 0.4837\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4672 - accuracy: 0.4837\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4625 - accuracy: 0.4837\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4580 - accuracy: 0.4837\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4535 - accuracy: 0.4837\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4491 - accuracy: 0.4837\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4448 - accuracy: 0.4837\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4405 - accuracy: 0.4837\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4363 - accuracy: 0.4837\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4322 - accuracy: 0.4837\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4281 - accuracy: 0.4836\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4241 - accuracy: 0.4836\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4202 - accuracy: 0.4836\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4163 - accuracy: 0.4836\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4124 - accuracy: 0.4836\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4086 - accuracy: 0.4836\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4049 - accuracy: 0.4836\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4012 - accuracy: 0.4836\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3976 - accuracy: 0.4836\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3940 - accuracy: 0.4837\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3904 - accuracy: 0.4836\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3869 - accuracy: 0.4837\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3835 - accuracy: 0.4836\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3801 - accuracy: 0.4836\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3767 - accuracy: 0.4836\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3734 - accuracy: 0.4836\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3701 - accuracy: 0.4836\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3669 - accuracy: 0.4836\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3637 - accuracy: 0.4836\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3606 - accuracy: 0.4836\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3574 - accuracy: 0.4836\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3543 - accuracy: 0.4836\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3513 - accuracy: 0.4836\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3483 - accuracy: 0.4836\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3453 - accuracy: 0.4836\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3423 - accuracy: 0.4836\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3394 - accuracy: 0.4836\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3365 - accuracy: 0.4836\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3337 - accuracy: 0.4836\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3309 - accuracy: 0.4836\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3281 - accuracy: 0.4836\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3253 - accuracy: 0.4836\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3226 - accuracy: 0.4836\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3199 - accuracy: 0.4836\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3172 - accuracy: 0.4836\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3146 - accuracy: 0.4836\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3120 - accuracy: 0.4836\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3094 - accuracy: 0.4836\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3068 - accuracy: 0.4836\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3043 - accuracy: 0.4836\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3017 - accuracy: 0.4836\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2993 - accuracy: 0.4836\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2968 - accuracy: 0.4835\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2943 - accuracy: 0.4835\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2919 - accuracy: 0.4835\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2895 - accuracy: 0.4835\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2872 - accuracy: 0.4836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179d993ac88>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5049526744441999\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    1    1    0    0]\n",
      " [   0 1377 3089   27    0]\n",
      " [   2 1434 3124   28    0]\n",
      " [   0    1    1    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4493\n",
      "         4.0       0.50      1.00      0.67      4588\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50      9086\n",
      "   macro avg       0.10      0.20      0.13      9086\n",
      "weighted avg       0.25      0.50      0.34      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_75 (Dense)            (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,257\n",
      "Trainable params: 19,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 7.2861 - accuracy: 0.4422\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9584 - accuracy: 6.0533e-04\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.9541 - accuracy: 6.0533e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179dcf5c508>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00022011886418666079\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0    0]\n",
      " [   2    0    0    0    0    0]\n",
      " [4492    0    0    1    0    0]\n",
      " [4586    0    0    2    0    0]\n",
      " [   2    0    0    0    0    0]\n",
      " [   1    0    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4493\n",
      "         4.0       0.67      0.00      0.00      4588\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9086\n",
      "   macro avg       0.11      0.00      0.00      9086\n",
      "weighted avg       0.34      0.00      0.00      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,295\n",
      "Trainable params: 8,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 4s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 700s 617ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 4s 3ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4253 - accuracy: 0.0017\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.4253 - accuracy: 0.0017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179e0519e48>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00022011886418666079\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   2    0    0    0    0]\n",
      " [4493    0    0    0    0]\n",
      " [4587    1    0    0    0]\n",
      " [   2    0    0    0    0]\n",
      " [   1    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      1.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4493\n",
      "         4.0       0.00      0.00      0.00      4588\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9086\n",
      "   macro avg       0.00      0.20      0.00      9086\n",
      "weighted avg       0.00      0.00      0.00      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_85 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,359\n",
      "Trainable params: 2,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4375 - accuracy: 0.0271\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 9.4375 - accuracy: 0.0271\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.4374 - accuracy: 0.0271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179e6e7d988>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.037090028615452346\n",
      "Tasa de aciertos balanceada regresión logística: 0.02\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0    0]\n",
      " [   2    0    0    0    0    0]\n",
      " [4492    0    0    1    0    0]\n",
      " [4586    0    0    2    0    0]\n",
      " [   2    0    0    0    0    0]\n",
      " [   1    0    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.50      0.08      0.13      4493\n",
      "         4.0       0.00      0.00      0.00      4588\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.04      9086\n",
      "   macro avg       0.08      0.01      0.02      9086\n",
      "weighted avg       0.25      0.04      0.06      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 25)                850       \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 20)                520       \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 17)                357       \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 14)                252       \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 12)                180       \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 11)                143       \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,319\n",
      "Trainable params: 10,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.0039 - accuracy: 0.4835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179bbf6d088>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5049526744441999\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    2    0    0]\n",
      " [   0    0 4493    0    0]\n",
      " [   0    0 4588    0    0]\n",
      " [   0    0    2    0    0]\n",
      " [   0    0    1    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4493\n",
      "         4.0       0.50      1.00      0.67      4588\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50      9086\n",
      "   macro avg       0.10      0.20      0.13      9086\n",
      "weighted avg       0.25      0.50      0.34      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,575\n",
      "Trainable params: 4,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.7762 - accuracy: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179ce2bf6c8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00022011886418666079\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    2    0]\n",
      " [   0    0    0 4493    0]\n",
      " [   0    0    0 4588    0]\n",
      " [   0    0    0    2    0]\n",
      " [   0    0    0    1    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4493\n",
      "         4.0       0.00      0.00      0.00      4588\n",
      "         5.0       0.00      1.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9086\n",
      "   macro avg       0.00      0.20      0.00      9086\n",
      "weighted avg       0.00      0.00      0.00      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_110 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 9.8534 - accuracy: 0.4835\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 9.8534 - accuracy: 0.4835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179d43b6548>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5049526744441999\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    2    0    0]\n",
      " [   0    0 4493    0    0]\n",
      " [   0    0 4588    0    0]\n",
      " [   0    0    2    0    0]\n",
      " [   0    0    1    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4493\n",
      "         4.0       0.50      1.00      0.67      4588\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50      9086\n",
      "   macro avg       0.10      0.20      0.13      9086\n",
      "weighted avg       0.25      0.50      0.34      9086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 21, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,965\n",
      "Trainable params: 9,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 34.1016 - accuracy: 0.4966\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.4602 - accuracy: 0.4983\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 4.5838 - accuracy: 0.4981\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1349 - accuracy: 0.5018\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.0379 - accuracy: 0.4939\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 4.7180 - accuracy: 0.5008\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1726 - accuracy: 0.5038\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.8424 - accuracy: 0.4961\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7835 - accuracy: 0.5001\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.8106 - accuracy: 0.5025\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.0433 - accuracy: 0.4989\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7697 - accuracy: 0.5095\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7429 - accuracy: 0.5039\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7390 - accuracy: 0.5074\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7350 - accuracy: 0.5072\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5066\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5108\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7449 - accuracy: 0.5065\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7275 - accuracy: 0.5082\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7275 - accuracy: 0.5088\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7275 - accuracy: 0.5061\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7275 - accuracy: 0.5093\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7275 - accuracy: 0.5055\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5066\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7277 - accuracy: 0.5050\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5094\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5055\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7275 - accuracy: 0.5073\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5076\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7275 - accuracy: 0.5044\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7276 - accuracy: 0.5063\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7275 - accuracy: 0.5103\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7276 - accuracy: 0.5027\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5063\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7276 - accuracy: 0.5079\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5050\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5074\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5089\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5049\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5057\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5063\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5078\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5090\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7275 - accuracy: 0.5040\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5058\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5095\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5097\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5088\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5071\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5095\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5073\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5077\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5088\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5086\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5104\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5102\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5090\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5051\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5078\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5100\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5088\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5095\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5069\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5092\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5084\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5095\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5095\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5094\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5104\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5073\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5076\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5092\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5100\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5101\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5074\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5111\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5094\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5088\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5087\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5101\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5101\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5088\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5089\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5101\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5100\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5084\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5103\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5076\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5105\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5102\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5099\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5087\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5109\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5065\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5082\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5105\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5095\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5089\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5097\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179e70ff088>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.49443526170798896\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4487    0    0    0]\n",
      " [   0 4583    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      1.00      0.66      4487\n",
      "         4.0       0.00      0.00      0.00      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9075\n",
      "   macro avg       0.10      0.20      0.13      9075\n",
      "weighted avg       0.24      0.49      0.33      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_125 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,652\n",
      "Trainable params: 4,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 36.8965 - accuracy: 0.4930\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 12.7915 - accuracy: 0.5004\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0133 - accuracy: 0.4998\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.4520 - accuracy: 0.4999\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4236 - accuracy: 0.4914\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7490 - accuracy: 0.5053\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7299 - accuracy: 0.5082\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5031\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7274 - accuracy: 0.5061\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7300 - accuracy: 0.5083\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5082\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7274 - accuracy: 0.5073\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5087\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5088\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7274 - accuracy: 0.5058\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7274 - accuracy: 0.5080\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5092\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5070\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5070\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5056\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7275 - accuracy: 0.5050\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7274 - accuracy: 0.5069\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5080\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5094\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5035\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5080\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5068\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5095\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7274 - accuracy: 0.5073\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7274 - accuracy: 0.5066\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5077\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5055\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5078\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5071\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5071\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5064\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5052\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5071\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5074\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5074\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5107\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5102\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5066\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5079\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5076\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5071\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5103\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5063\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7269 - accuracy: 0.5102\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5056\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5091\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5094\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5093\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5076\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5093\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5059\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5076\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5083\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5083\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5078\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5057\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5090\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5080\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5096\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5092\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5066\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5079\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5085\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5079\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5102\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5082\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5087\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.0746 - accuracy: 0.5093\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5116\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5098\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5115\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5094\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5089\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5082\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5085\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5085\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5085\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5067\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5083\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5092\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5076\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5081\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5080\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5086\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5093\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5093\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5111\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5109\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5077\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5088\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5069\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5082\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5095\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5077\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179f69fa848>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.49443526170798896\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4487    0    0    0]\n",
      " [   0 4583    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      1.00      0.66      4487\n",
      "         4.0       0.00      0.00      0.00      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9075\n",
      "   macro avg       0.10      0.20      0.13      9075\n",
      "weighted avg       0.24      0.49      0.33      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,578\n",
      "Trainable params: 1,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 18.6092 - accuracy: 0.4948\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.9444 - accuracy: 0.5115\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.8634 - accuracy: 0.5115\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7663 - accuracy: 0.5115\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7773 - accuracy: 0.5115\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7360 - accuracy: 0.5115\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7319 - accuracy: 0.5115\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7297 - accuracy: 0.5115\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7286 - accuracy: 0.5115\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7279 - accuracy: 0.5115\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7276 - accuracy: 0.5115\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5115\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7272 - accuracy: 0.5115\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5115\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5115\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7268 - accuracy: 0.5104\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5106\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.5115\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179fa4832c8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.49443526170798896\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4487    0    0    0]\n",
      " [   0 4583    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      1.00      0.66      4487\n",
      "         4.0       0.00      0.00      0.00      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9075\n",
      "   macro avg       0.10      0.20      0.13      9075\n",
      "weighted avg       0.24      0.49      0.33      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 21, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_135 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,257\n",
      "Trainable params: 20,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7785 - accuracy: 0.0018\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7785 - accuracy: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179fdec67c8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00022038567493112948\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   2    0    0    0    0]\n",
      " [4487    0    0    0    0]\n",
      " [4583    0    0    0    0]\n",
      " [   2    0    0    0    0]\n",
      " [   1    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      1.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4487\n",
      "         4.0       0.00      0.00      0.00      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9075\n",
      "   macro avg       0.00      0.20      0.00      9075\n",
      "weighted avg       0.00      0.00      0.00      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_140 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,935\n",
      "Trainable params: 8,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.2090 - accuracy: 0.5110\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.5109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179b5ccd288>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.49443526170798896\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4453   34    0    0]\n",
      " [   0 4549   34    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      0.99      0.66      4487\n",
      "         4.0       0.50      0.01      0.01      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9075\n",
      "   macro avg       0.20      0.20      0.13      9075\n",
      "weighted avg       0.50      0.49      0.33      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_145 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,679\n",
      "Trainable params: 2,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 8.9882 - accuracy: 0.0023\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7776 - accuracy: 0.0018\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7772 - accuracy: 0.0018\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7772 - accuracy: 0.0018\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7772 - accuracy: 0.0018\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7772 - accuracy: 0.0018\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7772 - accuracy: 0.0018\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.7772 - accuracy: 0.0018\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.7772 - accuracy: 0.0018\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.7771 - accuracy: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179823320c8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00022038567493112948\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   2    0    0    0    0]\n",
      " [4487    0    0    0    0]\n",
      " [4583    0    0    0    0]\n",
      " [   2    0    0    0    0]\n",
      " [   1    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      1.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4487\n",
      "         4.0       0.00      0.00      0.00      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9075\n",
      "   macro avg       0.00      0.20      0.00      9075\n",
      "weighted avg       0.00      0.00      0.00      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 21, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_150 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,319\n",
      "Trainable params: 11,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 17.0007 - accuracy: 0.0021\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 4s 3ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 4s 3ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 4s 3ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 17.1777 - accuracy: 0.0021\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 17.1777 - accuracy: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17985e41048>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00022038567493112948\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0    0]\n",
      " [   0    0    0    0    2    0]\n",
      " [ 300    0    0    0 4187    0]\n",
      " [ 352    0    0    0 4231    0]\n",
      " [   0    0    0    0    2    0]\n",
      " [   0    0    0    0    1    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4487\n",
      "         4.0       0.00      0.00      0.00      4583\n",
      "         5.0       0.00      1.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9075\n",
      "   macro avg       0.00      0.17      0.00      9075\n",
      "weighted avg       0.00      0.00      0.00      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,215\n",
      "Trainable params: 5,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 4s 3ms/step - loss: 1.1512 - accuracy: 0.4834\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.1515 - accuracy: 0.4834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1798ced7288>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5050137741046832\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    2    0    0]\n",
      " [   0    0 4487    0    0]\n",
      " [   0    0 4583    0    0]\n",
      " [   0    0    2    0    0]\n",
      " [   0    0    1    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4487\n",
      "         4.0       0.51      1.00      0.67      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51      9075\n",
      "   macro avg       0.10      0.20      0.13      9075\n",
      "weighted avg       0.26      0.51      0.34      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_170 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,713\n",
      "Trainable params: 1,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 4s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17991b0e108>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0    0]\n",
      " [   0    0    0    0    2    0]\n",
      " [ 300    0    0    0 4187    0]\n",
      " [ 352    0    0    0 4231    0]\n",
      " [   0    0    0    0    2    0]\n",
      " [   0    0    0    0    1    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00       2.0\n",
      "         3.0       0.00      0.00      0.00    4487.0\n",
      "         4.0       0.00      0.00      0.00    4583.0\n",
      "         5.0       0.00      0.00      0.00       2.0\n",
      "         6.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00    9075.0\n",
      "   macro avg       0.00      0.00      0.00    9075.0\n",
      "weighted avg       0.00      0.00      0.00    9075.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_180 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,965\n",
      "Trainable params: 9,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 22.9086 - accuracy: 0.4951\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.2509 - accuracy: 0.4968\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 5.3864 - accuracy: 0.4956\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 4.6840 - accuracy: 0.4953\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 4.1899 - accuracy: 0.4990\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.9478 - accuracy: 0.4966\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.7881 - accuracy: 0.4991\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.5984 - accuracy: 0.4999\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.4941 - accuracy: 0.4924\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.3899 - accuracy: 0.5013\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.2939 - accuracy: 0.4996\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.1784 - accuracy: 0.4991\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.1552 - accuracy: 0.5031\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.0366 - accuracy: 0.5030\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.0405 - accuracy: 0.5002\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.0059 - accuracy: 0.5006\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.9613 - accuracy: 0.5004\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.9224 - accuracy: 0.5012\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8149 - accuracy: 0.5064\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7629 - accuracy: 0.5028\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7646 - accuracy: 0.5013\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 2.7244 - accuracy: 0.5086\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7104 - accuracy: 0.5039\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.6709 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.6159 - accuracy: 0.5037\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.6258 - accuracy: 0.5015\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.5533 - accuracy: 0.5016\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.5182 - accuracy: 0.5019\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.5095 - accuracy: 0.5066\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.5184 - accuracy: 0.5039\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.4464 - accuracy: 0.4994\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.4139 - accuracy: 0.5047\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.4094 - accuracy: 0.5077\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.4280 - accuracy: 0.5012\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.3715 - accuracy: 0.5021\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.3486 - accuracy: 0.5043\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.3620 - accuracy: 0.5029\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.3063 - accuracy: 0.5033\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.3096 - accuracy: 0.5024\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2833 - accuracy: 0.5028\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2520 - accuracy: 0.5081\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2579 - accuracy: 0.5060\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.2315 - accuracy: 0.5064\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2306 - accuracy: 0.5016\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2239 - accuracy: 0.5046\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1917 - accuracy: 0.5027\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.1639 - accuracy: 0.5096\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1587 - accuracy: 0.5019\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1444 - accuracy: 0.5066\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1391 - accuracy: 0.5063\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1420 - accuracy: 0.5044\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1202 - accuracy: 0.5056\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1318 - accuracy: 0.5003\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0882 - accuracy: 0.5044\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0607 - accuracy: 0.5066\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0746 - accuracy: 0.5071\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.0930 - accuracy: 0.5013\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.0486 - accuracy: 0.5040\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.0382 - accuracy: 0.5037\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.0306 - accuracy: 0.5061\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0060 - accuracy: 0.5082\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0331 - accuracy: 0.5029\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.0061 - accuracy: 0.5052\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0040 - accuracy: 0.5055\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9981 - accuracy: 0.5060\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9648 - accuracy: 0.5053\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9634 - accuracy: 0.5066\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9566 - accuracy: 0.5053\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.9294 - accuracy: 0.5061\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9243 - accuracy: 0.5072\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9227 - accuracy: 0.5090\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9334 - accuracy: 0.5043\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9175 - accuracy: 0.5055\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9013 - accuracy: 0.5034\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9145 - accuracy: 0.5021\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8988 - accuracy: 0.5056\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8722 - accuracy: 0.5057\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8729 - accuracy: 0.5038\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8610 - accuracy: 0.5034\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8489 - accuracy: 0.5049\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8688 - accuracy: 0.5046\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8267 - accuracy: 0.5088\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8325 - accuracy: 0.5090\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8257 - accuracy: 0.5012\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.7987 - accuracy: 0.5082\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8253 - accuracy: 0.5056\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8046 - accuracy: 0.5059\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7960 - accuracy: 0.5051\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7889 - accuracy: 0.5077\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.7719 - accuracy: 0.5045\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7895 - accuracy: 0.5059\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7742 - accuracy: 0.5085\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7777 - accuracy: 0.5028\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7639 - accuracy: 0.5069\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.7559 - accuracy: 0.5086\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.7537 - accuracy: 0.5064\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.7416 - accuracy: 0.5059\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7387 - accuracy: 0.5028\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7157 - accuracy: 0.5091\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7180 - accuracy: 0.5055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1799389e0c8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5129476584022039\n",
      "Tasa de aciertos balanceada regresión logística: 0.21\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   7 3165 1314    0    1]\n",
      " [  12 3079 1490    1    1]\n",
      " [   0    1    1    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.51      0.71      0.59      4487\n",
      "         4.0       0.53      0.33      0.40      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51      9075\n",
      "   macro avg       0.21      0.21      0.20      9075\n",
      "weighted avg       0.52      0.51      0.50      9075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_185 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,652\n",
      "Trainable params: 4,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 4s 2ms/step - loss: 26.0965 - accuracy: 0.4944\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 11.1000 - accuracy: 0.5055\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 8.9227 - accuracy: 0.5084\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.8420 - accuracy: 0.5098\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.0059 - accuracy: 0.5100\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 6.5853 - accuracy: 0.5072\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 6.1163 - accuracy: 0.5089\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 5.6917 - accuracy: 0.5063\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 5.3916 - accuracy: 0.5040\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 5.0905 - accuracy: 0.5032\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 4.8733 - accuracy: 0.5045\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 4.6417 - accuracy: 0.5051\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 4.4502 - accuracy: 0.5006\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 4.2721 - accuracy: 0.5015\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 4.1034 - accuracy: 0.5028\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.9444 - accuracy: 0.5007\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.7938 - accuracy: 0.4997\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.6525 - accuracy: 0.5040\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.5358 - accuracy: 0.4985\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.3835 - accuracy: 0.4996\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.2561 - accuracy: 0.4977\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.1488 - accuracy: 0.4963\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.0507 - accuracy: 0.4988\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.9269 - accuracy: 0.4981\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8023 - accuracy: 0.4963\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7219 - accuracy: 0.4955\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.6477 - accuracy: 0.4970\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.5721 - accuracy: 0.4957\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.5088 - accuracy: 0.4977\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.4934 - accuracy: 0.4956\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.4713 - accuracy: 0.4944\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.4388 - accuracy: 0.4957\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.4297 - accuracy: 0.4962\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.4077 - accuracy: 0.4961\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.3812 - accuracy: 0.4943\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.3680 - accuracy: 0.4947\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.3310 - accuracy: 0.4942\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.3433 - accuracy: 0.4944\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.3150 - accuracy: 0.4938\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.3031 - accuracy: 0.4964\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2903 - accuracy: 0.4968\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.2691 - accuracy: 0.4953\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2640 - accuracy: 0.4943\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2454 - accuracy: 0.4957\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2404 - accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2316 - accuracy: 0.4934\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2134 - accuracy: 0.4979\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1915 - accuracy: 0.4954\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1976 - accuracy: 0.4918\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1839 - accuracy: 0.4943\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1649 - accuracy: 0.4964\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1581 - accuracy: 0.4968\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1406 - accuracy: 0.4978\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1352 - accuracy: 0.4965\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1240 - accuracy: 0.4904\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.1174 - accuracy: 0.4940\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1031 - accuracy: 0.4932\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.0904 - accuracy: 0.4956\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0782 - accuracy: 0.4966\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0578 - accuracy: 0.4927\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0623 - accuracy: 0.4935\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0556 - accuracy: 0.4950\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.0499 - accuracy: 0.4948\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0468 - accuracy: 0.4912\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0283 - accuracy: 0.4964\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0318 - accuracy: 0.4925\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0231 - accuracy: 0.4924\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0135 - accuracy: 0.4934\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0122 - accuracy: 0.4899\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.0066 - accuracy: 0.4930\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9928 - accuracy: 0.4926\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9907 - accuracy: 0.4967\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9795 - accuracy: 0.4958\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9804 - accuracy: 0.4946\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9715 - accuracy: 0.4900\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9716 - accuracy: 0.4931\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9581 - accuracy: 0.4931\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9495 - accuracy: 0.4974\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9409 - accuracy: 0.4949\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9328 - accuracy: 0.4945\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9291 - accuracy: 0.4943\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9209 - accuracy: 0.4955\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9281 - accuracy: 0.4948\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9164 - accuracy: 0.4922\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.9043 - accuracy: 0.4898\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9111 - accuracy: 0.4945\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9040 - accuracy: 0.4932\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8951 - accuracy: 0.4955\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8930 - accuracy: 0.4928\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8790 - accuracy: 0.4938\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8838 - accuracy: 0.4941\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8798 - accuracy: 0.4938\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8673 - accuracy: 0.4959\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8686 - accuracy: 0.4938\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8623 - accuracy: 0.4915\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8579 - accuracy: 0.4982\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8450 - accuracy: 0.4979\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8450 - accuracy: 0.4929\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8331 - accuracy: 0.4952\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8403 - accuracy: 0.4938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179dd17b108>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5018181818181818\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 2264 2223    0    0]\n",
      " [   0 2292 2290    0    1]\n",
      " [   0    0    2    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.50      0.50      0.50      4487\n",
      "         4.0       0.51      0.50      0.50      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50      9075\n",
      "   macro avg       0.20      0.20      0.20      9075\n",
      "weighted avg       0.50      0.50      0.50      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_190 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,578\n",
      "Trainable params: 1,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 4s 2ms/step - loss: 103.8860 - accuracy: 0.4418\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 6.3617 - accuracy: 0.4877\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 5.2064 - accuracy: 0.4900\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 4.7149 - accuracy: 0.4980\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 4.4294 - accuracy: 0.5021\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 4.2728 - accuracy: 0.5015\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 4.1421 - accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 4.0155 - accuracy: 0.5065\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.9248 - accuracy: 0.5031\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 3.8496 - accuracy: 0.5013\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.8175 - accuracy: 0.5058\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.7471 - accuracy: 0.5067\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.7057 - accuracy: 0.5044\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.6448 - accuracy: 0.5058\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.6092 - accuracy: 0.5095\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.5748 - accuracy: 0.5067\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.5395 - accuracy: 0.5064\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.5087 - accuracy: 0.5070\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.4799 - accuracy: 0.5032\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.4519 - accuracy: 0.5059\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.4211 - accuracy: 0.5076\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.3973 - accuracy: 0.5053\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.3657 - accuracy: 0.5071\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.3532 - accuracy: 0.5070\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.3262 - accuracy: 0.5083\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.2964 - accuracy: 0.5071\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.2959 - accuracy: 0.5065\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.2697 - accuracy: 0.5064\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.2362 - accuracy: 0.5122\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.2253 - accuracy: 0.5058\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.2085 - accuracy: 0.5057\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.1938 - accuracy: 0.5053\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.1814 - accuracy: 0.5067\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.1677 - accuracy: 0.5069\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.1508 - accuracy: 0.5051\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.1337 - accuracy: 0.5062\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.1308 - accuracy: 0.5083\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.1040 - accuracy: 0.5078\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.0906 - accuracy: 0.5060\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.0785 - accuracy: 0.5063\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.0706 - accuracy: 0.5048\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.0664 - accuracy: 0.5060\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.0463 - accuracy: 0.5054\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.0422 - accuracy: 0.5048\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 3.0294 - accuracy: 0.5071\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.0158 - accuracy: 0.5087\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.0048 - accuracy: 0.5064\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.0025 - accuracy: 0.5059\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.0053 - accuracy: 0.5058\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.9911 - accuracy: 0.5058\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.9774 - accuracy: 0.5072\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.9631 - accuracy: 0.5069\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.9618 - accuracy: 0.5071\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.9597 - accuracy: 0.5028\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.9524 - accuracy: 0.5076\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.9489 - accuracy: 0.5071\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.9321 - accuracy: 0.5083\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.9328 - accuracy: 0.5051\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.9206 - accuracy: 0.5050\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.9107 - accuracy: 0.5060\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.9027 - accuracy: 0.5057\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.9049 - accuracy: 0.5069\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8994 - accuracy: 0.5048\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.8949 - accuracy: 0.5059\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8790 - accuracy: 0.5067\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8710 - accuracy: 0.5094\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8709 - accuracy: 0.5066\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8679 - accuracy: 0.5065\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8572 - accuracy: 0.5056\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8445 - accuracy: 0.5069\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8357 - accuracy: 0.5087\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8298 - accuracy: 0.5051\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8332 - accuracy: 0.5059\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8259 - accuracy: 0.5043\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8219 - accuracy: 0.5051\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8132 - accuracy: 0.5099\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.8067 - accuracy: 0.5058\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7963 - accuracy: 0.5067\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7961 - accuracy: 0.5037\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7888 - accuracy: 0.5056\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7877 - accuracy: 0.5073\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7858 - accuracy: 0.5056\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7691 - accuracy: 0.5056\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7568 - accuracy: 0.5072\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7588 - accuracy: 0.5083\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.7663 - accuracy: 0.5055\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7606 - accuracy: 0.5067\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7419 - accuracy: 0.5054\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7471 - accuracy: 0.5053\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7384 - accuracy: 0.5088\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7330 - accuracy: 0.5044\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7231 - accuracy: 0.5059\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7217 - accuracy: 0.5038\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7171 - accuracy: 0.5051\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7095 - accuracy: 0.5044\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7043 - accuracy: 0.5055\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.7048 - accuracy: 0.5074\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.6961 - accuracy: 0.5050\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.6970 - accuracy: 0.5060\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.6996 - accuracy: 0.5065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179e7238188>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5058953168044077\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   7 3165 1314    0    1]\n",
      " [  12 3079 1490    1    1]\n",
      " [   0    1    1    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.50      0.54      0.52      4487\n",
      "         4.0       0.51      0.47      0.49      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51      9075\n",
      "   macro avg       0.20      0.20      0.20      9075\n",
      "weighted avg       0.51      0.51      0.51      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_195 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,257\n",
      "Trainable params: 20,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 4s 2ms/step - loss: 9.2398 - accuracy: 0.0022\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2069 - accuracy: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179dd13fe08>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00022038567493112948\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    2    0]\n",
      " [   0    0    0 4487    0]\n",
      " [   0    0    0 4583    0]\n",
      " [   0    0    0    2    0]\n",
      " [   0    0    0    1    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4487\n",
      "         4.0       0.00      0.00      0.00      4583\n",
      "         5.0       0.00      1.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9075\n",
      "   macro avg       0.00      0.20      0.00      9075\n",
      "weighted avg       0.00      0.00      0.00      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_200 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,935\n",
      "Trainable params: 8,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2181 - accuracy: 8.2645e-04\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 9.2176 - accuracy: 7.7135e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179dd089188>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00011019283746556474\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    2]\n",
      " [   9  104    0    0    0 4374]\n",
      " [   7  119    0    0    0 4457]\n",
      " [   0    0    0    0    0    2]\n",
      " [   0    0    0    0    0    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4487\n",
      "         4.0       0.00      0.00      0.00      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      1.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9075\n",
      "   macro avg       0.00      0.17      0.00      9075\n",
      "weighted avg       0.00      0.00      0.00      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_205 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,679\n",
      "Trainable params: 2,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 4s 2ms/step - loss: 16.1034 - accuracy: 0.0018\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.0898 - accuracy: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179827a66c8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00022038567493112948\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    2    0]\n",
      " [   0    0    0 4487    0]\n",
      " [   0    0    0 4583    0]\n",
      " [   0    0    0    2    0]\n",
      " [   0    0    0    1    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      1.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4487\n",
      "         4.0       0.00      0.00      0.00      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9075\n",
      "   macro avg       0.00      0.20      0.00      9075\n",
      "weighted avg       0.00      0.00      0.00      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_210 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,319\n",
      "Trainable params: 11,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 5s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 3s 3ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.4498 - accuracy: 8.5399e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17986111288>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00011019283746556474\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    2]\n",
      " [   0    0    0    0 4487]\n",
      " [   0    0    0    0 4583]\n",
      " [   0    0    0    0    2]\n",
      " [   0    0    0    0    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4487\n",
      "         4.0       0.00      0.00      0.00      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      1.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9075\n",
      "   macro avg       0.00      0.20      0.00      9075\n",
      "weighted avg       0.00      0.00      0.00      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_220 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,215\n",
      "Trainable params: 5,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 8.0568 - accuracy: 0.5081\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8748 - accuracy: 0.5115\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.8744 - accuracy: 0.5115\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8740 - accuracy: 0.5115\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8737 - accuracy: 0.5115\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8737 - accuracy: 0.5115\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8740 - accuracy: 0.5115\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8742 - accuracy: 0.5115\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8741 - accuracy: 0.5115\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8735 - accuracy: 0.5115\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8734 - accuracy: 0.5115\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8733 - accuracy: 0.5115\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.8734 - accuracy: 0.5115\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 7.8738 - accuracy: 0.5115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1798cff29c8>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.49443526170798896\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4487    0    0    0]\n",
      " [   0 4583    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      1.00      0.66      4487\n",
      "         4.0       0.00      0.00      0.00      4583\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9075\n",
      "   macro avg       0.10      0.20      0.13      9075\n",
      "weighted avg       0.24      0.49      0.33      9075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_230 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,713\n",
      "Trainable params: 1,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 4.5928 - accuracy: 0.1864\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.1038 - accuracy: 0.0069\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9749 - accuracy: 4.4077e-04\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9546 - accuracy: 2.4793e-04\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9472 - accuracy: 5.5096e-05\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17993cf5388>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    2]\n",
      " [   0    0    0    0 4487]\n",
      " [   0    0    0    0 4583]\n",
      " [   0    0    0    0    2]\n",
      " [   0    0    0    0    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00       2.0\n",
      "         3.0       0.00      0.00      0.00    4487.0\n",
      "         4.0       0.00      0.00      0.00    4583.0\n",
      "         5.0       0.00      0.00      0.00       2.0\n",
      "         6.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00    9075.0\n",
      "   macro avg       0.00      0.00      0.00    9075.0\n",
      "weighted avg       0.00      0.00      0.00    9075.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 35, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_240 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,365\n",
      "Trainable params: 11,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 33.6161 - accuracy: 0.4989\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.8925 - accuracy: 0.5007\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.5279 - accuracy: 0.4980\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 5.7296 - accuracy: 0.4948\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.2496 - accuracy: 0.5023\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.9279 - accuracy: 0.4999\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9817 - accuracy: 0.4932\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.9399 - accuracy: 0.5012\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7514 - accuracy: 0.5080\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7525 - accuracy: 0.5077\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7648 - accuracy: 0.5065\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7621 - accuracy: 0.5091\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5098\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7269 - accuracy: 0.5066\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.5091\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7273 - accuracy: 0.5072\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.5088\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.5091\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7275 - accuracy: 0.5046\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7273 - accuracy: 0.5056\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7274 - accuracy: 0.5066\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7276 - accuracy: 0.5072\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7275 - accuracy: 0.5053\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7276 - accuracy: 0.5082\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7275 - accuracy: 0.5018\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7274 - accuracy: 0.5074\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7273 - accuracy: 0.5067\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.5048\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5069\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7272 - accuracy: 0.5078\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7274 - accuracy: 0.5043\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.5033\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7273 - accuracy: 0.5078\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5066\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5103\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7273 - accuracy: 0.5055\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5063\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5076\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.5039\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.5081\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.5072\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5093\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5074\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5069\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5116\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5094\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5089\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7271 - accuracy: 0.5087\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5098\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5092\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5098\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5089\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5099\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5093\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5077\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5097\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5091\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5078\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5088\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5090\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5094\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5109\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5108\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5077\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5092\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5109\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5088\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5107\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5097\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5097\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5105\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5105\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5091\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7269 - accuracy: 0.5111\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5101\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5112\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5103\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5107\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5104\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.5102\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5087\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5103\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5109\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5090\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5115\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5103\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5096\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5100\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5106\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7269 - accuracy: 0.5091\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5092\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5081\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5092\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5111\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5099\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5096\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5099\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5109\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5099\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179e73c7088>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.49454304927791864\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4486    0    0    0]\n",
      " [   0 4580    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      1.00      0.66      4486\n",
      "         4.0       0.00      0.00      0.00      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9071\n",
      "   macro avg       0.10      0.20      0.13      9071\n",
      "weighted avg       0.24      0.49      0.33      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_245 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,548\n",
      "Trainable params: 5,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 49.7980 - accuracy: 0.4683\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.0543 - accuracy: 0.4918\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.2207 - accuracy: 0.4994\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7539 - accuracy: 0.5065\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7498 - accuracy: 0.5026\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.1384 - accuracy: 0.4991\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.8705 - accuracy: 0.5105\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7283 - accuracy: 0.5115\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7274 - accuracy: 0.5102\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5104\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5085\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5076\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.5088\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5085\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.5067\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5085\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5087\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5064\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5092\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5088\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5114\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.5087\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5090\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5074\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5076\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5077\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5085\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5077\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5090\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.5072\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.5090\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5084\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5092\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5088\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5110\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5089\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5084\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5098\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5106\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5087\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5103\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5090\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5090\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5089\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5092\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5086\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5108\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5096\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5100\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5110\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5087\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5109\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5080\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5088\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5099\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5101\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5101\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5082\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5108\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5110\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5110\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5097\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5087\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5095\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5093\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5099\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5105\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5096\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5103\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5081\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5102\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5090\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5055\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5082\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5107\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5109\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5095\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5115\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5109\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5115\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5088\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5091\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5103\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5096\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5103\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5092\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5096\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5103\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5101\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5095\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5111\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7268 - accuracy: 0.5105\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5060\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5110\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5094\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5104\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5096\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5096\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5109\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179f1d38688>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.49454304927791864\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4486    0    0    0]\n",
      " [   0 4580    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      1.00      0.66      4486\n",
      "         4.0       0.00      0.00      0.00      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9071\n",
      "   macro avg       0.10      0.20      0.13      9071\n",
      "weighted avg       0.24      0.49      0.33      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_250 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,026\n",
      "Trainable params: 2,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 19.4085 - accuracy: 0.4969\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 8.8927 - accuracy: 0.5013\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.3578 - accuracy: 0.5017\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.6829 - accuracy: 0.5036\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7770 - accuracy: 0.5012\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.1005 - accuracy: 0.5074\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.8272 - accuracy: 0.5074\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.8126 - accuracy: 0.5015\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.0523 - accuracy: 0.5006\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7409 - accuracy: 0.5017\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7740 - accuracy: 0.5038\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7363 - accuracy: 0.5060\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5095\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5109\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5106\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5088\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5096\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5078\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5100\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5101\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5105\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5085\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5093\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5088\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5096\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5095\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5081\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.5071\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7272 - accuracy: 0.5081\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5073\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5091\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5079\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5095\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5081\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5051\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5095\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5085\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5096\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5105\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5096\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5086\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5111\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5091\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5075\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5097\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5104\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5097\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7271 - accuracy: 0.5097\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5076\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5097\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5084\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5109\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5079\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5100\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5090\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5083\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5087\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5104\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5114\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5081\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5087\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5110\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5097\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5090\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5091\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5073\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5085\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5068\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5109\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5099\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5091\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5096\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5084\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5083\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5110\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5098\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5091\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5101\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5085\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5082\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5066\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5097\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7270 - accuracy: 0.5093\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5110\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5114\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5095\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5075\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5094\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5083\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5107\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5075\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5100\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5104\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5110\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5064\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5106\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5084\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7271 - accuracy: 0.5099\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7269 - accuracy: 0.5104\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7270 - accuracy: 0.5092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179f2632f08>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.49454304927791864\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4486    0    0    0]\n",
      " [   0 4580    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      1.00      0.66      4486\n",
      "         4.0       0.00      0.00      0.00      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9071\n",
      "   macro avg       0.10      0.20      0.13      9071\n",
      "weighted avg       0.24      0.49      0.33      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 35, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_255 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_256 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,657\n",
      "Trainable params: 21,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.6554 - accuracy: 0.4806\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.2064 - accuracy: 0.5115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179fdf93808>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.49454304927791864\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4486    0    0    0]\n",
      " [   0 4580    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      1.00      0.66      4486\n",
      "         4.0       0.00      0.00      0.00      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9071\n",
      "   macro avg       0.10      0.20      0.13      9071\n",
      "weighted avg       0.24      0.49      0.33      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_260 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_261 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_262 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_264 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,831\n",
      "Trainable params: 9,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.4034 - accuracy: 0.4316\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.3962 - accuracy: 0.4834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179fe57f3c8>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5049057435784368\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    2    0    0]\n",
      " [   0    0 4486    0    0]\n",
      " [   0    0 4580    0    0]\n",
      " [   0    0    2    0    0]\n",
      " [   0    0    1    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4486\n",
      "         4.0       0.50      1.00      0.67      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50      9071\n",
      "   macro avg       0.10      0.20      0.13      9071\n",
      "weighted avg       0.25      0.50      0.34      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_265 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,127\n",
      "Trainable params: 3,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7628 - accuracy: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179fe63a408>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00022048285745783266\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4486    0    0    0]\n",
      " [   0 4580    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4486\n",
      "         4.0       0.00      0.00      0.00      4580\n",
      "         5.0       0.00      1.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9071\n",
      "   macro avg       0.00      0.20      0.00      9071\n",
      "weighted avg       0.00      0.00      0.00      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 35, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_270 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_271 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_272 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_274 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_277 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_278 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_279 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,719\n",
      "Trainable params: 12,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.3976 - accuracy: 0.4691\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.1795 - accuracy: 0.4807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179f6cdc2c8>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5029213978613163\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0    0]\n",
      " [   0    0    0    2    0    0]\n",
      " [  13    0    0 4473    0    0]\n",
      " [  18    0    0 4562    0    0]\n",
      " [   0    0    0    2    0    0]\n",
      " [   0    0    0    1    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4486\n",
      "         4.0       0.50      1.00      0.67      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50      9071\n",
      "   macro avg       0.08      0.17      0.11      9071\n",
      "weighted avg       0.25      0.50      0.34      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_280 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_282 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,111\n",
      "Trainable params: 6,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6667 - accuracy: 0.0018\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 9.6666 - accuracy: 0.0018\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 9.6666 - accuracy: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17989726308>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00022048285745783266\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0    0]\n",
      " [   0    2    0    0    0    0]\n",
      " [   0 4486    0    0    0    0]\n",
      " [   1 4579    0    0    0    0]\n",
      " [   0    2    0    0    0    0]\n",
      " [   0    1    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "         2.0       0.00      1.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4486\n",
      "         4.0       0.00      0.00      0.00      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9071\n",
      "   macro avg       0.00      0.17      0.00      9071\n",
      "weighted avg       0.00      0.00      0.00      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_290 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_292 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_294 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,161\n",
      "Trainable params: 2,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9518 - accuracy: 7.7169e-04\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1798d49b108>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0    0]\n",
      " [   0    0    0    2    0    0]\n",
      " [  13    0    0 4473    0    0]\n",
      " [  18    0    0 4562    0    0]\n",
      " [   0    0    0    2    0    0]\n",
      " [   0    0    0    1    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00       2.0\n",
      "         3.0       0.00      0.00      0.00    4486.0\n",
      "         4.0       0.00      0.00      0.00    4580.0\n",
      "         5.0       0.00      0.00      0.00       2.0\n",
      "         6.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00    9071.0\n",
      "   macro avg       0.00      0.00      0.00    9071.0\n",
      "weighted avg       0.00      0.00      0.00    9071.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_300 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_301 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_302 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_303 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_304 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,365\n",
      "Trainable params: 11,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 40.8721 - accuracy: 0.4976\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 18.5820 - accuracy: 0.5028\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 14.9817 - accuracy: 0.5027\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 13.0981 - accuracy: 0.4993\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 11.6959 - accuracy: 0.5015\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 10.4327 - accuracy: 0.5030\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.7653 - accuracy: 0.5032\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.0539 - accuracy: 0.4965\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 8.4418 - accuracy: 0.5023\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 8.1340 - accuracy: 0.5019\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 7.5408 - accuracy: 0.5032\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 7.3178 - accuracy: 0.4999\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 7.0755 - accuracy: 0.4946\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.5304 - accuracy: 0.5002\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.2873 - accuracy: 0.5006\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.0432 - accuracy: 0.4966\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 5.7611 - accuracy: 0.4975\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.7219 - accuracy: 0.4987\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.7194 - accuracy: 0.4945\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.3456 - accuracy: 0.5048\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.3764 - accuracy: 0.4964\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.2814 - accuracy: 0.4975\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.0787 - accuracy: 0.5026\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.1207 - accuracy: 0.4998\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.0702 - accuracy: 0.4990\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.9835 - accuracy: 0.4981\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.9900 - accuracy: 0.4974\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.9013 - accuracy: 0.4993\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.8262 - accuracy: 0.4976\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.7732 - accuracy: 0.4982\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.7516 - accuracy: 0.4971\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.7224 - accuracy: 0.4975\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.5987 - accuracy: 0.5007\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.6040 - accuracy: 0.4986\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.4790 - accuracy: 0.4998\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.5071 - accuracy: 0.5004\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.4330 - accuracy: 0.4971\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.4758 - accuracy: 0.4997\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.4563 - accuracy: 0.4999\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.3545 - accuracy: 0.5034\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.2853 - accuracy: 0.5008\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.2816 - accuracy: 0.4986\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.2175 - accuracy: 0.4973\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.2503 - accuracy: 0.4988\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.2514 - accuracy: 0.4990\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1204 - accuracy: 0.5023\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1379 - accuracy: 0.4972\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1473 - accuracy: 0.5011\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1028 - accuracy: 0.5001\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.0394 - accuracy: 0.5003\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9862 - accuracy: 0.5010\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.0104 - accuracy: 0.4989\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9584 - accuracy: 0.5043\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9317 - accuracy: 0.5027\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9652 - accuracy: 0.4999\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.8796 - accuracy: 0.5011\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9056 - accuracy: 0.5021\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.8887 - accuracy: 0.4989\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.8714 - accuracy: 0.5014\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.8018 - accuracy: 0.5034\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.8350 - accuracy: 0.5028\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.7872 - accuracy: 0.4992\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.7338 - accuracy: 0.5007\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.7454 - accuracy: 0.5029\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.6816 - accuracy: 0.5012\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.6867 - accuracy: 0.5004\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.7115 - accuracy: 0.5025\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.6369 - accuracy: 0.5030\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.6126 - accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.6305 - accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.6265 - accuracy: 0.5007\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.5917 - accuracy: 0.5058\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.6008 - accuracy: 0.5025\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.6121 - accuracy: 0.4999\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.5524 - accuracy: 0.5024\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.4887 - accuracy: 0.5020\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.5238 - accuracy: 0.5027\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.4467 - accuracy: 0.5064\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.4763 - accuracy: 0.5014\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.5168 - accuracy: 0.5026\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.4628 - accuracy: 0.5032\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.4566 - accuracy: 0.5006\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.4229 - accuracy: 0.5067\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.4632 - accuracy: 0.5007\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.4158 - accuracy: 0.5010\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.3981 - accuracy: 0.4978\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.4005 - accuracy: 0.5020\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.3414 - accuracy: 0.5018\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.3650 - accuracy: 0.5025\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.3244 - accuracy: 0.5038\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.2831 - accuracy: 0.5025\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.2929 - accuracy: 0.5014\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.2757 - accuracy: 0.4999\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.2919 - accuracy: 0.5014\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.3214 - accuracy: 0.5008\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.2553 - accuracy: 0.5015\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.2425 - accuracy: 0.5031\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.1948 - accuracy: 0.5062\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.2152 - accuracy: 0.5006\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.2404 - accuracy: 0.5022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17993978548>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4969683607099548\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    1    1    0    0]\n",
      " [   0 3881  604    1    0]\n",
      " [   0 3952  627    1    0]\n",
      " [   0    1    1    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.50      0.87      0.63      4486\n",
      "         4.0       0.51      0.14      0.22      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50      9071\n",
      "   macro avg       0.20      0.20      0.17      9071\n",
      "weighted avg       0.50      0.50      0.42      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_305 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_306 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,548\n",
      "Trainable params: 5,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 44.1934 - accuracy: 0.4825\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 12.6712 - accuracy: 0.4877\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 10.9197 - accuracy: 0.4893\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.5752 - accuracy: 0.4956\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 8.4289 - accuracy: 0.5017\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 7.8498 - accuracy: 0.5051\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 7.4038 - accuracy: 0.5039\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 7.0590 - accuracy: 0.5051\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.6490 - accuracy: 0.5039\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.3692 - accuracy: 0.5057\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.0805 - accuracy: 0.5022\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.7876 - accuracy: 0.5041\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.5740 - accuracy: 0.5020\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.3279 - accuracy: 0.5060\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.1540 - accuracy: 0.5107\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.0027 - accuracy: 0.5067\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.8742 - accuracy: 0.5035\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.7756 - accuracy: 0.5070\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.6795 - accuracy: 0.5069\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.5846 - accuracy: 0.5072\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.4906 - accuracy: 0.5074\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.4238 - accuracy: 0.5069\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.3425 - accuracy: 0.5057\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.2643 - accuracy: 0.5089\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1735 - accuracy: 0.5065\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1218 - accuracy: 0.5068\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.0372 - accuracy: 0.5067\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9827 - accuracy: 0.5072\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.9210 - accuracy: 0.5040\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.8543 - accuracy: 0.5059\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.8233 - accuracy: 0.5055\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.7758 - accuracy: 0.5035\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.7301 - accuracy: 0.5068\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.6969 - accuracy: 0.5068\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.6414 - accuracy: 0.5049\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.6082 - accuracy: 0.5067\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.5629 - accuracy: 0.5027\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.5535 - accuracy: 0.5025\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.4996 - accuracy: 0.5060\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.4683 - accuracy: 0.5037\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.4605 - accuracy: 0.5061\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.4174 - accuracy: 0.5042\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.3885 - accuracy: 0.5043\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.3583 - accuracy: 0.5044\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.3331 - accuracy: 0.5032\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.2937 - accuracy: 0.5070\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.2741 - accuracy: 0.5038\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.2445 - accuracy: 0.5054\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.2228 - accuracy: 0.5052\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.2091 - accuracy: 0.5045\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.1747 - accuracy: 0.5063\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.1522 - accuracy: 0.5084\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.1314 - accuracy: 0.5050\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.1081 - accuracy: 0.5078\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.0819 - accuracy: 0.5061\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.0713 - accuracy: 0.5041\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.0377 - accuracy: 0.5097\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.0131 - accuracy: 0.5068\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.0010 - accuracy: 0.5044\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.9802 - accuracy: 0.5035\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.9672 - accuracy: 0.5058\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.9415 - accuracy: 0.5015\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.9191 - accuracy: 0.5047\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.8982 - accuracy: 0.5064\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.8823 - accuracy: 0.5022\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.8690 - accuracy: 0.5047\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.8502 - accuracy: 0.5071\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.8330 - accuracy: 0.5062\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.8176 - accuracy: 0.5030\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.7967 - accuracy: 0.5054\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.7763 - accuracy: 0.5063\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.7611 - accuracy: 0.5077\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.7473 - accuracy: 0.5078\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.7187 - accuracy: 0.5054\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.7232 - accuracy: 0.5046\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.7019 - accuracy: 0.5070\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.6795 - accuracy: 0.5078\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.6659 - accuracy: 0.5077\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.6566 - accuracy: 0.5078\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.6380 - accuracy: 0.5052\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.6220 - accuracy: 0.5058\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.6154 - accuracy: 0.5038\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.5978 - accuracy: 0.5074\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.5803 - accuracy: 0.5050\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.5767 - accuracy: 0.5050\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.5647 - accuracy: 0.5036\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.5397 - accuracy: 0.5087\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.5266 - accuracy: 0.5059\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.5175 - accuracy: 0.5064\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.5034 - accuracy: 0.5073\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4902 - accuracy: 0.5070\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4747 - accuracy: 0.5076\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4638 - accuracy: 0.5071\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4573 - accuracy: 0.5078\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4395 - accuracy: 0.5062\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4348 - accuracy: 0.5040\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4242 - accuracy: 0.5068\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4041 - accuracy: 0.5074\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.3945 - accuracy: 0.5034\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.3876 - accuracy: 0.5043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179f15764c8>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5049057435784368\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0    0]\n",
      " [   0    0    0    2    0    0]\n",
      " [   4    0 2051 2425    6    0]\n",
      " [   7    0 2041 2529    3    0]\n",
      " [   0    0    1    1    0    0]\n",
      " [   0    0    0    1    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.50      0.46      0.48      4486\n",
      "         4.0       0.51      0.55      0.53      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50      9071\n",
      "   macro avg       0.17      0.17      0.17      9071\n",
      "weighted avg       0.51      0.50      0.50      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_310 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_312 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,026\n",
      "Trainable params: 2,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 289.3181 - accuracy: 0.0694\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 43.1961 - accuracy: 0.1239\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 29.0188 - accuracy: 0.1541\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 22.6641 - accuracy: 0.1864\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 19.2171 - accuracy: 0.2087\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.6489 - accuracy: 0.2218\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 14.5150 - accuracy: 0.2321\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 12.5433 - accuracy: 0.2456\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 10.4010 - accuracy: 0.2806\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 8.3399 - accuracy: 0.3498\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 6.9061 - accuracy: 0.4117\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.0885 - accuracy: 0.4411\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.5763 - accuracy: 0.4607\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.2262 - accuracy: 0.4704\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.9911 - accuracy: 0.4804\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.8058 - accuracy: 0.4824\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.6659 - accuracy: 0.4882\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.5571 - accuracy: 0.4898\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.4577 - accuracy: 0.4921\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.3770 - accuracy: 0.4906\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.2977 - accuracy: 0.4955\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.2260 - accuracy: 0.4950\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.1644 - accuracy: 0.4970\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1039 - accuracy: 0.4965\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.0471 - accuracy: 0.4978\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9989 - accuracy: 0.4976\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9505 - accuracy: 0.4963\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9052 - accuracy: 0.5007\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.8564 - accuracy: 0.4995\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.8160 - accuracy: 0.5012\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.7783 - accuracy: 0.4999\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.7454 - accuracy: 0.5006\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.7003 - accuracy: 0.4995\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.6690 - accuracy: 0.5005\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.4997 - accuracy: 0.4946\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.0436 - accuracy: 0.4977\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.9044 - accuracy: 0.5014\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.8188 - accuracy: 0.5033\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.7528 - accuracy: 0.5043\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.7147 - accuracy: 0.5052\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.6778 - accuracy: 0.5061\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.6425 - accuracy: 0.5052\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.6094 - accuracy: 0.5077\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.5830 - accuracy: 0.5053\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.5595 - accuracy: 0.5059\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.5333 - accuracy: 0.5071\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.5154 - accuracy: 0.5069\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4947 - accuracy: 0.5065\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4729 - accuracy: 0.5052\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4576 - accuracy: 0.5059\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4392 - accuracy: 0.5047\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4241 - accuracy: 0.5041\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.4058 - accuracy: 0.5055\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.3923 - accuracy: 0.5077\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.3739 - accuracy: 0.5050\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.3655 - accuracy: 0.5044\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.3473 - accuracy: 0.5068\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.3299 - accuracy: 0.5067\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.3184 - accuracy: 0.5067\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.3060 - accuracy: 0.5067\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.2951 - accuracy: 0.5050\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.2805 - accuracy: 0.5055\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.2687 - accuracy: 0.5051\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.2557 - accuracy: 0.5063\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.2444 - accuracy: 0.5043\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.2315 - accuracy: 0.5053\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.2251 - accuracy: 0.5073\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.2165 - accuracy: 0.5053\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.2082 - accuracy: 0.5057\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.1965 - accuracy: 0.5057\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.1898 - accuracy: 0.5052\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.1784 - accuracy: 0.5052\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.1692 - accuracy: 0.5045\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1635 - accuracy: 0.5047\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.1549 - accuracy: 0.5041\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.1470 - accuracy: 0.5045\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.1353 - accuracy: 0.5064\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.1331 - accuracy: 0.5055\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.1195 - accuracy: 0.5071\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1150 - accuracy: 0.5077\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.1041 - accuracy: 0.5082\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.1027 - accuracy: 0.5034\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0945 - accuracy: 0.5062\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0877 - accuracy: 0.5056\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0790 - accuracy: 0.5053\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0757 - accuracy: 0.5044\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0667 - accuracy: 0.5050\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0610 - accuracy: 0.5069\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0580 - accuracy: 0.5072\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0519 - accuracy: 0.5066\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0436 - accuracy: 0.5068\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0385 - accuracy: 0.5094\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0349 - accuracy: 0.5067\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0273 - accuracy: 0.5072\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0203 - accuracy: 0.5072\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0172 - accuracy: 0.5063\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0117 - accuracy: 0.5056\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0081 - accuracy: 0.5079\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.9989 - accuracy: 0.5053\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.9984 - accuracy: 0.5058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179f24300c8>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5073310550104729\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    1    1    0    0]\n",
      " [   0 3881  604    1    0]\n",
      " [   0 3952  627    1    0]\n",
      " [   0    1    1    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.50      0.45      0.47      4486\n",
      "         4.0       0.51      0.56      0.54      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51      9071\n",
      "   macro avg       0.17      0.17      0.17      9071\n",
      "weighted avg       0.51      0.51      0.51      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_315 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_316 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_318 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,657\n",
      "Trainable params: 21,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.5128 - accuracy: 0.0021\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4649 - accuracy: 0.0017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179fab490c8>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00033072428618674895\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    2]\n",
      " [   0    2    0    0 4484]\n",
      " [   0    2    0    0 4578]\n",
      " [   0    0    0    0    2]\n",
      " [   0    0    0    0    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.50      0.00      0.00      4486\n",
      "         4.0       0.00      0.00      0.00      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      1.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9071\n",
      "   macro avg       0.10      0.20      0.00      9071\n",
      "weighted avg       0.25      0.00      0.00      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_320 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,831\n",
      "Trainable params: 9,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.6069 - accuracy: 0.0018\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7700 - accuracy: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a0b90a088>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00022048285745783266\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    2    0]\n",
      " [   0    0    0 4486    0]\n",
      " [   0    0    0 4580    0]\n",
      " [   0    0    0    2    0]\n",
      " [   0    0    0    1    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4486\n",
      "         4.0       0.00      0.00      0.00      4580\n",
      "         5.0       0.00      1.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9071\n",
      "   macro avg       0.00      0.20      0.00      9071\n",
      "weighted avg       0.00      0.00      0.00      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_325 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_328 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,127\n",
      "Trainable params: 3,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.1027 - accuracy: 8.2681e-04\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 16.0915 - accuracy: 8.2681e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a2afc4088>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.00011024142872891633\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    2]\n",
      " [   0    2    0    0 4484]\n",
      " [   0    2    0    0 4578]\n",
      " [   0    0    0    0    2]\n",
      " [   0    0    0    0    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4486\n",
      "         4.0       0.00      0.00      0.00      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      1.00      0.00         1\n",
      "\n",
      "    accuracy                           0.00      9071\n",
      "   macro avg       0.00      0.20      0.00      9071\n",
      "weighted avg       0.00      0.00      0.00      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_330 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,719\n",
      "Trainable params: 12,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5620 - accuracy: 0.5115\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5624 - accuracy: 0.5115\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5624 - accuracy: 0.5115\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 8.5625 - accuracy: 0.5115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a2b36ea48>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.49454304927791864\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4486    0    0    0]\n",
      " [   0 4580    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.49      1.00      0.66      4486\n",
      "         4.0       0.00      0.00      0.00      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49      9071\n",
      "   macro avg       0.10      0.20      0.13      9071\n",
      "weighted avg       0.24      0.49      0.33      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_340 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_342 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_343 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_344 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_345 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_346 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_348 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_349 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,111\n",
      "Trainable params: 6,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7810 - accuracy: 0.4830\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.7740 - accuracy: 0.4834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a54875548>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5049057435784368\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[   0    0    2    0    0]\n",
      " [   0    0 4486    0    0]\n",
      " [   0    0 4580    0    0]\n",
      " [   0    0    2    0    0]\n",
      " [   0    0    1    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00         2\n",
      "         3.0       0.00      0.00      0.00      4486\n",
      "         4.0       0.50      1.00      0.67      4580\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50      9071\n",
      "   macro avg       0.10      0.20      0.13      9071\n",
      "weighted avg       0.25      0.50      0.34      9071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_350 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_351 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_352 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_353 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_354 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_355 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_356 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_357 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_358 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,161\n",
      "Trainable params: 2,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a54db34c8>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    2    0    0    0]\n",
      " [   0 4486    0    0    0]\n",
      " [   0 4580    0    0    0]\n",
      " [   0    2    0    0    0]\n",
      " [   0    1    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00       2.0\n",
      "         3.0       0.00      0.00      0.00    4486.0\n",
      "         4.0       0.00      0.00      0.00    4580.0\n",
      "         5.0       0.00      0.00      0.00       2.0\n",
      "         6.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00    9071.0\n",
      "   macro avg       0.00      0.00      0.00    9071.0\n",
      "weighted avg       0.00      0.00      0.00    9071.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERVALO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.494497</td>\n",
       "      <td>0.494497</td>\n",
       "      <td>0.494497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.495378</td>\n",
       "      <td>0.506273</td>\n",
       "      <td>0.504953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.037090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.504953</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.504953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.494497     0.494497     0.494497\n",
       "Experimento 2- RELU+ADAM         0.000220     0.000000     0.000000\n",
       "Experimento 3- RELU+ADAM         0.000220     0.000000     0.494497\n",
       "Experimento 1- RELU+ADAGRAD      0.495378     0.506273     0.504953\n",
       "Experimento 2- RELU+ADAGRAD      0.000220     0.000220     0.037090\n",
       "Experimento 3- RELU+ADAGRAD      0.504953     0.000220     0.504953"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['100 Neuronas'] = None\n",
    "df1['64 Neuronas'] = None\n",
    "df1['32 Neuronas'] = None\n",
    "df1.loc['Experimento 1- RELU+ADAM'] = [0.4944970283953335,0.4944970283953335,0.4944970283953335]\n",
    "df1.loc['Experimento 2- RELU+ADAM'] = [0.00022011886418666079,0.0,0.0]\n",
    "df1.loc['Experimento 3- RELU+ADAM'] = [0.00022011886418666079,0.0,0.4944970283953335]\n",
    "df1.loc['Experimento 1- RELU+ADAGRAD'] =[0.4953775038520801,0.5062733876293198,0.5049526744441999]\n",
    "df1.loc['Experimento 2- RELU+ADAGRAD'] =[0.00022011886418666079,0.00022011886418666079,0.037090028615452346]\n",
    "df1.loc['Experimento 3- RELU+ADAGRAD'] = [0.5049526744441999,0.00022011886418666079,0.5049526744441999]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.494435</td>\n",
       "      <td>0.494435</td>\n",
       "      <td>0.494435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.494435</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.505014</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.512948</td>\n",
       "      <td>0.501818</td>\n",
       "      <td>0.505895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.494435</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.494435     0.494435     0.494435\n",
       "Experimento 2- RELU+ADAM         0.000220     0.494435     0.000220\n",
       "Experimento 3- RELU+ADAM         0.000220     0.505014     0.000000\n",
       "Experimento 1- RELU+ADAGRAD      0.512948     0.501818     0.505895\n",
       "Experimento 2- RELU+ADAGRAD      0.000220     0.000110     0.000220\n",
       "Experimento 3- RELU+ADAGRAD      0.000110     0.494435     0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['100 Neuronas'] = None\n",
    "df2['64 Neuronas'] = None\n",
    "df2['32 Neuronas'] = None\n",
    "df2.loc['Experimento 1- RELU+ADAM'] = [0.49443526170798896,0.49443526170798896,0.49443526170798896]\n",
    "df2.loc['Experimento 2- RELU+ADAM'] =[0.00022038567493112948,0.49443526170798896,0.00022038567493112948]\n",
    "df2.loc['Experimento 3- RELU+ADAM'] = [0.00022038567493112948,0.5050137741046832,0.0]\n",
    "df2.loc['Experimento 1- RELU+ADAGRAD'] = [0.5129476584022039,0.5018181818181818,0.5058953168044077]\n",
    "df2.loc['Experimento 2- RELU+ADAGRAD'] = [0.00022038567493112948,0.00011019283746556474,0.00022038567493112948]\n",
    "df2.loc['Experimento 3- RELU+ADAGRAD'] = [0.00011019283746556474,0.49443526170798896,0.0]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.494543</td>\n",
       "      <td>0.494543</td>\n",
       "      <td>0.494543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.494543</td>\n",
       "      <td>0.504906</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.502921</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.496968</td>\n",
       "      <td>0.504906</td>\n",
       "      <td>0.507331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.494543</td>\n",
       "      <td>0.504906</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.494543     0.494543     0.494543\n",
       "Experimento 2- RELU+ADAM         0.494543     0.504906     0.000220\n",
       "Experimento 3- RELU+ADAM         0.502921     0.000220     0.000000\n",
       "Experimento 1- RELU+ADAGRAD      0.496968     0.504906     0.507331\n",
       "Experimento 2- RELU+ADAGRAD      0.000331     0.000220     0.000110\n",
       "Experimento 3- RELU+ADAGRAD      0.494543     0.504906     0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame()\n",
    "df3['100 Neuronas'] = None\n",
    "df3['64 Neuronas'] = None\n",
    "df3['32 Neuronas'] = None\n",
    "df3.loc['Experimento 1- RELU+ADAM'] = [0.49454304927791864,0.49454304927791864,0.49454304927791864]\n",
    "df3.loc['Experimento 2- RELU+ADAM'] = [0.49454304927791864,0.5049057435784368,0.00022048285745783266]\n",
    "df3.loc['Experimento 3- RELU+ADAM'] = [0.5029213978613163,0.00022048285745783266,0.0]\n",
    "df3.loc['Experimento 1- RELU+ADAGRAD'] = [0.4969683607099548,0.5049057435784368,0.5073310550104729]\n",
    "df3.loc['Experimento 2- RELU+ADAGRAD'] = [0.00033072428618674895,0.00022048285745783266,0.00011024142872891633]\n",
    "df3.loc['Experimento 3- RELU+ADAGRAD'] = [0.49454304927791864,0.5049057435784368,0.0]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18c4de172c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,20))\n",
    "fig.add_subplot(2,2,1)\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 1')\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM' ,color ='red')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 2')\n",
    "fig.add_subplot(2,2,3)\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 3')\n",
    "plt.legend(bbox_to_anchor = (2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run 1hora-porintervalos2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix,balanced_accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subida(list):\n",
    "    resultado = []\n",
    "    for i in range(1,len(list)):\n",
    "        if  (list)[i] > (list)[i-1]:\n",
    "            resultado.append(1)\n",
    "        else:\n",
    "            resultado.append(0)\n",
    "    return resultado\n",
    "\n",
    "def acierto(list1,list2):\n",
    "    sum = 0\n",
    "    for i in range(0,len(list1)):\n",
    "        if(list1[i]==list2[i]):\n",
    "            sum = sum +1\n",
    "    a = sum/len(list1)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 11, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_360 (Dense)           (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_361 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_362 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_363 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_364 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,965\n",
      "Trainable params: 8,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 56.6550 - accuracy: 0.8353\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 5.8786 - accuracy: 0.8465\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.5312 - accuracy: 0.8665\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.1408 - accuracy: 0.8876\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.8847 - accuracy: 0.9026\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.4876 - accuracy: 0.9143\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.0013 - accuracy: 0.8981\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.4916 - accuracy: 0.9125\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.4112 - accuracy: 0.9156\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3632 - accuracy: 0.9189\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3796 - accuracy: 0.9091\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3540 - accuracy: 0.9208\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3412 - accuracy: 0.9211\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3380 - accuracy: 0.9211\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3410 - accuracy: 0.9211\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3450 - accuracy: 0.9209\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3351 - accuracy: 0.9211\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3335 - accuracy: 0.9211\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3335 - accuracy: 0.9211\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3336 - accuracy: 0.9211\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3335 - accuracy: 0.9211\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3335 - accuracy: 0.9211\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3335 - accuracy: 0.9211\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3335 - accuracy: 0.9211\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3335 - accuracy: 0.9211\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3335 - accuracy: 0.9211\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.9211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179a3d26348>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9535600308132497\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0  210    0]\n",
      " [   0 8665    0]\n",
      " [   0  212    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       210\n",
      "         3.0       0.95      1.00      0.98      8665\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.95      9087\n",
      "   macro avg       0.32      0.33      0.33      9087\n",
      "weighted avg       0.91      0.95      0.93      9087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_365 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_366 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_368 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_369 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,012\n",
      "Trainable params: 4,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 19.1231 - accuracy: 0.8652\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.5930 - accuracy: 0.9211\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.4227 - accuracy: 0.9211\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3766 - accuracy: 0.9211\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3575 - accuracy: 0.9211\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3474 - accuracy: 0.9211\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3417 - accuracy: 0.9211\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3383 - accuracy: 0.9211\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3363 - accuracy: 0.9211\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3351 - accuracy: 0.9211\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3344 - accuracy: 0.9211\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3339 - accuracy: 0.9211\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3336 - accuracy: 0.9211\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3335 - accuracy: 0.9211\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179a44f7188>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9535600308132497\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0  210    0]\n",
      " [   0 8665    0]\n",
      " [   0  212    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       210\n",
      "         3.0       0.95      1.00      0.98      8665\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.95      9087\n",
      "   macro avg       0.32      0.33      0.33      9087\n",
      "weighted avg       0.91      0.95      0.93      9087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_370 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_371 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_372 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_373 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_374 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,258\n",
      "Trainable params: 1,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 165.1392 - accuracy: 0.8584\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6065 - accuracy: 0.9211\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.4314 - accuracy: 0.9210\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3762 - accuracy: 0.9211\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3571 - accuracy: 0.9211\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3472 - accuracy: 0.9211\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3416 - accuracy: 0.9211\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3383 - accuracy: 0.9211\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3362 - accuracy: 0.9211\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3351 - accuracy: 0.9211\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3343 - accuracy: 0.9211\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3339 - accuracy: 0.9211\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3336 - accuracy: 0.9211\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3335 - accuracy: 0.9211\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3334 - accuracy: 0.9211\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3333 - accuracy: 0.9211\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9211\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179a495a748>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9535600308132497\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0  210    0]\n",
      " [   0 8665    0]\n",
      " [   0  212    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       210\n",
      "         3.0       0.95      1.00      0.98      8665\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.95      9087\n",
      "   macro avg       0.32      0.33      0.33      9087\n",
      "weighted avg       0.91      0.95      0.93      9087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 11, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_375 (Dense)           (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_376 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_378 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,257\n",
      "Trainable params: 19,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.4176 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a268a0848>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0  210]\n",
      " [   0    0    0 8665]\n",
      " [   0    0    0  212]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00     210.0\n",
      "         3.0       0.00      0.00      0.00    8665.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "         6.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    9087.0\n",
      "   macro avg       0.00      0.00      0.00    9087.0\n",
      "weighted avg       0.00      0.00      0.00    9087.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_380 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_381 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_382 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_383 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_384 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,295\n",
      "Trainable params: 8,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.0640 - accuracy: 0.9027\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9645 - accuracy: 0.9211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179aa0a5a88>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9535600308132497\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0  210    0]\n",
      " [   0 8665    0]\n",
      " [   0  212    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       210\n",
      "         3.0       0.95      1.00      0.98      8665\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.95      9087\n",
      "   macro avg       0.32      0.33      0.33      9087\n",
      "weighted avg       0.91      0.95      0.93      9087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_385 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_386 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_387 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_388 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_389 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,359\n",
      "Trainable params: 2,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.6463 - accuracy: 0.9211\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2714 - accuracy: 0.9211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179aa71f3c8>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9535600308132497\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0    0    0  210]\n",
      " [   0    0    0 8665]\n",
      " [   0    0    0  212]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       210\n",
      "         3.0       0.95      1.00      0.98      8665\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.95      9087\n",
      "   macro avg       0.32      0.33      0.33      9087\n",
      "weighted avg       0.91      0.95      0.93      9087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 11, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_390 (Dense)           (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_391 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_392 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_393 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_394 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_395 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_396 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_397 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_398 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_399 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,319\n",
      "Trainable params: 10,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 1.6126 - accuracy: 8.8043e-04\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.6117 - accuracy: 2.4762e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a2626c148>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [ 210    0    0    0]\n",
      " [8665    0    0    0]\n",
      " [ 212    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00     210.0\n",
      "         3.0       0.00      0.00      0.00    8665.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "\n",
      "    accuracy                           0.00    9087.0\n",
      "   macro avg       0.00      0.00      0.00    9087.0\n",
      "weighted avg       0.00      0.00      0.00    9087.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_400 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_401 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_402 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_403 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_404 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_405 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_406 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_407 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_408 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_409 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,575\n",
      "Trainable params: 4,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5041 - accuracy: 0.0382\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 15.5025 - accuracy: 0.0382\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5026 - accuracy: 0.0382\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 15.5025 - accuracy: 0.0382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a2ad62088>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.023109937273027403\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[ 210    0    0]\n",
      " [8665    0    0]\n",
      " [ 212    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.02      1.00      0.05       210\n",
      "         3.0       0.00      0.00      0.00      8665\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.02      9087\n",
      "   macro avg       0.01      0.33      0.02      9087\n",
      "weighted avg       0.00      0.02      0.00      9087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_410 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_411 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_412 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_413 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_414 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_415 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_416 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_417 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_418 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_419 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 3s 1ms/step - loss: 16.1142 - accuracy: 2.4762e-04\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.1141 - accuracy: 2.4762e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a36415108>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [ 210    0    0    0]\n",
      " [8665    0    0    0]\n",
      " [ 212    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00     210.0\n",
      "         3.0       0.00      0.00      0.00    8665.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "\n",
      "    accuracy                           0.00    9087.0\n",
      "   macro avg       0.00      0.00      0.00    9087.0\n",
      "weighted avg       0.00      0.00      0.00    9087.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_420 (Dense)           (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_421 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_422 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_423 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_424 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,965\n",
      "Trainable params: 8,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 132.1031 - accuracy: 0.8006\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 5.1329 - accuracy: 0.8416\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.5852 - accuracy: 0.8622\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.1566 - accuracy: 0.8648\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.8665 - accuracy: 0.8726\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.6491 - accuracy: 0.8766\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.5383 - accuracy: 0.8735\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.4539 - accuracy: 0.8776\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3494 - accuracy: 0.8800\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3587 - accuracy: 0.8807\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2174 - accuracy: 0.8822\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2183 - accuracy: 0.8843\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0964 - accuracy: 0.8873\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0094 - accuracy: 0.8890\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9949 - accuracy: 0.8906\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9956 - accuracy: 0.8923\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9369 - accuracy: 0.8947\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9543 - accuracy: 0.8924\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.9277 - accuracy: 0.8935\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8956 - accuracy: 0.8951\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8587 - accuracy: 0.8974\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8756 - accuracy: 0.8962\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8211 - accuracy: 0.8961\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8130 - accuracy: 0.8975\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8353 - accuracy: 0.8981\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8307 - accuracy: 0.8974\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7485 - accuracy: 0.9006\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.7639 - accuracy: 0.9009\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.7947 - accuracy: 0.8980\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.7779 - accuracy: 0.8987\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7737 - accuracy: 0.9013\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7537 - accuracy: 0.9007\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7169 - accuracy: 0.9032\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7260 - accuracy: 0.9010\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.6979 - accuracy: 0.9031\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7162 - accuracy: 0.9005\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7198 - accuracy: 0.9008\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7135 - accuracy: 0.9024\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7253 - accuracy: 0.9006\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.7146 - accuracy: 0.9012\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.6926 - accuracy: 0.9029\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6612 - accuracy: 0.9031\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6763 - accuracy: 0.9033\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6664 - accuracy: 0.9042\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6845 - accuracy: 0.9022\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6783 - accuracy: 0.9040\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6610 - accuracy: 0.9032\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6657 - accuracy: 0.9019\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6942 - accuracy: 0.9025\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6545 - accuracy: 0.9046\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.6497 - accuracy: 0.9040\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6267 - accuracy: 0.9051\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6655 - accuracy: 0.9035\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6515 - accuracy: 0.9035\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6201 - accuracy: 0.9055\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6285 - accuracy: 0.9053\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6356 - accuracy: 0.9046\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6167 - accuracy: 0.9051\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6241 - accuracy: 0.9058\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6263 - accuracy: 0.9050\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6095 - accuracy: 0.9059\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6166 - accuracy: 0.9045\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.6319 - accuracy: 0.9052\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6187 - accuracy: 0.9050\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6003 - accuracy: 0.9058\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6113 - accuracy: 0.9045\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5862 - accuracy: 0.9060\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5874 - accuracy: 0.9064\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6007 - accuracy: 0.9059\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5930 - accuracy: 0.9061\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5750 - accuracy: 0.9062\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5878 - accuracy: 0.9070\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5802 - accuracy: 0.9073\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.5714 - accuracy: 0.9071\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5715 - accuracy: 0.9075\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5779 - accuracy: 0.9078\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5799 - accuracy: 0.9060\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5576 - accuracy: 0.9083\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5762 - accuracy: 0.9063\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5552 - accuracy: 0.9075\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5553 - accuracy: 0.9069\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5635 - accuracy: 0.9069\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.5667 - accuracy: 0.9064\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.5783 - accuracy: 0.9063\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.5482 - accuracy: 0.9074\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5594 - accuracy: 0.9070\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.9081\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5581 - accuracy: 0.9082\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5646 - accuracy: 0.9069\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.5545 - accuracy: 0.9081\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.9074\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5463 - accuracy: 0.9077\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.9085\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5308 - accuracy: 0.9082\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.5347 - accuracy: 0.9084\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.5311 - accuracy: 0.9088\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.9078\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5412 - accuracy: 0.9084\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5303 - accuracy: 0.9082\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5397 - accuracy: 0.9073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a460f5608>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9493782326400352\n",
      "Tasa de aciertos balanceada regresión logística: 0.35\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [   0    6  202    2]\n",
      " [   1   37 8617   10]\n",
      " [   0    3  205    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         2.0       0.13      0.03      0.05       210\n",
      "         3.0       0.95      0.99      0.97      8665\n",
      "         4.0       0.25      0.02      0.04       212\n",
      "\n",
      "    accuracy                           0.95      9087\n",
      "   macro avg       0.33      0.26      0.26      9087\n",
      "weighted avg       0.92      0.95      0.93      9087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_425 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_426 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_427 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_428 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_429 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,012\n",
      "Trainable params: 4,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 23.0186 - accuracy: 0.8381\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 4.0759 - accuracy: 0.8483\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.9516 - accuracy: 0.8433\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.5905 - accuracy: 0.8434\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.3262 - accuracy: 0.8439\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.1443 - accuracy: 0.8439\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9817 - accuracy: 0.8486\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.8514 - accuracy: 0.8515\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.7556 - accuracy: 0.8543\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.6439 - accuracy: 0.8584\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.5766 - accuracy: 0.8603\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.5348 - accuracy: 0.8631\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.4572 - accuracy: 0.8657\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.4282 - accuracy: 0.8661\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3916 - accuracy: 0.8683\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3427 - accuracy: 0.8699\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3462 - accuracy: 0.8729\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2810 - accuracy: 0.8744\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2641 - accuracy: 0.8745\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2239 - accuracy: 0.8752\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2006 - accuracy: 0.8778\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.1683 - accuracy: 0.8783\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.1355 - accuracy: 0.8821\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.1058 - accuracy: 0.8817\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0895 - accuracy: 0.8836\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0609 - accuracy: 0.8853\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0357 - accuracy: 0.8867\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.0167 - accuracy: 0.8880\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0032 - accuracy: 0.8885\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9735 - accuracy: 0.8907\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9517 - accuracy: 0.8919\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9520 - accuracy: 0.8918\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9162 - accuracy: 0.8941\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9119 - accuracy: 0.8948\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8946 - accuracy: 0.8955\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8722 - accuracy: 0.8967\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8846 - accuracy: 0.8962\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8616 - accuracy: 0.8972\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8517 - accuracy: 0.8970\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.8486 - accuracy: 0.8985\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8340 - accuracy: 0.8980\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8299 - accuracy: 0.8990\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8140 - accuracy: 0.8989\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8090 - accuracy: 0.8995\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7985 - accuracy: 0.8998\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7910 - accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7848 - accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7731 - accuracy: 0.9009\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7660 - accuracy: 0.9005\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7584 - accuracy: 0.9010\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 3s 3ms/step - loss: 0.7505 - accuracy: 0.9002\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7460 - accuracy: 0.8997\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7399 - accuracy: 0.9013\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7383 - accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7306 - accuracy: 0.9010\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7246 - accuracy: 0.9011\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7184 - accuracy: 0.9009\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7107 - accuracy: 0.9010\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7092 - accuracy: 0.9019\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7095 - accuracy: 0.9009\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6989 - accuracy: 0.9016\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.6961 - accuracy: 0.9024\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6991 - accuracy: 0.9017\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6916 - accuracy: 0.9022\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6909 - accuracy: 0.9021\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.6869 - accuracy: 0.9022\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6873 - accuracy: 0.9014\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6793 - accuracy: 0.9026\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6791 - accuracy: 0.9020\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6704 - accuracy: 0.9029\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6716 - accuracy: 0.9031\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6684 - accuracy: 0.9027\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.6621 - accuracy: 0.9030\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6635 - accuracy: 0.9031\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6590 - accuracy: 0.9027\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6555 - accuracy: 0.9017\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6554 - accuracy: 0.9032\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6490 - accuracy: 0.9030\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6493 - accuracy: 0.9035\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6448 - accuracy: 0.9025\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6469 - accuracy: 0.9020\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6423 - accuracy: 0.9035\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6386 - accuracy: 0.9022\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6351 - accuracy: 0.9025\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6339 - accuracy: 0.9035\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6348 - accuracy: 0.9034\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6300 - accuracy: 0.9028\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6267 - accuracy: 0.9030\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6268 - accuracy: 0.9037\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6226 - accuracy: 0.9034\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6233 - accuracy: 0.9037\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6156 - accuracy: 0.9039\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6234 - accuracy: 0.9032\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6117 - accuracy: 0.9031\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6106 - accuracy: 0.9040\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.6111 - accuracy: 0.9039\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6041 - accuracy: 0.9034\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6040 - accuracy: 0.9030\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.6030 - accuracy: 0.9029\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.5984 - accuracy: 0.9025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179faa008c8>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.8546274898206229\n",
      "Tasa de aciertos balanceada regresión logística: 0.34\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [   0   23  183    4]\n",
      " [   8  844 7738   75]\n",
      " [   0   24  183    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         2.0       0.03      0.11      0.04       210\n",
      "         3.0       0.95      0.89      0.92      8665\n",
      "         4.0       0.06      0.02      0.03       212\n",
      "\n",
      "    accuracy                           0.85      9087\n",
      "   macro avg       0.26      0.26      0.25      9087\n",
      "weighted avg       0.91      0.85      0.88      9087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_430 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_431 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_432 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_433 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_434 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,258\n",
      "Trainable params: 1,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 50.6830 - accuracy: 0.9086\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 18.5858 - accuracy: 0.8961\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 10.5163 - accuracy: 0.8853\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 7.5850 - accuracy: 0.8818\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 5.6116 - accuracy: 0.8842\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 4.3056 - accuracy: 0.8825\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 3.5067 - accuracy: 0.8769\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.9911 - accuracy: 0.8839\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.6485 - accuracy: 0.8910\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.4294 - accuracy: 0.8939\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.2657 - accuracy: 0.8970\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.1181 - accuracy: 0.8992\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.9838 - accuracy: 0.8988\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.8710 - accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.7747 - accuracy: 0.8999\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.6982 - accuracy: 0.9009\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.6257 - accuracy: 0.9011\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.5696 - accuracy: 0.9013\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.5198 - accuracy: 0.9010\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4725 - accuracy: 0.9015\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4370 - accuracy: 0.9021\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3989 - accuracy: 0.9032\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3678 - accuracy: 0.9016\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3353 - accuracy: 0.9027\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3181 - accuracy: 0.9024\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2944 - accuracy: 0.9030\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2754 - accuracy: 0.9028\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2556 - accuracy: 0.9033\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2421 - accuracy: 0.9030\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2251 - accuracy: 0.9026\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.2101 - accuracy: 0.9031\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.1999 - accuracy: 0.9032\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.1850 - accuracy: 0.9033\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.1735 - accuracy: 0.9039\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.1597 - accuracy: 0.9035\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.1450 - accuracy: 0.9041\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.1357 - accuracy: 0.9042\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.1212 - accuracy: 0.9041\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.1106 - accuracy: 0.9041\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0987 - accuracy: 0.9042\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0829 - accuracy: 0.9040\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0708 - accuracy: 0.9044\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0615 - accuracy: 0.9039\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0479 - accuracy: 0.9038\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0365 - accuracy: 0.9038\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0286 - accuracy: 0.9044\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0169 - accuracy: 0.9040\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.0097 - accuracy: 0.9056\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9973 - accuracy: 0.9051\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9879 - accuracy: 0.9050\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9761 - accuracy: 0.9046\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9697 - accuracy: 0.9055\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9573 - accuracy: 0.9055\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9526 - accuracy: 0.9055\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9432 - accuracy: 0.9057\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9335 - accuracy: 0.9055\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9227 - accuracy: 0.9058\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9153 - accuracy: 0.9061\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.9060 - accuracy: 0.9062\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8995 - accuracy: 0.9063\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8934 - accuracy: 0.9058\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8850 - accuracy: 0.9066\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8775 - accuracy: 0.9065\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8704 - accuracy: 0.9063\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8654 - accuracy: 0.9068\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8586 - accuracy: 0.9070\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8540 - accuracy: 0.9064\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8484 - accuracy: 0.9065\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8408 - accuracy: 0.9065\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8363 - accuracy: 0.9063\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8314 - accuracy: 0.9062\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8261 - accuracy: 0.9068\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8193 - accuracy: 0.9062\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8161 - accuracy: 0.9064\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8094 - accuracy: 0.9061\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8054 - accuracy: 0.9062\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.8013 - accuracy: 0.9061\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7953 - accuracy: 0.9059\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7915 - accuracy: 0.9058\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7854 - accuracy: 0.9064\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.7824 - accuracy: 0.9057\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7776 - accuracy: 0.9061\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7733 - accuracy: 0.9062\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7699 - accuracy: 0.9063\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7661 - accuracy: 0.9064\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7625 - accuracy: 0.9062\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7594 - accuracy: 0.9068\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7556 - accuracy: 0.9070\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7522 - accuracy: 0.9069\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7498 - accuracy: 0.9065\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7455 - accuracy: 0.9073\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7409 - accuracy: 0.9070\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 0.7374 - accuracy: 0.9075\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7333 - accuracy: 0.9072\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7311 - accuracy: 0.9073\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7279 - accuracy: 0.9068\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7258 - accuracy: 0.9073\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7217 - accuracy: 0.9068\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7201 - accuracy: 0.9073\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 0.7174 - accuracy: 0.9074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a42cff948>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9432155827005613\n",
      "Tasa de aciertos balanceada regresión logística: 0.34\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [   0    6  202    2]\n",
      " [   1   37 8617   10]\n",
      " [   0    3  205    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.10      0.01      0.02       210\n",
      "         3.0       0.95      0.99      0.97      8665\n",
      "         4.0       0.06      0.02      0.03       212\n",
      "\n",
      "    accuracy                           0.94      9087\n",
      "   macro avg       0.37      0.34      0.34      9087\n",
      "weighted avg       0.91      0.94      0.93      9087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_435 (Dense)           (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_436 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_437 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_438 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_439 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,257\n",
      "Trainable params: 19,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2185 - accuracy: 2.4762e-04\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.2173 - accuracy: 2.4762e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17991e4cd88>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [ 210    0    0    0]\n",
      " [8665    0    0    0]\n",
      " [ 212    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00     210.0\n",
      "         3.0       0.00      0.00      0.00    8665.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "\n",
      "    accuracy                           0.00    9087.0\n",
      "   macro avg       0.00      0.00      0.00    9087.0\n",
      "weighted avg       0.00      0.00      0.00    9087.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_440 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_441 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_442 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_443 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_444 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,295\n",
      "Trainable params: 8,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.6477 - accuracy: 2.7513e-04\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4089 - accuracy: 0.0268\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.4044 - accuracy: 0.1499\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3940 - accuracy: 0.6625\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6550\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 1.3939 - accuracy: 0.6526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179a9c4bbc8>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4110267414988445\n",
      "Tasa de aciertos balanceada regresión logística: 0.14\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [  84    0  126    0]\n",
      " [4930    0 3735    0]\n",
      " [  87    0  125    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "         2.0       0.00      0.00      0.00       210\n",
      "         3.0       0.94      0.43      0.59      8665\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.41      9087\n",
      "   macro avg       0.23      0.11      0.15      9087\n",
      "weighted avg       0.89      0.41      0.56      9087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_445 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_446 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_447 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_448 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_449 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,359\n",
      "Trainable params: 2,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 8.0699 - accuracy: 0.0382\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.0451 - accuracy: 0.0382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a18a21208>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.023109937273027403\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [ 210    0    0    0]\n",
      " [8665    0    0    0]\n",
      " [ 212    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.02      1.00      0.05       210\n",
      "         3.0       0.00      0.00      0.00      8665\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.02      9087\n",
      "   macro avg       0.01      0.33      0.02      9087\n",
      "weighted avg       0.00      0.02      0.00      9087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_450 (Dense)           (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_451 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_452 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_453 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_454 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_455 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_456 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_457 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_458 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_459 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,319\n",
      "Trainable params: 10,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 3s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8507 - accuracy: 0.0403\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8507 - accuracy: 0.0403\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.8506 - accuracy: 0.0403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a2eb2c508>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0233300319137229\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0    0  210]\n",
      " [   0    0 8665]\n",
      " [   0    0  212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       210\n",
      "         3.0       0.00      0.00      0.00      8665\n",
      "         4.0       0.02      1.00      0.05       212\n",
      "\n",
      "    accuracy                           0.02      9087\n",
      "   macro avg       0.01      0.33      0.02      9087\n",
      "weighted avg       0.00      0.02      0.00      9087\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_460 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_461 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_462 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_463 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_464 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_465 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_466 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_467 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_468 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_469 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,575\n",
      "Trainable params: 4,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 2.3663 - accuracy: 0.0014\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9558 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9543 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9539 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9539 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9539 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9541 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9509 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9494 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9481 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9479 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9564 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9561 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9555 - accuracy: 2.7513e-05\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9546 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9520 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9506 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9506 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9506 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9506 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9506 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9506 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9502 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9499 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9498 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9498 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9498 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9498 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9498 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9498 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9498 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9497 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9497 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9495 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9494 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9494 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 1.9494 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9491 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9491 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9490 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9490 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9490 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9485 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9483 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9483 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 1.9482 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a36864848>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0]\n",
      " [ 210    0    0    0    0]\n",
      " [8664    0    0    0    1]\n",
      " [ 212    0    0    0    0]\n",
      " [   0    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00     210.0\n",
      "         3.0       0.00      0.00      0.00    8665.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "         6.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    9087.0\n",
      "   macro avg       0.00      0.00      0.00    9087.0\n",
      "weighted avg       0.00      0.00      0.00    9087.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_470 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_471 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_472 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_473 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_474 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_475 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_476 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_477 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_478 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_479 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 2/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 3/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 4/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 5/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 6/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 7/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 8/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 9/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 10/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 11/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 12/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 13/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 14/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 15/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 16/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 17/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 18/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 19/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 20/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 21/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 22/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 23/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 24/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 25/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 26/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 27/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 28/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 29/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 30/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 31/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 32/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 33/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 34/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 35/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 36/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 37/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 38/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 39/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 40/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 41/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 42/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 43/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 44/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 45/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 46/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 47/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 48/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 49/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 50/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 51/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 52/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 53/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 54/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 55/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 56/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 57/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 58/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 59/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 60/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 61/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 62/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 63/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 64/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 65/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 66/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 67/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 68/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 69/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 70/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 71/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 72/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 73/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 74/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 75/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 76/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 77/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 78/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 79/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 80/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 81/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 82/100\n",
      "1136/1136 [==============================] - 2s 2ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 83/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 84/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 85/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 86/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 87/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 88/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 89/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 90/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 91/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 92/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 93/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 94/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 95/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 96/100\n",
      "1136/1136 [==============================] - 1s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 97/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 98/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 99/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n",
      "Epoch 100/100\n",
      "1136/1136 [==============================] - 2s 1ms/step - loss: 16.4601 - accuracy: 1.3757e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a4620e3c8>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0  210]\n",
      " [   0    0 8665]\n",
      " [   0    0  212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00     210.0\n",
      "         3.0       0.00      0.00      0.00    8665.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "         5.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    9087.0\n",
      "   macro avg       0.00      0.00      0.00    9087.0\n",
      "weighted avg       0.00      0.00      0.00    9087.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 21, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_480 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_481 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_482 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_483 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_484 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,965\n",
      "Trainable params: 9,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 33.0775 - accuracy: 0.8351\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 3.1655 - accuracy: 0.8636\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.5624 - accuracy: 0.9145\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 3.0338 - accuracy: 0.9071\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9518 - accuracy: 0.8982\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3081 - accuracy: 0.9022\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.4208 - accuracy: 0.9166\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3843 - accuracy: 0.9189\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.7613 - accuracy: 0.9135\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3416 - accuracy: 0.9213\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3811 - accuracy: 0.9200\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9213\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a49dc61c8>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9536139268400177\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0  209    0]\n",
      " [   0 8655    0]\n",
      " [   0  212    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.95      1.00      0.98      8655\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.95      9076\n",
      "   macro avg       0.32      0.33      0.33      9076\n",
      "weighted avg       0.91      0.95      0.93      9076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_485 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_486 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_487 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_488 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_489 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,652\n",
      "Trainable params: 4,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 9.7474 - accuracy: 0.8506\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.1655 - accuracy: 0.8900\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4923 - accuracy: 0.9089\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.5170 - accuracy: 0.9174\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.5511 - accuracy: 0.9150\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3939 - accuracy: 0.9195\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3765 - accuracy: 0.9199\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.6946 - accuracy: 0.9109\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3910 - accuracy: 0.9176\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3542 - accuracy: 0.9209\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3438 - accuracy: 0.9211\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.4108 - accuracy: 0.9213\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3704 - accuracy: 0.9213\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3503 - accuracy: 0.9213\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3421 - accuracy: 0.9213\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3380 - accuracy: 0.9213\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3358 - accuracy: 0.9213\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3345 - accuracy: 0.9213\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3338 - accuracy: 0.9213\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3333 - accuracy: 0.9213\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9213\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a4d4d4048>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9536139268400177\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0  209    0]\n",
      " [   0 8655    0]\n",
      " [   0  212    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.95      1.00      0.98      8655\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.95      9076\n",
      "   macro avg       0.32      0.33      0.33      9076\n",
      "weighted avg       0.91      0.95      0.93      9076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_490 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_491 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_492 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_493 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_494 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,578\n",
      "Trainable params: 1,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 41.2623 - accuracy: 0.7977\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8317 - accuracy: 0.8879\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.9738 - accuracy: 0.9064\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.6102 - accuracy: 0.9140\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.8335 - accuracy: 0.9138\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3911 - accuracy: 0.9211\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3562 - accuracy: 0.9211\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3550 - accuracy: 0.9211\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3388 - accuracy: 0.9212\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3364 - accuracy: 0.9212\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3336 - accuracy: 0.9213\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3330 - accuracy: 0.9213\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3532 - accuracy: 0.9212\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3388 - accuracy: 0.9213\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3342 - accuracy: 0.9213\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3333 - accuracy: 0.9213\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3330 - accuracy: 0.9213\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a4d96e608>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9536139268400177\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0  209    0]\n",
      " [   0 8655    0]\n",
      " [   0  212    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.95      1.00      0.98      8655\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.95      9076\n",
      "   macro avg       0.32      0.33      0.33      9076\n",
      "weighted avg       0.91      0.95      0.93      9076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 21, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_495 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_496 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_497 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_498 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_499 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,257\n",
      "Trainable params: 20,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9456 - accuracy: 1.3773e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a511f1108>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0  209]\n",
      " [   0    0    0 8655]\n",
      " [   0    0    0  212]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00     209.0\n",
      "         3.0       0.00      0.00      0.00    8655.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "         5.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    9076.0\n",
      "   macro avg       0.00      0.00      0.00    9076.0\n",
      "weighted avg       0.00      0.00      0.00    9076.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_500 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_501 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_502 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_503 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_504 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,935\n",
      "Trainable params: 8,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6157 - accuracy: 0.9060\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.6157 - accuracy: 0.9060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a55378b08>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9284927280740414\n",
      "Tasa de aciertos balanceada regresión logística: 0.34\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [   0    0  198   11]\n",
      " [   1    0 8418  236]\n",
      " [   0    0  203    9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.95      0.97      0.96      8655\n",
      "         4.0       0.04      0.04      0.04       212\n",
      "\n",
      "    accuracy                           0.93      9076\n",
      "   macro avg       0.25      0.25      0.25      9076\n",
      "weighted avg       0.91      0.93      0.92      9076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_505 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_506 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_507 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_508 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_509 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,679\n",
      "Trainable params: 2,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7217 - accuracy: 0.0012\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7199 - accuracy: 0.0013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a58dd2308>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.000991626267078008\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0  209]\n",
      " [   0    0    0 8655]\n",
      " [   0    0    0  212]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       1.00      0.00      0.00      8655\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.00      9076\n",
      "   macro avg       0.25      0.00      0.00      9076\n",
      "weighted avg       0.95      0.00      0.00      9076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 21, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_510 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_511 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_512 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_513 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_514 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_515 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_516 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_517 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_518 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_519 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,319\n",
      "Trainable params: 11,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2572 - accuracy: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a5d8b7f88>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.000991626267078008\n",
      "Tasa de aciertos balanceada regresión logística: 0.01\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0]\n",
      " [   0    9    0    0  200]\n",
      " [   9  140    0    0 8506]\n",
      " [   0    5    0    0  207]\n",
      " [   0    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "         2.0       0.06      0.04      0.05       209\n",
      "         3.0       0.00      0.00      0.00      8655\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.00      9076\n",
      "   macro avg       0.01      0.01      0.01      9076\n",
      "weighted avg       0.00      0.00      0.00      9076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_520 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_521 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_522 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_523 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_524 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_525 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_526 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_527 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_528 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_529 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,215\n",
      "Trainable params: 5,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 3s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.5689 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a65ceeb88>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0  209]\n",
      " [   0    0    0 8655]\n",
      " [   0    0    0  212]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00     209.0\n",
      "         3.0       0.00      0.00      0.00    8655.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "         6.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    9076.0\n",
      "   macro avg       0.00      0.00      0.00    9076.0\n",
      "weighted avg       0.00      0.00      0.00    9076.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_530 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_531 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_532 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_533 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_534 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_535 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_536 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_537 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_538 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_539 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,713\n",
      "Trainable params: 1,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 3s 1ms/step - loss: 2.0152 - accuracy: 0.8898\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3139 - accuracy: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ab6a39948>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9536139268400177\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0    0]\n",
      " [   0    9    0    0  200]\n",
      " [   9  140    0    0 8506]\n",
      " [   0    5    0    0  207]\n",
      " [   0    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.95      1.00      0.98      8655\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.95      9076\n",
      "   macro avg       0.32      0.33      0.33      9076\n",
      "weighted avg       0.91      0.95      0.93      9076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_540 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_541 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_542 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_543 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_544 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,965\n",
      "Trainable params: 9,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 72.6133 - accuracy: 0.8801\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 6.1417 - accuracy: 0.8621\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 5.0114 - accuracy: 0.8634\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 4.5541 - accuracy: 0.8625\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 4.0886 - accuracy: 0.8618\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 3.8719 - accuracy: 0.8621\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 3.5372 - accuracy: 0.8636\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 3.4224 - accuracy: 0.8650\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 3.2281 - accuracy: 0.8641\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 3.1637 - accuracy: 0.8657\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 3.2149 - accuracy: 0.8645\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.9953 - accuracy: 0.8660\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.8420 - accuracy: 0.8666\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.7737 - accuracy: 0.8680\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.7949 - accuracy: 0.8669\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.6962 - accuracy: 0.8671\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.6039 - accuracy: 0.8686\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.5437 - accuracy: 0.8676\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.4646 - accuracy: 0.8666\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.4133 - accuracy: 0.8693\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.4728 - accuracy: 0.8694\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.3623 - accuracy: 0.8700\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.2684 - accuracy: 0.8699\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.2667 - accuracy: 0.8709\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.2247 - accuracy: 0.8710\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.2248 - accuracy: 0.8697\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.2063 - accuracy: 0.8708\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2458 - accuracy: 0.8707\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0828 - accuracy: 0.8732\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.1735 - accuracy: 0.8707\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0559 - accuracy: 0.8712\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0792 - accuracy: 0.8704\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.1154 - accuracy: 0.8698\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9680 - accuracy: 0.8716\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9621 - accuracy: 0.8726\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9852 - accuracy: 0.8731\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9452 - accuracy: 0.8724\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9223 - accuracy: 0.8728\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.8876 - accuracy: 0.8710\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9197 - accuracy: 0.8752\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8695 - accuracy: 0.8733\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8510 - accuracy: 0.8743\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.8105 - accuracy: 0.8742\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.8103 - accuracy: 0.8746\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7900 - accuracy: 0.8753\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7729 - accuracy: 0.8754\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7251 - accuracy: 0.8767\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7294 - accuracy: 0.8770\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6786 - accuracy: 0.8782\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6546 - accuracy: 0.8777\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6457 - accuracy: 0.8796\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6980 - accuracy: 0.8794\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6278 - accuracy: 0.8783\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6253 - accuracy: 0.8794\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7037 - accuracy: 0.8779\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6675 - accuracy: 0.8777\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6595 - accuracy: 0.8803\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6368 - accuracy: 0.8792\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6239 - accuracy: 0.8785\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6237 - accuracy: 0.8776\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.5584 - accuracy: 0.8811\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6023 - accuracy: 0.8790\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.5580 - accuracy: 0.8812\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5418 - accuracy: 0.8820\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5417 - accuracy: 0.8809\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5390 - accuracy: 0.8815\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5237 - accuracy: 0.8818\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5103 - accuracy: 0.8805\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5255 - accuracy: 0.8822\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5030 - accuracy: 0.8808\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4838 - accuracy: 0.8814\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4904 - accuracy: 0.8808\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4692 - accuracy: 0.8855\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5237 - accuracy: 0.8800\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4834 - accuracy: 0.8814\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4359 - accuracy: 0.8830\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4503 - accuracy: 0.8836\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4589 - accuracy: 0.8814\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4294 - accuracy: 0.8846\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4016 - accuracy: 0.8834\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4127 - accuracy: 0.8842\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3771 - accuracy: 0.8853\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4182 - accuracy: 0.8825\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3846 - accuracy: 0.8842\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4042 - accuracy: 0.8852\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3699 - accuracy: 0.8833\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3900 - accuracy: 0.8842\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3530 - accuracy: 0.8854\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3845 - accuracy: 0.8856\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3435 - accuracy: 0.8861\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3381 - accuracy: 0.8839\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3842 - accuracy: 0.8851\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.3345 - accuracy: 0.8864\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3682 - accuracy: 0.8837\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3369 - accuracy: 0.8865\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3390 - accuracy: 0.8842\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3623 - accuracy: 0.8837\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3231 - accuracy: 0.8857\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3151 - accuracy: 0.8862\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3479 - accuracy: 0.8854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a511f5bc8>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9270603790215954\n",
      "Tasa de aciertos balanceada regresión logística: 0.36\n",
      "Matriz de confusión:\n",
      "[[   5  186   17    1]\n",
      " [  25 8392  237    1]\n",
      " [   3  192   17    0]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.15      0.02      0.04       209\n",
      "         3.0       0.96      0.97      0.96      8655\n",
      "         4.0       0.06      0.08      0.07       212\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93      9076\n",
      "   macro avg       0.29      0.27      0.27      9076\n",
      "weighted avg       0.92      0.93      0.92      9076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_545 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_546 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_547 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_548 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_549 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,652\n",
      "Trainable params: 4,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 22.1669 - accuracy: 0.8396\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 4.5227 - accuracy: 0.8611\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 3.7596 - accuracy: 0.8588\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 3.1900 - accuracy: 0.8596\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.6543 - accuracy: 0.8625\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.5547 - accuracy: 0.8657\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.4127 - accuracy: 0.8686\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.2661 - accuracy: 0.8693\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1729 - accuracy: 0.8717\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.1062 - accuracy: 0.8724\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0810 - accuracy: 0.8706\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0085 - accuracy: 0.8738\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9725 - accuracy: 0.8760\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9835 - accuracy: 0.8742\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.9274 - accuracy: 0.8758\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.8952 - accuracy: 0.8770\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.8957 - accuracy: 0.8771\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.9099 - accuracy: 0.8754\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8798 - accuracy: 0.8766\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8674 - accuracy: 0.8775\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8396 - accuracy: 0.8776\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.8091 - accuracy: 0.8774\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8244 - accuracy: 0.8785\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8008 - accuracy: 0.8768\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8064 - accuracy: 0.8781\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7621 - accuracy: 0.8799\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7652 - accuracy: 0.8800\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7733 - accuracy: 0.8790\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7539 - accuracy: 0.8792\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7289 - accuracy: 0.8796\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7318 - accuracy: 0.8774\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7317 - accuracy: 0.8783\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7213 - accuracy: 0.8798\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7260 - accuracy: 0.8799\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6958 - accuracy: 0.8798\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6994 - accuracy: 0.8795\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6944 - accuracy: 0.8807\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6920 - accuracy: 0.8800\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6677 - accuracy: 0.8812\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6858 - accuracy: 0.8813\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6582 - accuracy: 0.8811\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6593 - accuracy: 0.8814\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6635 - accuracy: 0.8822\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6535 - accuracy: 0.8807\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.6433 - accuracy: 0.8822\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6397 - accuracy: 0.8827\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6308 - accuracy: 0.8825\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6298 - accuracy: 0.8832\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6206 - accuracy: 0.8828\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6152 - accuracy: 0.8823\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6061 - accuracy: 0.8833\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6158 - accuracy: 0.8814\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6063 - accuracy: 0.8826\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5894 - accuracy: 0.8829\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5955 - accuracy: 0.8824\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5824 - accuracy: 0.8831\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.5910 - accuracy: 0.8834\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5747 - accuracy: 0.8831\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5826 - accuracy: 0.8831\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5719 - accuracy: 0.8834\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5772 - accuracy: 0.8839\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5686 - accuracy: 0.8845\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5547 - accuracy: 0.8830\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5613 - accuracy: 0.8842\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5597 - accuracy: 0.8852\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5402 - accuracy: 0.8833\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5451 - accuracy: 0.8850\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.5439 - accuracy: 0.8849\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5448 - accuracy: 0.8838\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5330 - accuracy: 0.8857\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5240 - accuracy: 0.8859\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5340 - accuracy: 0.8837\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5222 - accuracy: 0.8850\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5199 - accuracy: 0.8851\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5212 - accuracy: 0.8834\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5138 - accuracy: 0.8855\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5144 - accuracy: 0.8850\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4939 - accuracy: 0.8857\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5073 - accuracy: 0.8846\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4986 - accuracy: 0.8839\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4918 - accuracy: 0.8854\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4875 - accuracy: 0.8864\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4866 - accuracy: 0.8858\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4869 - accuracy: 0.8860\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4774 - accuracy: 0.8855\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4832 - accuracy: 0.8855\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4878 - accuracy: 0.8852\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4884 - accuracy: 0.8869\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4674 - accuracy: 0.8858\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4699 - accuracy: 0.8850\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.4656 - accuracy: 0.8855\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4558 - accuracy: 0.8861\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4651 - accuracy: 0.8864\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4459 - accuracy: 0.8863\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4528 - accuracy: 0.8859\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4431 - accuracy: 0.8868\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4518 - accuracy: 0.8862\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4474 - accuracy: 0.8873\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4499 - accuracy: 0.8867\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4302 - accuracy: 0.8877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179a45a9048>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9400617011899515\n",
      "Tasa de aciertos balanceada regresión logística: 0.34\n",
      "Matriz de confusión:\n",
      "[[   5  202    2]\n",
      " [  60 8524   71]\n",
      " [   6  203    3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.07      0.02      0.04       209\n",
      "         3.0       0.95      0.98      0.97      8655\n",
      "         4.0       0.04      0.01      0.02       212\n",
      "\n",
      "    accuracy                           0.94      9076\n",
      "   macro avg       0.35      0.34      0.34      9076\n",
      "weighted avg       0.91      0.94      0.93      9076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_550 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_551 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_552 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_553 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_554 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,578\n",
      "Trainable params: 1,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 38.8492 - accuracy: 0.8029\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 12.4683 - accuracy: 0.8311\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 7.7488 - accuracy: 0.8422\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 6.6313 - accuracy: 0.8556\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 6.0749 - accuracy: 0.8578\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 5.6325 - accuracy: 0.8586\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 5.2343 - accuracy: 0.8585\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 4.8230 - accuracy: 0.8590\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 4.4171 - accuracy: 0.8638\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 4.0002 - accuracy: 0.8734\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 3.6087 - accuracy: 0.8804\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 3.3317 - accuracy: 0.8815\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 3.0970 - accuracy: 0.8799\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.9143 - accuracy: 0.8775\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.8023 - accuracy: 0.8791\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.6877 - accuracy: 0.8793\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.6076 - accuracy: 0.8799\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.5062 - accuracy: 0.8795\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.4532 - accuracy: 0.8802\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.3791 - accuracy: 0.8814\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.3189 - accuracy: 0.8805\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.2599 - accuracy: 0.8813\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.2082 - accuracy: 0.8826\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.1541 - accuracy: 0.8826\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.1169 - accuracy: 0.8835\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0734 - accuracy: 0.8840\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0208 - accuracy: 0.8834\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0074 - accuracy: 0.8838\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9655 - accuracy: 0.8842\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9454 - accuracy: 0.8842\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.9146 - accuracy: 0.8845\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8919 - accuracy: 0.8834\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8663 - accuracy: 0.8853\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8476 - accuracy: 0.8850\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8227 - accuracy: 0.8854\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.8076 - accuracy: 0.8841\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7908 - accuracy: 0.8846\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7676 - accuracy: 0.8852\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7557 - accuracy: 0.8859\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7420 - accuracy: 0.8856\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7267 - accuracy: 0.8850\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7100 - accuracy: 0.8853\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.7031 - accuracy: 0.8857\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6886 - accuracy: 0.8862\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6807 - accuracy: 0.8847\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6733 - accuracy: 0.8863\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6505 - accuracy: 0.8853\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6476 - accuracy: 0.8862\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6400 - accuracy: 0.8852\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6255 - accuracy: 0.8851\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6163 - accuracy: 0.8862\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6062 - accuracy: 0.8874\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.6058 - accuracy: 0.8866\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5964 - accuracy: 0.8856\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5892 - accuracy: 0.8860\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5807 - accuracy: 0.8862\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5733 - accuracy: 0.8860\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5648 - accuracy: 0.8866\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5571 - accuracy: 0.8868\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5448 - accuracy: 0.8864\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5395 - accuracy: 0.8867\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5288 - accuracy: 0.8868\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5248 - accuracy: 0.8869\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.5222 - accuracy: 0.8876\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5226 - accuracy: 0.8879\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5154 - accuracy: 0.8865\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.5025 - accuracy: 0.8879\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4983 - accuracy: 0.8874\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4903 - accuracy: 0.8871\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4801 - accuracy: 0.8872\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4816 - accuracy: 0.8875\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4683 - accuracy: 0.8864\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4721 - accuracy: 0.8869\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4593 - accuracy: 0.8879\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4537 - accuracy: 0.8875\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4511 - accuracy: 0.8879\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4482 - accuracy: 0.8871\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4378 - accuracy: 0.8875\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4417 - accuracy: 0.8881\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4215 - accuracy: 0.8879\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4254 - accuracy: 0.8878\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4217 - accuracy: 0.8886\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4155 - accuracy: 0.8875\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4019 - accuracy: 0.8884\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4053 - accuracy: 0.8877\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.4014 - accuracy: 0.8890\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3910 - accuracy: 0.8880\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3917 - accuracy: 0.8882\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3841 - accuracy: 0.8886\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3777 - accuracy: 0.8882\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3775 - accuracy: 0.8891\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3666 - accuracy: 0.8891\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3658 - accuracy: 0.8889\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3657 - accuracy: 0.8879\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3589 - accuracy: 0.8883\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3612 - accuracy: 0.8893\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3525 - accuracy: 0.8887\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3491 - accuracy: 0.8883\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 1.3393 - accuracy: 0.8894\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.3419 - accuracy: 0.8887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a460b4508>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9323490524460114\n",
      "Tasa de aciertos balanceada regresión logística: 0.37\n",
      "Matriz de confusión:\n",
      "[[   5  186   17    1]\n",
      " [  25 8392  237    1]\n",
      " [   3  192   17    0]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.16      0.08      0.10       209\n",
      "         3.0       0.96      0.97      0.97      8655\n",
      "         4.0       0.08      0.07      0.07       212\n",
      "\n",
      "    accuracy                           0.93      9076\n",
      "   macro avg       0.40      0.37      0.38      9076\n",
      "weighted avg       0.92      0.93      0.93      9076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_555 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_556 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_557 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_558 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_559 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,257\n",
      "Trainable params: 20,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5514 - accuracy: 0.0402\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 15.5506 - accuracy: 0.0402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a18ea6048>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0247906566769502\n",
      "Tasa de aciertos balanceada regresión logística: 0.35\n",
      "Matriz de confusión:\n",
      "[[  19    0  190]\n",
      " [1265    0 7390]\n",
      " [   6    0  206]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.01      0.09      0.03       209\n",
      "         3.0       0.00      0.00      0.00      8655\n",
      "         4.0       0.03      0.97      0.05       212\n",
      "\n",
      "    accuracy                           0.02      9076\n",
      "   macro avg       0.01      0.35      0.03      9076\n",
      "weighted avg       0.00      0.02      0.00      9076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_560 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_561 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_562 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_563 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_564 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,935\n",
      "Trainable params: 8,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1839 - accuracy: 2.4792e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a36039248>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [ 209    0    0    0]\n",
      " [8655    0    0    0]\n",
      " [ 212    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00     209.0\n",
      "         3.0       0.00      0.00      0.00    8655.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "\n",
      "    accuracy                           0.00    9076.0\n",
      "   macro avg       0.00      0.00      0.00    9076.0\n",
      "weighted avg       0.00      0.00      0.00    9076.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_565 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_566 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_567 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_568 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_569 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,679\n",
      "Trainable params: 2,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 16.1172 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a4294bf48>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  19    0  190]\n",
      " [1265    0 7390]\n",
      " [   6    0  206]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00     209.0\n",
      "         3.0       0.00      0.00      0.00    8655.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "\n",
      "    accuracy                           0.00    9076.0\n",
      "   macro avg       0.00      0.00      0.00    9076.0\n",
      "weighted avg       0.00      0.00      0.00    9076.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_570 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_571 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_572 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_573 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_574 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_575 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_576 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_577 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_578 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_579 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,319\n",
      "Trainable params: 11,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8068 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 16.8072 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a466bf048>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [ 209    0    0    0]\n",
      " [8655    0    0    0]\n",
      " [ 212    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00     209.0\n",
      "         3.0       0.00      0.00      0.00    8655.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "\n",
      "    accuracy                           0.00    9076.0\n",
      "   macro avg       0.00      0.00      0.00    9076.0\n",
      "weighted avg       0.00      0.00      0.00    9076.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_580 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_581 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_582 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_583 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_584 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_585 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_586 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_587 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_588 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_589 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,215\n",
      "Trainable params: 5,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7526 - accuracy: 0.9206\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 1.7522 - accuracy: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a4a1b5108>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9535037461436756\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0  209    0    0]\n",
      " [   0 8654    0    1]\n",
      " [   0  212    0    0]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.95      1.00      0.98      8655\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95      9076\n",
      "   macro avg       0.24      0.25      0.24      9076\n",
      "weighted avg       0.91      0.95      0.93      9076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_590 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_591 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_592 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_593 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_594 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_595 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_596 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_597 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_598 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_599 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,713\n",
      "Trainable params: 1,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 11/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 12/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 13/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 14/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 15/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 16/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 17/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 18/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 19/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 20/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 21/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 22/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 23/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 24/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 25/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 26/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 27/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 28/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 29/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 30/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 31/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 32/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 33/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 34/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 35/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 36/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 37/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 38/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 39/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 40/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 41/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 42/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 43/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 44/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 45/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 46/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 47/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 48/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 49/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 50/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 51/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 52/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 53/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 54/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 55/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 56/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 57/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 58/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 59/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 60/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 61/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 62/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 63/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 64/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 65/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 66/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 67/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 68/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 69/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 70/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 71/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 72/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 73/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 74/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 75/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 76/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 77/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 78/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 79/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 80/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 81/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 82/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 83/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 84/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 85/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 86/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 87/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 88/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 89/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 90/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 91/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 92/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 93/100\n",
      "1135/1135 [==============================] - 2s 2ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 94/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 95/100\n",
      "1135/1135 [==============================] - 1s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 96/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 97/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 98/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 99/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n",
      "Epoch 100/100\n",
      "1135/1135 [==============================] - 2s 1ms/step - loss: 2.0048 - accuracy: 1.3773e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a59082548>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [ 209    0    0    0]\n",
      " [8655    0    0    0]\n",
      " [ 212    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00     209.0\n",
      "         3.0       0.00      0.00      0.00    8655.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "         5.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    9076.0\n",
      "   macro avg       0.00      0.00      0.00    9076.0\n",
      "weighted avg       0.00      0.00      0.00    9076.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 35, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_600 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_601 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_602 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_603 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_604 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,365\n",
      "Trainable params: 11,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 41.9542 - accuracy: 0.8400\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.5899 - accuracy: 0.8894\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 5.5494 - accuracy: 0.8908\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.0705 - accuracy: 0.8987\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.4198 - accuracy: 0.9174\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.6749 - accuracy: 0.9112\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3640 - accuracy: 0.9206\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3547 - accuracy: 0.9207\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3564 - accuracy: 0.9211\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3353 - accuracy: 0.9213\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3332 - accuracy: 0.9213\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179e0897808>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9535934744268078\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0  209    0]\n",
      " [   0 8651    0]\n",
      " [   0  212    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.95      1.00      0.98      8651\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.95      9072\n",
      "   macro avg       0.32      0.33      0.33      9072\n",
      "weighted avg       0.91      0.95      0.93      9072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_605 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_606 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_607 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_608 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_609 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,548\n",
      "Trainable params: 5,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 49.2763 - accuracy: 0.8393\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.9714 - accuracy: 0.8593\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.8587 - accuracy: 0.8677\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.8197 - accuracy: 0.8757\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.1425 - accuracy: 0.8980\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.5178 - accuracy: 0.8995\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.4328 - accuracy: 0.9173\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.4434 - accuracy: 0.9028\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.4356 - accuracy: 0.9165\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.7504 - accuracy: 0.9158\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3673 - accuracy: 0.9193\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.4294 - accuracy: 0.9187\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3377 - accuracy: 0.9212\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3446 - accuracy: 0.9210\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3343 - accuracy: 0.9213\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3337 - accuracy: 0.9213\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.9213\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3330 - accuracy: 0.9213\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9213\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3330 - accuracy: 0.9213\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3330 - accuracy: 0.9213\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9213\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3330 - accuracy: 0.9213\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3330 - accuracy: 0.9213\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ac56ccb88>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9535934744268078\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0  209    0]\n",
      " [   0 8651    0]\n",
      " [   0  212    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.95      1.00      0.98      8651\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.95      9072\n",
      "   macro avg       0.32      0.33      0.33      9072\n",
      "weighted avg       0.91      0.95      0.93      9072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_610 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_611 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_612 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_613 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_614 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,026\n",
      "Trainable params: 2,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 14.4905 - accuracy: 0.8177\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.6501 - accuracy: 0.9208\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.4424 - accuracy: 0.9213\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3871 - accuracy: 0.9213\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3743 - accuracy: 0.9210\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3544 - accuracy: 0.9213\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3429 - accuracy: 0.9213\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3388 - accuracy: 0.9213\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3364 - accuracy: 0.9213\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3349 - accuracy: 0.9213\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3340 - accuracy: 0.9213\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3334 - accuracy: 0.9213\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3331 - accuracy: 0.9213\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3329 - accuracy: 0.9213\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3328 - accuracy: 0.9213\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.9213\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.9213\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ae2249448>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9535934744268078\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0  209    0]\n",
      " [   0 8651    0]\n",
      " [   0  212    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.95      1.00      0.98      8651\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.95      9072\n",
      "   macro avg       0.32      0.33      0.33      9072\n",
      "weighted avg       0.91      0.95      0.93      9072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 35, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_615 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_616 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_617 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_618 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_619 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,657\n",
      "Trainable params: 21,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3823 - accuracy: 0.1086\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.3137 - accuracy: 0.0427\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.3137 - accuracy: 0.0427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ae5e4fec8>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.024911816578483244\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0    0  209]\n",
      " [   0   15 8636]\n",
      " [   0    1  211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.94      0.00      0.00      8651\n",
      "         4.0       0.02      1.00      0.05       212\n",
      "\n",
      "    accuracy                           0.02      9072\n",
      "   macro avg       0.32      0.33      0.02      9072\n",
      "weighted avg       0.89      0.02      0.00      9072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_620 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_621 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_622 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_623 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_624 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,831\n",
      "Trainable params: 9,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 10797s 10s/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1500s 1s/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6333 - accuracy: 0.0014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17aed789148>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0002204585537918871\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   2    0    0  207]\n",
      " [  42    0    1 8608]\n",
      " [   3    0    0  209]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.04      0.01      0.02       209\n",
      "         3.0       0.00      0.00      0.00      8651\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.00      9072\n",
      "   macro avg       0.01      0.00      0.00      9072\n",
      "weighted avg       0.00      0.00      0.00      9072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_625 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_626 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_627 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_628 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_629 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,127\n",
      "Trainable params: 3,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7946 - accuracy: 0.0359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17aede606c8>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.022156084656084655\n",
      "Tasa de aciertos balanceada regresión logística: 0.32\n",
      "Matriz de confusión:\n",
      "[[   0    0  209]\n",
      " [   0   15 8636]\n",
      " [   0    1  211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.00      0.00      0.00      8651\n",
      "         4.0       0.03      0.95      0.05       212\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.02      9072\n",
      "   macro avg       0.01      0.24      0.01      9072\n",
      "weighted avg       0.00      0.02      0.00      9072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 35, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_630 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_631 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_632 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_633 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_634 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_635 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_636 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_637 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_638 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_639 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,719\n",
      "Trainable params: 12,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.6624 - accuracy: 1.3779e-04\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 1.3779e-04\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 1.3779e-04\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 1.3779e-04\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 1.3779e-04\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 1.3779e-04\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 1.3779e-04\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 1.3779e-04\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 1.3779e-04\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 1.3779e-04\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 1.3779e-04\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 1.3779e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17af672e5c8>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0  209]\n",
      " [   0    0    0 8651]\n",
      " [   0    0    0  212]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00     209.0\n",
      "         3.0       0.00      0.00      0.00    8651.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "         5.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    9072.0\n",
      "   macro avg       0.00      0.00      0.00    9072.0\n",
      "weighted avg       0.00      0.00      0.00    9072.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_640 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_641 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_642 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_643 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_644 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_645 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_646 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_647 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_648 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_649 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,111\n",
      "Trainable params: 6,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.2332 - accuracy: 0.0012\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7169 - accuracy: 1.3779e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17afa4fa508>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0  209]\n",
      " [   0    0    0 8651]\n",
      " [   0    0    0  212]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00     209.0\n",
      "         3.0       0.00      0.00      0.00    8651.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "         5.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    9072.0\n",
      "   macro avg       0.00      0.00      0.00    9072.0\n",
      "weighted avg       0.00      0.00      0.00    9072.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_650 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_651 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_652 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_653 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_654 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_655 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_656 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_657 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_658 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_659 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,161\n",
      "Trainable params: 2,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.6001 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17afab97408>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0  209]\n",
      " [   0    0    0 8651]\n",
      " [   0    0    0  212]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00     209.0\n",
      "         3.0       0.00      0.00      0.00    8651.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "\n",
      "    accuracy                           0.00    9072.0\n",
      "   macro avg       0.00      0.00      0.00    9072.0\n",
      "weighted avg       0.00      0.00      0.00    9072.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_660 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_661 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_662 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_663 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_664 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,365\n",
      "Trainable params: 11,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 40.5619 - accuracy: 0.8549\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 11.5849 - accuracy: 0.8643\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 8.8274 - accuracy: 0.8683\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 7.1431 - accuracy: 0.8687\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 6.2614 - accuracy: 0.8718\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 5.5434 - accuracy: 0.8734\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 5.0899 - accuracy: 0.8784\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.7430 - accuracy: 0.8756\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.5107 - accuracy: 0.8788\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.2441 - accuracy: 0.8774\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 4.0575 - accuracy: 0.8785\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.0296 - accuracy: 0.8785\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.7281 - accuracy: 0.8792\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.6382 - accuracy: 0.8791\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.5117 - accuracy: 0.8796\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.3570 - accuracy: 0.8799\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.2966 - accuracy: 0.8792\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.2897 - accuracy: 0.8790\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.1992 - accuracy: 0.8785\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 3.1456 - accuracy: 0.8783\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 3.0642 - accuracy: 0.8779\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.0731 - accuracy: 0.8769\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.9110 - accuracy: 0.8794\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.9688 - accuracy: 0.8776\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.8748 - accuracy: 0.8773\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.8190 - accuracy: 0.8784\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.7735 - accuracy: 0.8793\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.8284 - accuracy: 0.8784\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.7047 - accuracy: 0.8782\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.7026 - accuracy: 0.8775\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.6861 - accuracy: 0.8793\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.5529 - accuracy: 0.8794\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.5480 - accuracy: 0.8805\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.5416 - accuracy: 0.8811\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.5562 - accuracy: 0.8796\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.5155 - accuracy: 0.8801\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.5264 - accuracy: 0.8774\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.4588 - accuracy: 0.8799\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.4161 - accuracy: 0.8803\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.4215 - accuracy: 0.8784\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.3912 - accuracy: 0.8779\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.3423 - accuracy: 0.8805\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.3552 - accuracy: 0.8792\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.2931 - accuracy: 0.8803\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.2618 - accuracy: 0.8780\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.2588 - accuracy: 0.8799\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.2950 - accuracy: 0.8812\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.2128 - accuracy: 0.8801\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.1999 - accuracy: 0.8790\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1890 - accuracy: 0.8794\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1737 - accuracy: 0.8791\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1241 - accuracy: 0.8807\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1051 - accuracy: 0.8805\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1295 - accuracy: 0.8801\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.0759 - accuracy: 0.8804\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.0778 - accuracy: 0.8811\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.0943 - accuracy: 0.8789\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0615 - accuracy: 0.8821\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0417 - accuracy: 0.8795\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.0407 - accuracy: 0.8805\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.0254 - accuracy: 0.8810\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.0072 - accuracy: 0.8804\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.0026 - accuracy: 0.8809\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9794 - accuracy: 0.8810\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9642 - accuracy: 0.8813\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9554 - accuracy: 0.8819\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 1.9898 - accuracy: 0.8795\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9100 - accuracy: 0.8806\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.8910 - accuracy: 0.8823\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9353 - accuracy: 0.8808\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.8823 - accuracy: 0.8820\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.8911 - accuracy: 0.8825\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9027 - accuracy: 0.8813\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.8583 - accuracy: 0.8816\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.8547 - accuracy: 0.8816\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.8398 - accuracy: 0.8828\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.8337 - accuracy: 0.8820\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.8639 - accuracy: 0.8821\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.8085 - accuracy: 0.8819\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.8200 - accuracy: 0.8831\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7869 - accuracy: 0.8833\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7631 - accuracy: 0.8830\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7967 - accuracy: 0.8820\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7957 - accuracy: 0.8828\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7905 - accuracy: 0.8825\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7622 - accuracy: 0.8837\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7374 - accuracy: 0.8818\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7528 - accuracy: 0.8820\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7726 - accuracy: 0.8811\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6941 - accuracy: 0.8840\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7351 - accuracy: 0.8827\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7193 - accuracy: 0.8829\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7199 - accuracy: 0.8813\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6989 - accuracy: 0.8839\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6907 - accuracy: 0.8826\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7214 - accuracy: 0.8830\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6822 - accuracy: 0.8836\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6914 - accuracy: 0.8825\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6589 - accuracy: 0.8840\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6349 - accuracy: 0.8831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17b0361efc8>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9501763668430335\n",
      "Tasa de aciertos balanceada regresión logística: 0.34\n",
      "Matriz de confusión:\n",
      "[[   3  198    8    0]\n",
      " [  13 8612   25    1]\n",
      " [   5  202    5    0]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.14      0.01      0.03       209\n",
      "         3.0       0.96      1.00      0.98      8651\n",
      "         4.0       0.13      0.02      0.04       212\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95      9072\n",
      "   macro avg       0.31      0.26      0.26      9072\n",
      "weighted avg       0.92      0.95      0.93      9072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_665 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_666 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_667 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_668 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_669 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,548\n",
      "Trainable params: 5,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 20.3093 - accuracy: 0.8566\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 7.3559 - accuracy: 0.8578\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 5.9210 - accuracy: 0.8579\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 5.0518 - accuracy: 0.8598\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.4426 - accuracy: 0.8637\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.1138 - accuracy: 0.8661\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.7289 - accuracy: 0.8661\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.4673 - accuracy: 0.8682\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.3834 - accuracy: 0.8722\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.2527 - accuracy: 0.8714\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.0786 - accuracy: 0.8745\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.9524 - accuracy: 0.8740\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.8811 - accuracy: 0.8754\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.7865 - accuracy: 0.8750\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.6901 - accuracy: 0.8770\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.6848 - accuracy: 0.8768\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.6183 - accuracy: 0.8787\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.6073 - accuracy: 0.8772\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.5081 - accuracy: 0.8777\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.4838 - accuracy: 0.8775\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.4515 - accuracy: 0.8797\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.4291 - accuracy: 0.8780\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.4022 - accuracy: 0.8792\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.3660 - accuracy: 0.8791\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.3651 - accuracy: 0.8798\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.3309 - accuracy: 0.8792\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.3037 - accuracy: 0.8785\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.2703 - accuracy: 0.8787\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.2500 - accuracy: 0.8808\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.2299 - accuracy: 0.8786\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.2084 - accuracy: 0.8797\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1781 - accuracy: 0.8789\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1636 - accuracy: 0.8788\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1531 - accuracy: 0.8803\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1421 - accuracy: 0.8801\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1087 - accuracy: 0.8807\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1067 - accuracy: 0.8800\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.1007 - accuracy: 0.8803\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.0578 - accuracy: 0.8800\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.0573 - accuracy: 0.8803\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 2.0255 - accuracy: 0.8812\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.0122 - accuracy: 0.8801\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 2.0140 - accuracy: 0.8813\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9828 - accuracy: 0.8800\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9615 - accuracy: 0.8807\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9669 - accuracy: 0.8821\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9430 - accuracy: 0.8809\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9176 - accuracy: 0.8824\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9212 - accuracy: 0.8817\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9187 - accuracy: 0.8823\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9033 - accuracy: 0.8809\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.8908 - accuracy: 0.8834\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.8862 - accuracy: 0.8819\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.8548 - accuracy: 0.8821\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.8460 - accuracy: 0.8823\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.8406 - accuracy: 0.8826\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.8261 - accuracy: 0.8819\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.8310 - accuracy: 0.8823\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.8203 - accuracy: 0.8830\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7830 - accuracy: 0.8836\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7893 - accuracy: 0.8834\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7758 - accuracy: 0.8841\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7603 - accuracy: 0.8830\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7380 - accuracy: 0.8844\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7454 - accuracy: 0.8828\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7563 - accuracy: 0.8836\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7211 - accuracy: 0.8848\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7232 - accuracy: 0.8829\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.7030 - accuracy: 0.8841\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6995 - accuracy: 0.8844\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7038 - accuracy: 0.8846\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6957 - accuracy: 0.8838\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6817 - accuracy: 0.8834\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6584 - accuracy: 0.8854\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6506 - accuracy: 0.8841\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6517 - accuracy: 0.8840\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6454 - accuracy: 0.8851\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6310 - accuracy: 0.8853\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6234 - accuracy: 0.8844\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6183 - accuracy: 0.8855\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.6193 - accuracy: 0.8857\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.6085 - accuracy: 0.8847\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.6075 - accuracy: 0.8851\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.5878 - accuracy: 0.8856\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.5896 - accuracy: 0.8858\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.5784 - accuracy: 0.8845\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.5778 - accuracy: 0.8858\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 1.5687 - accuracy: 0.8854\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.5601 - accuracy: 0.8860\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.5551 - accuracy: 0.8859\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.5483 - accuracy: 0.8853\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.5547 - accuracy: 0.8863\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.5366 - accuracy: 0.8864\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.5381 - accuracy: 0.8859\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.5212 - accuracy: 0.8853\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.5234 - accuracy: 0.8859\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.5093 - accuracy: 0.8860\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.5114 - accuracy: 0.8863\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4975 - accuracy: 0.8868\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.4972 - accuracy: 0.8867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17b0e7ff308>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.8727954144620811\n",
      "Tasa de aciertos balanceada regresión logística: 0.38\n",
      "Matriz de confusión:\n",
      "[[  27  174    8]\n",
      " [ 555 7869  227]\n",
      " [  32  158   22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.04      0.13      0.07       209\n",
      "         3.0       0.96      0.91      0.93      8651\n",
      "         4.0       0.09      0.10      0.09       212\n",
      "\n",
      "    accuracy                           0.87      9072\n",
      "   macro avg       0.36      0.38      0.36      9072\n",
      "weighted avg       0.92      0.87      0.89      9072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_670 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_671 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_672 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_673 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_674 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,026\n",
      "Trainable params: 2,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 31.4379 - accuracy: 0.8396\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 9.5314 - accuracy: 0.8589\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 8.5084 - accuracy: 0.8610\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 8.0073 - accuracy: 0.8602\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 7.6790 - accuracy: 0.8587\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 7.3679 - accuracy: 0.8594\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 7.1012 - accuracy: 0.8573\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.9303 - accuracy: 0.8582\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 6.7643 - accuracy: 0.8563\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.6336 - accuracy: 0.8568\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.4622 - accuracy: 0.8579\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.3397 - accuracy: 0.8557\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.2396 - accuracy: 0.8577\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.1243 - accuracy: 0.8580\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 6.0380 - accuracy: 0.8578\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 5.9777 - accuracy: 0.8580\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.8673 - accuracy: 0.8576\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.7869 - accuracy: 0.8566\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 5.7108 - accuracy: 0.8575\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.6537 - accuracy: 0.8572\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.6032 - accuracy: 0.8583\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.5393 - accuracy: 0.8581\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.4728 - accuracy: 0.8579\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.4159 - accuracy: 0.8582\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.3592 - accuracy: 0.8591\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 5.3111 - accuracy: 0.8593\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 5.2778 - accuracy: 0.8587\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.2355 - accuracy: 0.8601\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 5.1884 - accuracy: 0.8601\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.1289 - accuracy: 0.8594\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.0993 - accuracy: 0.8601\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.0763 - accuracy: 0.8601\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.0494 - accuracy: 0.8613\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 5.0010 - accuracy: 0.8612\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.9509 - accuracy: 0.8594\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.9194 - accuracy: 0.8608\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 4.8874 - accuracy: 0.8605\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.8677 - accuracy: 0.8629\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.8387 - accuracy: 0.8605\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.8118 - accuracy: 0.8628\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.7696 - accuracy: 0.8614\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.7501 - accuracy: 0.8616\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.7280 - accuracy: 0.8621\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.6953 - accuracy: 0.8637\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.6830 - accuracy: 0.8637\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.6604 - accuracy: 0.8634\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.6399 - accuracy: 0.8630\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 4.6340 - accuracy: 0.8640\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.5940 - accuracy: 0.8637\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.5560 - accuracy: 0.8629\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.5345 - accuracy: 0.8640\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.5117 - accuracy: 0.8650\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.5108 - accuracy: 0.8642\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.4858 - accuracy: 0.8636\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.4705 - accuracy: 0.8651\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.4479 - accuracy: 0.8654\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.4306 - accuracy: 0.8646\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.4337 - accuracy: 0.8666\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.4086 - accuracy: 0.8646\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.3877 - accuracy: 0.8653\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.3665 - accuracy: 0.8657\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.3484 - accuracy: 0.8642\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.3562 - accuracy: 0.8660\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 4.3391 - accuracy: 0.8666\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.3181 - accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.3135 - accuracy: 0.8656\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.2794 - accuracy: 0.8659\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.2651 - accuracy: 0.8657\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 4.2303 - accuracy: 0.8652\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.2545 - accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.2254 - accuracy: 0.8664\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.2145 - accuracy: 0.8672\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1915 - accuracy: 0.8675\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1745 - accuracy: 0.8664\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1578 - accuracy: 0.8670\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1688 - accuracy: 0.8674\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1486 - accuracy: 0.8674\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1352 - accuracy: 0.8670\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1273 - accuracy: 0.8677\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 4.1081 - accuracy: 0.8672\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.0979 - accuracy: 0.8676\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.1000 - accuracy: 0.8675\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.0913 - accuracy: 0.8685\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.0797 - accuracy: 0.8684\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.0721 - accuracy: 0.8683\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.0402 - accuracy: 0.8699\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.0355 - accuracy: 0.8689\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.0290 - accuracy: 0.8686\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.0178 - accuracy: 0.8688\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 4.0026 - accuracy: 0.8681\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 4.0073 - accuracy: 0.8685\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9824 - accuracy: 0.8692\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9748 - accuracy: 0.8686\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9469 - accuracy: 0.8684\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9614 - accuracy: 0.8688\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9535 - accuracy: 0.8688\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9407 - accuracy: 0.8690\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9376 - accuracy: 0.8698\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 3.9306 - accuracy: 0.8703\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 1s 1ms/step - loss: 3.9245 - accuracy: 0.8698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17b0ee446c8>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9072971781305115\n",
      "Tasa de aciertos balanceada regresión logística: 0.34\n",
      "Matriz de confusión:\n",
      "[[   3  198    8    0]\n",
      " [  13 8612   25    1]\n",
      " [   5  202    5    0]\n",
      " [   0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "         2.0       0.03      0.04      0.03       209\n",
      "         3.0       0.96      0.95      0.95      8651\n",
      "         4.0       0.06      0.05      0.05       212\n",
      "\n",
      "    accuracy                           0.91      9072\n",
      "   macro avg       0.26      0.26      0.26      9072\n",
      "weighted avg       0.91      0.91      0.91      9072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_675 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_676 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_677 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_678 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_679 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,657\n",
      "Trainable params: 21,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.2378 - accuracy: 0.0402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17b0e6feac8>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.023368606701940034\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0    0  209]\n",
      " [   0    0 8651]\n",
      " [   0    0  212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.00      0.00      0.00      8651\n",
      "         4.0       0.02      1.00      0.05       212\n",
      "\n",
      "    accuracy                           0.02      9072\n",
      "   macro avg       0.01      0.33      0.02      9072\n",
      "weighted avg       0.00      0.02      0.00      9072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_680 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_681 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_682 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_683 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_684 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,831\n",
      "Trainable params: 9,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.7192 - accuracy: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17b0f35d148>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.9535934744268078\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0  209    0]\n",
      " [   0 8651    0]\n",
      " [   0  212    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.95      1.00      0.98      8651\n",
      "         4.0       0.00      0.00      0.00       212\n",
      "\n",
      "    accuracy                           0.95      9072\n",
      "   macro avg       0.32      0.33      0.33      9072\n",
      "weighted avg       0.91      0.95      0.93      9072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_685 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_686 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_687 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_688 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_689 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,127\n",
      "Trainable params: 3,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.7093 - accuracy: 1.3779e-04\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0836 - accuracy: 1.3779e-04\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0551 - accuracy: 1.3779e-04\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 16.0016 - accuracy: 1.3779e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a65d17a88>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0  209]\n",
      " [   0    0 8651]\n",
      " [   0    0  212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00     209.0\n",
      "         3.0       0.00      0.00      0.00    8651.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "         5.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00    9072.0\n",
      "   macro avg       0.00      0.00      0.00    9072.0\n",
      "weighted avg       0.00      0.00      0.00    9072.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_690 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_691 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_692 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_693 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_694 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_695 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_696 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_697 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_698 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_699 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,719\n",
      "Trainable params: 12,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6483 - accuracy: 2.4803e-04\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.6482 - accuracy: 2.4803e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17b0ee00588>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [ 209    0    0    0]\n",
      " [8651    0    0    0]\n",
      " [ 212    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00     209.0\n",
      "         3.0       0.00      0.00      0.00    8651.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "\n",
      "    accuracy                           0.00    9072.0\n",
      "   macro avg       0.00      0.00      0.00    9072.0\n",
      "weighted avg       0.00      0.00      0.00    9072.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_700 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_701 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_702 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_703 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_704 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_705 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_706 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_707 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_708 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_709 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,111\n",
      "Trainable params: 6,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 3s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 2.0068 - accuracy: 0.0402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179aa343548>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.023368606701940034\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[   0    0  209]\n",
      " [   0    0 8651]\n",
      " [   0    0  212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       209\n",
      "         3.0       0.00      0.00      0.00      8651\n",
      "         4.0       0.02      1.00      0.05       212\n",
      "\n",
      "    accuracy                           0.02      9072\n",
      "   macro avg       0.01      0.33      0.02      9072\n",
      "weighted avg       0.00      0.02      0.00      9072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_710 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_711 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_712 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_713 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_714 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_715 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_716 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_717 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_718 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_719 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,161\n",
      "Trainable params: 2,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9586 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9463 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1134/1134 [==============================] - 2s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1134/1134 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a5118a388>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[   0    0    0    0]\n",
      " [ 209    0    0    0]\n",
      " [8651    0    0    0]\n",
      " [ 212    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00     209.0\n",
      "         3.0       0.00      0.00      0.00    8651.0\n",
      "         4.0       0.00      0.00      0.00     212.0\n",
      "\n",
      "    accuracy                           0.00    9072.0\n",
      "   macro avg       0.00      0.00      0.00    9072.0\n",
      "weighted avg       0.00      0.00      0.00    9072.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERVALO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.953560</td>\n",
       "      <td>0.953560</td>\n",
       "      <td>0.953560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.953560</td>\n",
       "      <td>0.953560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023110</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.949378</td>\n",
       "      <td>0.854627</td>\n",
       "      <td>0.943216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411027</td>\n",
       "      <td>0.023110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.023330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.953560     0.953560     0.953560\n",
       "Experimento 2- RELU+ADAM         0.000000     0.953560     0.953560\n",
       "Experimento 3- RELU+ADAM         0.000000     0.023110     0.000000\n",
       "Experimento 1- RELU+ADAGRAD      0.949378     0.854627     0.943216\n",
       "Experimento 2- RELU+ADAGRAD      0.000000     0.411027     0.023110\n",
       "Experimento 3- RELU+ADAGRAD      0.023330     0.000000     0.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['100 Neuronas'] = None\n",
    "df1['64 Neuronas'] = None\n",
    "df1['32 Neuronas'] = None\n",
    "df1.loc['Experimento 1- RELU+ADAM'] = [0.9535600308132497,0.9535600308132497,0.9535600308132497]\n",
    "df1.loc['Experimento 2- RELU+ADAM'] = [0.0,0.9535600308132497,0.9535600308132497]\n",
    "df1.loc['Experimento 3- RELU+ADAM'] = [0.0,0.023109937273027403,0.0]\n",
    "df1.loc['Experimento 1- RELU+ADAGRAD'] =[0.9493782326400352,0.8546274898206229,0.9432155827005613]\n",
    "df1.loc['Experimento 2- RELU+ADAGRAD'] =[0.0,0.4110267414988445,0.023109937273027403]\n",
    "df1.loc['Experimento 3- RELU+ADAGRAD'] = [0.0233300319137229,0.0,0.0]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.953614</td>\n",
       "      <td>0.953614</td>\n",
       "      <td>0.953614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.928493</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.953614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.927060</td>\n",
       "      <td>0.940062</td>\n",
       "      <td>0.932349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.024791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.953504</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.953614     0.953614     0.953614\n",
       "Experimento 2- RELU+ADAM         0.000000     0.928493     0.000992\n",
       "Experimento 3- RELU+ADAM         0.000992     0.000000     0.953614\n",
       "Experimento 1- RELU+ADAGRAD      0.927060     0.940062     0.932349\n",
       "Experimento 2- RELU+ADAGRAD      0.024791     0.000000     0.000000\n",
       "Experimento 3- RELU+ADAGRAD      0.000000     0.953504     0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['100 Neuronas'] = None\n",
    "df2['64 Neuronas'] = None\n",
    "df2['32 Neuronas'] = None\n",
    "df2.loc['Experimento 1- RELU+ADAM'] = [0.9536139268400177,0.9536139268400177,0.9536139268400177]\n",
    "df2.loc['Experimento 2- RELU+ADAM'] =[0.0,0.9284927280740414,0.000991626267078008]\n",
    "df2.loc['Experimento 3- RELU+ADAM'] = [0.000991626267078008,0.0,0.9536139268400177]\n",
    "df2.loc['Experimento 1- RELU+ADAGRAD'] = [0.9270603790215954,0.9400617011899515,0.9323490524460114]\n",
    "df2.loc['Experimento 2- RELU+ADAGRAD'] = [0.0247906566769502,0.0,0.0]\n",
    "df2.loc['Experimento 3- RELU+ADAGRAD'] = [0.0,0.9535037461436756,0.0]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.953593</td>\n",
       "      <td>0.953593</td>\n",
       "      <td>0.953593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.024912</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.022156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.950176</td>\n",
       "      <td>0.872795</td>\n",
       "      <td>0.907297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.023369</td>\n",
       "      <td>0.953593</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023369</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.953593     0.953593     0.953593\n",
       "Experimento 2- RELU+ADAM         0.024912     0.000220     0.022156\n",
       "Experimento 3- RELU+ADAM         0.000000     0.000000     0.000000\n",
       "Experimento 1- RELU+ADAGRAD      0.950176     0.872795     0.907297\n",
       "Experimento 2- RELU+ADAGRAD      0.023369     0.953593     0.000000\n",
       "Experimento 3- RELU+ADAGRAD      0.000000     0.023369     0.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame()\n",
    "df3['100 Neuronas'] = None\n",
    "df3['64 Neuronas'] = None\n",
    "df3['32 Neuronas'] = None\n",
    "df3.loc['Experimento 1- RELU+ADAM'] = [0.9535934744268078,0.9535934744268078,0.9535934744268078]\n",
    "df3.loc['Experimento 2- RELU+ADAM'] = [0.024911816578483244,0.0002204585537918871,0.022156084656084655]\n",
    "df3.loc['Experimento 3- RELU+ADAM'] =[0.0,0.0,0.0]\n",
    "df3.loc['Experimento 1- RELU+ADAGRAD'] = [0.9501763668430335,0.8727954144620811,0.9072971781305115]\n",
    "df3.loc['Experimento 2- RELU+ADAGRAD'] = [0.023368606701940034,0.9535934744268078,0.0]\n",
    "df3.loc['Experimento 3- RELU+ADAGRAD'] = [0.0,0.023368606701940034,0.0]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18c4de17288>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,20))\n",
    "fig.add_subplot(2,2,1)\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 1')\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM' ,color ='red')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 2')\n",
    "fig.add_subplot(2,2,3)\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 3')\n",
    "plt.legend(bbox_to_anchor = (2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
