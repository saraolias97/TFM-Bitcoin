{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense intervalos - datos 10 dias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run 10dias-porintervalos1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix,balanced_accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subida(list):\n",
    "    resultado = []\n",
    "    for i in range(1,len(list)):\n",
    "        if  (list)[i] > (list)[i-1]:\n",
    "            resultado.append(1)\n",
    "        else:\n",
    "            resultado.append(0)\n",
    "    return resultado\n",
    "\n",
    "def acierto(list1,list2):\n",
    "    sum = 0\n",
    "    for i in range(0,len(list1)):\n",
    "        if(list1[i]==list2[i]):\n",
    "            sum = sum +1\n",
    "    a = sum/len(list1)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 12, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 25)                850       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,065\n",
      "Trainable params: 9,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 2ms/step - loss: 1215.9388 - accuracy: 0.2122\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 178.9677 - accuracy: 0.3123\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 164.3412 - accuracy: 0.3137\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 106.0734 - accuracy: 0.3568\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 139.7979 - accuracy: 0.3707\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 95.5539 - accuracy: 0.4184\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 92.7619 - accuracy: 0.3826\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 90.2793 - accuracy: 0.4390\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 76.2393 - accuracy: 0.4456\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 87.3587 - accuracy: 0.4529\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 97.4178 - accuracy: 0.4284\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 66.0865 - accuracy: 0.4702\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 86.1353 - accuracy: 0.4430\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 77.5487 - accuracy: 0.4476\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 64.4659 - accuracy: 0.4622\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 66.0200 - accuracy: 0.4702\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 45.9770 - accuracy: 0.4794\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.2595 - accuracy: 0.5292\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.9540 - accuracy: 0.5119\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 36.7770 - accuracy: 0.5451\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.5326 - accuracy: 0.5086\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.8944 - accuracy: 0.5531\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42.7887 - accuracy: 0.5279\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.5988 - accuracy: 0.5285\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 39.1081 - accuracy: 0.5206\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 26.0118 - accuracy: 0.5497\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.7412 - accuracy: 0.5358\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.6298 - accuracy: 0.5332\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 22.3787 - accuracy: 0.5802\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 35.2401 - accuracy: 0.5219\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 23.5400 - accuracy: 0.5378\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 24.7397 - accuracy: 0.5245\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 21.9400 - accuracy: 0.5232\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.2758 - accuracy: 0.5285\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 39.2270 - accuracy: 0.4748\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.9164 - accuracy: 0.5332\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 28.8571 - accuracy: 0.5099\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.6274 - accuracy: 0.5458\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.1631 - accuracy: 0.5192\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.7128 - accuracy: 0.5504\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.7864 - accuracy: 0.5139\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 24.5374 - accuracy: 0.4901\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 22.4234 - accuracy: 0.4821\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 21.1701 - accuracy: 0.4907\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1337 - accuracy: 0.5232\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.8133 - accuracy: 0.5272\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.8600 - accuracy: 0.5259\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.3983 - accuracy: 0.4894\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7409 - accuracy: 0.5338\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.4943 - accuracy: 0.5292\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.5259 - accuracy: 0.5590\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6502 - accuracy: 0.5484\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.2724 - accuracy: 0.5438\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7109 - accuracy: 0.5584\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2523 - accuracy: 0.5564\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.0665 - accuracy: 0.5225\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.9741 - accuracy: 0.5119\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.6996 - accuracy: 0.5537\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.0960 - accuracy: 0.5146\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.2206 - accuracy: 0.5729\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.8317 - accuracy: 0.5550\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7478 - accuracy: 0.5424\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.3983 - accuracy: 0.5743\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.1654 - accuracy: 0.5590\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.0834 - accuracy: 0.5484\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7202 - accuracy: 0.5365\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.8496 - accuracy: 0.5497\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.5255 - accuracy: 0.5643\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.9791 - accuracy: 0.5729\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.2452 - accuracy: 0.5663\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1097 - accuracy: 0.5517\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.8370 - accuracy: 0.5451\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.5338 - accuracy: 0.5159\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2070 - accuracy: 0.5564\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.6813 - accuracy: 0.6054\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.0077 - accuracy: 0.5477\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.2472 - accuracy: 0.5849\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.3815 - accuracy: 0.5610\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5016 - accuracy: 0.5696\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.3592 - accuracy: 0.5789\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.1805 - accuracy: 0.5889\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.3052 - accuracy: 0.5875\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.3930 - accuracy: 0.5763\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.6003 - accuracy: 0.5802\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.1080 - accuracy: 0.5484\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.7590 - accuracy: 0.4761\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.9241 - accuracy: 0.5232\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.9024 - accuracy: 0.6001\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.3334 - accuracy: 0.5869\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.9136 - accuracy: 0.5398\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.8695 - accuracy: 0.5743\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.9234 - accuracy: 0.5955\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.2114 - accuracy: 0.5670\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.4280 - accuracy: 0.5676\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.4734 - accuracy: 0.5981\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.0396 - accuracy: 0.5663\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.6363 - accuracy: 0.5789\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.4363 - accuracy: 0.5550\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.3631 - accuracy: 0.5908\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1997 - accuracy: 0.5882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd5aa078c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5490716180371353\n",
      "Tasa de aciertos balanceada regresión logística: 0.55\n",
      "Matriz de confusión:\n",
      "[[59 15  2  1  0  0]\n",
      " [17 22 11 11  1  0]\n",
      " [11 10 19 29  3  0]\n",
      " [ 3  2  4 58 11  2]\n",
      " [ 0  0  1 21 23  7]\n",
      " [ 0  0  0  4  4 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.66      0.77      0.71        77\n",
      "         2.0       0.45      0.35      0.40        62\n",
      "         3.0       0.51      0.26      0.35        72\n",
      "         4.0       0.47      0.72      0.57        80\n",
      "         5.0       0.55      0.44      0.49        52\n",
      "         6.0       0.74      0.76      0.75        34\n",
      "\n",
      "    accuracy                           0.55       377\n",
      "   macro avg       0.56      0.55      0.54       377\n",
      "weighted avg       0.55      0.55      0.53       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 64)                832       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 21)                693       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                352       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,076\n",
      "Trainable params: 4,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 451.9370 - accuracy: 0.2188\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 95.4612 - accuracy: 0.2984\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 59.2752 - accuracy: 0.2944\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.0035 - accuracy: 0.3090\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.3819 - accuracy: 0.2719\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.4115 - accuracy: 0.2646\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.4104 - accuracy: 0.2507\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2086 - accuracy: 0.2367\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0500 - accuracy: 0.2407\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9534 - accuracy: 0.2314\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8539 - accuracy: 0.2334\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8123 - accuracy: 0.2281\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7775 - accuracy: 0.2314\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7609 - accuracy: 0.2832\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7468 - accuracy: 0.2871\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7444 - accuracy: 0.2845\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7342 - accuracy: 0.2878\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7355 - accuracy: 0.2838\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7253 - accuracy: 0.2858\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7316 - accuracy: 0.2765\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7288 - accuracy: 0.2812\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7143 - accuracy: 0.2798\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7518 - accuracy: 0.2672\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7693 - accuracy: 0.2792\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7357 - accuracy: 0.2686\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7122 - accuracy: 0.2832\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7251 - accuracy: 0.2865\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7073 - accuracy: 0.2991\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6853 - accuracy: 0.2958\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6848 - accuracy: 0.2924\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7696 - accuracy: 0.2871\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7390 - accuracy: 0.2540\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7225 - accuracy: 0.2659\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6998 - accuracy: 0.2772\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6866 - accuracy: 0.2845\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6542 - accuracy: 0.3031\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7039 - accuracy: 0.2686\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6814 - accuracy: 0.2891\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7038 - accuracy: 0.2825\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6887 - accuracy: 0.2759\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6871 - accuracy: 0.2759\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7355 - accuracy: 0.2838\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6691 - accuracy: 0.2838\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6379 - accuracy: 0.3031\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7099 - accuracy: 0.2838\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6769 - accuracy: 0.2752\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6546 - accuracy: 0.2891\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7766 - accuracy: 0.2732\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7409 - accuracy: 0.2513\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6469 - accuracy: 0.2653\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6352 - accuracy: 0.2964\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6224 - accuracy: 0.2938\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6407 - accuracy: 0.2885\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6226 - accuracy: 0.2977\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5958 - accuracy: 0.3117\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6098 - accuracy: 0.3097\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5922 - accuracy: 0.3130\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5572 - accuracy: 0.3362\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5508 - accuracy: 0.3375\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5783 - accuracy: 0.3210\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5487 - accuracy: 0.3336\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5258 - accuracy: 0.3435\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7857 - accuracy: 0.2493\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7162 - accuracy: 0.2367\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6973 - accuracy: 0.2401\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6910 - accuracy: 0.2427\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6880 - accuracy: 0.2473\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6665 - accuracy: 0.2580\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6313 - accuracy: 0.2798\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6298 - accuracy: 0.2812\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6443 - accuracy: 0.2951\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6562 - accuracy: 0.2765\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6306 - accuracy: 0.3150\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5265 - accuracy: 0.3767\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5043 - accuracy: 0.3700\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4629 - accuracy: 0.4105\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5441 - accuracy: 0.3667\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5684 - accuracy: 0.3462\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5785 - accuracy: 0.3243\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5331 - accuracy: 0.3501\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4575 - accuracy: 0.4131\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3507 - accuracy: 0.4257\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3440 - accuracy: 0.4231\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3623 - accuracy: 0.4224\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5354 - accuracy: 0.3700\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3927 - accuracy: 0.3720\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3738 - accuracy: 0.3866\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3435 - accuracy: 0.3826\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3582 - accuracy: 0.4118\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3606 - accuracy: 0.4105\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3490 - accuracy: 0.4111\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3021 - accuracy: 0.3999\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.2497 - accuracy: 0.4264\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3328 - accuracy: 0.4231\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3499 - accuracy: 0.3926\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6693 - accuracy: 0.2699\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6598 - accuracy: 0.2977\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4779 - accuracy: 0.4012\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4735 - accuracy: 0.3840\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4781 - accuracy: 0.3919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd5bf93408>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2519893899204244\n",
      "Tasa de aciertos balanceada regresión logística: 0.28\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0 77  0  0]\n",
      " [ 0  0  0 61  0  1]\n",
      " [ 0  0  2 68  0  2]\n",
      " [ 0  0  1 65  0 14]\n",
      " [ 0  0  0 29  0 23]\n",
      " [ 0  0  0  6  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.67      0.03      0.05        72\n",
      "         4.0       0.21      0.81      0.34        80\n",
      "         5.0       0.00      0.00      0.00        52\n",
      "         6.0       0.41      0.82      0.55        34\n",
      "\n",
      "    accuracy                           0.25       377\n",
      "   macro avg       0.22      0.28      0.16       377\n",
      "weighted avg       0.21      0.25      0.13       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 32)                416       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 11)                187       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,290\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 588.3517 - accuracy: 0.1054\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9422 - accuracy: 0.2520\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9234 - accuracy: 0.2520\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9156 - accuracy: 0.2520\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9079 - accuracy: 0.2520\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9008 - accuracy: 0.2520\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8937 - accuracy: 0.2520\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8872 - accuracy: 0.2520\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8810 - accuracy: 0.2520\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8750 - accuracy: 0.2520\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8694 - accuracy: 0.2520\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8642 - accuracy: 0.2520\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8591 - accuracy: 0.2520\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8544 - accuracy: 0.2520\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8499 - accuracy: 0.2520\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8459 - accuracy: 0.2520\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8419 - accuracy: 0.2520\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8383 - accuracy: 0.2520\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8349 - accuracy: 0.2520\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8317 - accuracy: 0.2520\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8286 - accuracy: 0.2520\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8257 - accuracy: 0.2520\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8230 - accuracy: 0.2520\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8204 - accuracy: 0.2520\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8178 - accuracy: 0.2520\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8155 - accuracy: 0.2520\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8133 - accuracy: 0.2520\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8111 - accuracy: 0.2520\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8091 - accuracy: 0.2520\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8071 - accuracy: 0.2520\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8052 - accuracy: 0.2520\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8035 - accuracy: 0.2520\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8017 - accuracy: 0.2520\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8002 - accuracy: 0.2520\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7987 - accuracy: 0.2520\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7971 - accuracy: 0.2520\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7957 - accuracy: 0.2520\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7943 - accuracy: 0.2520\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7929 - accuracy: 0.2520\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.2520\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7904 - accuracy: 0.2520\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7892 - accuracy: 0.2520\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7880 - accuracy: 0.2520\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7870 - accuracy: 0.2520\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7860 - accuracy: 0.2520\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7849 - accuracy: 0.2520\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7839 - accuracy: 0.2520\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7829 - accuracy: 0.2520\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7819 - accuracy: 0.2520\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7811 - accuracy: 0.2520\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7801 - accuracy: 0.2520\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7793 - accuracy: 0.2520\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7785 - accuracy: 0.2520\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7777 - accuracy: 0.2520\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7769 - accuracy: 0.2520\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7761 - accuracy: 0.2520\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7753 - accuracy: 0.2520\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7747 - accuracy: 0.2520\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7740 - accuracy: 0.2520\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7733 - accuracy: 0.2520\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7727 - accuracy: 0.2520\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7721 - accuracy: 0.2520\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7714 - accuracy: 0.2520\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7709 - accuracy: 0.2520\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7702 - accuracy: 0.2520\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7698 - accuracy: 0.2520\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7691 - accuracy: 0.2520\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7686 - accuracy: 0.2520\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7681 - accuracy: 0.2520\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7676 - accuracy: 0.2520\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7671 - accuracy: 0.2520\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7666 - accuracy: 0.2520\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7662 - accuracy: 0.2520\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7658 - accuracy: 0.2520\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7653 - accuracy: 0.2520\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7648 - accuracy: 0.2520\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7644 - accuracy: 0.2520\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7640 - accuracy: 0.2520\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7637 - accuracy: 0.2520\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7633 - accuracy: 0.2520\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7629 - accuracy: 0.2520\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7625 - accuracy: 0.2520\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7622 - accuracy: 0.2520\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7618 - accuracy: 0.2520\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7615 - accuracy: 0.2520\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7611 - accuracy: 0.2520\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7608 - accuracy: 0.2520\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7605 - accuracy: 0.2520\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7602 - accuracy: 0.2520\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7600 - accuracy: 0.2520\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.7596 - accuracy: 0.2520\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7593 - accuracy: 0.2520\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7590 - accuracy: 0.2520\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7587 - accuracy: 0.2520\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7585 - accuracy: 0.2520\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7582 - accuracy: 0.2520\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7580 - accuracy: 0.2520\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7577 - accuracy: 0.2520\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7574 - accuracy: 0.2520\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7572 - accuracy: 0.2520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd5d1bd908>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.09018567639257294\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[59 15  2  1  0  0]\n",
      " [17 22 11 11  1  0]\n",
      " [11 10 19 29  3  0]\n",
      " [ 3  2  4 58 11  2]\n",
      " [ 0  0  1 21 23  7]\n",
      " [ 0  0  0  4  4 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        52\n",
      "         6.0       0.09      1.00      0.17        34\n",
      "\n",
      "    accuracy                           0.09       377\n",
      "   macro avg       0.02      0.17      0.03       377\n",
      "weighted avg       0.01      0.09      0.01       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 12, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,357\n",
      "Trainable params: 19,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 11.7323 - accuracy: 0.1585\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.2975 - accuracy: 0.1771\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.9880 - accuracy: 0.1830\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4217 - accuracy: 0.1678\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6822 - accuracy: 0.1631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd5d8bb908>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.20424403183023873\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[77  0  0  0  0  0]\n",
      " [62  0  0  0  0  0]\n",
      " [72  0  0  0  0  0]\n",
      " [80  0  0  0  0  0]\n",
      " [52  0  0  0  0  0]\n",
      " [34  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      1.00      0.34        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        52\n",
      "         6.0       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.20       377\n",
      "   macro avg       0.03      0.17      0.06       377\n",
      "weighted avg       0.04      0.20      0.07       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 64)                832       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,359\n",
      "Trainable params: 8,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 6.8295 - accuracy: 0.1744\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.0669 - accuracy: 0.1704\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7939 - accuracy: 0.1200\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5502 - accuracy: 0.1134\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5397 - accuracy: 0.1134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd5ebdb508>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1856763925729443\n",
      "Tasa de aciertos balanceada regresión logística: 0.18\n",
      "Matriz de confusión:\n",
      "[[ 0 72  5  0  0  0]\n",
      " [ 0 55  7  0  0  0]\n",
      " [ 0 57 15  0  0  0]\n",
      " [ 0 61 19  0  0  0]\n",
      " [ 0 44  8  0  0  0]\n",
      " [ 0 31  3  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.17      0.89      0.29        62\n",
      "         3.0       0.26      0.21      0.23        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        52\n",
      "         6.0       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.19       377\n",
      "   macro avg       0.07      0.18      0.09       377\n",
      "weighted avg       0.08      0.19      0.09       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 32)                416       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,391\n",
      "Trainable params: 2,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 11.3860 - accuracy: 0.1306\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4865 - accuracy: 0.1220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd600b1988>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.16180371352785147\n",
      "Tasa de aciertos balanceada regresión logística: 0.16\n",
      "Matriz de confusión:\n",
      "[[77  0  0  0  0  0]\n",
      " [62  0  0  0  0  0]\n",
      " [72  0  0  0  0  0]\n",
      " [80  0  0  0  0  0]\n",
      " [52  0  0  0  0  0]\n",
      " [34  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.12      0.21      0.15        77\n",
      "         2.0       0.19      0.73      0.30        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        52\n",
      "         6.0       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.16       377\n",
      "   macro avg       0.05      0.16      0.07       377\n",
      "weighted avg       0.05      0.16      0.08       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 12, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 25)                850       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 20)                520       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 17)                357       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 14)                252       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 12)                180       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 11)                143       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,419\n",
      "Trainable params: 10,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 12.5678 - accuracy: 0.0146\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.7497 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd60604fc8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [77  0  0  0  0  0  0]\n",
      " [62  0  0  0  0  0  0]\n",
      " [72  0  0  0  0  0  0]\n",
      " [80  0  0  0  0  0  0]\n",
      " [52  0  0  0  0  0  0]\n",
      " [34  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00      62.0\n",
      "         3.0       0.00      0.00      0.00      72.0\n",
      "         4.0       0.00      0.00      0.00      80.0\n",
      "         5.0       0.00      0.00      0.00      52.0\n",
      "         6.0       0.00      0.00      0.00      34.0\n",
      "\n",
      "    accuracy                           0.00     377.0\n",
      "   macro avg       0.00      0.00      0.00     377.0\n",
      "weighted avg       0.00      0.00      0.00     377.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 64)                832       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 21)                693       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 16)                352       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 13)                221       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 11)                154       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,639\n",
      "Trainable params: 4,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8100 - accuracy: 0.2520\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8100 - accuracy: 0.2520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd618eac88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.09018567639257294\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0 77]\n",
      " [ 0  0  0  0  0 62]\n",
      " [ 0  0  0  0  0 72]\n",
      " [ 0  0  0  0  0 80]\n",
      " [ 0  0  0  0  0 52]\n",
      " [ 0  0  0  0  0 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        52\n",
      "         6.0       0.09      1.00      0.17        34\n",
      "\n",
      "    accuracy                           0.09       377\n",
      "   macro avg       0.02      0.17      0.03       377\n",
      "weighted avg       0.01      0.09      0.01       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 32)                416       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 11)                187       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,425\n",
      "Trainable params: 1,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 2ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2740 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd62e4e548>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [77  0  0  0  0  0  0]\n",
      " [62  0  0  0  0  0  0]\n",
      " [72  0  0  0  0  0  0]\n",
      " [80  0  0  0  0  0  0]\n",
      " [52  0  0  0  0  0  0]\n",
      " [34  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00      62.0\n",
      "         3.0       0.00      0.00      0.00      72.0\n",
      "         4.0       0.00      0.00      0.00      80.0\n",
      "         5.0       0.00      0.00      0.00      52.0\n",
      "         6.0       0.00      0.00      0.00      34.0\n",
      "\n",
      "    accuracy                           0.00     377.0\n",
      "   macro avg       0.00      0.00      0.00     377.0\n",
      "weighted avg       0.00      0.00      0.00     377.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 25)                850       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,065\n",
      "Trainable params: 9,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 1959.0240 - accuracy: 0.1883\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 919.3713 - accuracy: 0.2248\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 528.3305 - accuracy: 0.2354\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 374.1447 - accuracy: 0.2513\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 301.9269 - accuracy: 0.2666\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 259.5494 - accuracy: 0.2765\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 217.9481 - accuracy: 0.2792\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 185.2930 - accuracy: 0.2679\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 162.0975 - accuracy: 0.2752\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 145.6564 - accuracy: 0.2905\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 132.0091 - accuracy: 0.3017\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 118.2380 - accuracy: 0.3057\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 108.6141 - accuracy: 0.2924\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 99.7995 - accuracy: 0.3196\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 89.8170 - accuracy: 0.3435\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 82.7074 - accuracy: 0.3601\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 73.3630 - accuracy: 0.3707\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 68.4809 - accuracy: 0.3581\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 62.5495 - accuracy: 0.3740\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 55.6361 - accuracy: 0.3853\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 53.4419 - accuracy: 0.3773\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 45.6124 - accuracy: 0.3866\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42.5723 - accuracy: 0.3806\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 40.1757 - accuracy: 0.3840\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 36.0326 - accuracy: 0.4005\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.8367 - accuracy: 0.3972\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.0140 - accuracy: 0.4025\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.0195 - accuracy: 0.4098\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.8106 - accuracy: 0.4151\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.1050 - accuracy: 0.4058\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 28.2046 - accuracy: 0.4211\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 28.6635 - accuracy: 0.4138\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.9087 - accuracy: 0.4218\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.9094 - accuracy: 0.4257\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.7277 - accuracy: 0.4290\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.6456 - accuracy: 0.4284\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.3414 - accuracy: 0.4377\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.6043 - accuracy: 0.4370\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.0980 - accuracy: 0.4277\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.7585 - accuracy: 0.4403\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.7106 - accuracy: 0.4483\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.6857 - accuracy: 0.4383\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.9043 - accuracy: 0.4231\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.7560 - accuracy: 0.4523\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.1605 - accuracy: 0.4483\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.3591 - accuracy: 0.4271\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.4789 - accuracy: 0.4496\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.9028 - accuracy: 0.4430\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.2339 - accuracy: 0.4390\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.7126 - accuracy: 0.4576\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.7208 - accuracy: 0.4503\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.7772 - accuracy: 0.4728\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.3953 - accuracy: 0.4556\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.7514 - accuracy: 0.4609\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.2443 - accuracy: 0.4595\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.3433 - accuracy: 0.4562\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.9833 - accuracy: 0.4483\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.8196 - accuracy: 0.4635\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.4244 - accuracy: 0.4562\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 18.2777 - accuracy: 0.4569\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.2666 - accuracy: 0.4609\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.5087 - accuracy: 0.4602\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.8374 - accuracy: 0.4569\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.3906 - accuracy: 0.4721\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.2377 - accuracy: 0.4569\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.7530 - accuracy: 0.4629\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.3040 - accuracy: 0.4609\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.9472 - accuracy: 0.4549\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.4895 - accuracy: 0.4622\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5286 - accuracy: 0.4556\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.9015 - accuracy: 0.4556\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.2682 - accuracy: 0.4755\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.2458 - accuracy: 0.4781\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.0881 - accuracy: 0.4622\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.5802 - accuracy: 0.4695\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.0119 - accuracy: 0.4556\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.8872 - accuracy: 0.4542\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9986 - accuracy: 0.4642\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.4796 - accuracy: 0.4715\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.8400 - accuracy: 0.4642\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.1501 - accuracy: 0.4761\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.8916 - accuracy: 0.4682\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.6763 - accuracy: 0.4741\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1750 - accuracy: 0.4841\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.6611 - accuracy: 0.4881\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.2896 - accuracy: 0.4748\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.8718 - accuracy: 0.4834\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.3926 - accuracy: 0.4755\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.8621 - accuracy: 0.4881\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.2035 - accuracy: 0.4775\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.5990 - accuracy: 0.4881\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.7842 - accuracy: 0.4721\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7950 - accuracy: 0.4761\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.0997 - accuracy: 0.4748\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.6810 - accuracy: 0.4768\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.9926 - accuracy: 0.4861\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.4878 - accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.3136 - accuracy: 0.4894\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.3341 - accuracy: 0.4828\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.8967 - accuracy: 0.4702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd64422888>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4350132625994695\n",
      "Tasa de aciertos balanceada regresión logística: 0.39\n",
      "Matriz de confusión:\n",
      "[[64  4  2  7  0  0]\n",
      " [24  7 14 17  0  0]\n",
      " [11  2 24 31  2  2]\n",
      " [ 4  2 16 52  3  3]\n",
      " [ 1  0  9 25 10  7]\n",
      " [ 0  0  2 10 15  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.62      0.83      0.71        77\n",
      "         2.0       0.47      0.11      0.18        62\n",
      "         3.0       0.36      0.33      0.35        72\n",
      "         4.0       0.37      0.65      0.47        80\n",
      "         5.0       0.33      0.19      0.24        52\n",
      "         6.0       0.37      0.21      0.26        34\n",
      "\n",
      "    accuracy                           0.44       377\n",
      "   macro avg       0.42      0.39      0.37       377\n",
      "weighted avg       0.43      0.44      0.40       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_65 (Dense)            (None, 64)                832       \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 21)                693       \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 16)                352       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,076\n",
      "Trainable params: 4,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 2335.3354 - accuracy: 0.1419\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1280.3840 - accuracy: 0.1824\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 834.3569 - accuracy: 0.1983\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 651.7596 - accuracy: 0.2221\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 532.8829 - accuracy: 0.2361\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 454.9132 - accuracy: 0.2454\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 398.4997 - accuracy: 0.2454\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 340.6414 - accuracy: 0.2546\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 300.2159 - accuracy: 0.2546\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 263.7006 - accuracy: 0.2586\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 234.0707 - accuracy: 0.2672\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 211.4716 - accuracy: 0.2540\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 192.7259 - accuracy: 0.2586\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 176.7166 - accuracy: 0.2646\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 163.6528 - accuracy: 0.2653\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 153.2670 - accuracy: 0.2679\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 144.4538 - accuracy: 0.2639\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 138.2600 - accuracy: 0.2699\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 132.1855 - accuracy: 0.2745\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 128.1294 - accuracy: 0.2891\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 124.0470 - accuracy: 0.2891\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 117.4484 - accuracy: 0.3031\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 112.6378 - accuracy: 0.3123\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 108.6175 - accuracy: 0.3070\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 104.9918 - accuracy: 0.3163\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 101.2975 - accuracy: 0.3190\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 98.5471 - accuracy: 0.3216\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 95.3763 - accuracy: 0.3223\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 92.1571 - accuracy: 0.3196\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 89.4559 - accuracy: 0.3223\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 87.0517 - accuracy: 0.3355\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 84.1743 - accuracy: 0.3362\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 81.5767 - accuracy: 0.3501\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 79.6119 - accuracy: 0.3488\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 77.8602 - accuracy: 0.3488\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 76.1528 - accuracy: 0.3541\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 74.3901 - accuracy: 0.3548\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 73.6637 - accuracy: 0.3641\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 72.4236 - accuracy: 0.3740\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 70.9256 - accuracy: 0.3707\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 70.0593 - accuracy: 0.3753\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 69.5117 - accuracy: 0.3720\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 68.4657 - accuracy: 0.3733\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 67.4085 - accuracy: 0.3773\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 66.5256 - accuracy: 0.3747\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 65.7912 - accuracy: 0.3674\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 64.7809 - accuracy: 0.3899\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 64.0279 - accuracy: 0.3826\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 63.3454 - accuracy: 0.3813\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 62.9415 - accuracy: 0.3800\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 62.0976 - accuracy: 0.3826\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 61.2669 - accuracy: 0.3879\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 60.2821 - accuracy: 0.3952\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 59.9582 - accuracy: 0.3873\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 59.3548 - accuracy: 0.3966\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 58.6892 - accuracy: 0.3952\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 58.2835 - accuracy: 0.3853\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 57.5541 - accuracy: 0.3806\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 56.9538 - accuracy: 0.3919\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 56.5903 - accuracy: 0.3853\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 55.9038 - accuracy: 0.3939\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 55.4152 - accuracy: 0.3859\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 55.1962 - accuracy: 0.3893\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 55.4044 - accuracy: 0.3813\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 53.8829 - accuracy: 0.3886\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 53.6013 - accuracy: 0.3979\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 53.1741 - accuracy: 0.3906\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 52.9635 - accuracy: 0.3826\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 52.3029 - accuracy: 0.3793\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 51.8204 - accuracy: 0.3952\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 51.5101 - accuracy: 0.3866\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 50.9343 - accuracy: 0.3899\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 50.6572 - accuracy: 0.3840\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 50.1797 - accuracy: 0.3939\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 49.9734 - accuracy: 0.3893\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 49.6765 - accuracy: 0.3919\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 49.1779 - accuracy: 0.3853\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 48.8559 - accuracy: 0.3780\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 48.6577 - accuracy: 0.3866\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 48.3753 - accuracy: 0.3906\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 47.7993 - accuracy: 0.3859\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 47.5021 - accuracy: 0.3906\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 47.1799 - accuracy: 0.3879\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.7018 - accuracy: 0.3899\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.4665 - accuracy: 0.3873\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.2399 - accuracy: 0.3840\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 45.9481 - accuracy: 0.3899\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 45.5315 - accuracy: 0.3906\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 45.6453 - accuracy: 0.3972\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 45.1393 - accuracy: 0.3866\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.6589 - accuracy: 0.3899\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.6447 - accuracy: 0.3859\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.0586 - accuracy: 0.3946\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43.9779 - accuracy: 0.3879\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43.7769 - accuracy: 0.3972\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 43.2515 - accuracy: 0.3966\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43.1754 - accuracy: 0.3932\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42.8437 - accuracy: 0.3946\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42.5372 - accuracy: 0.3906\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42.3100 - accuracy: 0.4038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd647f2848>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.35278514588859416\n",
      "Tasa de aciertos balanceada regresión logística: 0.36\n",
      "Matriz de confusión:\n",
      "[[52 13  5  1  2  4]\n",
      " [13 17  9  8 11  4]\n",
      " [ 3 15 19 17 14  4]\n",
      " [ 6  4 30 15 10 15]\n",
      " [ 0  0 12 10 14 16]\n",
      " [ 0  0  5  6  7 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.70      0.68      0.69        77\n",
      "         2.0       0.35      0.27      0.31        62\n",
      "         3.0       0.24      0.26      0.25        72\n",
      "         4.0       0.26      0.19      0.22        80\n",
      "         5.0       0.24      0.27      0.25        52\n",
      "         6.0       0.27      0.47      0.34        34\n",
      "\n",
      "    accuracy                           0.35       377\n",
      "   macro avg       0.34      0.36      0.34       377\n",
      "weighted avg       0.36      0.35      0.35       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_70 (Dense)            (None, 32)                416       \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 11)                187       \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,290\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 5488.2095 - accuracy: 0.2520\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2826.0266 - accuracy: 0.2401\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2047.8149 - accuracy: 0.2779\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1642.5941 - accuracy: 0.3044\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1320.0957 - accuracy: 0.3070\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1045.8591 - accuracy: 0.3044\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 822.2263 - accuracy: 0.3183\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 631.9216 - accuracy: 0.2931\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 454.5435 - accuracy: 0.2785\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 309.7819 - accuracy: 0.2679\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 204.4436 - accuracy: 0.2546\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 125.7990 - accuracy: 0.2089\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 81.0926 - accuracy: 0.1950\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.6389 - accuracy: 0.1877\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.3910 - accuracy: 0.2023\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.8918 - accuracy: 0.2115\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.4050 - accuracy: 0.2056\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.9217 - accuracy: 0.2082\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.9744 - accuracy: 0.2069\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.4606 - accuracy: 0.2009\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.1250 - accuracy: 0.1963\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0636 - accuracy: 0.1956\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.1992 - accuracy: 0.1969\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.4851 - accuracy: 0.1930\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.8281 - accuracy: 0.1943\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1788 - accuracy: 0.1910\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.6438 - accuracy: 0.1857\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.2225 - accuracy: 0.1877\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8038 - accuracy: 0.1870\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.4347 - accuracy: 0.1943\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.1841 - accuracy: 0.1883\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.9488 - accuracy: 0.1950\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6837 - accuracy: 0.1923\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.4976 - accuracy: 0.1950\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.3056 - accuracy: 0.1930\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.1051 - accuracy: 0.1923\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.9111 - accuracy: 0.1936\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.7414 - accuracy: 0.1930\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.5907 - accuracy: 0.1903\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.4446 - accuracy: 0.1897\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.3203 - accuracy: 0.1903\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.1674 - accuracy: 0.1923\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.0043 - accuracy: 0.1903\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.8625 - accuracy: 0.1930\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7558 - accuracy: 0.1903\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.6305 - accuracy: 0.1916\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5251 - accuracy: 0.1903\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.4186 - accuracy: 0.1910\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.3559 - accuracy: 0.1910\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.3197 - accuracy: 0.1916\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2861 - accuracy: 0.1916\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2781 - accuracy: 0.1903\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2366 - accuracy: 0.1890\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2211 - accuracy: 0.1890\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1793 - accuracy: 0.1883\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1475 - accuracy: 0.1877\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.1281 - accuracy: 0.1877\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1054 - accuracy: 0.1870\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0947 - accuracy: 0.1870\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1225 - accuracy: 0.1850\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0782 - accuracy: 0.1863\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0734 - accuracy: 0.1857\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0664 - accuracy: 0.1857\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0608 - accuracy: 0.1857\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0431 - accuracy: 0.1857\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0410 - accuracy: 0.1844\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0515 - accuracy: 0.1844\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0454 - accuracy: 0.1850\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0319 - accuracy: 0.1850\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0374 - accuracy: 0.1844\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0294 - accuracy: 0.1850\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0218 - accuracy: 0.1844\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0212 - accuracy: 0.1844\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0192 - accuracy: 0.1850\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9950 - accuracy: 0.1844\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0033 - accuracy: 0.1850\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9897 - accuracy: 0.1850\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9841 - accuracy: 0.1844\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9808 - accuracy: 0.1844\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9767 - accuracy: 0.1844\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9741 - accuracy: 0.1844\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9708 - accuracy: 0.1837\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9665 - accuracy: 0.1844\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9487 - accuracy: 0.1837\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9454 - accuracy: 0.1837\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9362 - accuracy: 0.1844\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9347 - accuracy: 0.1844\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9332 - accuracy: 0.1844\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9327 - accuracy: 0.1844\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9318 - accuracy: 0.1844\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9318 - accuracy: 0.1844\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9298 - accuracy: 0.1844\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9311 - accuracy: 0.1844\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9295 - accuracy: 0.1844\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9285 - accuracy: 0.1844\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9285 - accuracy: 0.1844\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9265 - accuracy: 0.1844\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9274 - accuracy: 0.1844\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9255 - accuracy: 0.1844\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9255 - accuracy: 0.1844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd65b86648>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.19363395225464192\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[64  4  2  7  0  0]\n",
      " [24  7 14 17  0  0]\n",
      " [11  2 24 31  2  2]\n",
      " [ 4  2 16 52  3  3]\n",
      " [ 1  0  9 25 10  7]\n",
      " [ 0  0  2 10 15  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.01      0.03        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.19      1.00      0.32        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        52\n",
      "         6.0       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.19       377\n",
      "   macro avg       0.20      0.17      0.06       377\n",
      "weighted avg       0.24      0.19      0.07       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_75 (Dense)            (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,357\n",
      "Trainable params: 19,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 12.9183 - accuracy: 0.0245\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4035 - accuracy: 0.0279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd603e6988>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0636604774535809\n",
      "Tasa de aciertos balanceada regresión logística: 0.05\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [26  0  0  0 51  0  0]\n",
      " [23  0  0  0 39  0  0]\n",
      " [35  0  0  0 37  0  0]\n",
      " [56  0  0  0 24  0  0]\n",
      " [24  0  0  0 28  0  0]\n",
      " [10  0  0  0 24  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.12      0.30      0.17        80\n",
      "         5.0       0.00      0.00      0.00        52\n",
      "         6.0       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.06       377\n",
      "   macro avg       0.02      0.04      0.02       377\n",
      "weighted avg       0.03      0.06      0.04       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 64)                832       \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,359\n",
      "Trainable params: 8,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 11.1788 - accuracy: 0.0975\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.6228 - accuracy: 0.0975\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6717 - accuracy: 0.0975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd66045208>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.16445623342175067\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0 77  0  0  0  0]\n",
      " [ 0 62  0  0  0  0]\n",
      " [ 0 72  0  0  0  0]\n",
      " [ 0 80  0  0  0  0]\n",
      " [ 0 52  0  0  0  0]\n",
      " [ 0 34  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.16      1.00      0.28        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        52\n",
      "         6.0       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.16       377\n",
      "   macro avg       0.03      0.17      0.05       377\n",
      "weighted avg       0.03      0.16      0.05       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_85 (Dense)            (None, 32)                416       \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,391\n",
      "Trainable params: 2,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 6.0826 - accuracy: 0.2520\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1111 - accuracy: 0.2520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd672ed808>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.09018567639257294\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [26  0  0  0 51  0  0]\n",
      " [23  0  0  0 39  0  0]\n",
      " [35  0  0  0 37  0  0]\n",
      " [56  0  0  0 24  0  0]\n",
      " [24  0  0  0 28  0  0]\n",
      " [10  0  0  0 24  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        52\n",
      "         6.0       0.09      1.00      0.17        34\n",
      "\n",
      "    accuracy                           0.09       377\n",
      "   macro avg       0.02      0.17      0.03       377\n",
      "weighted avg       0.01      0.09      0.01       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 25)                850       \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 20)                520       \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 17)                357       \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 14)                252       \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 12)                180       \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 11)                143       \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,419\n",
      "Trainable params: 10,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 8.6695 - accuracy: 0.1194\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.3532 - accuracy: 0.1293\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.2097 - accuracy: 0.1227\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.6235 - accuracy: 0.1021\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.5675 - accuracy: 0.1127\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7603 - accuracy: 0.1107\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.8049 - accuracy: 0.1121\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.1956 - accuracy: 0.0995\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.5942 - accuracy: 0.1008\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.3750 - accuracy: 0.1008\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.5090 - accuracy: 0.1001\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.5090 - accuracy: 0.1001\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.5089 - accuracy: 0.1001\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.5292 - accuracy: 0.0995\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6763 - accuracy: 0.1200\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7389 - accuracy: 0.1260\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7389 - accuracy: 0.1260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd67760908>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07161803713527852\n",
      "Tasa de aciertos balanceada regresión logística: 0.06\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [50 27  0  0  0  0  0]\n",
      " [40 22  0  0  0  0  0]\n",
      " [38 34  0  0  0  0  0]\n",
      " [25 55  0  0  0  0  0]\n",
      " [29 23  0  0  0  0  0]\n",
      " [27  7  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.16      0.35      0.22        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        52\n",
      "         6.0       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.07       377\n",
      "   macro avg       0.02      0.05      0.03       377\n",
      "weighted avg       0.03      0.07      0.05       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,639\n",
      "Trainable params: 4,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 14.9419 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9120 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd68c7c708>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [77  0  0  0  0  0  0]\n",
      " [62  0  0  0  0  0  0]\n",
      " [72  0  0  0  0  0  0]\n",
      " [80  0  0  0  0  0  0]\n",
      " [52  0  0  0  0  0  0]\n",
      " [34  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00      62.0\n",
      "         3.0       0.00      0.00      0.00      72.0\n",
      "         4.0       0.00      0.00      0.00      80.0\n",
      "         5.0       0.00      0.00      0.00      52.0\n",
      "         6.0       0.00      0.00      0.00      34.0\n",
      "\n",
      "    accuracy                           0.00     377.0\n",
      "   macro avg       0.00      0.00      0.00     377.0\n",
      "weighted avg       0.00      0.00      0.00     377.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_110 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,425\n",
      "Trainable params: 1,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 12.1254 - accuracy: 0.1698\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.7012 - accuracy: 0.1578\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5184 - accuracy: 0.1545\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5184 - accuracy: 0.1545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd6a0e1a08>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.15119363395225463\n",
      "Tasa de aciertos balanceada regresión logística: 0.13\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [50 27  0  0  0  0  0]\n",
      " [40 22  0  0  0  0  0]\n",
      " [38 34  0  0  0  0  0]\n",
      " [25 55  0  0  0  0  0]\n",
      " [29 23  0  0  0  0  0]\n",
      " [27  7  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.18      0.79      0.29        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        52\n",
      "         6.0       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.15       377\n",
      "   macro avg       0.03      0.11      0.04       377\n",
      "weighted avg       0.03      0.15      0.05       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 22, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,065\n",
      "Trainable params: 10,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 723.4658 - accuracy: 0.1817\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 153.6269 - accuracy: 0.2063\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 99.5089 - accuracy: 0.2835\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 110.5962 - accuracy: 0.3115\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 76.5766 - accuracy: 0.3176\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 70.2117 - accuracy: 0.3689\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.3405 - accuracy: 0.3695\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.5771 - accuracy: 0.3675\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.5764 - accuracy: 0.4488\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.9146 - accuracy: 0.4030\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.4200 - accuracy: 0.4242\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.3633 - accuracy: 0.4372\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.6726 - accuracy: 0.4413\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.5030 - accuracy: 0.4208\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.0563 - accuracy: 0.4652\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.7389 - accuracy: 0.4829\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.8598 - accuracy: 0.4604\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.9918 - accuracy: 0.5075\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.1632 - accuracy: 0.5055\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.8753 - accuracy: 0.4754\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.7443 - accuracy: 0.4959\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.6921 - accuracy: 0.4488\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.4775 - accuracy: 0.4501\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.4091 - accuracy: 0.4740\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.5381 - accuracy: 0.4857\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.7300 - accuracy: 0.4686\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.4486 - accuracy: 0.4843\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.0769 - accuracy: 0.5041\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.0249 - accuracy: 0.5198\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.6970 - accuracy: 0.4686\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.1553 - accuracy: 0.5389\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1379 - accuracy: 0.5102\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.9650 - accuracy: 0.5205\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.3651 - accuracy: 0.5219\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.4525 - accuracy: 0.5451\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0034 - accuracy: 0.5403\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2896 - accuracy: 0.5622\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6608 - accuracy: 0.5512\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9269 - accuracy: 0.5642\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9689 - accuracy: 0.5799\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3520 - accuracy: 0.5779\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7153 - accuracy: 0.5847\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8526 - accuracy: 0.5786\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2177 - accuracy: 0.5478\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0987 - accuracy: 0.5027\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2407 - accuracy: 0.5403\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1448 - accuracy: 0.5485\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8226 - accuracy: 0.5663\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2769 - accuracy: 0.5635\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9756 - accuracy: 0.5704\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3142 - accuracy: 0.5253\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0385 - accuracy: 0.5219\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4796 - accuracy: 0.5601\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5250 - accuracy: 0.5731\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6815 - accuracy: 0.4966\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1521 - accuracy: 0.5615\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3267 - accuracy: 0.5451\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8685 - accuracy: 0.5717\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4909 - accuracy: 0.5731\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.7333 - accuracy: 0.5116\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7184 - accuracy: 0.5656\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8896 - accuracy: 0.5676\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6437 - accuracy: 0.6113\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5596 - accuracy: 0.5731\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1615 - accuracy: 0.5847\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5042 - accuracy: 0.5669\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9451 - accuracy: 0.5867\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8981 - accuracy: 0.5581\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6603 - accuracy: 0.5936\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0705 - accuracy: 0.5601\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0815 - accuracy: 0.5717\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0775 - accuracy: 0.5505\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4839 - accuracy: 0.6107\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5812 - accuracy: 0.6086\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6675 - accuracy: 0.5990\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6665 - accuracy: 0.6127\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0873 - accuracy: 0.6230\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6345 - accuracy: 0.5704\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7752 - accuracy: 0.5478\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6319 - accuracy: 0.6018\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2962 - accuracy: 0.5806\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0354 - accuracy: 0.5690\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4587 - accuracy: 0.5307\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.4373 - accuracy: 0.5102\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3023 - accuracy: 0.5423\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3451 - accuracy: 0.5833\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7922 - accuracy: 0.5881\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6128 - accuracy: 0.5922\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2581 - accuracy: 0.5444\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9445 - accuracy: 0.5526\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2808 - accuracy: 0.5683\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4815 - accuracy: 0.5581\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2640 - accuracy: 0.5908\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1103 - accuracy: 0.6291\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6920 - accuracy: 0.5772\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4788 - accuracy: 0.5820\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3355 - accuracy: 0.5915\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0133 - accuracy: 0.5430\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4462 - accuracy: 0.5355\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0091 - accuracy: 0.5260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd6b628b48>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.40437158469945356\n",
      "Tasa de aciertos balanceada regresión logística: 0.42\n",
      "Matriz de confusión:\n",
      "[[71  6  0  0  0  0]\n",
      " [41 21  0  0  0  0]\n",
      " [26 39  5  2  0  0]\n",
      " [ 5 29 11 26  2  7]\n",
      " [ 3  7  2 20  3 12]\n",
      " [ 0  2  0  2  2 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.49      0.92      0.64        77\n",
      "         2.0       0.20      0.34      0.25        62\n",
      "         3.0       0.28      0.07      0.11        72\n",
      "         4.0       0.52      0.33      0.40        80\n",
      "         5.0       0.43      0.06      0.11        47\n",
      "         6.0       0.54      0.79      0.64        28\n",
      "\n",
      "    accuracy                           0.40       366\n",
      "   macro avg       0.41      0.42      0.36       366\n",
      "weighted avg       0.40      0.40      0.35       366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_125 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,716\n",
      "Trainable params: 4,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 858.9103 - accuracy: 0.1633\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1975 - accuracy: 0.2445\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9252 - accuracy: 0.2466\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9152 - accuracy: 0.2466\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9055 - accuracy: 0.2466\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8965 - accuracy: 0.2466\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8878 - accuracy: 0.2466\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8800 - accuracy: 0.2466\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8726 - accuracy: 0.2466\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8658 - accuracy: 0.2466\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8596 - accuracy: 0.2466\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8538 - accuracy: 0.2466\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8484 - accuracy: 0.2466\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8436 - accuracy: 0.2466\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8390 - accuracy: 0.2466\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8347 - accuracy: 0.2466\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8308 - accuracy: 0.2466\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8272 - accuracy: 0.2466\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8239 - accuracy: 0.2466\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8207 - accuracy: 0.2466\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8177 - accuracy: 0.2466\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8150 - accuracy: 0.2466\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8124 - accuracy: 0.2466\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8100 - accuracy: 0.2466\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8077 - accuracy: 0.2466\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8056 - accuracy: 0.2466\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8036 - accuracy: 0.2466\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8016 - accuracy: 0.2466\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7999 - accuracy: 0.2466\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7981 - accuracy: 0.2466\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7965 - accuracy: 0.2466\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7948 - accuracy: 0.2466\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7934 - accuracy: 0.2466\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7920 - accuracy: 0.2466\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7906 - accuracy: 0.2466\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7894 - accuracy: 0.2466\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7881 - accuracy: 0.2466\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7869 - accuracy: 0.2466\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7857 - accuracy: 0.2466\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7847 - accuracy: 0.2466\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7836 - accuracy: 0.2466\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7826 - accuracy: 0.2466\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7816 - accuracy: 0.2466\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7807 - accuracy: 0.2466\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7798 - accuracy: 0.2466\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7789 - accuracy: 0.2466\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7780 - accuracy: 0.2466\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7772 - accuracy: 0.2466\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7764 - accuracy: 0.2466\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7757 - accuracy: 0.2466\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7750 - accuracy: 0.2466\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7742 - accuracy: 0.2466\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7736 - accuracy: 0.2466\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7730 - accuracy: 0.2466\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7723 - accuracy: 0.2466\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7716 - accuracy: 0.2466\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7710 - accuracy: 0.2466\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7705 - accuracy: 0.2466\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7700 - accuracy: 0.2466\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7694 - accuracy: 0.2466\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7688 - accuracy: 0.2466\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7683 - accuracy: 0.2466\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7678 - accuracy: 0.2466\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7674 - accuracy: 0.2466\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7669 - accuracy: 0.2466\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7665 - accuracy: 0.2466\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7660 - accuracy: 0.2466\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7655 - accuracy: 0.2466\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7651 - accuracy: 0.2466\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7646 - accuracy: 0.2466\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7643 - accuracy: 0.2466\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7639 - accuracy: 0.2466\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7635 - accuracy: 0.2466\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7631 - accuracy: 0.2466\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7628 - accuracy: 0.2466\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7624 - accuracy: 0.2466\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7622 - accuracy: 0.2466\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7618 - accuracy: 0.2466\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7615 - accuracy: 0.2466\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7612 - accuracy: 0.2466\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7609 - accuracy: 0.2466\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7606 - accuracy: 0.2466\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7603 - accuracy: 0.2466\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7600 - accuracy: 0.2466\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7597 - accuracy: 0.2466\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7594 - accuracy: 0.2466\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7592 - accuracy: 0.2466\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7589 - accuracy: 0.2466\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7587 - accuracy: 0.2466\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7584 - accuracy: 0.2466\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7582 - accuracy: 0.2466\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7580 - accuracy: 0.2466\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7577 - accuracy: 0.2466\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7575 - accuracy: 0.2466\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7573 - accuracy: 0.2466\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7571 - accuracy: 0.2466\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7569 - accuracy: 0.2466\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7566 - accuracy: 0.2466\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7565 - accuracy: 0.2466\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7563 - accuracy: 0.2466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd64803108>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07650273224043716\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0 77]\n",
      " [ 0  0  0  0  0 62]\n",
      " [ 0  0  0  0  0 72]\n",
      " [ 0  0  0  0  0 80]\n",
      " [ 0  0  0  0  0 47]\n",
      " [ 0  0  0  0  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.08      1.00      0.14        28\n",
      "\n",
      "    accuracy                           0.08       366\n",
      "   macro avg       0.01      0.17      0.02       366\n",
      "weighted avg       0.01      0.08      0.01       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,610\n",
      "Trainable params: 1,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 1148.7664 - accuracy: 0.1810\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 248.6735 - accuracy: 0.1489\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 98.0810 - accuracy: 0.2029\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.2099 - accuracy: 0.2459\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2847 - accuracy: 0.2445\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9655 - accuracy: 0.2473\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9293 - accuracy: 0.2500\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8933 - accuracy: 0.2514\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8804 - accuracy: 0.2480\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8394 - accuracy: 0.2507\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8332 - accuracy: 0.2486\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8242 - accuracy: 0.2507\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8201 - accuracy: 0.2480\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8131 - accuracy: 0.2493\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8128 - accuracy: 0.2500\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8005 - accuracy: 0.2507\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8200 - accuracy: 0.2507\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7915 - accuracy: 0.2500\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7875 - accuracy: 0.2500\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7923 - accuracy: 0.2486\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7872 - accuracy: 0.2466\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7844 - accuracy: 0.2466\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7817 - accuracy: 0.2466\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7794 - accuracy: 0.2466\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7771 - accuracy: 0.2466\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7752 - accuracy: 0.2466\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7731 - accuracy: 0.2466\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7714 - accuracy: 0.2466\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7698 - accuracy: 0.2466\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7684 - accuracy: 0.2466\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7670 - accuracy: 0.2466\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7657 - accuracy: 0.2466\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7646 - accuracy: 0.2466\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7635 - accuracy: 0.2466\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7625 - accuracy: 0.2466\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7617 - accuracy: 0.2466\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7608 - accuracy: 0.2466\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7601 - accuracy: 0.2466\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7592 - accuracy: 0.2466\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7586 - accuracy: 0.2466\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7579 - accuracy: 0.2466\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7573 - accuracy: 0.2466\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7568 - accuracy: 0.2466\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7563 - accuracy: 0.2466\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7561 - accuracy: 0.2466\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7554 - accuracy: 0.2466\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7550 - accuracy: 0.2466\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7546 - accuracy: 0.2466\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7543 - accuracy: 0.2466\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7539 - accuracy: 0.2466\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7536 - accuracy: 0.2466\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7532 - accuracy: 0.2466\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7530 - accuracy: 0.2466\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7527 - accuracy: 0.2466\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7525 - accuracy: 0.2466\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7523 - accuracy: 0.2466\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7521 - accuracy: 0.2466\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7519 - accuracy: 0.2466\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7517 - accuracy: 0.2466\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7514 - accuracy: 0.2466\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7512 - accuracy: 0.2466\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7510 - accuracy: 0.2466\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7511 - accuracy: 0.2466\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7509 - accuracy: 0.2466\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7506 - accuracy: 0.2466\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7505 - accuracy: 0.2466\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7504 - accuracy: 0.2466\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7503 - accuracy: 0.2466\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7501 - accuracy: 0.2466\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7500 - accuracy: 0.2466\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7499 - accuracy: 0.2466\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7498 - accuracy: 0.2466\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7497 - accuracy: 0.2466\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7497 - accuracy: 0.2466\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7496 - accuracy: 0.2466\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7494 - accuracy: 0.2466\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7495 - accuracy: 0.2466\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7493 - accuracy: 0.2466\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7494 - accuracy: 0.2466\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7492 - accuracy: 0.2466\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7491 - accuracy: 0.2466\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7490 - accuracy: 0.2466\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7490 - accuracy: 0.2466\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7489 - accuracy: 0.2466\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7490 - accuracy: 0.2466\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7489 - accuracy: 0.2466\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7489 - accuracy: 0.2466\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7487 - accuracy: 0.2466\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7488 - accuracy: 0.2466\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7486 - accuracy: 0.2466\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7486 - accuracy: 0.2466\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7485 - accuracy: 0.2466\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7486 - accuracy: 0.2466\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7485 - accuracy: 0.2466\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7485 - accuracy: 0.2466\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7484 - accuracy: 0.2466\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7484 - accuracy: 0.2466\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7483 - accuracy: 0.2466\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7482 - accuracy: 0.2466\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7483 - accuracy: 0.2466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd6ba9b088>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07650273224043716\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[71  6  0  0  0  0]\n",
      " [41 21  0  0  0  0]\n",
      " [26 39  5  2  0  0]\n",
      " [ 5 29 11 26  2  7]\n",
      " [ 3  7  2 20  3 12]\n",
      " [ 0  2  0  2  2 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.08      1.00      0.14        28\n",
      "\n",
      "    accuracy                           0.08       366\n",
      "   macro avg       0.01      0.17      0.02       366\n",
      "weighted avg       0.01      0.08      0.01       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 22, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_135 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,357\n",
      "Trainable params: 20,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 8.0768 - accuracy: 0.1277\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3582 - accuracy: 0.1257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd6cefcfc8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.14207650273224043\n",
      "Tasa de aciertos balanceada regresión logística: 0.18\n",
      "Matriz de confusión:\n",
      "[[ 6  0  0  0 71  0]\n",
      " [ 3  0  0  0 59  0]\n",
      " [ 5  0  0  0 67  0]\n",
      " [ 4  0  0  0 76  0]\n",
      " [ 1  0  0  0 46  0]\n",
      " [ 0  0  0  0 28  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.32      0.08      0.12        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.13      0.98      0.23        47\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.14       366\n",
      "   macro avg       0.07      0.18      0.06       366\n",
      "weighted avg       0.08      0.14      0.06       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_140 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,999\n",
      "Trainable params: 8,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9012 - accuracy: 0.1988\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.1988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd6e312a48>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2185792349726776\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0 77  0  0]\n",
      " [ 0  0  0 62  0  0]\n",
      " [ 0  0  0 72  0  0]\n",
      " [ 0  0  0 80  0  0]\n",
      " [ 0  0  0 47  0  0]\n",
      " [ 0  0  0 28  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.22      1.00      0.36        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.22       366\n",
      "   macro avg       0.04      0.17      0.06       366\n",
      "weighted avg       0.05      0.22      0.08       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_145 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,711\n",
      "Trainable params: 2,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9684 - accuracy: 0.1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd6e70d048>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.27049180327868855\n",
      "Tasa de aciertos balanceada regresión logística: 0.22\n",
      "Matriz de confusión:\n",
      "[[ 6  0  0  0 71  0]\n",
      " [ 3  0  0  0 59  0]\n",
      " [ 5  0  0  0 67  0]\n",
      " [ 4  0  0  0 76  0]\n",
      " [ 1  0  0  0 46  0]\n",
      " [ 0  0  0  0 28  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.26      0.69      0.38        77\n",
      "         2.0       0.15      0.13      0.14        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.35      0.47      0.40        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.27       366\n",
      "   macro avg       0.13      0.22      0.15       366\n",
      "weighted avg       0.16      0.27      0.19       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 22, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_150 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,419\n",
      "Trainable params: 11,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0885 - accuracy: 0.2466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd6fac3f88>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07650273224043716\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0 77]\n",
      " [ 0  0  0  0  0 62]\n",
      " [ 0  0  0  0  0 72]\n",
      " [ 0  0  0  0  0 80]\n",
      " [ 0  0  0  0  0 47]\n",
      " [ 0  0  0  0  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.08      1.00      0.14        28\n",
      "\n",
      "    accuracy                           0.08       366\n",
      "   macro avg       0.01      0.17      0.02       366\n",
      "weighted avg       0.01      0.08      0.01       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,279\n",
      "Trainable params: 5,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd65ed13c8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2103825136612022\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[77  0  0  0  0  0]\n",
      " [62  0  0  0  0  0]\n",
      " [72  0  0  0  0  0]\n",
      " [80  0  0  0  0  0]\n",
      " [47  0  0  0  0  0]\n",
      " [28  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.21      1.00      0.35        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.21       366\n",
      "   macro avg       0.04      0.17      0.06       366\n",
      "weighted avg       0.04      0.21      0.07       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_170 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,745\n",
      "Trainable params: 1,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2589 - accuracy: 0.0963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd718d3188>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.16939890710382513\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0 77]\n",
      " [ 0  0  0  0  0 62]\n",
      " [ 0  0  0  0  0 72]\n",
      " [ 0  0  0  0  0 80]\n",
      " [ 0  0  0  0  0 47]\n",
      " [ 0  0  0  0  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.17      1.00      0.29        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.17       366\n",
      "   macro avg       0.03      0.17      0.05       366\n",
      "weighted avg       0.03      0.17      0.05       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_180 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,065\n",
      "Trainable params: 10,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 2915.3303 - accuracy: 0.1202\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 717.0559 - accuracy: 0.1257\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 326.7333 - accuracy: 0.1919\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 227.7323 - accuracy: 0.2111\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 181.6281 - accuracy: 0.2343\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 149.4998 - accuracy: 0.2350\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 128.9464 - accuracy: 0.2500\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 109.5432 - accuracy: 0.2568\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 98.4835 - accuracy: 0.2602\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 89.7252 - accuracy: 0.2698\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.5742 - accuracy: 0.2889\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.3335 - accuracy: 0.2923\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.3443 - accuracy: 0.2923\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.2485 - accuracy: 0.2944\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.4109 - accuracy: 0.2923\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 68.9021 - accuracy: 0.2971\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.1152 - accuracy: 0.3026\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.7948 - accuracy: 0.3046\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.0375 - accuracy: 0.3135\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.7621 - accuracy: 0.3128\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.5669 - accuracy: 0.3190\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.1649 - accuracy: 0.3149\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.4688 - accuracy: 0.3176\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.9113 - accuracy: 0.3169\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.2922 - accuracy: 0.3279\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.0278 - accuracy: 0.3402\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.9523 - accuracy: 0.3395\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.7708 - accuracy: 0.3538\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.3823 - accuracy: 0.3306\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.7183 - accuracy: 0.3456\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.5764 - accuracy: 0.3415\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.6340 - accuracy: 0.3443\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.8417 - accuracy: 0.3518\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.1678 - accuracy: 0.3559\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.1487 - accuracy: 0.3525\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.3423 - accuracy: 0.3593\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.6303 - accuracy: 0.3654\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.2375 - accuracy: 0.3689\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.7868 - accuracy: 0.3613\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.1792 - accuracy: 0.3586\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.0342 - accuracy: 0.3586\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.6418 - accuracy: 0.3613\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.3403 - accuracy: 0.3586\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.2024 - accuracy: 0.3818\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 40.3544 - accuracy: 0.3811\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.3606 - accuracy: 0.3675\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.6771 - accuracy: 0.3750\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.1158 - accuracy: 0.3798\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.8279 - accuracy: 0.3730\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.6725 - accuracy: 0.3798\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.3535 - accuracy: 0.3852\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0635 - accuracy: 0.3914\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.6019 - accuracy: 0.3784\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.7592 - accuracy: 0.3852\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.0748 - accuracy: 0.3941\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.1832 - accuracy: 0.4003\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.7817 - accuracy: 0.3934\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.4084 - accuracy: 0.3907\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.8654 - accuracy: 0.3907\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.8684 - accuracy: 0.3928\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.2181 - accuracy: 0.4098\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.1132 - accuracy: 0.3975\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.9835 - accuracy: 0.4078\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.9360 - accuracy: 0.3955\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 34.4499 - accuracy: 0.4030\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.4866 - accuracy: 0.4003\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.4377 - accuracy: 0.4044\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 33.8266 - accuracy: 0.3975\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.5843 - accuracy: 0.4112\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.2090 - accuracy: 0.4133\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.7477 - accuracy: 0.4057\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.6621 - accuracy: 0.4133\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.7831 - accuracy: 0.4030\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.3527 - accuracy: 0.4098\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.9292 - accuracy: 0.4324\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.1044 - accuracy: 0.4146\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.1331 - accuracy: 0.4180\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.1027 - accuracy: 0.4133\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.3372 - accuracy: 0.4146\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.9961 - accuracy: 0.4167\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.9100 - accuracy: 0.4290\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.2419 - accuracy: 0.4208\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.4090 - accuracy: 0.4160\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.8381 - accuracy: 0.4071\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.4426 - accuracy: 0.4051\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.8957 - accuracy: 0.4378\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.6306 - accuracy: 0.4303\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.3419 - accuracy: 0.4208\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.4427 - accuracy: 0.4187\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.0764 - accuracy: 0.4208\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.9818 - accuracy: 0.4173\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.2980 - accuracy: 0.4194\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.8727 - accuracy: 0.4214\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.6705 - accuracy: 0.4249\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.9100 - accuracy: 0.4187\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.4131 - accuracy: 0.4201\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.1893 - accuracy: 0.4153\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.4081 - accuracy: 0.4228\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.3217 - accuracy: 0.4214\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.3633 - accuracy: 0.4221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd6e683608>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2540983606557377\n",
      "Tasa de aciertos balanceada regresión logística: 0.29\n",
      "Matriz de confusión:\n",
      "[[29 33  8  4  2  1]\n",
      " [18 13 16  8  3  4]\n",
      " [15 22  4 18 10  3]\n",
      " [ 3  9  7 20 24 17]\n",
      " [ 2  2  6 15  9 13]\n",
      " [ 0  0  1  9  0 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.43      0.38      0.40        77\n",
      "         2.0       0.16      0.21      0.18        62\n",
      "         3.0       0.10      0.06      0.07        72\n",
      "         4.0       0.27      0.25      0.26        80\n",
      "         5.0       0.19      0.19      0.19        47\n",
      "         6.0       0.32      0.64      0.43        28\n",
      "\n",
      "    accuracy                           0.25       366\n",
      "   macro avg       0.25      0.29      0.26       366\n",
      "weighted avg       0.25      0.25      0.24       366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_185 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,716\n",
      "Trainable params: 4,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 2293.3452 - accuracy: 0.2268\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 540.1147 - accuracy: 0.2240\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 345.4554 - accuracy: 0.2158\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 245.2365 - accuracy: 0.2117\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 193.5702 - accuracy: 0.2363\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 169.0257 - accuracy: 0.2275\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 152.3674 - accuracy: 0.2439\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 138.5252 - accuracy: 0.2493\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 130.1848 - accuracy: 0.2466\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 123.5181 - accuracy: 0.2657\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 116.1496 - accuracy: 0.2657\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 110.9261 - accuracy: 0.2705\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 106.1884 - accuracy: 0.2753\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 102.5489 - accuracy: 0.2780\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 99.8007 - accuracy: 0.2766\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 96.2934 - accuracy: 0.2787\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 94.3720 - accuracy: 0.2780\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.5806 - accuracy: 0.2848\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.8403 - accuracy: 0.2801\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 88.9549 - accuracy: 0.2937\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.0863 - accuracy: 0.2835\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.9436 - accuracy: 0.2842\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.9918 - accuracy: 0.2889\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.9995 - accuracy: 0.2869\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.2071 - accuracy: 0.2951\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.1540 - accuracy: 0.2842\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.2152 - accuracy: 0.2876\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.3230 - accuracy: 0.2917\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.3033 - accuracy: 0.2862\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.2833 - accuracy: 0.2869\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.5060 - accuracy: 0.2930\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.0143 - accuracy: 0.2842\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.0953 - accuracy: 0.2923\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.5288 - accuracy: 0.2917\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.2833 - accuracy: 0.2917\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.1287 - accuracy: 0.2923\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.6321 - accuracy: 0.2896\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.5290 - accuracy: 0.2910\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.8901 - accuracy: 0.2910\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.2031 - accuracy: 0.2958\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.3823 - accuracy: 0.2917\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.5964 - accuracy: 0.2978\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.6387 - accuracy: 0.2992\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.9501 - accuracy: 0.3012\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.8891 - accuracy: 0.2964\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.2945 - accuracy: 0.3046\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.9589 - accuracy: 0.2999\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.3665 - accuracy: 0.3067\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.8154 - accuracy: 0.3046\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.9950 - accuracy: 0.2869\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.7581 - accuracy: 0.3060\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.2869 - accuracy: 0.3053\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.4412 - accuracy: 0.2944\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.6381 - accuracy: 0.3135\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.1220 - accuracy: 0.3060\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.8472 - accuracy: 0.3142\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.5977 - accuracy: 0.3094\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.2782 - accuracy: 0.3019\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.4643 - accuracy: 0.3046\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.4241 - accuracy: 0.3142\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.9150 - accuracy: 0.3142\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.7299 - accuracy: 0.3053\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.1050 - accuracy: 0.3074\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.7200 - accuracy: 0.3169\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.4887 - accuracy: 0.3128\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.2368 - accuracy: 0.3115\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.1782 - accuracy: 0.3163\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.3864 - accuracy: 0.3197\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.4509 - accuracy: 0.3217\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.4006 - accuracy: 0.3108\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.0184 - accuracy: 0.3169\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.0787 - accuracy: 0.3149\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.6309 - accuracy: 0.3142\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.4719 - accuracy: 0.3183\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.8297 - accuracy: 0.3245\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.6283 - accuracy: 0.3265\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.0128 - accuracy: 0.3122\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.0126 - accuracy: 0.3204\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.9768 - accuracy: 0.3183\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.1488 - accuracy: 0.3169\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.8353 - accuracy: 0.3265\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.7147 - accuracy: 0.3251\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.4730 - accuracy: 0.3101\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.6242 - accuracy: 0.3204\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.0049 - accuracy: 0.3231\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.5644 - accuracy: 0.3122\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.2679 - accuracy: 0.3265\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.1051 - accuracy: 0.3231\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.5027 - accuracy: 0.3204\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.9529 - accuracy: 0.3224\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.2504 - accuracy: 0.3286\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.7603 - accuracy: 0.3217\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.6470 - accuracy: 0.3197\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.9225 - accuracy: 0.3210\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.6747 - accuracy: 0.3272\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.1340 - accuracy: 0.3258\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.0735 - accuracy: 0.3176\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.2128 - accuracy: 0.3163\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.8991 - accuracy: 0.3169\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.8437 - accuracy: 0.3176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd72c1e088>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2540983606557377\n",
      "Tasa de aciertos balanceada regresión logística: 0.25\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0 40  5 12  5  0 15]\n",
      " [ 0  9  2  9 13  1 28]\n",
      " [ 0 12  4 12 21  3 20]\n",
      " [ 1  2  8 11 23  6 29]\n",
      " [ 0  2  6  7 10  4 18]\n",
      " [ 0  0  6  4  1  5 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.62      0.52      0.56        77\n",
      "         2.0       0.06      0.03      0.04        62\n",
      "         3.0       0.22      0.17      0.19        72\n",
      "         4.0       0.32      0.29      0.30        80\n",
      "         5.0       0.21      0.09      0.12        47\n",
      "         6.0       0.10      0.43      0.16        28\n",
      "\n",
      "    accuracy                           0.25       366\n",
      "   macro avg       0.22      0.22      0.20       366\n",
      "weighted avg       0.29      0.25      0.26       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_190 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,610\n",
      "Trainable params: 1,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 5049.6924 - accuracy: 0.1981\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2384.7695 - accuracy: 0.2042\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1861.8467 - accuracy: 0.2145\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1500.1208 - accuracy: 0.2186\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1224.3492 - accuracy: 0.2261\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1005.8030 - accuracy: 0.2261\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 876.1228 - accuracy: 0.2493\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 795.9918 - accuracy: 0.2432\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 725.0362 - accuracy: 0.2411\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 660.8355 - accuracy: 0.2466\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 604.8900 - accuracy: 0.2555\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 558.2068 - accuracy: 0.2602\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 519.8699 - accuracy: 0.2623\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 483.4290 - accuracy: 0.2575\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 448.5704 - accuracy: 0.2575\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 419.3560 - accuracy: 0.2575\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 395.0332 - accuracy: 0.2582\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 371.7890 - accuracy: 0.2582\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 351.1407 - accuracy: 0.2445\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 330.5296 - accuracy: 0.2391\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 310.2283 - accuracy: 0.2336\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 290.2672 - accuracy: 0.2254\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 271.2240 - accuracy: 0.2261\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 252.5520 - accuracy: 0.2343\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 224.9932 - accuracy: 0.2240\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 188.5938 - accuracy: 0.2097\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 145.2977 - accuracy: 0.1926\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 107.7497 - accuracy: 0.1646\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.8167 - accuracy: 0.1393\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.7296 - accuracy: 0.1352\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.8824 - accuracy: 0.1339\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.2005 - accuracy: 0.1339\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.5485 - accuracy: 0.1298\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.0874 - accuracy: 0.1305\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.8451 - accuracy: 0.1264\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.4632 - accuracy: 0.1243\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0250 - accuracy: 0.1264\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.1864 - accuracy: 0.1277\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.3960 - accuracy: 0.1305\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.8598 - accuracy: 0.1339\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.4582 - accuracy: 0.1339\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.2054 - accuracy: 0.1346\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.1631 - accuracy: 0.1359\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.0865 - accuracy: 0.1284\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.9956 - accuracy: 0.1305\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.0272 - accuracy: 0.1831\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.1251 - accuracy: 0.1940\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.1922 - accuracy: 0.1954\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.3227 - accuracy: 0.1947\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.5981 - accuracy: 0.1926\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.8781 - accuracy: 0.1899\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.1657 - accuracy: 0.1899\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.5059 - accuracy: 0.1892\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.8850 - accuracy: 0.1872\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.1461 - accuracy: 0.1899\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.5421 - accuracy: 0.1885\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.9505 - accuracy: 0.1919\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.5411 - accuracy: 0.1885\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.0912 - accuracy: 0.1906\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.5892 - accuracy: 0.1913\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.0827 - accuracy: 0.1919\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.7157 - accuracy: 0.1913\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.3172 - accuracy: 0.1933\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.9954 - accuracy: 0.1913\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5862 - accuracy: 0.1906\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.3109 - accuracy: 0.1919\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0008 - accuracy: 0.1933\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6720 - accuracy: 0.1913\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.3609 - accuracy: 0.1892\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.9812 - accuracy: 0.1892\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6643 - accuracy: 0.1919\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.3165 - accuracy: 0.1919\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0535 - accuracy: 0.1878\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.8176 - accuracy: 0.1885\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.5298 - accuracy: 0.1872\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2457 - accuracy: 0.1837\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9513 - accuracy: 0.1858\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6591 - accuracy: 0.1885\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3876 - accuracy: 0.1885\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0997 - accuracy: 0.1878\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8964 - accuracy: 0.1885\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.6701 - accuracy: 0.1885\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.4655 - accuracy: 0.1892\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2491 - accuracy: 0.1906\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0173 - accuracy: 0.1885\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7999 - accuracy: 0.1878\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6008 - accuracy: 0.1865\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4283 - accuracy: 0.1885\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2629 - accuracy: 0.1885\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1314 - accuracy: 0.1885\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9944 - accuracy: 0.1878\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8688 - accuracy: 0.1878\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7493 - accuracy: 0.1851\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6480 - accuracy: 0.1858\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5614 - accuracy: 0.1858\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4062 - accuracy: 0.1865\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2875 - accuracy: 0.1851\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1626 - accuracy: 0.1892\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.0373 - accuracy: 0.1872\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8964 - accuracy: 0.1878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd74045c88>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.18032786885245902\n",
      "Tasa de aciertos balanceada regresión logística: 0.15\n",
      "Matriz de confusión:\n",
      "[[29 33  8  4  2  1]\n",
      " [18 13 16  8  3  4]\n",
      " [15 22  4 18 10  3]\n",
      " [ 3  9  7 20 24 17]\n",
      " [ 2  2  6 15  9 13]\n",
      " [ 0  0  1  9  0 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.18      0.82      0.30        72\n",
      "         4.0       0.35      0.09      0.14        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.18       366\n",
      "   macro avg       0.08      0.13      0.06       366\n",
      "weighted avg       0.11      0.18      0.09       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_195 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,357\n",
      "Trainable params: 20,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 13.5014 - accuracy: 0.1619\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5088 - accuracy: 0.1619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd743997c8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2103825136612022\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[77  0  0  0  0  0]\n",
      " [62  0  0  0  0  0]\n",
      " [72  0  0  0  0  0]\n",
      " [80  0  0  0  0  0]\n",
      " [47  0  0  0  0  0]\n",
      " [28  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.21      1.00      0.35        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.21       366\n",
      "   macro avg       0.04      0.17      0.06       366\n",
      "weighted avg       0.04      0.21      0.07       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_200 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,999\n",
      "Trainable params: 8,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 12.1863 - accuracy: 0.0505\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9593 - accuracy: 0.0266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd7574d048>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.06557377049180328\n",
      "Tasa de aciertos balanceada regresión logística: 0.05\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [27  0  0  0 50  0  0]\n",
      " [25  0  0  0 37  0  0]\n",
      " [32  0  0  0 40  0  0]\n",
      " [56  0  0  0 24  0  0]\n",
      " [24  0  0  0 23  0  0]\n",
      " [ 8  0  0  0 20  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.12      0.30      0.18        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.07       366\n",
      "   macro avg       0.02      0.04      0.03       366\n",
      "weighted avg       0.03      0.07      0.04       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_205 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,711\n",
      "Trainable params: 2,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 7.3825 - accuracy: 0.2070\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2951 - accuracy: 0.2063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd75b3f888>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.12021857923497267\n",
      "Tasa de aciertos balanceada regresión logística: 0.14\n",
      "Matriz de confusión:\n",
      "[[77  0  0  0  0  0]\n",
      " [62  0  0  0  0  0]\n",
      " [72  0  0  0  0  0]\n",
      " [80  0  0  0  0  0]\n",
      " [47  0  0  0  0  0]\n",
      " [28  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.21      0.46      0.29        72\n",
      "         4.0       0.00      0.00      0.00        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.05      0.39      0.09        28\n",
      "\n",
      "    accuracy                           0.12       366\n",
      "   macro avg       0.04      0.14      0.06       366\n",
      "weighted avg       0.04      0.12      0.06       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_210 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,419\n",
      "Trainable params: 11,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5933 - accuracy: 0.0048\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5933 - accuracy: 0.0048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd76e7eb88>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.01366120218579235\n",
      "Tasa de aciertos balanceada regresión logística: 0.01\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [77  0  0  0  0  0  0]\n",
      " [61  0  0  0  1  0  0]\n",
      " [69  0  0  0  3  0  0]\n",
      " [75  0  0  0  5  0  0]\n",
      " [47  0  0  0  0  0  0]\n",
      " [28  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.56      0.06      0.11        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.01       366\n",
      "   macro avg       0.08      0.01      0.02       366\n",
      "weighted avg       0.12      0.01      0.02       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_220 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,279\n",
      "Trainable params: 5,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.1988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd7840e588>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2185792349726776\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0 77  0  0]\n",
      " [ 0  0  0 62  0  0]\n",
      " [ 0  0  0 72  0  0]\n",
      " [ 0  0  0 80  0  0]\n",
      " [ 0  0  0 47  0  0]\n",
      " [ 0  0  0 28  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.22      1.00      0.36        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.22       366\n",
      "   macro avg       0.04      0.17      0.06       366\n",
      "weighted avg       0.05      0.22      0.08       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_230 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,745\n",
      "Trainable params: 1,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1869 - accuracy: 0.1988\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1869 - accuracy: 0.1988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd7890d848>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2185792349726776\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [77  0  0  0  0  0  0]\n",
      " [61  0  0  0  1  0  0]\n",
      " [69  0  0  0  3  0  0]\n",
      " [75  0  0  0  5  0  0]\n",
      " [47  0  0  0  0  0  0]\n",
      " [28  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        62\n",
      "         3.0       0.00      0.00      0.00        72\n",
      "         4.0       0.22      1.00      0.36        80\n",
      "         5.0       0.00      0.00      0.00        47\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.22       366\n",
      "   macro avg       0.04      0.17      0.06       366\n",
      "weighted avg       0.05      0.22      0.08       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 36, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_240 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,465\n",
      "Trainable params: 11,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 879.3229 - accuracy: 0.2065\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 168.5161 - accuracy: 0.2314\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 109.0673 - accuracy: 0.2873\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.8955 - accuracy: 0.3377\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 95.3092 - accuracy: 0.3066\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.9217 - accuracy: 0.3322\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.2796 - accuracy: 0.3253\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.1833 - accuracy: 0.3653\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.7242 - accuracy: 0.3660\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.2743 - accuracy: 0.3536\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.4217 - accuracy: 0.3902\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.3033 - accuracy: 0.4095\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 86.1400 - accuracy: 0.3425\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.6568 - accuracy: 0.4123\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.3290 - accuracy: 0.4095\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.0048 - accuracy: 0.4489\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.5841 - accuracy: 0.4344\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.5199 - accuracy: 0.4689\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.9599 - accuracy: 0.4523\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.1400 - accuracy: 0.3992\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.8459 - accuracy: 0.4724\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.0301 - accuracy: 0.4634\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.1705 - accuracy: 0.4068\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.7114 - accuracy: 0.4275\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.1243 - accuracy: 0.4613\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2391 - accuracy: 0.4606\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 21.2657 - accuracy: 0.4392\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6127 - accuracy: 0.4834\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.7226 - accuracy: 0.5097\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.3346 - accuracy: 0.4772\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9255 - accuracy: 0.5380\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.7941 - accuracy: 0.4586\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.2720 - accuracy: 0.4399\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.1360 - accuracy: 0.4938\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6135 - accuracy: 0.4972\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1644 - accuracy: 0.5117\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.3707 - accuracy: 0.5062\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.0797 - accuracy: 0.5677\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.1033 - accuracy: 0.5407\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.1349 - accuracy: 0.5152\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5423 - accuracy: 0.5200\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0379 - accuracy: 0.5394\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5291 - accuracy: 0.4945\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0819 - accuracy: 0.5421\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1344 - accuracy: 0.5228\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2717 - accuracy: 0.4952\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1970 - accuracy: 0.5041\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3275 - accuracy: 0.5262\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7080 - accuracy: 0.5228\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.1679 - accuracy: 0.4655\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6145 - accuracy: 0.5325\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8919 - accuracy: 0.5539\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5784 - accuracy: 0.5352\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6499 - accuracy: 0.5131\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1489 - accuracy: 0.5207\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8473 - accuracy: 0.5794\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4554 - accuracy: 0.5076\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3757 - accuracy: 0.5760\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0496 - accuracy: 0.5974\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7590 - accuracy: 0.6077\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2894 - accuracy: 0.5836\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6320 - accuracy: 0.6264\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3924 - accuracy: 0.6506\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6693 - accuracy: 0.6133\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5674 - accuracy: 0.6464\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3704 - accuracy: 0.6581\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3407 - accuracy: 0.6588\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3628 - accuracy: 0.6319\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2389 - accuracy: 0.6720\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4496 - accuracy: 0.6285\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2127 - accuracy: 0.6360\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2013 - accuracy: 0.6506\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2597 - accuracy: 0.6291\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2457 - accuracy: 0.6291\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3725 - accuracy: 0.6146\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3475 - accuracy: 0.5919\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2026 - accuracy: 0.5994\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4215 - accuracy: 0.5711\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3683 - accuracy: 0.5753\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0994 - accuracy: 0.6119\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1639 - accuracy: 0.5891\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2167 - accuracy: 0.5994\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0943 - accuracy: 0.6188\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0442 - accuracy: 0.6319\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9686 - accuracy: 0.6526\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9486 - accuracy: 0.6464\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0142 - accuracy: 0.6312\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.9931 - accuracy: 0.6257\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2083 - accuracy: 0.5836\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4277 - accuracy: 0.5359\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0506 - accuracy: 0.6057\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1054 - accuracy: 0.5974\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1915 - accuracy: 0.5601\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2243 - accuracy: 0.5718\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2378 - accuracy: 0.5856\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1537 - accuracy: 0.5684\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0429 - accuracy: 0.5856\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.0105 - accuracy: 0.6133\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0718 - accuracy: 0.6098\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.9866 - accuracy: 0.6257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd79dfc548>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4419889502762431\n",
      "Tasa de aciertos balanceada regresión logística: 0.46\n",
      "Matriz de confusión:\n",
      "[[26 42  7  2  0  0]\n",
      " [ 0 30 21 10  0  0]\n",
      " [ 0 13 26 28  4  0]\n",
      " [ 0  0 13 39 23  4]\n",
      " [ 0  0  2 17 25  2]\n",
      " [ 0  0  0  3 11 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.34      0.50        77\n",
      "         2.0       0.35      0.49      0.41        61\n",
      "         3.0       0.38      0.37      0.37        71\n",
      "         4.0       0.39      0.49      0.44        79\n",
      "         5.0       0.40      0.54      0.46        46\n",
      "         6.0       0.70      0.50      0.58        28\n",
      "\n",
      "    accuracy                           0.44       362\n",
      "   macro avg       0.54      0.46      0.46       362\n",
      "weighted avg       0.54      0.44      0.45       362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_245 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,612\n",
      "Trainable params: 5,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 1267.5469 - accuracy: 0.1754\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8424 - accuracy: 0.2162\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2531 - accuracy: 0.2037\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1094 - accuracy: 0.2086\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0658 - accuracy: 0.2058\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9938 - accuracy: 0.2086\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9823 - accuracy: 0.2300\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8984 - accuracy: 0.2493\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8530 - accuracy: 0.2507\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8903 - accuracy: 0.2500\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8436 - accuracy: 0.2493\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8376 - accuracy: 0.2493\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8318 - accuracy: 0.2493\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8827 - accuracy: 0.2500\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8259 - accuracy: 0.2472\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8214 - accuracy: 0.2472\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8164 - accuracy: 0.2472\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8110 - accuracy: 0.2479\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8193 - accuracy: 0.2479\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8565 - accuracy: 0.2479\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8193 - accuracy: 0.2479\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7991 - accuracy: 0.2486\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7964 - accuracy: 0.2486\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7941 - accuracy: 0.2486\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.2486\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7897 - accuracy: 0.2486\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7877 - accuracy: 0.2486\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7858 - accuracy: 0.2486\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7841 - accuracy: 0.2486\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7825 - accuracy: 0.2486\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7809 - accuracy: 0.2486\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7795 - accuracy: 0.2486\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7780 - accuracy: 0.2486\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7766 - accuracy: 0.2486\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7753 - accuracy: 0.2486\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7741 - accuracy: 0.2486\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7730 - accuracy: 0.2486\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7718 - accuracy: 0.2486\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7708 - accuracy: 0.2486\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7697 - accuracy: 0.2486\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7687 - accuracy: 0.2486\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7886 - accuracy: 0.2472\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7669 - accuracy: 0.2486\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7660 - accuracy: 0.2486\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7652 - accuracy: 0.2486\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7645 - accuracy: 0.2486\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7636 - accuracy: 0.2486\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7628 - accuracy: 0.2486\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7621 - accuracy: 0.2486\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7614 - accuracy: 0.2486\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7607 - accuracy: 0.2486\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7600 - accuracy: 0.2486\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7594 - accuracy: 0.2486\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7587 - accuracy: 0.2486\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7582 - accuracy: 0.2486\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7577 - accuracy: 0.2486\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7571 - accuracy: 0.2486\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4985 - accuracy: 0.2403\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8262 - accuracy: 0.2431\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7696 - accuracy: 0.2431\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7691 - accuracy: 0.2431\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7686 - accuracy: 0.2431\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7682 - accuracy: 0.2431\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7677 - accuracy: 0.2431\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7673 - accuracy: 0.2431\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7668 - accuracy: 0.2431\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7663 - accuracy: 0.2431\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7660 - accuracy: 0.2431\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7656 - accuracy: 0.2431\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7652 - accuracy: 0.2431\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7648 - accuracy: 0.2431\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7646 - accuracy: 0.2431\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7641 - accuracy: 0.2431\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7637 - accuracy: 0.2431\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7634 - accuracy: 0.2431\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7632 - accuracy: 0.2431\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7628 - accuracy: 0.2431\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7625 - accuracy: 0.2431\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7621 - accuracy: 0.2431\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7619 - accuracy: 0.2431\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7617 - accuracy: 0.2431\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7613 - accuracy: 0.2431\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7611 - accuracy: 0.2431\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7608 - accuracy: 0.2431\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7605 - accuracy: 0.2431\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7603 - accuracy: 0.2431\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7601 - accuracy: 0.2431\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7598 - accuracy: 0.2431\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7595 - accuracy: 0.2431\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7593 - accuracy: 0.2431\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7591 - accuracy: 0.2431\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7588 - accuracy: 0.2431\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7587 - accuracy: 0.2431\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7584 - accuracy: 0.2431\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7583 - accuracy: 0.2431\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7581 - accuracy: 0.2431\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7579 - accuracy: 0.2431\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7578 - accuracy: 0.2431\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7575 - accuracy: 0.2431\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7574 - accuracy: 0.2431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd79d6af08>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07734806629834254\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0 77]\n",
      " [ 0  0  0  0  0 61]\n",
      " [ 0  0  0  0  0 71]\n",
      " [ 0  0  0  0  0 79]\n",
      " [ 0  0  0  0  0 46]\n",
      " [ 0  0  0  0  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        61\n",
      "         3.0       0.00      0.00      0.00        71\n",
      "         4.0       0.00      0.00      0.00        79\n",
      "         5.0       0.00      0.00      0.00        46\n",
      "         6.0       0.08      1.00      0.14        28\n",
      "\n",
      "    accuracy                           0.08       362\n",
      "   macro avg       0.01      0.17      0.02       362\n",
      "weighted avg       0.01      0.08      0.01       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_250 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,058\n",
      "Trainable params: 2,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 564.8505 - accuracy: 0.1664\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9333 - accuracy: 0.1982\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9234 - accuracy: 0.2037\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9140 - accuracy: 0.2431\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9050 - accuracy: 0.2431\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8966 - accuracy: 0.2431\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8888 - accuracy: 0.2431\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8813 - accuracy: 0.2431\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8744 - accuracy: 0.2431\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8681 - accuracy: 0.2431\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8622 - accuracy: 0.2431\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8568 - accuracy: 0.2431\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8517 - accuracy: 0.2431\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8471 - accuracy: 0.2431\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8427 - accuracy: 0.2431\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8388 - accuracy: 0.2431\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8350 - accuracy: 0.2431\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8314 - accuracy: 0.2431\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8281 - accuracy: 0.2431\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8250 - accuracy: 0.2431\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8221 - accuracy: 0.2431\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8195 - accuracy: 0.2431\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8169 - accuracy: 0.2431\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8145 - accuracy: 0.2431\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8122 - accuracy: 0.2431\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8100 - accuracy: 0.2431\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8081 - accuracy: 0.2431\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8061 - accuracy: 0.2431\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8042 - accuracy: 0.2431\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8025 - accuracy: 0.2431\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8008 - accuracy: 0.2431\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7992 - accuracy: 0.2431\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7977 - accuracy: 0.2431\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7961 - accuracy: 0.2431\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7948 - accuracy: 0.2431\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7935 - accuracy: 0.2431\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7922 - accuracy: 0.2431\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7909 - accuracy: 0.2431\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7897 - accuracy: 0.2431\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7886 - accuracy: 0.2431\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7875 - accuracy: 0.2431\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7864 - accuracy: 0.2431\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7854 - accuracy: 0.2431\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7845 - accuracy: 0.2431\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7835 - accuracy: 0.2431\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7825 - accuracy: 0.2431\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7817 - accuracy: 0.2431\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7808 - accuracy: 0.2431\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7801 - accuracy: 0.2431\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7792 - accuracy: 0.2431\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7784 - accuracy: 0.2431\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7777 - accuracy: 0.2431\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7770 - accuracy: 0.2431\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7763 - accuracy: 0.2431\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7756 - accuracy: 0.2431\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7749 - accuracy: 0.2431\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7743 - accuracy: 0.2431\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7737 - accuracy: 0.2431\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7731 - accuracy: 0.2431\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7725 - accuracy: 0.2431\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7720 - accuracy: 0.2431\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7714 - accuracy: 0.2431\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7709 - accuracy: 0.2431\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7705 - accuracy: 0.2431\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7699 - accuracy: 0.2431\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7695 - accuracy: 0.2431\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7689 - accuracy: 0.2431\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7685 - accuracy: 0.2431\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7680 - accuracy: 0.2431\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7676 - accuracy: 0.2431\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7671 - accuracy: 0.2431\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7668 - accuracy: 0.2431\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7663 - accuracy: 0.2431\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7659 - accuracy: 0.2431\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7657 - accuracy: 0.2431\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7653 - accuracy: 0.2431\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7649 - accuracy: 0.2431\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7645 - accuracy: 0.2431\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7641 - accuracy: 0.2431\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7638 - accuracy: 0.2431\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7635 - accuracy: 0.2431\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7632 - accuracy: 0.2431\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7629 - accuracy: 0.2431\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7626 - accuracy: 0.2431\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7623 - accuracy: 0.2431\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7620 - accuracy: 0.2431\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7617 - accuracy: 0.2431\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7615 - accuracy: 0.2431\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7613 - accuracy: 0.2431\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7609 - accuracy: 0.2431\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7607 - accuracy: 0.2431\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7605 - accuracy: 0.2431\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7602 - accuracy: 0.2431\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7599 - accuracy: 0.2431\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7597 - accuracy: 0.2431\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7595 - accuracy: 0.2431\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7593 - accuracy: 0.2431\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7590 - accuracy: 0.2431\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7589 - accuracy: 0.2431\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7587 - accuracy: 0.2431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd75b1f708>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07734806629834254\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[26 42  7  2  0  0]\n",
      " [ 0 30 21 10  0  0]\n",
      " [ 0 13 26 28  4  0]\n",
      " [ 0  0 13 39 23  4]\n",
      " [ 0  0  2 17 25  2]\n",
      " [ 0  0  0  3 11 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        61\n",
      "         3.0       0.00      0.00      0.00        71\n",
      "         4.0       0.00      0.00      0.00        79\n",
      "         5.0       0.00      0.00      0.00        46\n",
      "         6.0       0.08      1.00      0.14        28\n",
      "\n",
      "    accuracy                           0.08       362\n",
      "   macro avg       0.01      0.17      0.02       362\n",
      "weighted avg       0.01      0.08      0.01       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 36, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_255 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_256 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,757\n",
      "Trainable params: 21,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8766 - accuracy: 0.1982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd7c4f5188>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.21823204419889503\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0 77  0  0]\n",
      " [ 0  0  0 61  0  0]\n",
      " [ 0  0  0 71  0  0]\n",
      " [ 0  0  0 79  0  0]\n",
      " [ 0  0  0 46  0  0]\n",
      " [ 0  0  0 28  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        61\n",
      "         3.0       0.00      0.00      0.00        71\n",
      "         4.0       0.22      1.00      0.36        79\n",
      "         5.0       0.00      0.00      0.00        46\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.22       362\n",
      "   macro avg       0.04      0.17      0.06       362\n",
      "weighted avg       0.05      0.22      0.08       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_260 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_261 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_262 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_264 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,895\n",
      "Trainable params: 9,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 8.0826 - accuracy: 0.1789\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4169 - accuracy: 0.2196\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4260 - accuracy: 0.2279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd7c8f2488>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07734806629834254\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0 77]\n",
      " [ 0  0  0  0  0 61]\n",
      " [ 0  0  0  0  0 71]\n",
      " [ 0  0  0  0  0 79]\n",
      " [ 0  0  0  0  0 46]\n",
      " [ 0  0  0  0  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        61\n",
      "         3.0       0.00      0.00      0.00        71\n",
      "         4.0       0.00      0.00      0.00        79\n",
      "         5.0       0.00      0.00      0.00        46\n",
      "         6.0       0.08      1.00      0.14        28\n",
      "\n",
      "    accuracy                           0.08       362\n",
      "   macro avg       0.01      0.17      0.02       362\n",
      "weighted avg       0.01      0.08      0.01       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_265 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,159\n",
      "Trainable params: 3,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 10.0670 - accuracy: 0.1091\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3335 - accuracy: 0.1209\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.2776 - accuracy: 0.1215\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.2766 - accuracy: 0.1215\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6107 - accuracy: 0.1195\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7413 - accuracy: 0.1285\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3389 - accuracy: 0.1236\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0997 - accuracy: 0.1153\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2485 - accuracy: 0.1561\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4571 - accuracy: 0.1637\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2586 - accuracy: 0.1637\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2585 - accuracy: 0.1637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd7dd250c8>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.212707182320442\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0 77  0  0]\n",
      " [ 0  0  0 61  0  0]\n",
      " [ 0  0  0 71  0  0]\n",
      " [ 0  0  0 79  0  0]\n",
      " [ 0  0  0 46  0  0]\n",
      " [ 0  0  0 28  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.21      1.00      0.35        77\n",
      "         2.0       0.00      0.00      0.00        61\n",
      "         3.0       0.00      0.00      0.00        71\n",
      "         4.0       0.00      0.00      0.00        79\n",
      "         5.0       0.00      0.00      0.00        46\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.21       362\n",
      "   macro avg       0.04      0.17      0.06       362\n",
      "weighted avg       0.05      0.21      0.07       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 36, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_270 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_271 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_272 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_274 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_277 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_278 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_279 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,819\n",
      "Trainable params: 12,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 9.6619 - accuracy: 0.1512\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8618 - accuracy: 0.1236\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.9504 - accuracy: 0.1188\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8742 - accuracy: 0.2320\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.2438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd7e14a808>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1132596685082873\n",
      "Tasa de aciertos balanceada regresión logística: 0.19\n",
      "Matriz de confusión:\n",
      "[[ 0  0  5  0  0 72]\n",
      " [ 0  0  6  0  0 55]\n",
      " [ 0  0 15  0  0 56]\n",
      " [ 0  0 18  0  0 61]\n",
      " [ 0  0  7  0  0 39]\n",
      " [ 0  0  2  0  0 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        61\n",
      "         3.0       0.28      0.21      0.24        71\n",
      "         4.0       0.00      0.00      0.00        79\n",
      "         5.0       0.00      0.00      0.00        46\n",
      "         6.0       0.08      0.93      0.15        28\n",
      "\n",
      "    accuracy                           0.11       362\n",
      "   macro avg       0.06      0.19      0.07       362\n",
      "weighted avg       0.06      0.11      0.06       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_280 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_282 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,175\n",
      "Trainable params: 6,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 9.7688 - accuracy: 0.1982\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6984 - accuracy: 0.1982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd7f6d8508>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.21823204419889503\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0 77  0  0]\n",
      " [ 0  0  0 61  0  0]\n",
      " [ 0  0  0 71  0  0]\n",
      " [ 0  0  0 79  0  0]\n",
      " [ 0  0  0 46  0  0]\n",
      " [ 0  0  0 28  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        61\n",
      "         3.0       0.00      0.00      0.00        71\n",
      "         4.0       0.22      1.00      0.36        79\n",
      "         5.0       0.00      0.00      0.00        46\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.22       362\n",
      "   macro avg       0.04      0.17      0.06       362\n",
      "weighted avg       0.05      0.22      0.08       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_290 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_292 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_294 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,193\n",
      "Trainable params: 2,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 3.6181 - accuracy: 0.0331\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd7fc61e48>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[ 0  0  5  0  0 72]\n",
      " [ 0  0  6  0  0 55]\n",
      " [ 0  0 15  0  0 56]\n",
      " [ 0  0 18  0  0 61]\n",
      " [ 0  0  7  0  0 39]\n",
      " [ 0  0  2  0  0 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00      61.0\n",
      "         3.0       0.00      0.00      0.00      71.0\n",
      "         4.0       0.00      0.00      0.00      79.0\n",
      "         5.0       0.00      0.00      0.00      46.0\n",
      "         6.0       0.00      0.00      0.00      28.0\n",
      "\n",
      "    accuracy                           0.00     362.0\n",
      "   macro avg       0.00      0.00      0.00     362.0\n",
      "weighted avg       0.00      0.00      0.00     362.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_300 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_301 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_302 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_303 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_304 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,465\n",
      "Trainable params: 11,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 1664.8059 - accuracy: 0.1492\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 434.3477 - accuracy: 0.2300\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 267.1002 - accuracy: 0.2707\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 194.4901 - accuracy: 0.2956\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 152.3891 - accuracy: 0.2907\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 136.3262 - accuracy: 0.3122\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 124.5123 - accuracy: 0.3135\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 118.2678 - accuracy: 0.3198\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 108.9885 - accuracy: 0.3329\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 100.8401 - accuracy: 0.3529\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 100.0588 - accuracy: 0.3391\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 96.1395 - accuracy: 0.3481\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.4728 - accuracy: 0.3564\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 89.8244 - accuracy: 0.3474\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 85.9091 - accuracy: 0.3591\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 84.0475 - accuracy: 0.3619\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.9165 - accuracy: 0.3529\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.7341 - accuracy: 0.3674\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.5834 - accuracy: 0.3695\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.0676 - accuracy: 0.3605\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.0687 - accuracy: 0.3605\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.7701 - accuracy: 0.3771\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 72.3134 - accuracy: 0.3812\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.1692 - accuracy: 0.3743\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.5360 - accuracy: 0.3764\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.4922 - accuracy: 0.3791\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.1028 - accuracy: 0.3854\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.9411 - accuracy: 0.3833\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.1445 - accuracy: 0.3757\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.6822 - accuracy: 0.3950\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.6920 - accuracy: 0.3791\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.1510 - accuracy: 0.3826\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.0442 - accuracy: 0.3902\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.8075 - accuracy: 0.3874\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.2943 - accuracy: 0.4006\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.2967 - accuracy: 0.3950\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.2699 - accuracy: 0.3930\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.5404 - accuracy: 0.4054\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.3877 - accuracy: 0.4006\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.3395 - accuracy: 0.4116\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.2486 - accuracy: 0.4047\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.7434 - accuracy: 0.4061\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.5447 - accuracy: 0.4081\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.2338 - accuracy: 0.4019\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.0703 - accuracy: 0.4123\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.3643 - accuracy: 0.4151\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.8653 - accuracy: 0.4116\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.1183 - accuracy: 0.4137\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.7625 - accuracy: 0.4088\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.5737 - accuracy: 0.4164\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.3304 - accuracy: 0.4192\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.0163 - accuracy: 0.4116\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.6740 - accuracy: 0.4192\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.1869 - accuracy: 0.4144\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.3575 - accuracy: 0.4178\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.4402 - accuracy: 0.4323\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.1600 - accuracy: 0.4213\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.5648 - accuracy: 0.4261\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.1942 - accuracy: 0.4206\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.4179 - accuracy: 0.4157\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.6088 - accuracy: 0.4268\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.4541 - accuracy: 0.4296\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.1085 - accuracy: 0.4358\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.7219 - accuracy: 0.4344\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.7119 - accuracy: 0.4406\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.3325 - accuracy: 0.4192\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.7601 - accuracy: 0.4316\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.2859 - accuracy: 0.4351\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.9281 - accuracy: 0.4385\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.7820 - accuracy: 0.4247\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.6484 - accuracy: 0.4282\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.4692 - accuracy: 0.4392\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.5476 - accuracy: 0.4365\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.1870 - accuracy: 0.4406\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.6224 - accuracy: 0.4309\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.9339 - accuracy: 0.4489\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.7025 - accuracy: 0.4413\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.7102 - accuracy: 0.4330\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.1407 - accuracy: 0.4358\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.4397 - accuracy: 0.4289\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.5266 - accuracy: 0.4482\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.4011 - accuracy: 0.4378\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.8535 - accuracy: 0.4454\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.4057 - accuracy: 0.4358\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.0936 - accuracy: 0.4503\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.5758 - accuracy: 0.4344\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.8073 - accuracy: 0.4392\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.3880 - accuracy: 0.4454\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.6773 - accuracy: 0.4399\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.1964 - accuracy: 0.4434\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.2170 - accuracy: 0.4372\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.8356 - accuracy: 0.4323\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.0215 - accuracy: 0.4434\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.8826 - accuracy: 0.4565\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.3143 - accuracy: 0.4365\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.2759 - accuracy: 0.4448\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.3078 - accuracy: 0.4482\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.1379 - accuracy: 0.4392\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.7273 - accuracy: 0.4372\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0712 - accuracy: 0.4468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd0223c488>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.36464088397790057\n",
      "Tasa de aciertos balanceada regresión logística: 0.34\n",
      "Matriz de confusión:\n",
      "[[49 17  1 10  0  0]\n",
      " [19 20 13  6  1  2]\n",
      " [ 9 21 16 20  3  2]\n",
      " [ 4 13  9 33 12  8]\n",
      " [ 4  6  9 16  4  7]\n",
      " [ 1  1  3 10  3 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.57      0.64      0.60        77\n",
      "         2.0       0.26      0.33      0.29        61\n",
      "         3.0       0.31      0.23      0.26        71\n",
      "         4.0       0.35      0.42      0.38        79\n",
      "         5.0       0.17      0.09      0.12        46\n",
      "         6.0       0.34      0.36      0.35        28\n",
      "\n",
      "    accuracy                           0.36       362\n",
      "   macro avg       0.33      0.34      0.33       362\n",
      "weighted avg       0.35      0.36      0.35       362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_305 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_306 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,612\n",
      "Trainable params: 5,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 2155.0203 - accuracy: 0.1657\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 866.0502 - accuracy: 0.1913\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 501.2422 - accuracy: 0.1858\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 300.4489 - accuracy: 0.1775\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 241.3626 - accuracy: 0.1872\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 209.7445 - accuracy: 0.1941\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 190.7621 - accuracy: 0.1975\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 176.0681 - accuracy: 0.2079\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 162.3162 - accuracy: 0.2065\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 149.2626 - accuracy: 0.2251\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 137.6118 - accuracy: 0.2314\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 130.1033 - accuracy: 0.2410\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 122.4377 - accuracy: 0.2479\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 114.6702 - accuracy: 0.2459\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 108.0266 - accuracy: 0.2610\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 103.3688 - accuracy: 0.2459\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 98.8627 - accuracy: 0.2721\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 95.4270 - accuracy: 0.2673\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.1972 - accuracy: 0.2597\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 89.1524 - accuracy: 0.2742\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.9736 - accuracy: 0.2769\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 84.3362 - accuracy: 0.2838\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.7315 - accuracy: 0.2838\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.6339 - accuracy: 0.2811\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.7569 - accuracy: 0.2901\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.2063 - accuracy: 0.2845\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.4445 - accuracy: 0.2859\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.0876 - accuracy: 0.2845\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.7485 - accuracy: 0.2804\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.8722 - accuracy: 0.2887\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.6301 - accuracy: 0.2942\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.1697 - accuracy: 0.2880\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.6919 - accuracy: 0.2838\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.2741 - accuracy: 0.2928\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.0718 - accuracy: 0.2873\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.5322 - accuracy: 0.2873\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.1458 - accuracy: 0.2887\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.3522 - accuracy: 0.3004\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.3261 - accuracy: 0.3025\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.2751 - accuracy: 0.3087\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.5869 - accuracy: 0.3128\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.3465 - accuracy: 0.3108\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.9122 - accuracy: 0.3170\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.1208 - accuracy: 0.3115\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.3409 - accuracy: 0.3087\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.5309 - accuracy: 0.3163\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.2695 - accuracy: 0.3211\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.8455 - accuracy: 0.3163\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.4813 - accuracy: 0.3177\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.7277 - accuracy: 0.3211\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.1333 - accuracy: 0.3218\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.9932 - accuracy: 0.3211\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.4689 - accuracy: 0.3273\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.1429 - accuracy: 0.3322\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.3706 - accuracy: 0.3198\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.0536 - accuracy: 0.3322\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.9387 - accuracy: 0.3301\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.1719 - accuracy: 0.3363\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.9366 - accuracy: 0.3377\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.0511 - accuracy: 0.3446\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.5406 - accuracy: 0.3439\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.1642 - accuracy: 0.3460\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.7141 - accuracy: 0.3508\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.0120 - accuracy: 0.3363\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.9369 - accuracy: 0.3529\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.7005 - accuracy: 0.3412\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.9128 - accuracy: 0.3564\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.7347 - accuracy: 0.3557\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.3626 - accuracy: 0.3529\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.3902 - accuracy: 0.3453\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.9259 - accuracy: 0.3543\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.7581 - accuracy: 0.3536\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0040 - accuracy: 0.3501\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0345 - accuracy: 0.3494\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.9828 - accuracy: 0.3646\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.0556 - accuracy: 0.3626\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.2975 - accuracy: 0.3653\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.8185 - accuracy: 0.3612\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.5296 - accuracy: 0.3764\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.2641 - accuracy: 0.3605\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.2649 - accuracy: 0.3674\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.7781 - accuracy: 0.3709\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.6645 - accuracy: 0.3778\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.9557 - accuracy: 0.3646\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.9247 - accuracy: 0.3798\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.2345 - accuracy: 0.3722\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.7439 - accuracy: 0.3791\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.5123 - accuracy: 0.3722\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.2368 - accuracy: 0.3833\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.0016 - accuracy: 0.3819\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.0565 - accuracy: 0.3923\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.7258 - accuracy: 0.3791\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.3854 - accuracy: 0.3881\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.3387 - accuracy: 0.3812\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.3656 - accuracy: 0.3874\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.2130 - accuracy: 0.3902\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.0441 - accuracy: 0.3854\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.3366 - accuracy: 0.3909\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.4389 - accuracy: 0.3916\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.2091 - accuracy: 0.3785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd02601388>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3259668508287293\n",
      "Tasa de aciertos balanceada regresión logística: 0.29\n",
      "Matriz de confusión:\n",
      "[[55  7  7  4  4  0]\n",
      " [25  8  3 12 13  0]\n",
      " [12  3  5 23 26  2]\n",
      " [ 7  2 15 33 19  3]\n",
      " [ 3  4 14  8 14  3]\n",
      " [ 0  0  6  4 15  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.54      0.71      0.61        77\n",
      "         2.0       0.33      0.13      0.19        61\n",
      "         3.0       0.10      0.07      0.08        71\n",
      "         4.0       0.39      0.42      0.40        79\n",
      "         5.0       0.15      0.30      0.20        46\n",
      "         6.0       0.27      0.11      0.15        28\n",
      "\n",
      "    accuracy                           0.33       362\n",
      "   macro avg       0.30      0.29      0.27       362\n",
      "weighted avg       0.32      0.33      0.30       362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_310 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_312 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,058\n",
      "Trainable params: 2,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 3706.0017 - accuracy: 0.1844\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2115.7634 - accuracy: 0.1499\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1689.8225 - accuracy: 0.1305\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1380.3357 - accuracy: 0.1360\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1193.6239 - accuracy: 0.1319\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1073.5840 - accuracy: 0.1381\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 972.0709 - accuracy: 0.1485\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 883.3912 - accuracy: 0.1485\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 805.8004 - accuracy: 0.1533\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 735.3104 - accuracy: 0.1519\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 669.5895 - accuracy: 0.1651\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 610.2977 - accuracy: 0.1637\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 557.4999 - accuracy: 0.1609\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 515.2563 - accuracy: 0.1692\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 481.7240 - accuracy: 0.1651\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 452.8477 - accuracy: 0.1637\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 427.0676 - accuracy: 0.1678\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 402.9500 - accuracy: 0.1678\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 381.5011 - accuracy: 0.1609\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 361.9935 - accuracy: 0.1568\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 343.5787 - accuracy: 0.1533\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 325.5237 - accuracy: 0.1540\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 309.0008 - accuracy: 0.1492\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 293.9459 - accuracy: 0.1554\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 281.0120 - accuracy: 0.1395\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 267.8047 - accuracy: 0.1519\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 257.2855 - accuracy: 0.1519\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 246.7172 - accuracy: 0.1533\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 237.8685 - accuracy: 0.1568\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 228.2803 - accuracy: 0.1609\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 219.9276 - accuracy: 0.1519\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 212.4212 - accuracy: 0.1499\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 206.2418 - accuracy: 0.1519\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 199.0002 - accuracy: 0.1540\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 193.6946 - accuracy: 0.1602\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 187.3190 - accuracy: 0.1533\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 182.3039 - accuracy: 0.1554\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 177.4704 - accuracy: 0.1554\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 173.1738 - accuracy: 0.1602\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 168.8881 - accuracy: 0.1595\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 164.5224 - accuracy: 0.1595\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 160.3602 - accuracy: 0.1602\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 156.6076 - accuracy: 0.1657\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 152.8340 - accuracy: 0.1623\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 149.7228 - accuracy: 0.1644\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 145.8726 - accuracy: 0.1651\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 142.7523 - accuracy: 0.1630\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 139.3887 - accuracy: 0.1664\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 136.1631 - accuracy: 0.1651\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 133.5729 - accuracy: 0.1671\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 130.9961 - accuracy: 0.1630\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 128.1461 - accuracy: 0.1706\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 125.3571 - accuracy: 0.1664\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 122.7450 - accuracy: 0.1664\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 120.1976 - accuracy: 0.1637\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 117.2940 - accuracy: 0.1699\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 114.3375 - accuracy: 0.1706\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 111.0849 - accuracy: 0.1657\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 108.6091 - accuracy: 0.1733\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 105.4372 - accuracy: 0.1699\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 102.2555 - accuracy: 0.1713\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 99.6360 - accuracy: 0.1740\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 96.7393 - accuracy: 0.1692\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 93.7241 - accuracy: 0.1706\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.5707 - accuracy: 0.1733\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 88.3023 - accuracy: 0.1740\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.9622 - accuracy: 0.1789\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.7532 - accuracy: 0.1761\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.5589 - accuracy: 0.1740\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.3952 - accuracy: 0.1782\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.1970 - accuracy: 0.1727\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.0904 - accuracy: 0.1747\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.9385 - accuracy: 0.1699\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.6503 - accuracy: 0.1740\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.4544 - accuracy: 0.1733\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.5443 - accuracy: 0.1706\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.2913 - accuracy: 0.1664\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.9127 - accuracy: 0.1733\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.8009 - accuracy: 0.1809\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.9420 - accuracy: 0.1837\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.7202 - accuracy: 0.1796\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.8023 - accuracy: 0.1858\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.7933 - accuracy: 0.1885\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.8401 - accuracy: 0.1885\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.5940 - accuracy: 0.1934\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.9208 - accuracy: 0.1899\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.0228 - accuracy: 0.1823\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.1859 - accuracy: 0.1837\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.6454 - accuracy: 0.1982\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0299 - accuracy: 0.1941\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.6742 - accuracy: 0.1920\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.2347 - accuracy: 0.1954\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.8782 - accuracy: 0.2037\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.5299 - accuracy: 0.1961\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.2570 - accuracy: 0.2030\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.0833 - accuracy: 0.2099\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.0515 - accuracy: 0.2065\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.0471 - accuracy: 0.2106\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.8942 - accuracy: 0.2169\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.9698 - accuracy: 0.2175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd03990108>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1464088397790055\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[49 17  1 10  0  0]\n",
      " [19 20 13  6  1  2]\n",
      " [ 9 21 16 20  3  2]\n",
      " [ 4 13  9 33 12  8]\n",
      " [ 4  6  9 16  4  7]\n",
      " [ 1  1  3 10  3 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       1.00      0.02      0.03        61\n",
      "         3.0       0.18      0.11      0.14        71\n",
      "         4.0       0.19      0.27      0.22        79\n",
      "         5.0       0.11      0.04      0.06        46\n",
      "         6.0       0.11      0.75      0.20        28\n",
      "\n",
      "    accuracy                           0.15       362\n",
      "   macro avg       0.23      0.17      0.09       362\n",
      "weighted avg       0.27      0.15      0.10       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_315 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_316 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_318 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,757\n",
      "Trainable params: 21,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 8.6828 - accuracy: 0.1070\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7095 - accuracy: 0.1064\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3071 - accuracy: 0.1209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd03d4c088>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.09392265193370165\n",
      "Tasa de aciertos balanceada regresión logística: 0.08\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [37 17 23  0  0  0  0]\n",
      " [27 17 17  0  0  0  0]\n",
      " [24 30 17  0  0  0  0]\n",
      " [16 46 17  0  0  0  0]\n",
      " [16 18 12  0  0  0  0]\n",
      " [15  6  7  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.13      0.22      0.16        77\n",
      "         2.0       0.18      0.28      0.22        61\n",
      "         3.0       0.00      0.00      0.00        71\n",
      "         4.0       0.00      0.00      0.00        79\n",
      "         5.0       0.00      0.00      0.00        46\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.09       362\n",
      "   macro avg       0.04      0.07      0.05       362\n",
      "weighted avg       0.06      0.09      0.07       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_320 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,895\n",
      "Trainable params: 9,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 10.7719 - accuracy: 0.0587\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1666 - accuracy: 0.0877\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.2353 - accuracy: 0.0946\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6450 - accuracy: 0.1506\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1754 - accuracy: 0.1533\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9868 - accuracy: 0.1450\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9194 - accuracy: 0.1478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd7f6a2308>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0856353591160221\n",
      "Tasa de aciertos balanceada regresión logística: 0.12\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 6  0  0 40  0  0 31]\n",
      " [13  0  0 21  0  0 27]\n",
      " [20  0  0 18  0  0 33]\n",
      " [27  0  0 37  0  0 15]\n",
      " [12  0  0 20  0  0 14]\n",
      " [ 4  0  0 11  0  0 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        61\n",
      "         3.0       0.12      0.25      0.17        71\n",
      "         4.0       0.00      0.00      0.00        79\n",
      "         5.0       0.00      0.00      0.00        46\n",
      "         6.0       0.10      0.46      0.16        28\n",
      "\n",
      "    accuracy                           0.09       362\n",
      "   macro avg       0.03      0.10      0.05       362\n",
      "weighted avg       0.03      0.09      0.04       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_325 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_328 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,159\n",
      "Trainable params: 3,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7886 - accuracy: 0.1789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd024e4788>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.19613259668508287\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [37 17 23  0  0  0  0]\n",
      " [27 17 17  0  0  0  0]\n",
      " [24 30 17  0  0  0  0]\n",
      " [16 46 17  0  0  0  0]\n",
      " [16 18 12  0  0  0  0]\n",
      " [15  6  7  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        61\n",
      "         3.0       0.20      1.00      0.33        71\n",
      "         4.0       0.00      0.00      0.00        79\n",
      "         5.0       0.00      0.00      0.00        46\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.20       362\n",
      "   macro avg       0.03      0.17      0.05       362\n",
      "weighted avg       0.04      0.20      0.06       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_330 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,819\n",
      "Trainable params: 12,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 7.8348 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1306 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd0590e4c8>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [77  0  0  0  0  0  0]\n",
      " [61  0  0  0  0  0  0]\n",
      " [71  0  0  0  0  0  0]\n",
      " [79  0  0  0  0  0  0]\n",
      " [46  0  0  0  0  0  0]\n",
      " [28  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00      61.0\n",
      "         3.0       0.00      0.00      0.00      71.0\n",
      "         4.0       0.00      0.00      0.00      79.0\n",
      "         5.0       0.00      0.00      0.00      46.0\n",
      "         6.0       0.00      0.00      0.00      28.0\n",
      "\n",
      "    accuracy                           0.00     362.0\n",
      "   macro avg       0.00      0.00      0.00     362.0\n",
      "weighted avg       0.00      0.00      0.00     362.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_340 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_342 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_343 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_344 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_345 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_346 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_348 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_349 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,175\n",
      "Trainable params: 6,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5277 - accuracy: 0.0974\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5276 - accuracy: 0.0974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd06dd2108>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1685082872928177\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0 77  0  0  0  0]\n",
      " [ 0 61  0  0  0  0]\n",
      " [ 0 71  0  0  0  0]\n",
      " [ 0 79  0  0  0  0]\n",
      " [ 0 46  0  0  0  0]\n",
      " [ 0 28  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.17      1.00      0.29        61\n",
      "         3.0       0.00      0.00      0.00        71\n",
      "         4.0       0.00      0.00      0.00        79\n",
      "         5.0       0.00      0.00      0.00        46\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.17       362\n",
      "   macro avg       0.03      0.17      0.05       362\n",
      "weighted avg       0.03      0.17      0.05       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_350 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_351 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_352 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_353 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_354 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_355 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_356 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_357 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_358 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,193\n",
      "Trainable params: 2,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - accuracy: 0.0974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd082d8288>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1685082872928177\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [77  0  0  0  0  0  0]\n",
      " [61  0  0  0  0  0  0]\n",
      " [71  0  0  0  0  0  0]\n",
      " [79  0  0  0  0  0  0]\n",
      " [46  0  0  0  0  0  0]\n",
      " [28  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.17      1.00      0.29        61\n",
      "         3.0       0.00      0.00      0.00        71\n",
      "         4.0       0.00      0.00      0.00        79\n",
      "         5.0       0.00      0.00      0.00        46\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.17       362\n",
      "   macro avg       0.03      0.17      0.05       362\n",
      "weighted avg       0.03      0.17      0.05       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERVALO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.549072</td>\n",
       "      <td>0.251989</td>\n",
       "      <td>0.090186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.204244</td>\n",
       "      <td>0.185676</td>\n",
       "      <td>0.161804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090186</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.435013</td>\n",
       "      <td>0.352785</td>\n",
       "      <td>0.193634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.063660</td>\n",
       "      <td>0.164456</td>\n",
       "      <td>0.090186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.071618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.549072     0.251989     0.090186\n",
       "Experimento 2- RELU+ADAM         0.204244     0.185676     0.161804\n",
       "Experimento 3- RELU+ADAM         0.000000     0.090186     0.000000\n",
       "Experimento 1- RELU+ADAGRAD      0.435013     0.352785     0.193634\n",
       "Experimento 2- RELU+ADAGRAD      0.063660     0.164456     0.090186\n",
       "Experimento 3- RELU+ADAGRAD      0.071618     0.000000     0.151194"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['100 Neuronas'] = None\n",
    "df1['64 Neuronas'] = None\n",
    "df1['32 Neuronas'] = None\n",
    "df1.loc['Experimento 1- RELU+ADAM'] = [0.5490716180371353,0.2519893899204244,0.09018567639257294]\n",
    "df1.loc['Experimento 2- RELU+ADAM'] = [0.20424403183023873,0.1856763925729443,0.16180371352785147]\n",
    "df1.loc['Experimento 3- RELU+ADAM'] = [0.0,0.09018567639257294,0.0]\n",
    "df1.loc['Experimento 1- RELU+ADAGRAD'] = [0.4350132625994695,0.35278514588859416,0.19363395225464192]\n",
    "df1.loc['Experimento 2- RELU+ADAGRAD'] = [0.0636604774535809,0.16445623342175067,0.09018567639257294]\n",
    "df1.loc['Experimento 3- RELU+ADAGRAD'] = [0.07161803713527852,0.0,0.15119363395225463]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.404372</td>\n",
       "      <td>0.076503</td>\n",
       "      <td>0.076503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.142077</td>\n",
       "      <td>0.218579</td>\n",
       "      <td>0.270492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.076503</td>\n",
       "      <td>0.210383</td>\n",
       "      <td>0.169399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.254098</td>\n",
       "      <td>0.254098</td>\n",
       "      <td>0.180328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.210383</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.120219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.013661</td>\n",
       "      <td>0.218579</td>\n",
       "      <td>0.218579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.404372     0.076503     0.076503\n",
       "Experimento 2- RELU+ADAM         0.142077     0.218579     0.270492\n",
       "Experimento 3- RELU+ADAM         0.076503     0.210383     0.169399\n",
       "Experimento 1- RELU+ADAGRAD      0.254098     0.254098     0.180328\n",
       "Experimento 2- RELU+ADAGRAD      0.210383     0.065574     0.120219\n",
       "Experimento 3- RELU+ADAGRAD      0.013661     0.218579     0.218579"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['100 Neuronas'] = None\n",
    "df2['64 Neuronas'] = None\n",
    "df2['32 Neuronas'] = None\n",
    "df2.loc['Experimento 1- RELU+ADAM'] = [0.40437158469945356,0.07650273224043716,0.07650273224043716]\n",
    "df2.loc['Experimento 2- RELU+ADAM'] = [0.14207650273224043,0.2185792349726776,0.27049180327868855]\n",
    "df2.loc['Experimento 3- RELU+ADAM'] = [0.07650273224043716,0.2103825136612022,0.16939890710382513]\n",
    "df2.loc['Experimento 1- RELU+ADAGRAD'] = [0.2540983606557377,0.2540983606557377,0.18032786885245902]\n",
    "df2.loc['Experimento 2- RELU+ADAGRAD'] = [0.2103825136612022,0.06557377049180328,0.12021857923497267]\n",
    "df2.loc['Experimento 3- RELU+ADAGRAD'] = [0.01366120218579235,0.2185792349726776,0.2185792349726776]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.441989</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.077348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.218232</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.212707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.113260</td>\n",
       "      <td>0.218232</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.364641</td>\n",
       "      <td>0.325967</td>\n",
       "      <td>0.146409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.093923</td>\n",
       "      <td>0.085635</td>\n",
       "      <td>0.196133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168508</td>\n",
       "      <td>0.168508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.441989     0.077348     0.077348\n",
       "Experimento 2- RELU+ADAM         0.218232     0.077348     0.212707\n",
       "Experimento 3- RELU+ADAM         0.113260     0.218232     0.000000\n",
       "Experimento 1- RELU+ADAGRAD      0.364641     0.325967     0.146409\n",
       "Experimento 2- RELU+ADAGRAD      0.093923     0.085635     0.196133\n",
       "Experimento 3- RELU+ADAGRAD      0.000000     0.168508     0.168508"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame()\n",
    "df3['100 Neuronas'] = None\n",
    "df3['64 Neuronas'] = None\n",
    "df3['32 Neuronas'] = None\n",
    "df3.loc['Experimento 1- RELU+ADAM'] = [0.4419889502762431,0.07734806629834254,0.07734806629834254]\n",
    "df3.loc['Experimento 2- RELU+ADAM'] = [0.21823204419889503,0.07734806629834254,0.212707182320442]\n",
    "df3.loc['Experimento 3- RELU+ADAM'] = [0.1132596685082873,0.21823204419889503,0.0]\n",
    "df3.loc['Experimento 1- RELU+ADAGRAD'] = [0.36464088397790057,0.3259668508287293,0.1464088397790055]\n",
    "df3.loc['Experimento 2- RELU+ADAGRAD'] = [0.09392265193370165,0.0856353591160221,0.19613259668508287]\n",
    "df3.loc['Experimento 3- RELU+ADAGRAD'] = [0.0,0.1685082872928177,0.1685082872928177]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16476cfe588>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,20))\n",
    "fig.add_subplot(2,2,1)\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 1')\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM' ,color ='red')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 2')\n",
    "fig.add_subplot(2,2,3)\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 3')\n",
    "plt.legend(bbox_to_anchor = (2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERVALO 1\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "df1['100 Neuronas'] = None\n",
    "df1['64 Neuronas'] = None\n",
    "df1['32 Neuronas'] = None\n",
    "df1.loc['Experimento 1- RELU+ADAM'] = [0.5490716180371353,0.2519893899204244,0.09018567639257294]\n",
    "df1.loc['Experimento 2- RELU+ADAM'] = [0.20424403183023873,0.1856763925729443,0.16180371352785147]\n",
    "df1.loc['Experimento 3- RELU+ADAM'] = [0.0,0.09018567639257294,0.0]\n",
    "df1.loc['Experimento 1- RELU+ADAGRAD'] = [0.4350132625994695,0.35278514588859416,0.19363395225464192]\n",
    "df1.loc['Experimento 2- RELU+ADAGRAD'] = [0.0636604774535809,0.16445623342175067,0.09018567639257294]\n",
    "df1.loc['Experimento 3- RELU+ADAGRAD'] = [0.07161803713527852,0.0,0.15119363395225463]\n",
    "df1\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "df2['100 Neuronas'] = None\n",
    "df2['64 Neuronas'] = None\n",
    "df2['32 Neuronas'] = None\n",
    "df2.loc['Experimento 1- RELU+ADAM'] = [0.40437158469945356,0.07650273224043716,0.07650273224043716]\n",
    "df2.loc['Experimento 2- RELU+ADAM'] = [0.14207650273224043,0.2185792349726776,0.27049180327868855]\n",
    "df2.loc['Experimento 3- RELU+ADAM'] = [0.07650273224043716,0.2103825136612022,0.16939890710382513]\n",
    "df2.loc['Experimento 1- RELU+ADAGRAD'] = [0.2540983606557377,0.2540983606557377,0.18032786885245902]\n",
    "df2.loc['Experimento 2- RELU+ADAGRAD'] = [0.2103825136612022,0.06557377049180328,0.12021857923497267]\n",
    "df2.loc['Experimento 3- RELU+ADAGRAD'] = [0.01366120218579235,0.2185792349726776,0.2185792349726776]\n",
    "df2\n",
    "\n",
    "df3 = pd.DataFrame()\n",
    "df3['100 Neuronas'] = None\n",
    "df3['64 Neuronas'] = None\n",
    "df3['32 Neuronas'] = None\n",
    "df3.loc['Experimento 1- RELU+ADAM'] = [0.4419889502762431,0.07734806629834254,0.07734806629834254]\n",
    "df3.loc['Experimento 2- RELU+ADAM'] = [0.21823204419889503,0.07734806629834254,0.212707182320442]\n",
    "df3.loc['Experimento 3- RELU+ADAM'] = [0.1132596685082873,0.21823204419889503,0.0]\n",
    "df3.loc['Experimento 1- RELU+ADAGRAD'] = [0.36464088397790057,0.3259668508287293,0.1464088397790055]\n",
    "df3.loc['Experimento 2- RELU+ADAGRAD'] = [0.09392265193370165,0.0856353591160221,0.19613259668508287]\n",
    "df3.loc['Experimento 3- RELU+ADAGRAD'] = [0.0,0.1685082872928177,0.1685082872928177]\n",
    "df3\n",
    "\n",
    "fig = plt.figure(figsize=(15,20))\n",
    "fig.add_subplot(2,2,1)\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 1')\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM' ,color ='red')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 2')\n",
    "fig.add_subplot(2,2,3)\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 3')\n",
    "plt.legend(bbox_to_anchor = (2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run 10dias-porintervalos2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix,balanced_accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subida(list):\n",
    "    resultado = []\n",
    "    for i in range(1,len(list)):\n",
    "        if  (list)[i] > (list)[i-1]:\n",
    "            resultado.append(1)\n",
    "        else:\n",
    "            resultado.append(0)\n",
    "    return resultado\n",
    "\n",
    "def acierto(list1,list2):\n",
    "    sum = 0\n",
    "    for i in range(0,len(list1)):\n",
    "        if(list1[i]==list2[i]):\n",
    "            sum = sum +1\n",
    "    a = sum/len(list1)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 12, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_360 (Dense)           (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_361 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_362 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_363 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_364 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,065\n",
      "Trainable params: 9,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 957.6065 - accuracy: 0.1731\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 131.1315 - accuracy: 0.2699\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 107.2421 - accuracy: 0.3024\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 73.7547 - accuracy: 0.3369\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 58.8023 - accuracy: 0.4045\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 61.3743 - accuracy: 0.4005\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 63.6539 - accuracy: 0.4012\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 62.5448 - accuracy: 0.4065\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 52.3302 - accuracy: 0.4410\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 58.6860 - accuracy: 0.4264\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 39.6192 - accuracy: 0.4808\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 33.2493 - accuracy: 0.4675\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 41.8671 - accuracy: 0.4297\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 48.8140 - accuracy: 0.4403\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 65.8125 - accuracy: 0.4357\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 54.1798 - accuracy: 0.4403\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 26.7316 - accuracy: 0.5351\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.5611 - accuracy: 0.5073\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.4604 - accuracy: 0.5212\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 27.7554 - accuracy: 0.5146\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 47.3158 - accuracy: 0.4768\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 87.4827 - accuracy: 0.3972\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 21.9642 - accuracy: 0.4881\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.3097 - accuracy: 0.5027\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.3151 - accuracy: 0.5219\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9483 - accuracy: 0.5325\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.2492 - accuracy: 0.5332\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.5752 - accuracy: 0.5623\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 19.1878 - accuracy: 0.5146\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.0257 - accuracy: 0.5239\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.4634 - accuracy: 0.5146\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.1311 - accuracy: 0.5497\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.4900 - accuracy: 0.5822\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6996 - accuracy: 0.5484\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.0886 - accuracy: 0.5736\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.0748 - accuracy: 0.5305\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.3799 - accuracy: 0.5332\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8725 - accuracy: 0.5875\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7628 - accuracy: 0.5637\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8786 - accuracy: 0.5590\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5389 - accuracy: 0.5776\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.1650 - accuracy: 0.5617\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.6169 - accuracy: 0.5723\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.5643 - accuracy: 0.5477\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.7619 - accuracy: 0.5418\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.4298 - accuracy: 0.5378\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.4463 - accuracy: 0.5385\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.2814 - accuracy: 0.5557\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.0796 - accuracy: 0.5763\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8764 - accuracy: 0.5133\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.0538 - accuracy: 0.5577\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8686 - accuracy: 0.5643\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.9996 - accuracy: 0.5517\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.0172 - accuracy: 0.5557\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7289 - accuracy: 0.5199\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7537 - accuracy: 0.5239\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.2499 - accuracy: 0.5537\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7376 - accuracy: 0.5544\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.2668 - accuracy: 0.5345\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.2646 - accuracy: 0.5590\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.8766 - accuracy: 0.5557\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.0994 - accuracy: 0.5371\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1353 - accuracy: 0.5146\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.6220 - accuracy: 0.5590\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.3961 - accuracy: 0.5630\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5759 - accuracy: 0.5279\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.4811 - accuracy: 0.5225\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.6674 - accuracy: 0.5690\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.0258 - accuracy: 0.5650\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2103 - accuracy: 0.5531\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.4674 - accuracy: 0.5484\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9920 - accuracy: 0.5710\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.3828 - accuracy: 0.5703\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.2527 - accuracy: 0.5477\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2043 - accuracy: 0.5405\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9706 - accuracy: 0.5623\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9803 - accuracy: 0.5716\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.0691 - accuracy: 0.5391\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9410 - accuracy: 0.5829\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.8308 - accuracy: 0.5265\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8028 - accuracy: 0.5869\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.4693 - accuracy: 0.5318\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.3566 - accuracy: 0.4980\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0950 - accuracy: 0.5683\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.3482 - accuracy: 0.5325\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6156 - accuracy: 0.5822\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6442 - accuracy: 0.5995\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9570 - accuracy: 0.5656\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8190 - accuracy: 0.5915\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.4897 - accuracy: 0.5153\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8435 - accuracy: 0.5557\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1346 - accuracy: 0.5683\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6549 - accuracy: 0.5716\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9958 - accuracy: 0.5577\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8716 - accuracy: 0.5517\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6049 - accuracy: 0.5637\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6554 - accuracy: 0.5451\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.4096 - accuracy: 0.5106\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.4690 - accuracy: 0.5484\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0362 - accuracy: 0.5199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd0b22d3c8>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5782493368700266\n",
      "Tasa de aciertos balanceada regresión logística: 0.54\n",
      "Matriz de confusión:\n",
      "[[54 22  1  0  0]\n",
      " [ 8 84  8  0  0]\n",
      " [ 0 35 14  7  4]\n",
      " [ 0 11 21 44 13]\n",
      " [ 0  6  8 15 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.87      0.70      0.78        77\n",
      "         2.0       0.53      0.84      0.65       100\n",
      "         3.0       0.27      0.23      0.25        60\n",
      "         4.0       0.67      0.49      0.57        89\n",
      "         5.0       0.56      0.43      0.49        51\n",
      "\n",
      "    accuracy                           0.58       377\n",
      "   macro avg       0.58      0.54      0.55       377\n",
      "weighted avg       0.60      0.58      0.57       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_365 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_366 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_368 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_369 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,076\n",
      "Trainable params: 4,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 1557.5010 - accuracy: 0.2487\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 162.0281 - accuracy: 0.2832\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 67.2950 - accuracy: 0.3223\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 51.8740 - accuracy: 0.3263\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 45.4489 - accuracy: 0.3588\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 32.8237 - accuracy: 0.3077\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.5629 - accuracy: 0.2653\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.9188 - accuracy: 0.1963\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9487 - accuracy: 0.1969\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8530 - accuracy: 0.2188\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8232 - accuracy: 0.2918\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8025 - accuracy: 0.2931\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7845 - accuracy: 0.2958\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7689 - accuracy: 0.2964\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7538 - accuracy: 0.2971\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7425 - accuracy: 0.2984\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7587 - accuracy: 0.2891\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7335 - accuracy: 0.2958\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7174 - accuracy: 0.2971\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7058 - accuracy: 0.2977\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6996 - accuracy: 0.2971\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6915 - accuracy: 0.2991\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6866 - accuracy: 0.2971\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6794 - accuracy: 0.2984\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6742 - accuracy: 0.2984\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6765 - accuracy: 0.2971\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6646 - accuracy: 0.2984\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6594 - accuracy: 0.3011\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6550 - accuracy: 0.3004\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6511 - accuracy: 0.3004\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6475 - accuracy: 0.3011\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6532 - accuracy: 0.3017\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6595 - accuracy: 0.2951\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6389 - accuracy: 0.2991\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6352 - accuracy: 0.2991\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7353 - accuracy: 0.2845\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6491 - accuracy: 0.2918\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6329 - accuracy: 0.2971\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6273 - accuracy: 0.2997\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6244 - accuracy: 0.2997\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6222 - accuracy: 0.3011\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6200 - accuracy: 0.3011\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6183 - accuracy: 0.3011\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6164 - accuracy: 0.3011\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6147 - accuracy: 0.3011\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6131 - accuracy: 0.3011\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6114 - accuracy: 0.3011\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6101 - accuracy: 0.3011\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6086 - accuracy: 0.3011\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6071 - accuracy: 0.3011\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6083 - accuracy: 0.3004\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6060 - accuracy: 0.2997\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6048 - accuracy: 0.2997\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6036 - accuracy: 0.2997\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6025 - accuracy: 0.3004\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6013 - accuracy: 0.3004\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6004 - accuracy: 0.2997\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5992 - accuracy: 0.3004\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5982 - accuracy: 0.3004\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5973 - accuracy: 0.3004\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5964 - accuracy: 0.3004\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5955 - accuracy: 0.3004\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5946 - accuracy: 0.3004\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5938 - accuracy: 0.3004\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5931 - accuracy: 0.3004\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5922 - accuracy: 0.3004\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5914 - accuracy: 0.3004\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5907 - accuracy: 0.3004\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5901 - accuracy: 0.3004\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5893 - accuracy: 0.3004\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5887 - accuracy: 0.3004\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5881 - accuracy: 0.3004\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5874 - accuracy: 0.3004\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5869 - accuracy: 0.3004\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5862 - accuracy: 0.3004\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5857 - accuracy: 0.3004\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5850 - accuracy: 0.3004\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5846 - accuracy: 0.3004\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5841 - accuracy: 0.3004\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5835 - accuracy: 0.3004\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5831 - accuracy: 0.3004\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5825 - accuracy: 0.3004\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5821 - accuracy: 0.3004\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5816 - accuracy: 0.3004\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5811 - accuracy: 0.3004\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5807 - accuracy: 0.3004\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5803 - accuracy: 0.3011\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5799 - accuracy: 0.3011\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5795 - accuracy: 0.3011\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5790 - accuracy: 0.3011\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5786 - accuracy: 0.3011\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5782 - accuracy: 0.3011\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5778 - accuracy: 0.3011\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5775 - accuracy: 0.3011\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5772 - accuracy: 0.3011\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5768 - accuracy: 0.3011\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5765 - accuracy: 0.3011\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5761 - accuracy: 0.3011\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5758 - accuracy: 0.3011\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5755 - accuracy: 0.3011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd0aa2e648>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.13527851458885942\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  77]\n",
      " [  0   0   0   0 100]\n",
      " [  0   0   0   0  60]\n",
      " [  0   0   0   0  89]\n",
      " [  0   0   0   0  51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.00      0.00      0.00        89\n",
      "         5.0       0.14      1.00      0.24        51\n",
      "\n",
      "    accuracy                           0.14       377\n",
      "   macro avg       0.03      0.20      0.05       377\n",
      "weighted avg       0.02      0.14      0.03       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_370 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_371 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_372 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_373 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_374 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,290\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 463.8124 - accuracy: 0.1844\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.1922 - accuracy: 0.2301\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.0246 - accuracy: 0.2858\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0520 - accuracy: 0.3004\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9596 - accuracy: 0.2924\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8013 - accuracy: 0.2984\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7625 - accuracy: 0.3024\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7590 - accuracy: 0.3031\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7580 - accuracy: 0.3017\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8223 - accuracy: 0.3011\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8833 - accuracy: 0.2984\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7834 - accuracy: 0.3004\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8201 - accuracy: 0.3004\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7349 - accuracy: 0.3011\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7258 - accuracy: 0.3011\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7174 - accuracy: 0.3011\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7096 - accuracy: 0.3011\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7023 - accuracy: 0.3011\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6958 - accuracy: 0.3011\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6896 - accuracy: 0.3011\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6838 - accuracy: 0.3011\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6785 - accuracy: 0.3011\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6736 - accuracy: 0.3011\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6688 - accuracy: 0.3011\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6645 - accuracy: 0.3011\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6604 - accuracy: 0.3011\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6567 - accuracy: 0.3011\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6531 - accuracy: 0.3011\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6497 - accuracy: 0.3011\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6466 - accuracy: 0.3011\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6437 - accuracy: 0.3011\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6408 - accuracy: 0.3011\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6382 - accuracy: 0.3011\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6357 - accuracy: 0.3011\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6333 - accuracy: 0.3011\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6311 - accuracy: 0.3011\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6288 - accuracy: 0.3011\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6268 - accuracy: 0.3011\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6248 - accuracy: 0.3011\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6229 - accuracy: 0.3011\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6211 - accuracy: 0.3011\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6195 - accuracy: 0.3011\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6178 - accuracy: 0.3011\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6163 - accuracy: 0.3011\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6147 - accuracy: 0.3011\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6133 - accuracy: 0.3011\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6119 - accuracy: 0.3011\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6105 - accuracy: 0.3011\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6092 - accuracy: 0.3011\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6080 - accuracy: 0.3011\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6068 - accuracy: 0.3011\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6057 - accuracy: 0.3011\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6046 - accuracy: 0.3011\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6035 - accuracy: 0.3011\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6025 - accuracy: 0.3011\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6015 - accuracy: 0.3011\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6005 - accuracy: 0.3011\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5996 - accuracy: 0.3011\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5987 - accuracy: 0.3011\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5978 - accuracy: 0.3011\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5970 - accuracy: 0.3011\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5962 - accuracy: 0.3011\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5954 - accuracy: 0.3011\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5947 - accuracy: 0.3011\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5939 - accuracy: 0.3011\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5931 - accuracy: 0.3011\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5924 - accuracy: 0.3011\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5918 - accuracy: 0.3011\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5911 - accuracy: 0.3011\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5905 - accuracy: 0.3011\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5899 - accuracy: 0.3011\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5893 - accuracy: 0.3011\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5887 - accuracy: 0.3011\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5882 - accuracy: 0.3011\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5877 - accuracy: 0.3011\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5871 - accuracy: 0.3011\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5866 - accuracy: 0.3011\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5860 - accuracy: 0.3011\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5856 - accuracy: 0.3011\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5850 - accuracy: 0.3011\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5846 - accuracy: 0.3011\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5841 - accuracy: 0.3011\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5837 - accuracy: 0.3011\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5833 - accuracy: 0.3011\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5829 - accuracy: 0.3011\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5825 - accuracy: 0.3011\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5821 - accuracy: 0.3011\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5816 - accuracy: 0.3011\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5814 - accuracy: 0.3011\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5809 - accuracy: 0.3011\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5806 - accuracy: 0.3011\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5802 - accuracy: 0.3011\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5799 - accuracy: 0.3011\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5796 - accuracy: 0.3011\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5793 - accuracy: 0.3011\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5790 - accuracy: 0.3011\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5786 - accuracy: 0.3011\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5784 - accuracy: 0.3011\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5780 - accuracy: 0.3011\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5778 - accuracy: 0.3011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd0acd4848>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.13527851458885942\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[54 22  1  0  0]\n",
      " [ 8 84  8  0  0]\n",
      " [ 0 35 14  7  4]\n",
      " [ 0 11 21 44 13]\n",
      " [ 0  6  8 15 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.00      0.00      0.00        89\n",
      "         5.0       0.14      1.00      0.24        51\n",
      "\n",
      "    accuracy                           0.14       377\n",
      "   macro avg       0.03      0.20      0.05       377\n",
      "weighted avg       0.02      0.14      0.03       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 12, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_375 (Dense)           (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_376 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_378 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,357\n",
      "Trainable params: 19,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 6.6901 - accuracy: 0.2188\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2188\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5287 - accuracy: 0.2195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd0b034a08>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2625994694960212\n",
      "Tasa de aciertos balanceada regresión logística: 0.24\n",
      "Matriz de confusión:\n",
      "[[53  0  0 24  0]\n",
      " [60  0  0 40  0]\n",
      " [26  0  0 34  0]\n",
      " [43  0  0 46  0]\n",
      " [35  0  0 16  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.24      0.69      0.36        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.29      0.52      0.37        89\n",
      "         5.0       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.26       377\n",
      "   macro avg       0.11      0.24      0.15       377\n",
      "weighted avg       0.12      0.26      0.16       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_380 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_381 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_382 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_383 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_384 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,359\n",
      "Trainable params: 8,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 14.2432 - accuracy: 0.0630\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.2489 - accuracy: 0.0889\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0597\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1819 - accuracy: 0.0584\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1819 - accuracy: 0.0584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd0d5d9988>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.034482758620689655\n",
      "Tasa de aciertos balanceada regresión logística: 0.03\n",
      "Matriz de confusión:\n",
      "[[13  0  0  0  0 64]\n",
      " [32  0  0  0  0 68]\n",
      " [25  0  0  0  0 35]\n",
      " [34  0  0  0  0 55]\n",
      " [12  0  0  0  0 39]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.11      0.17      0.13        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.00      0.00      0.00        89\n",
      "         5.0       0.00      0.00      0.00        51\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.03       377\n",
      "   macro avg       0.02      0.03      0.02       377\n",
      "weighted avg       0.02      0.03      0.03       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_385 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_386 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_387 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_388 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_389 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,391\n",
      "Trainable params: 2,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 2ms/step - loss: 10.2499 - accuracy: 0.0186\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.1155 - accuracy: 0.0477\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4184 - accuracy: 0.1121\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4178 - accuracy: 0.1134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd0da2c388>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.11140583554376658\n",
      "Tasa de aciertos balanceada regresión logística: 0.14\n",
      "Matriz de confusión:\n",
      "[[53  0  0 24  0]\n",
      " [60  0  0 40  0]\n",
      " [26  0  0 34  0]\n",
      " [43  0  0 46  0]\n",
      " [35  0  0 16  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.16      0.67      0.25        60\n",
      "         4.0       0.00      0.00      0.00        89\n",
      "         5.0       0.17      0.04      0.06        51\n",
      "\n",
      "    accuracy                           0.11       377\n",
      "   macro avg       0.05      0.12      0.05       377\n",
      "weighted avg       0.05      0.11      0.05       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 12, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_390 (Dense)           (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_391 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_392 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_393 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_394 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_395 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_396 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_397 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_398 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_399 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,419\n",
      "Trainable params: 10,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 9.9112 - accuracy: 0.0073\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6580 - accuracy: 0.0066\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.0729 - accuracy: 0.0836\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9298 - accuracy: 0.1207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd09a3c248>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.15915119363395225\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0  77   0   0]\n",
      " [  0   0 100   0   0]\n",
      " [  0   0  60   0   0]\n",
      " [  0   0  89   0   0]\n",
      " [  0   0  51   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.16      1.00      0.27        60\n",
      "         4.0       0.00      0.00      0.00        89\n",
      "         5.0       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.16       377\n",
      "   macro avg       0.03      0.20      0.05       377\n",
      "weighted avg       0.03      0.16      0.04       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_400 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_401 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_402 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_403 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_404 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_405 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_406 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_407 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_408 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_409 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,639\n",
      "Trainable params: 4,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1863 - accuracy: 0.2473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd0eda2908>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1962864721485411\n",
      "Tasa de aciertos balanceada regresión logística: 0.23\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0 20 57]\n",
      " [ 0  0  0 31 69]\n",
      " [ 0  0  0 22 38]\n",
      " [ 0  0  0 38 51]\n",
      " [ 0  0  0 15 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.30      0.43      0.35        89\n",
      "         5.0       0.14      0.71      0.24        51\n",
      "\n",
      "    accuracy                           0.20       377\n",
      "   macro avg       0.09      0.23      0.12       377\n",
      "weighted avg       0.09      0.20      0.12       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_410 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_411 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_412 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_413 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_414 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_415 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_416 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_417 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_418 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_419 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,425\n",
      "Trainable params: 1,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 4.6288 - accuracy: 0.0908\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.6391 - accuracy: 0.0643\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.2572 - accuracy: 0.0345\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.1535 - accuracy: 0.0729\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.6028 - accuracy: 0.0431\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.0175 - accuracy: 0.0391\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.0657 - accuracy: 0.0371\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.3877 - accuracy: 0.0776\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7682 - accuracy: 0.0332\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5002 - accuracy: 0.0345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd10330a08>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07957559681697612\n",
      "Tasa de aciertos balanceada regresión logística: 0.07\n",
      "Matriz de confusión:\n",
      "[[  0   0  77   0   0]\n",
      " [  0   0 100   0   0]\n",
      " [  0   0  60   0   0]\n",
      " [  0   0  89   0   0]\n",
      " [  0   0  51   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.25      0.34      0.29        89\n",
      "         5.0       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.08       377\n",
      "   macro avg       0.04      0.06      0.05       377\n",
      "weighted avg       0.06      0.08      0.07       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_420 (Dense)           (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_421 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_422 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_423 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_424 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,065\n",
      "Trainable params: 9,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 728.6393 - accuracy: 0.2639\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 120.2341 - accuracy: 0.3123\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 81.7229 - accuracy: 0.3786\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 79.7296 - accuracy: 0.3767\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 72.4322 - accuracy: 0.3826\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 62.5296 - accuracy: 0.4244\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 57.6069 - accuracy: 0.4151\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 58.0962 - accuracy: 0.4178\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 54.0508 - accuracy: 0.4277\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 48.9311 - accuracy: 0.4304\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 47.2228 - accuracy: 0.4284\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.9509 - accuracy: 0.4416\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43.7856 - accuracy: 0.4443\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 41.4484 - accuracy: 0.4582\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 39.6988 - accuracy: 0.4622\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 40.1846 - accuracy: 0.4443\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.9787 - accuracy: 0.4622\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 38.9140 - accuracy: 0.4483\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.8495 - accuracy: 0.4523\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.6615 - accuracy: 0.4629\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.1560 - accuracy: 0.4775\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.5386 - accuracy: 0.4801\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.7020 - accuracy: 0.4755\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.0808 - accuracy: 0.4748\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.9919 - accuracy: 0.4847\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.3964 - accuracy: 0.4788\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.9617 - accuracy: 0.4808\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.0589 - accuracy: 0.4675\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.6123 - accuracy: 0.4768\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.8107 - accuracy: 0.4828\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.9451 - accuracy: 0.4821\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 28.6255 - accuracy: 0.4814\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 27.3668 - accuracy: 0.5027\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 27.5661 - accuracy: 0.4794\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 27.5494 - accuracy: 0.4907\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.7338 - accuracy: 0.4861\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 26.1754 - accuracy: 0.4987\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.8091 - accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.8789 - accuracy: 0.5027\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.2985 - accuracy: 0.5126\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.7958 - accuracy: 0.5046\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 24.7246 - accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.8169 - accuracy: 0.5126\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.0392 - accuracy: 0.5166\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.1693 - accuracy: 0.5133\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.9453 - accuracy: 0.5159\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.6544 - accuracy: 0.5033\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.5664 - accuracy: 0.5099\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.8802 - accuracy: 0.5212\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.3664 - accuracy: 0.5239\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.0895 - accuracy: 0.5146\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.7041 - accuracy: 0.5239\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.3210 - accuracy: 0.5332\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.2854 - accuracy: 0.5139\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.9392 - accuracy: 0.5292\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.3851 - accuracy: 0.5279\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.8103 - accuracy: 0.5292\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.1217 - accuracy: 0.5232\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.9131 - accuracy: 0.5119\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.7578 - accuracy: 0.5305\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.4114 - accuracy: 0.5272\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.0689 - accuracy: 0.5252\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.9402 - accuracy: 0.5113\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.7647 - accuracy: 0.5179\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.8170 - accuracy: 0.5292\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.2577 - accuracy: 0.5332\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.3585 - accuracy: 0.5285\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.4482 - accuracy: 0.5279\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 19.7679 - accuracy: 0.5239\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 19.2396 - accuracy: 0.5199\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.4255 - accuracy: 0.5378\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.3229 - accuracy: 0.5378\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.9201 - accuracy: 0.5305\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.1714 - accuracy: 0.5464\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.3333 - accuracy: 0.5305\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.5487 - accuracy: 0.5491\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.6798 - accuracy: 0.5385\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.9757 - accuracy: 0.5298\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.2454 - accuracy: 0.5418\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.3429 - accuracy: 0.5378\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.4700 - accuracy: 0.5471\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.1062 - accuracy: 0.5438\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.5702 - accuracy: 0.5431\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.5377 - accuracy: 0.5225\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.8051 - accuracy: 0.5424\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5869 - accuracy: 0.5424\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5991 - accuracy: 0.5411\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.7737 - accuracy: 0.5597\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.1700 - accuracy: 0.5332\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.7831 - accuracy: 0.5458\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.4918 - accuracy: 0.5405\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.3330 - accuracy: 0.5325\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5030 - accuracy: 0.5385\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.0153 - accuracy: 0.5564\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.9597 - accuracy: 0.5504\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 17.8906 - accuracy: 0.5471\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.9705 - accuracy: 0.5391\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.0747 - accuracy: 0.5351\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.7809 - accuracy: 0.5398\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5253 - accuracy: 0.5365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd118ca908>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.47480106100795755\n",
      "Tasa de aciertos balanceada regresión logística: 0.48\n",
      "Matriz de confusión:\n",
      "[[61 13  3  0  0]\n",
      " [29 50 16  1  4]\n",
      " [12 20 21  5  2]\n",
      " [ 6 14 18 18 33]\n",
      " [ 3  7  4  8 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.55      0.79      0.65        77\n",
      "         2.0       0.48      0.50      0.49       100\n",
      "         3.0       0.34      0.35      0.34        60\n",
      "         4.0       0.56      0.20      0.30        89\n",
      "         5.0       0.43      0.57      0.49        51\n",
      "\n",
      "    accuracy                           0.47       377\n",
      "   macro avg       0.47      0.48      0.45       377\n",
      "weighted avg       0.48      0.47      0.45       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_425 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_426 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_427 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_428 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_429 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,076\n",
      "Trainable params: 4,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 1567.0332 - accuracy: 0.0405\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 538.4099 - accuracy: 0.0405\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 381.5986 - accuracy: 0.0451\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 307.7107 - accuracy: 0.0676\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 258.9499 - accuracy: 0.0749\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 225.8804 - accuracy: 0.0962\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 195.0339 - accuracy: 0.0915\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 170.8325 - accuracy: 0.0935\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 148.6988 - accuracy: 0.1054\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 128.5014 - accuracy: 0.1048\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 109.4946 - accuracy: 0.1041\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 93.9859 - accuracy: 0.1207\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 82.2218 - accuracy: 0.1293\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 72.8209 - accuracy: 0.1492\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 65.4003 - accuracy: 0.1684\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 60.0102 - accuracy: 0.1744\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 55.0380 - accuracy: 0.1989\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 51.3086 - accuracy: 0.2049\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 48.1405 - accuracy: 0.2162\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 45.1061 - accuracy: 0.2215\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43.2958 - accuracy: 0.2301\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 40.5472 - accuracy: 0.2347\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 39.2015 - accuracy: 0.2467\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.3881 - accuracy: 0.2493\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.9400 - accuracy: 0.2679\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.8312 - accuracy: 0.2792\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.2407 - accuracy: 0.2918\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.4450 - accuracy: 0.2812\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.2205 - accuracy: 0.2977\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.5720 - accuracy: 0.3031\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.6423 - accuracy: 0.2964\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 28.9249 - accuracy: 0.2944\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 27.8022 - accuracy: 0.3103\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 27.0255 - accuracy: 0.3282\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.1727 - accuracy: 0.3156\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.8356 - accuracy: 0.3176\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.1098 - accuracy: 0.3302\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.7105 - accuracy: 0.3229\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.0950 - accuracy: 0.3196\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.0572 - accuracy: 0.3408\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.8332 - accuracy: 0.3302\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.1052 - accuracy: 0.3382\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.8673 - accuracy: 0.3402\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.2682 - accuracy: 0.3508\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.8247 - accuracy: 0.3574\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.2129 - accuracy: 0.3568\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.0471 - accuracy: 0.3568\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.6744 - accuracy: 0.3641\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.4534 - accuracy: 0.3581\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.2859 - accuracy: 0.3853\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 18.4284 - accuracy: 0.3853\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.1120 - accuracy: 0.3714\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.9664 - accuracy: 0.3760\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.5841 - accuracy: 0.3966\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.1984 - accuracy: 0.3846\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.9213 - accuracy: 0.3879\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.7558 - accuracy: 0.4025\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5084 - accuracy: 0.3959\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.1863 - accuracy: 0.3939\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.0836 - accuracy: 0.4078\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.8290 - accuracy: 0.3959\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.5774 - accuracy: 0.4111\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.4232 - accuracy: 0.4111\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.7960 - accuracy: 0.3999\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.8995 - accuracy: 0.4138\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9646 - accuracy: 0.4138\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5516 - accuracy: 0.4105\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.6471 - accuracy: 0.4191\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.3843 - accuracy: 0.4191\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.2510 - accuracy: 0.4138\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.0975 - accuracy: 0.4158\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.8359 - accuracy: 0.4297\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7727 - accuracy: 0.4151\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.6875 - accuracy: 0.4350\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.5860 - accuracy: 0.4231\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.4368 - accuracy: 0.4344\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.3777 - accuracy: 0.4231\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.2285 - accuracy: 0.4251\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0639 - accuracy: 0.4284\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.8948 - accuracy: 0.4337\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.8837 - accuracy: 0.4271\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.7734 - accuracy: 0.4324\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.6521 - accuracy: 0.4397\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.6676 - accuracy: 0.4330\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.8934 - accuracy: 0.4257\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.3165 - accuracy: 0.4443\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.2870 - accuracy: 0.4416\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.2738 - accuracy: 0.4416\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.9880 - accuracy: 0.4523\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.9985 - accuracy: 0.4397\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.9909 - accuracy: 0.4489\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0774 - accuracy: 0.4304\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.7807 - accuracy: 0.4469\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.7857 - accuracy: 0.4469\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6376 - accuracy: 0.4576\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5327 - accuracy: 0.4536\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5797 - accuracy: 0.4476\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.3816 - accuracy: 0.4529\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2527 - accuracy: 0.4622\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.1940 - accuracy: 0.4655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd11c969c8>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3819628647214854\n",
      "Tasa de aciertos balanceada regresión logística: 0.39\n",
      "Matriz de confusión:\n",
      "[[51 14  1  9  1  1]\n",
      " [30 34  7 21  7  1]\n",
      " [ 8 14 10 16 12  0]\n",
      " [ 1 23 16 22 27  0]\n",
      " [ 0  8  6 10 27  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.57      0.66      0.61        77\n",
      "         2.0       0.37      0.34      0.35       100\n",
      "         3.0       0.25      0.17      0.20        60\n",
      "         4.0       0.28      0.25      0.26        89\n",
      "         5.0       0.36      0.53      0.43        51\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.38       377\n",
      "   macro avg       0.30      0.32      0.31       377\n",
      "weighted avg       0.37      0.38      0.37       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_430 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_431 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_432 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_433 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_434 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,290\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 1149.9283 - accuracy: 0.0153\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 253.8243 - accuracy: 0.1207\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 102.0684 - accuracy: 0.1870\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 45.0542 - accuracy: 0.2228\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.9328 - accuracy: 0.2513\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.0658 - accuracy: 0.2473\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.9245 - accuracy: 0.2500\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4161 - accuracy: 0.2553\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.7166 - accuracy: 0.2613\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.3490 - accuracy: 0.2606\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.2133 - accuracy: 0.2646\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3009 - accuracy: 0.2659\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5394 - accuracy: 0.2666\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.9368 - accuracy: 0.2759\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.5341 - accuracy: 0.2825\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.2742 - accuracy: 0.2851\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.0877 - accuracy: 0.2898\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.9604 - accuracy: 0.2924\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.8559 - accuracy: 0.2911\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7827 - accuracy: 0.2931\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7217 - accuracy: 0.2938\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.6535 - accuracy: 0.2951\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.6100 - accuracy: 0.2964\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5635 - accuracy: 0.2971\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5262 - accuracy: 0.2964\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.4883 - accuracy: 0.2977\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.4515 - accuracy: 0.2964\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.4255 - accuracy: 0.2984\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.3988 - accuracy: 0.2991\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.3755 - accuracy: 0.2984\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.3599 - accuracy: 0.2984\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.3449 - accuracy: 0.2977\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.3306 - accuracy: 0.2977\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.3210 - accuracy: 0.2984\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.3110 - accuracy: 0.2984\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2984 - accuracy: 0.2977\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2881 - accuracy: 0.2984\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2812 - accuracy: 0.2984\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2696 - accuracy: 0.2977\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2630 - accuracy: 0.2991\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2550 - accuracy: 0.2984\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2460 - accuracy: 0.2991\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2386 - accuracy: 0.2991\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2307 - accuracy: 0.2984\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2221 - accuracy: 0.2991\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2151 - accuracy: 0.2997\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2073 - accuracy: 0.2997\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2013 - accuracy: 0.2991\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1930 - accuracy: 0.2991\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1873 - accuracy: 0.2984\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1806 - accuracy: 0.2991\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1739 - accuracy: 0.2991\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1687 - accuracy: 0.2991\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1633 - accuracy: 0.2997\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1570 - accuracy: 0.2991\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1504 - accuracy: 0.2977\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1452 - accuracy: 0.2991\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1393 - accuracy: 0.2991\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1341 - accuracy: 0.2991\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1303 - accuracy: 0.3004\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1279 - accuracy: 0.2997\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1253 - accuracy: 0.3004\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1222 - accuracy: 0.3004\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1195 - accuracy: 0.3004\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1169 - accuracy: 0.2997\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1142 - accuracy: 0.3004\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1116 - accuracy: 0.3004\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1092 - accuracy: 0.3004\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1067 - accuracy: 0.3004\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1044 - accuracy: 0.2997\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1021 - accuracy: 0.3004\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0988 - accuracy: 0.3004\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0958 - accuracy: 0.2997\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0930 - accuracy: 0.3004\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0901 - accuracy: 0.2997\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0876 - accuracy: 0.3004\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0845 - accuracy: 0.3004\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0816 - accuracy: 0.2997\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.3004\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0764 - accuracy: 0.3004\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0736 - accuracy: 0.3004\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0709 - accuracy: 0.2997\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0690 - accuracy: 0.3004\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0659 - accuracy: 0.3004\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0632 - accuracy: 0.3004\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0605 - accuracy: 0.3004\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0584 - accuracy: 0.2997\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0556 - accuracy: 0.3004\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0535 - accuracy: 0.3004\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.0505 - accuracy: 0.2997\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0483 - accuracy: 0.3004\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0458 - accuracy: 0.3004\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0432 - accuracy: 0.3004\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0408 - accuracy: 0.3004\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0382 - accuracy: 0.2997\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0361 - accuracy: 0.3004\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0336 - accuracy: 0.3004\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0311 - accuracy: 0.3004\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0286 - accuracy: 0.3004\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0261 - accuracy: 0.3004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd13028948>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.13527851458885942\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[61 13  3  0  0]\n",
      " [29 50 16  1  4]\n",
      " [12 20 21  5  2]\n",
      " [ 6 14 18 18 33]\n",
      " [ 3  7  4  8 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.00      0.00      0.00        89\n",
      "         5.0       0.14      1.00      0.24        51\n",
      "\n",
      "    accuracy                           0.14       377\n",
      "   macro avg       0.03      0.20      0.05       377\n",
      "weighted avg       0.02      0.14      0.03       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_435 (Dense)           (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_436 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_437 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_438 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_439 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,357\n",
      "Trainable params: 19,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 14.5149 - accuracy: 0.1174\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5405 - accuracy: 0.1207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd133ecb48>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.15915119363395225\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0  77   0   0]\n",
      " [  0   0 100   0   0]\n",
      " [  0   0  60   0   0]\n",
      " [  0   0  89   0   0]\n",
      " [  0   0  51   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.16      1.00      0.27        60\n",
      "         4.0       0.00      0.00      0.00        89\n",
      "         5.0       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.16       377\n",
      "   macro avg       0.03      0.20      0.05       377\n",
      "weighted avg       0.03      0.16      0.04       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_440 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_441 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_442 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_443 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_444 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,359\n",
      "Trainable params: 8,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0218 - accuracy: 0.1691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd14739dc8>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1220159151193634\n",
      "Tasa de aciertos balanceada regresión logística: 0.15\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [12 23  0  0  0 42]\n",
      " [16 41  0  0  0 43]\n",
      " [ 4 35  0  0  0 21]\n",
      " [12 47  0  0  0 30]\n",
      " [11 17  0  0  0 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.14      0.30      0.19        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.00      0.00      0.00        89\n",
      "         5.0       0.14      0.45      0.22        51\n",
      "\n",
      "    accuracy                           0.12       377\n",
      "   macro avg       0.05      0.12      0.07       377\n",
      "weighted avg       0.05      0.12      0.07       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_445 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_446 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_447 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_448 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_449 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,391\n",
      "Trainable params: 2,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.3698 - accuracy: 0.0265\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3698 - accuracy: 0.0265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd14a09a08>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07957559681697612\n",
      "Tasa de aciertos balanceada regresión logística: 0.10\n",
      "Matriz de confusión:\n",
      "[[  0   0  77   0   0]\n",
      " [  0   0 100   0   0]\n",
      " [  0   0  60   0   0]\n",
      " [  0   0  89   0   0]\n",
      " [  0   0  51   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.12      0.50      0.20        60\n",
      "         4.0       0.00      0.00      0.00        89\n",
      "         5.0       0.00      0.00      0.00        51\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.08       377\n",
      "   macro avg       0.02      0.08      0.03       377\n",
      "weighted avg       0.02      0.08      0.03       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_450 (Dense)           (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_451 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_452 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_453 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_454 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_455 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_456 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_457 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_458 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_459 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,419\n",
      "Trainable params: 10,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 9.7682 - accuracy: 0.1631\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7348 - accuracy: 0.1631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd15e58888>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.20424403183023873\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 77   0   0   0   0]\n",
      " [100   0   0   0   0]\n",
      " [ 60   0   0   0   0]\n",
      " [ 89   0   0   0   0]\n",
      " [ 51   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      1.00      0.34        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.00      0.00      0.00        89\n",
      "         5.0       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.20       377\n",
      "   macro avg       0.04      0.20      0.07       377\n",
      "weighted avg       0.04      0.20      0.07       377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_460 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_461 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_462 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_463 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_464 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_465 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_466 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_467 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_468 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_469 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,639\n",
      "Trainable params: 4,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 6.4789 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4740 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd17372188>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0  77]\n",
      " [  0   0   0   0   0 100]\n",
      " [  0   0   0   0   0  60]\n",
      " [  0   0   0   0   0  89]\n",
      " [  0   0   0   0   0  51]\n",
      " [  0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00     100.0\n",
      "         3.0       0.00      0.00      0.00      60.0\n",
      "         4.0       0.00      0.00      0.00      89.0\n",
      "         5.0       0.00      0.00      0.00      51.0\n",
      "         6.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00     377.0\n",
      "   macro avg       0.00      0.00      0.00     377.0\n",
      "weighted avg       0.00      0.00      0.00     377.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_470 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_471 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_472 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_473 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_474 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_475 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_476 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_477 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_478 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_479 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,425\n",
      "Trainable params: 1,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd17804f48>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[ 77   0   0   0   0]\n",
      " [100   0   0   0   0]\n",
      " [ 60   0   0   0   0]\n",
      " [ 89   0   0   0   0]\n",
      " [ 51   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00     100.0\n",
      "         3.0       0.00      0.00      0.00      60.0\n",
      "         4.0       0.00      0.00      0.00      89.0\n",
      "         5.0       0.00      0.00      0.00      51.0\n",
      "\n",
      "    accuracy                           0.00     377.0\n",
      "   macro avg       0.00      0.00      0.00     377.0\n",
      "weighted avg       0.00      0.00      0.00     377.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 22, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_480 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_481 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_482 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_483 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_484 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,065\n",
      "Trainable params: 10,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 1486.7307 - accuracy: 0.2268\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 159.7789 - accuracy: 0.3005\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 70.3317 - accuracy: 0.3538\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 106.0919 - accuracy: 0.3286\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 79.9643 - accuracy: 0.3627\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.5777 - accuracy: 0.4051\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.3045 - accuracy: 0.4078\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.8680 - accuracy: 0.4228\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 49.4971 - accuracy: 0.4146\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.6620 - accuracy: 0.4310\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.7568 - accuracy: 0.4133\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 37.9339 - accuracy: 0.4426\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 33.3973 - accuracy: 0.4577\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.6906 - accuracy: 0.4836\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.3171 - accuracy: 0.4713\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.0790 - accuracy: 0.4583\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.0057 - accuracy: 0.4822\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 35.9522 - accuracy: 0.4440\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.8914 - accuracy: 0.4228\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.3448 - accuracy: 0.4802\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.8217 - accuracy: 0.4713\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2213 - accuracy: 0.5089\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.5555 - accuracy: 0.5260\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3816 - accuracy: 0.5403\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6653 - accuracy: 0.4932\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2933 - accuracy: 0.5198\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.8903 - accuracy: 0.5362\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.4048 - accuracy: 0.4508\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.8510 - accuracy: 0.5205\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2656 - accuracy: 0.4925\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 19.4213 - accuracy: 0.4720\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.5029 - accuracy: 0.4932\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2455 - accuracy: 0.5246\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.9297 - accuracy: 0.5109\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.2477 - accuracy: 0.5451\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9900 - accuracy: 0.5717\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4713 - accuracy: 0.5430\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4890 - accuracy: 0.5683\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8360 - accuracy: 0.5321\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3368 - accuracy: 0.5246\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5582 - accuracy: 0.5444\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1090 - accuracy: 0.5649\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.2907 - accuracy: 0.5184\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1884 - accuracy: 0.5615\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1990 - accuracy: 0.5342\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4332 - accuracy: 0.5499\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4805 - accuracy: 0.5581\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7676 - accuracy: 0.5546\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8251 - accuracy: 0.5519\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0255 - accuracy: 0.5895\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0730 - accuracy: 0.5369\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9102 - accuracy: 0.4966\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4512 - accuracy: 0.5546\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.4931 - accuracy: 0.5505\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5970 - accuracy: 0.5533\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5527 - accuracy: 0.5403\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5038 - accuracy: 0.5977\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8722 - accuracy: 0.5512\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2662 - accuracy: 0.5342\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8195 - accuracy: 0.5499\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0076 - accuracy: 0.5799\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4331 - accuracy: 0.5376\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3573 - accuracy: 0.5669\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0006 - accuracy: 0.5396\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5523 - accuracy: 0.5553\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8952 - accuracy: 0.5342\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0103 - accuracy: 0.5157\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6186 - accuracy: 0.4932\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6808 - accuracy: 0.5260\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.5724\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9019 - accuracy: 0.5499\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8640 - accuracy: 0.5171\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.7963 - accuracy: 0.4536\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3135 - accuracy: 0.5137\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4923 - accuracy: 0.5335\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4453 - accuracy: 0.5526\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5115 - accuracy: 0.5246\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6968 - accuracy: 0.5178\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3545 - accuracy: 0.5745\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5455 - accuracy: 0.5321\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7209 - accuracy: 0.5219\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0516 - accuracy: 0.5437\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9818 - accuracy: 0.4734\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3931 - accuracy: 0.4686\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5977 - accuracy: 0.5437\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7492 - accuracy: 0.5007\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7339 - accuracy: 0.5253\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4591 - accuracy: 0.5143\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1220 - accuracy: 0.4652\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0929 - accuracy: 0.5089\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9610 - accuracy: 0.5758\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0135 - accuracy: 0.5328\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8439 - accuracy: 0.5615\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7205 - accuracy: 0.5287\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1761 - accuracy: 0.5232\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.5444\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3215 - accuracy: 0.4447\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9144 - accuracy: 0.5485\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7809 - accuracy: 0.5376\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0753 - accuracy: 0.4993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd18c41508>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4098360655737705\n",
      "Tasa de aciertos balanceada regresión logística: 0.44\n",
      "Matriz de confusión:\n",
      "[[62  9  0  6  0]\n",
      " [21 33  3 31 12]\n",
      " [ 0  7  1 15 37]\n",
      " [ 0  4  0 17 63]\n",
      " [ 1  1  0  6 37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.74      0.81      0.77        77\n",
      "         2.0       0.61      0.33      0.43       100\n",
      "         3.0       0.25      0.02      0.03        60\n",
      "         4.0       0.23      0.20      0.21        84\n",
      "         5.0       0.25      0.82      0.38        45\n",
      "\n",
      "    accuracy                           0.41       366\n",
      "   macro avg       0.41      0.44      0.37       366\n",
      "weighted avg       0.45      0.41      0.38       366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_485 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_486 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_487 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_488 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_489 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,716\n",
      "Trainable params: 4,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 585.5154 - accuracy: 0.2684\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 102.4247 - accuracy: 0.3470\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.1695 - accuracy: 0.3429\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 70.5071 - accuracy: 0.3484\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 55.6427 - accuracy: 0.3620\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 57.4827 - accuracy: 0.3805\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.6479 - accuracy: 0.3791\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.2619 - accuracy: 0.3811\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 40.4621 - accuracy: 0.3873\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.7269 - accuracy: 0.3805\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.3410 - accuracy: 0.4092\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.1270 - accuracy: 0.4139\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.1937 - accuracy: 0.3846\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.4294 - accuracy: 0.4037\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.3643 - accuracy: 0.4515\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.2405 - accuracy: 0.4030\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.2591 - accuracy: 0.4255\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.2694 - accuracy: 0.4706\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.0815 - accuracy: 0.4501\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5811 - accuracy: 0.4515\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9573 - accuracy: 0.4515\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.2128 - accuracy: 0.4337\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.8610 - accuracy: 0.4617\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.1039 - accuracy: 0.4617\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.9163 - accuracy: 0.5007\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6100 - accuracy: 0.4652\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4384 - accuracy: 0.4775\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5548 - accuracy: 0.4816\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7524 - accuracy: 0.4686\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.0382 - accuracy: 0.5294\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5626 - accuracy: 0.5253\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3187 - accuracy: 0.5205\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7057 - accuracy: 0.4959\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.7267 - accuracy: 0.4863\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1607 - accuracy: 0.5423\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3898 - accuracy: 0.5553\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1004 - accuracy: 0.5150\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5500 - accuracy: 0.5376\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9527 - accuracy: 0.5410\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7466 - accuracy: 0.5512\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2037 - accuracy: 0.5273\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2466 - accuracy: 0.5280\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0971 - accuracy: 0.4679\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7551 - accuracy: 0.5130\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1518 - accuracy: 0.5512\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5163 - accuracy: 0.4652\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1886 - accuracy: 0.4385\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5822 - accuracy: 0.5082\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1234 - accuracy: 0.5410\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6926 - accuracy: 0.4973\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0999 - accuracy: 0.5205\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5507 - accuracy: 0.5827\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6794 - accuracy: 0.5710\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9121 - accuracy: 0.4925\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.4711 - accuracy: 0.5833\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8267 - accuracy: 0.5396\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6497 - accuracy: 0.4720\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1352 - accuracy: 0.3941\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2006 - accuracy: 0.5102\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1562 - accuracy: 0.5130\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8904 - accuracy: 0.5123\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.4335 - accuracy: 0.5567\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.4585 - accuracy: 0.5485\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6945 - accuracy: 0.5273\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.4335 - accuracy: 0.5642\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3073 - accuracy: 0.5581\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8675 - accuracy: 0.5075\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3041 - accuracy: 0.5663\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4742 - accuracy: 0.5355\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.4244 - accuracy: 0.5485\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1610 - accuracy: 0.5867\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3837 - accuracy: 0.5328\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1428 - accuracy: 0.4761\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3089 - accuracy: 0.5540\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9002 - accuracy: 0.4863\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9561 - accuracy: 0.4713\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9936 - accuracy: 0.4556\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8141 - accuracy: 0.4740\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8203 - accuracy: 0.4952\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0635 - accuracy: 0.4959\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6870 - accuracy: 0.4850\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.1333 - accuracy: 0.5895\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3088 - accuracy: 0.4727\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0132 - accuracy: 0.4296\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7546 - accuracy: 0.4645\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7575 - accuracy: 0.5020\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2287 - accuracy: 0.5642\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3015 - accuracy: 0.5485\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3617 - accuracy: 0.5253\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5047 - accuracy: 0.5137\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5000 - accuracy: 0.5157\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6935 - accuracy: 0.4966\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8120 - accuracy: 0.5034\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3068 - accuracy: 0.5301\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7667 - accuracy: 0.4822\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3290 - accuracy: 0.4795\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6386 - accuracy: 0.3914\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1825 - accuracy: 0.3934\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6132 - accuracy: 0.4522\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4325 - accuracy: 0.4392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd1a12f1c8>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3442622950819672\n",
      "Tasa de aciertos balanceada regresión logística: 0.40\n",
      "Matriz de confusión:\n",
      "[[73  2  0  0  2]\n",
      " [76  5  6  0 13]\n",
      " [14  7 13  0 26]\n",
      " [ 8  5  8  0 63]\n",
      " [ 5  1  4  0 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.41      0.95      0.58        77\n",
      "         2.0       0.25      0.05      0.08       100\n",
      "         3.0       0.42      0.22      0.29        60\n",
      "         4.0       0.00      0.00      0.00        84\n",
      "         5.0       0.25      0.78      0.38        45\n",
      "\n",
      "    accuracy                           0.34       366\n",
      "   macro avg       0.27      0.40      0.27       366\n",
      "weighted avg       0.26      0.34      0.24       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_490 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_491 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_492 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_493 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_494 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,610\n",
      "Trainable params: 1,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 1254.5446 - accuracy: 0.2090\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5794 - accuracy: 0.2917\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9887 - accuracy: 0.2951\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8868 - accuracy: 0.2964\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9795 - accuracy: 0.2964\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8463 - accuracy: 0.2971\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8312 - accuracy: 0.2971\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8171 - accuracy: 0.2971\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8038 - accuracy: 0.2971\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7915 - accuracy: 0.2971\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7800 - accuracy: 0.2971\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7692 - accuracy: 0.2971\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7591 - accuracy: 0.2971\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7497 - accuracy: 0.2971\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7410 - accuracy: 0.2971\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7328 - accuracy: 0.2971\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7251 - accuracy: 0.2971\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7180 - accuracy: 0.2971\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7113 - accuracy: 0.2971\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7050 - accuracy: 0.2971\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6992 - accuracy: 0.2971\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6937 - accuracy: 0.2971\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6885 - accuracy: 0.2971\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6837 - accuracy: 0.2971\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6791 - accuracy: 0.2971\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6748 - accuracy: 0.2971\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6708 - accuracy: 0.2971\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6669 - accuracy: 0.2971\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6633 - accuracy: 0.2971\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6598 - accuracy: 0.2971\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6566 - accuracy: 0.2971\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6535 - accuracy: 0.2971\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6506 - accuracy: 0.2971\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6477 - accuracy: 0.2971\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6451 - accuracy: 0.2971\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6426 - accuracy: 0.2971\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6401 - accuracy: 0.2971\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6380 - accuracy: 0.2971\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6357 - accuracy: 0.2971\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6336 - accuracy: 0.2971\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6316 - accuracy: 0.2971\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6296 - accuracy: 0.2971\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6279 - accuracy: 0.2971\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6261 - accuracy: 0.2971\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6244 - accuracy: 0.2971\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6227 - accuracy: 0.2971\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6212 - accuracy: 0.2971\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6196 - accuracy: 0.2971\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6182 - accuracy: 0.2971\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6168 - accuracy: 0.2971\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6155 - accuracy: 0.2971\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6142 - accuracy: 0.2971\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6129 - accuracy: 0.2971\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6117 - accuracy: 0.2971\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6106 - accuracy: 0.2971\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6095 - accuracy: 0.2971\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6083 - accuracy: 0.2971\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6074 - accuracy: 0.2971\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6064 - accuracy: 0.2971\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6053 - accuracy: 0.2971\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6044 - accuracy: 0.2971\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6035 - accuracy: 0.2971\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6026 - accuracy: 0.2971\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6017 - accuracy: 0.2971\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6009 - accuracy: 0.2971\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6001 - accuracy: 0.2971\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5994 - accuracy: 0.2971\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5985 - accuracy: 0.2971\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5978 - accuracy: 0.2971\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5971 - accuracy: 0.2971\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5964 - accuracy: 0.2971\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5958 - accuracy: 0.2971\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5951 - accuracy: 0.2971\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5945 - accuracy: 0.2971\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5939 - accuracy: 0.2971\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5933 - accuracy: 0.2971\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5927 - accuracy: 0.2971\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5921 - accuracy: 0.2971\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5916 - accuracy: 0.2971\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5910 - accuracy: 0.2971\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5905 - accuracy: 0.2971\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5900 - accuracy: 0.2971\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5894 - accuracy: 0.2971\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5890 - accuracy: 0.2971\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5885 - accuracy: 0.2971\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5880 - accuracy: 0.2971\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5875 - accuracy: 0.2971\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5872 - accuracy: 0.2971\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5868 - accuracy: 0.2971\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5863 - accuracy: 0.2971\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5859 - accuracy: 0.2971\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5856 - accuracy: 0.2971\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5851 - accuracy: 0.2971\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5848 - accuracy: 0.2971\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5844 - accuracy: 0.2971\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5840 - accuracy: 0.2971\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5837 - accuracy: 0.2971\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5834 - accuracy: 0.2971\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5830 - accuracy: 0.2971\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5827 - accuracy: 0.2971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd1a55c4c8>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.12295081967213115\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[62  9  0  6  0]\n",
      " [21 33  3 31 12]\n",
      " [ 0  7  1 15 37]\n",
      " [ 0  4  0 17 63]\n",
      " [ 1  1  0  6 37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.00      0.00      0.00        84\n",
      "         5.0       0.12      1.00      0.22        45\n",
      "\n",
      "    accuracy                           0.12       366\n",
      "   macro avg       0.02      0.20      0.04       366\n",
      "weighted avg       0.02      0.12      0.03       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 22, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_495 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_496 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_497 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_498 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_499 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,357\n",
      "Trainable params: 20,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 9.4863 - accuracy: 0.1250\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1087 - accuracy: 0.2971\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1584 - accuracy: 0.2971\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5278 - accuracy: 0.2971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd1bc5e348>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.12295081967213115\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  77]\n",
      " [  0   0   0   0 100]\n",
      " [  0   0   0   0  60]\n",
      " [  0   0   0   0  84]\n",
      " [  0   0   0   0  45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.00      0.00      0.00        84\n",
      "         5.0       0.12      1.00      0.22        45\n",
      "\n",
      "    accuracy                           0.12       366\n",
      "   macro avg       0.02      0.20      0.04       366\n",
      "weighted avg       0.02      0.12      0.03       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_500 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_501 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_502 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_503 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_504 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,999\n",
      "Trainable params: 8,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8185 - accuracy: 0.0157\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8185 - accuracy: 0.0157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd1c1778c8>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.06830601092896176\n",
      "Tasa de aciertos balanceada regresión logística: 0.08\n",
      "Matriz de confusión:\n",
      "[[ 0  0 53  0  0 24]\n",
      " [ 0  0 58  0  0 42]\n",
      " [ 0  0 25  0  0 35]\n",
      " [ 0  0 36  0  0 48]\n",
      " [ 0  0 27  0  0 18]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.13      0.42      0.19        60\n",
      "         4.0       0.00      0.00      0.00        84\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.07       366\n",
      "   macro avg       0.02      0.07      0.03       366\n",
      "weighted avg       0.02      0.07      0.03       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_505 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_506 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_507 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_508 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_509 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,711\n",
      "Trainable params: 2,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 11.8651 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0221 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd133e39c8>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  77]\n",
      " [  0   0   0   0 100]\n",
      " [  0   0   0   0  60]\n",
      " [  0   0   0   0  84]\n",
      " [  0   0   0   0  45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00     100.0\n",
      "         3.0       0.00      0.00      0.00      60.0\n",
      "         4.0       0.00      0.00      0.00      84.0\n",
      "         5.0       0.00      0.00      0.00      45.0\n",
      "         6.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00     366.0\n",
      "   macro avg       0.00      0.00      0.00     366.0\n",
      "weighted avg       0.00      0.00      0.00     366.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 22, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_510 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_511 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_512 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_513 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_514 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_515 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_516 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_517 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_518 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_519 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,419\n",
      "Trainable params: 11,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 9.3257 - accuracy: 0.0239\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3242 - accuracy: 0.0178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd14670908>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.01092896174863388\n",
      "Tasa de aciertos balanceada regresión logística: 0.01\n",
      "Matriz de confusión:\n",
      "[[ 4  0  0  0  0 73]\n",
      " [ 9  0  0  0  0 91]\n",
      " [ 9  0  0  0  0 51]\n",
      " [11  0  0  0  0 73]\n",
      " [ 3  0  0  0  0 42]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.11      0.05      0.07        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.00      0.00      0.00        84\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.01       366\n",
      "   macro avg       0.02      0.01      0.01       366\n",
      "weighted avg       0.02      0.01      0.01       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_520 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_521 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_522 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_523 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_524 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_525 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_526 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_527 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_528 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_529 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,279\n",
      "Trainable params: 5,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 7.1428 - accuracy: 0.2029\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1942 - accuracy: 0.2316\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5218 - accuracy: 0.1960\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6695 - accuracy: 0.1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd1e4e0588>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.25956284153005466\n",
      "Tasa de aciertos balanceada regresión logística: 0.19\n",
      "Matriz de confusión:\n",
      "[[ 0 75  0  0  2]\n",
      " [ 0 93  0  0  7]\n",
      " [ 0 53  0  0  7]\n",
      " [ 0 78  0  0  6]\n",
      " [ 0 43  0  0  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.27      0.93      0.42       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.00      0.00      0.00        84\n",
      "         5.0       0.08      0.04      0.06        45\n",
      "\n",
      "    accuracy                           0.26       366\n",
      "   macro avg       0.07      0.19      0.10       366\n",
      "weighted avg       0.08      0.26      0.12       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_530 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_531 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_532 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_533 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_534 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_535 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_536 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_537 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_538 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_539 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,745\n",
      "Trainable params: 1,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2020 - accuracy: 0.1619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd1fa1f908>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2103825136612022\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 4  0  0  0  0 73]\n",
      " [ 9  0  0  0  0 91]\n",
      " [ 9  0  0  0  0 51]\n",
      " [11  0  0  0  0 73]\n",
      " [ 3  0  0  0  0 42]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.21      1.00      0.35        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.00      0.00      0.00        84\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.21       366\n",
      "   macro avg       0.04      0.20      0.07       366\n",
      "weighted avg       0.04      0.21      0.07       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_540 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_541 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_542 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_543 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_544 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,065\n",
      "Trainable params: 10,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 741.5674 - accuracy: 0.2254\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 223.9063 - accuracy: 0.2466\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 128.6225 - accuracy: 0.2794\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 100.9538 - accuracy: 0.3033\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 89.3263 - accuracy: 0.3115\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.3181 - accuracy: 0.3320\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.4421 - accuracy: 0.3566\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.9533 - accuracy: 0.3607\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.0811 - accuracy: 0.3572\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.3226 - accuracy: 0.3689\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.4065 - accuracy: 0.3648\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.5678 - accuracy: 0.3641\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.0761 - accuracy: 0.3832\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.7179 - accuracy: 0.3777\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.7947 - accuracy: 0.3873\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.1944 - accuracy: 0.3900\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.9170 - accuracy: 0.4051\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.5232 - accuracy: 0.3948\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.6293 - accuracy: 0.3962\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.7923 - accuracy: 0.3996\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.0651 - accuracy: 0.4037\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.2573 - accuracy: 0.4051\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.9169 - accuracy: 0.4133\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.7911 - accuracy: 0.3996\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.6985 - accuracy: 0.3832\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.3902 - accuracy: 0.4146\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.5116 - accuracy: 0.4214\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.4417 - accuracy: 0.4173\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.4967 - accuracy: 0.4283\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.0957 - accuracy: 0.4153\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.2172 - accuracy: 0.4249\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.9426 - accuracy: 0.4167\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.8995 - accuracy: 0.4235\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.0128 - accuracy: 0.4296\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.6661 - accuracy: 0.4290\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.2810 - accuracy: 0.4221\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.8724 - accuracy: 0.4221\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.3116 - accuracy: 0.4214\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.6731 - accuracy: 0.4351\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.8839 - accuracy: 0.4378\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.0623 - accuracy: 0.4358\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.6020 - accuracy: 0.4433\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.3399 - accuracy: 0.4290\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.4020 - accuracy: 0.4467\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.8059 - accuracy: 0.4392\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.6610 - accuracy: 0.4324\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.4718 - accuracy: 0.4515\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.1663 - accuracy: 0.4419\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.7858 - accuracy: 0.4454\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.1270 - accuracy: 0.4433\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.8434 - accuracy: 0.4501\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.7648 - accuracy: 0.4454\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.8183 - accuracy: 0.4549\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.2399 - accuracy: 0.4413\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.2899 - accuracy: 0.4617\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.5579 - accuracy: 0.4536\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.8816 - accuracy: 0.4624\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.4179 - accuracy: 0.4542\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.9136 - accuracy: 0.4549\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.0567 - accuracy: 0.4549\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.7327 - accuracy: 0.4570\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.4252 - accuracy: 0.4658\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.6475 - accuracy: 0.4604\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.1024 - accuracy: 0.4536\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.8236 - accuracy: 0.4706\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.6100 - accuracy: 0.4652\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.0745 - accuracy: 0.4665\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.5873 - accuracy: 0.4624\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.4220 - accuracy: 0.4665\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.6780 - accuracy: 0.4590\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.4578 - accuracy: 0.4734\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.7616 - accuracy: 0.4775\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.4125 - accuracy: 0.4638\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.9089 - accuracy: 0.4686\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.7358 - accuracy: 0.4795\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.7854 - accuracy: 0.4747\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.2447 - accuracy: 0.4734\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.2497 - accuracy: 0.4788\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.4042 - accuracy: 0.4706\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.7509 - accuracy: 0.4624\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.4234 - accuracy: 0.4843\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.9326 - accuracy: 0.4720\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.9940 - accuracy: 0.4713\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.4684 - accuracy: 0.4645\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.8684 - accuracy: 0.4747\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.6936 - accuracy: 0.4665\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.3854 - accuracy: 0.4631\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.9560 - accuracy: 0.4775\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.1941 - accuracy: 0.4727\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.5958 - accuracy: 0.4781\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.9773 - accuracy: 0.4795\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.7309 - accuracy: 0.4925\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.3560 - accuracy: 0.4877\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.7624 - accuracy: 0.4781\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.2698 - accuracy: 0.4788\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.0681 - accuracy: 0.4816\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.2269 - accuracy: 0.4754\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.1670 - accuracy: 0.4713\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.3363 - accuracy: 0.4720\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.9633 - accuracy: 0.4836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd1ffba348>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3825136612021858\n",
      "Tasa de aciertos balanceada regresión logística: 0.36\n",
      "Matriz de confusión:\n",
      "[[42 30  1  2  2]\n",
      " [21 53  2 19  5]\n",
      " [ 6 32  1 12  9]\n",
      " [ 2 29  9 24 20]\n",
      " [ 2 10  2 11 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.58      0.55      0.56        77\n",
      "         2.0       0.34      0.53      0.42       100\n",
      "         3.0       0.07      0.02      0.03        60\n",
      "         4.0       0.35      0.29      0.32        84\n",
      "         5.0       0.36      0.44      0.40        45\n",
      "\n",
      "    accuracy                           0.38       366\n",
      "   macro avg       0.34      0.36      0.34       366\n",
      "weighted avg       0.35      0.38      0.36       366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_545 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_546 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_547 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_548 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_549 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,716\n",
      "Trainable params: 4,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 2564.2434 - accuracy: 0.1981\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 304.4416 - accuracy: 0.2411\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.9518 - accuracy: 0.2807\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6359 - accuracy: 0.2930\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9839 - accuracy: 0.2958\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5897 - accuracy: 0.2964\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8651 - accuracy: 0.2964\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6487 - accuracy: 0.2978\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4687 - accuracy: 0.2985\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3372 - accuracy: 0.2985\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2624 - accuracy: 0.2985\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1978 - accuracy: 0.2978\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1389 - accuracy: 0.2964\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0957 - accuracy: 0.2971\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0575 - accuracy: 0.2971\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0295 - accuracy: 0.2978\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0021 - accuracy: 0.2971\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9781 - accuracy: 0.2978\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9553 - accuracy: 0.2964\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9411 - accuracy: 0.2971\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9289 - accuracy: 0.2971\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9217 - accuracy: 0.2971\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9172 - accuracy: 0.2971\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9152 - accuracy: 0.2978\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9139 - accuracy: 0.2964\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9124 - accuracy: 0.2971\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9113 - accuracy: 0.2978\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9104 - accuracy: 0.2978\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9097 - accuracy: 0.2978\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9089 - accuracy: 0.2978\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9078 - accuracy: 0.2978\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9067 - accuracy: 0.2978\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9057 - accuracy: 0.2978\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9047 - accuracy: 0.2691\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9038 - accuracy: 0.2227\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9030 - accuracy: 0.2227\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9021 - accuracy: 0.2227\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9013 - accuracy: 0.2227\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9006 - accuracy: 0.2227\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8998 - accuracy: 0.2227\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8990 - accuracy: 0.2227\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8983 - accuracy: 0.2227\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8976 - accuracy: 0.2227\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8969 - accuracy: 0.2227\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8962 - accuracy: 0.2227\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8955 - accuracy: 0.2227\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8948 - accuracy: 0.2227\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8941 - accuracy: 0.2227\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8935 - accuracy: 0.2227\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8928 - accuracy: 0.2227\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8921 - accuracy: 0.2227\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8915 - accuracy: 0.2227\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8909 - accuracy: 0.2227\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8902 - accuracy: 0.2227\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8896 - accuracy: 0.2234\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8890 - accuracy: 0.2227\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8884 - accuracy: 0.2227\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8878 - accuracy: 0.2227\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8878 - accuracy: 0.2227\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8867 - accuracy: 0.2227\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8860 - accuracy: 0.2227\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8855 - accuracy: 0.2227\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8849 - accuracy: 0.2227\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8843 - accuracy: 0.2227\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8838 - accuracy: 0.2227\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8832 - accuracy: 0.2227\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8826 - accuracy: 0.2227\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8821 - accuracy: 0.2227\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8815 - accuracy: 0.2227\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8810 - accuracy: 0.2227\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8805 - accuracy: 0.2227\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8799 - accuracy: 0.2227\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8797 - accuracy: 0.2227\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8789 - accuracy: 0.2227\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8784 - accuracy: 0.2227\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8778 - accuracy: 0.2227\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8773 - accuracy: 0.2227\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8768 - accuracy: 0.2227\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8763 - accuracy: 0.2227\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8758 - accuracy: 0.2227\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8753 - accuracy: 0.2227\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8750 - accuracy: 0.2227\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8743 - accuracy: 0.2227\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8738 - accuracy: 0.2227\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8733 - accuracy: 0.2227\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8728 - accuracy: 0.2227\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8723 - accuracy: 0.2227\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8718 - accuracy: 0.2227\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8714 - accuracy: 0.2227\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8709 - accuracy: 0.2227\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8704 - accuracy: 0.2227\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8699 - accuracy: 0.2227\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8697 - accuracy: 0.2227\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8691 - accuracy: 0.2227\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8686 - accuracy: 0.2227\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8681 - accuracy: 0.2227\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8676 - accuracy: 0.2227\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8672 - accuracy: 0.2227\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8667 - accuracy: 0.2227\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8662 - accuracy: 0.2227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd21263308>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.22950819672131148\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  77   0]\n",
      " [  0   0   0 100   0]\n",
      " [  0   1   0  59   0]\n",
      " [  0   0   0  84   0]\n",
      " [  0   0   0  45   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.23      1.00      0.37        84\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.23       366\n",
      "   macro avg       0.05      0.20      0.07       366\n",
      "weighted avg       0.05      0.23      0.09       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_550 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_551 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_552 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_553 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_554 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,610\n",
      "Trainable params: 1,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 2782.1924 - accuracy: 0.1523\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1059.5592 - accuracy: 0.1585\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 588.5467 - accuracy: 0.1742\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 325.8196 - accuracy: 0.1899\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 198.4846 - accuracy: 0.1817\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 133.7300 - accuracy: 0.1796\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 102.4787 - accuracy: 0.1680\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.7885 - accuracy: 0.1633\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.6764 - accuracy: 0.1571\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.9906 - accuracy: 0.1585\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.5811 - accuracy: 0.1598\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.4384 - accuracy: 0.1571\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.5141 - accuracy: 0.1592\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.4870 - accuracy: 0.1598\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.1784 - accuracy: 0.1605\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.4387 - accuracy: 0.1612\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.1523 - accuracy: 0.1598\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.1775 - accuracy: 0.1598\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.3091 - accuracy: 0.1633\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.5906 - accuracy: 0.1633\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.7653 - accuracy: 0.1619\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.1947 - accuracy: 0.1633\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6540 - accuracy: 0.1653\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4210 - accuracy: 0.1653\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4714 - accuracy: 0.1646\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5988 - accuracy: 0.1653\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6829 - accuracy: 0.1646\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.9228 - accuracy: 0.1646\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2976 - accuracy: 0.1639\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8357 - accuracy: 0.1626\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2700 - accuracy: 0.1626\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8313 - accuracy: 0.1633\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4865 - accuracy: 0.1626\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.2176 - accuracy: 0.1633\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.9601 - accuracy: 0.1626\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.7361 - accuracy: 0.1633\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5194 - accuracy: 0.1626\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.2978 - accuracy: 0.1626\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0984 - accuracy: 0.1633\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8849 - accuracy: 0.1626\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6667 - accuracy: 0.1626\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4047 - accuracy: 0.1626\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1353 - accuracy: 0.1619\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8694 - accuracy: 0.1612\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6419 - accuracy: 0.1612\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5047 - accuracy: 0.1612\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3973 - accuracy: 0.1612\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3014 - accuracy: 0.1612\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2147 - accuracy: 0.1612\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1448 - accuracy: 0.1612\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0766 - accuracy: 0.1612\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0115 - accuracy: 0.1612\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9570 - accuracy: 0.1619\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9021 - accuracy: 0.1619\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8473 - accuracy: 0.1619\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7926 - accuracy: 0.1619\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7380 - accuracy: 0.1619\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6837 - accuracy: 0.1619\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6303 - accuracy: 0.1619\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5767 - accuracy: 0.1619\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5533 - accuracy: 0.1619\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5077 - accuracy: 0.1619\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4572 - accuracy: 0.1619\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4316 - accuracy: 0.1619\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3925 - accuracy: 0.1619\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3570 - accuracy: 0.1619\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3139 - accuracy: 0.1619\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2811 - accuracy: 0.1619\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2503 - accuracy: 0.1619\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2083 - accuracy: 0.1619\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1706 - accuracy: 0.1619\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1333 - accuracy: 0.1619\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1077 - accuracy: 0.1619\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0596 - accuracy: 0.1619\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0202 - accuracy: 0.1619\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0001 - accuracy: 0.1619\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9607 - accuracy: 0.1619\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9330 - accuracy: 0.1619\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9114 - accuracy: 0.1619\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9293 - accuracy: 0.1619\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9101 - accuracy: 0.1619\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8944 - accuracy: 0.1619\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8934 - accuracy: 0.1619\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8925 - accuracy: 0.1619\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8917 - accuracy: 0.1619\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8908 - accuracy: 0.1619\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8898 - accuracy: 0.1619\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8888 - accuracy: 0.1619\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8880 - accuracy: 0.1619\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8870 - accuracy: 0.1619\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8860 - accuracy: 0.1619\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8856 - accuracy: 0.1626\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8867 - accuracy: 0.1619\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8842 - accuracy: 0.1619\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8832 - accuracy: 0.1619\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8824 - accuracy: 0.1619\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8814 - accuracy: 0.1619\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8805 - accuracy: 0.1619\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8796 - accuracy: 0.1619\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8787 - accuracy: 0.1619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd215a5248>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2103825136612022\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[42 30  1  2  2]\n",
      " [21 53  2 19  5]\n",
      " [ 6 32  1 12  9]\n",
      " [ 2 29  9 24 20]\n",
      " [ 2 10  2 11 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.21      1.00      0.35        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.00      0.00      0.00        84\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.21       366\n",
      "   macro avg       0.04      0.20      0.07       366\n",
      "weighted avg       0.04      0.21      0.07       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_555 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_556 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_557 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_558 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_559 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,357\n",
      "Trainable params: 20,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 4.4202 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4010 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd228f5208>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [62  0  0  0  0  0 15]\n",
      " [65  0  0  0  0  0 35]\n",
      " [30  0  0  0  0  0 30]\n",
      " [44  0  0  0  0  0 40]\n",
      " [32  0  0  0  0  0 13]\n",
      " [ 0  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00     100.0\n",
      "         3.0       0.00      0.00      0.00      60.0\n",
      "         4.0       0.00      0.00      0.00      84.0\n",
      "         5.0       0.00      0.00      0.00      45.0\n",
      "         6.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00     366.0\n",
      "   macro avg       0.00      0.00      0.00     366.0\n",
      "weighted avg       0.00      0.00      0.00     366.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_560 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_561 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_562 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_563 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_564 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,999\n",
      "Trainable params: 8,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1031 - accuracy: 0.2835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd22c82c08>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.12021857923497267\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0 47  0 30]\n",
      " [ 0  0 44  0 56]\n",
      " [ 0  0 22  0 38]\n",
      " [ 0  0 22  0 62]\n",
      " [ 0  0 23  0 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.14      0.37      0.20        60\n",
      "         4.0       0.00      0.00      0.00        84\n",
      "         5.0       0.11      0.49      0.17        45\n",
      "\n",
      "    accuracy                           0.12       366\n",
      "   macro avg       0.05      0.17      0.08       366\n",
      "weighted avg       0.04      0.12      0.05       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_565 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_566 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_567 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_568 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_569 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,711\n",
      "Trainable params: 2,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 6.9486 - accuracy: 0.1619\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1740 - accuracy: 0.1899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd240a2ac8>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2978142076502732\n",
      "Tasa de aciertos balanceada regresión logística: 0.23\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [62  0  0  0  0  0 15]\n",
      " [65  0  0  0  0  0 35]\n",
      " [30  0  0  0  0  0 30]\n",
      " [44  0  0  0  0  0 40]\n",
      " [32  0  0  0  0  0 13]\n",
      " [ 0  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.32      0.32      0.32        77\n",
      "         2.0       0.29      0.84      0.43       100\n",
      "         3.0       0.00      0.00      0.00        60\n",
      "         4.0       0.00      0.00      0.00        84\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.30       366\n",
      "   macro avg       0.12      0.23      0.15       366\n",
      "weighted avg       0.15      0.30      0.19       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_570 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_571 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_572 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_573 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_574 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_575 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_576 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_577 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_578 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_579 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,419\n",
      "Trainable params: 11,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2187 - accuracy: 0.1195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd244c2488>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.16120218579234974\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 0  0 77  0  0  0]\n",
      " [ 0  0 98  0  0  2]\n",
      " [ 0  0 59  0  0  1]\n",
      " [ 0  0 80  0  0  4]\n",
      " [ 0  0 45  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00       100\n",
      "         3.0       0.16      0.98      0.28        60\n",
      "         4.0       0.00      0.00      0.00        84\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.16       366\n",
      "   macro avg       0.03      0.16      0.05       366\n",
      "weighted avg       0.03      0.16      0.05       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_580 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_581 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_582 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_583 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_584 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_585 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_586 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_587 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_588 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_589 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,279\n",
      "Trainable params: 5,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 5.8952 - accuracy: 0.1202\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3129 - accuracy: 0.0048\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0630 - accuracy: 0.0048\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3877 - accuracy: 0.0191\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2189 - accuracy: 0.0102\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0687 - accuracy: 0.0068\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1298 - accuracy: 0.0075\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1047 - accuracy: 0.0075\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1047 - accuracy: 0.0075\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1044 - accuracy: 0.0082\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0614 - accuracy: 0.0041\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0048 - accuracy: 0.0034\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0076 - accuracy: 0.0027\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd259215c8>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [77  0  0  0  0  0]\n",
      " [99  1  0  0  0  0]\n",
      " [60  0  0  0  0  0]\n",
      " [84  0  0  0  0  0]\n",
      " [45  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00     100.0\n",
      "         3.0       0.00      0.00      0.00      60.0\n",
      "         4.0       0.00      0.00      0.00      84.0\n",
      "         5.0       0.00      0.00      0.00      45.0\n",
      "\n",
      "    accuracy                           0.00     366.0\n",
      "   macro avg       0.00      0.00      0.00     366.0\n",
      "weighted avg       0.00      0.00      0.00     366.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_590 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_591 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_592 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_593 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_594 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_595 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_596 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_597 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_598 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_599 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,745\n",
      "Trainable params: 1,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd26d818c8>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[ 0  0 77  0  0  0]\n",
      " [ 0  0 98  0  0  2]\n",
      " [ 0  0 59  0  0  1]\n",
      " [ 0  0 80  0  0  4]\n",
      " [ 0  0 45  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00     100.0\n",
      "         3.0       0.00      0.00      0.00      60.0\n",
      "         4.0       0.00      0.00      0.00      84.0\n",
      "         5.0       0.00      0.00      0.00      45.0\n",
      "\n",
      "    accuracy                           0.00     366.0\n",
      "   macro avg       0.00      0.00      0.00     366.0\n",
      "weighted avg       0.00      0.00      0.00     366.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 36, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_600 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_601 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_602 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_603 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_604 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,465\n",
      "Trainable params: 11,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 605.4686 - accuracy: 0.2742\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 121.8486 - accuracy: 0.2486\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 120.4897 - accuracy: 0.2666\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 75.2253 - accuracy: 0.2597\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 67.0679 - accuracy: 0.2859\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 57.4282 - accuracy: 0.3025\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 64.4355 - accuracy: 0.2914\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.0390 - accuracy: 0.3073\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.9115 - accuracy: 0.3522\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.8476 - accuracy: 0.3343\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.6518 - accuracy: 0.3128\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 40.8985 - accuracy: 0.3356\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.6200 - accuracy: 0.3612\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.6244 - accuracy: 0.3398\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.1789 - accuracy: 0.3778\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 33.2431 - accuracy: 0.3577\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.8555 - accuracy: 0.3778\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.0938 - accuracy: 0.3653\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.3240 - accuracy: 0.3847\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.9478 - accuracy: 0.3916\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.9004 - accuracy: 0.4061\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.2297 - accuracy: 0.4040\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.1527 - accuracy: 0.3819\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.7170 - accuracy: 0.4330\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.2420 - accuracy: 0.4641\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8974 - accuracy: 0.4751\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.6339 - accuracy: 0.4448\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.2579 - accuracy: 0.4530\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.1371 - accuracy: 0.4579\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5564 - accuracy: 0.4945\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.6769 - accuracy: 0.5152\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9303 - accuracy: 0.5173\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.1071 - accuracy: 0.5097\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9487 - accuracy: 0.5076\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0752 - accuracy: 0.5131\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.8575 - accuracy: 0.4993\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8411 - accuracy: 0.4952\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0114 - accuracy: 0.5338\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5757 - accuracy: 0.5262\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0293 - accuracy: 0.5463\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.3120 - accuracy: 0.5104\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8602 - accuracy: 0.5504\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5899 - accuracy: 0.5773\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6988 - accuracy: 0.5407\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6230 - accuracy: 0.5649\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4907 - accuracy: 0.5504\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7002 - accuracy: 0.5331\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3805 - accuracy: 0.5173\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6757 - accuracy: 0.5608\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.2071 - accuracy: 0.5117\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1639 - accuracy: 0.5594\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0335 - accuracy: 0.5566\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0597 - accuracy: 0.5691\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6212 - accuracy: 0.5435\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3285 - accuracy: 0.5235\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8479 - accuracy: 0.5767\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1311 - accuracy: 0.5511\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.7019 - accuracy: 0.5670\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2964 - accuracy: 0.5891\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5322 - accuracy: 0.5442\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0086 - accuracy: 0.5587\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.1459 - accuracy: 0.5677\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5333 - accuracy: 0.5849\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4364 - accuracy: 0.5691\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.9549 - accuracy: 0.5470\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1581 - accuracy: 0.5622\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.9677 - accuracy: 0.5580\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7801 - accuracy: 0.5939\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6721 - accuracy: 0.5677\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3036 - accuracy: 0.5656\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8589 - accuracy: 0.5580\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3108 - accuracy: 0.5698\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5227 - accuracy: 0.6098\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1857 - accuracy: 0.5532\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6752 - accuracy: 0.5518\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.2605 - accuracy: 0.5359\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7274 - accuracy: 0.5905\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5823 - accuracy: 0.5711\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4179 - accuracy: 0.6202\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3265 - accuracy: 0.5801\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1748 - accuracy: 0.5891\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5907 - accuracy: 0.6098\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7239 - accuracy: 0.6043\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4855 - accuracy: 0.5546\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2531 - accuracy: 0.5725\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7979 - accuracy: 0.6008\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0620 - accuracy: 0.5684\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6287 - accuracy: 0.5780\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9904 - accuracy: 0.5725\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4164 - accuracy: 0.5815\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4704 - accuracy: 0.5387\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5854 - accuracy: 0.5760\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0036 - accuracy: 0.5711\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3650 - accuracy: 0.5856\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7310 - accuracy: 0.5891\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1379 - accuracy: 0.5939\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6676 - accuracy: 0.6077\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5908 - accuracy: 0.5442\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4031 - accuracy: 0.5684\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0555 - accuracy: 0.5746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd03935ac8>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4088397790055249\n",
      "Tasa de aciertos balanceada regresión logística: 0.40\n",
      "Matriz de confusión:\n",
      "[[36 24 13  4  0]\n",
      " [14 45 36  4  0]\n",
      " [12 19 19  5  4]\n",
      " [ 6 13 14 30 19]\n",
      " [ 5  5  6 11 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.49      0.47      0.48        77\n",
      "         2.0       0.42      0.45      0.44        99\n",
      "         3.0       0.22      0.32      0.26        59\n",
      "         4.0       0.56      0.37      0.44        82\n",
      "         5.0       0.44      0.40      0.42        45\n",
      "\n",
      "    accuracy                           0.41       362\n",
      "   macro avg       0.43      0.40      0.41       362\n",
      "weighted avg       0.44      0.41      0.42       362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_605 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_606 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_607 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_608 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_609 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,612\n",
      "Trainable params: 5,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 973.1465 - accuracy: 0.1934\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 96.3621 - accuracy: 0.2569\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 57.1410 - accuracy: 0.2631\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.5640 - accuracy: 0.2714\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.1563 - accuracy: 0.2769\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1195 - accuracy: 0.2479\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9879 - accuracy: 0.2334\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8655 - accuracy: 0.2307\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8946 - accuracy: 0.2314\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8173 - accuracy: 0.2307\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7800 - accuracy: 0.2390\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7676 - accuracy: 0.2963\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7540 - accuracy: 0.2977\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7478 - accuracy: 0.2970\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7478 - accuracy: 0.2963\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7442 - accuracy: 0.2935\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7313 - accuracy: 0.2942\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7242 - accuracy: 0.2956\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7165 - accuracy: 0.2935\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7095 - accuracy: 0.2935\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7143 - accuracy: 0.2921\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6973 - accuracy: 0.2935\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6917 - accuracy: 0.2935\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6866 - accuracy: 0.2935\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6817 - accuracy: 0.2935\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6771 - accuracy: 0.2935\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6729 - accuracy: 0.2935\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6688 - accuracy: 0.2935\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6650 - accuracy: 0.2935\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6614 - accuracy: 0.2935\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6580 - accuracy: 0.2935\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6547 - accuracy: 0.2935\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6516 - accuracy: 0.2935\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6487 - accuracy: 0.2935\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6459 - accuracy: 0.2935\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6432 - accuracy: 0.2935\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6408 - accuracy: 0.2935\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6384 - accuracy: 0.2935\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6361 - accuracy: 0.2935\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6339 - accuracy: 0.2935\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6317 - accuracy: 0.2935\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6298 - accuracy: 0.2935\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6278 - accuracy: 0.2935\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6260 - accuracy: 0.2935\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6242 - accuracy: 0.2935\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6226 - accuracy: 0.2935\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6209 - accuracy: 0.2935\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6194 - accuracy: 0.2935\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6178 - accuracy: 0.2935\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6164 - accuracy: 0.2935\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6150 - accuracy: 0.2935\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6137 - accuracy: 0.2935\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6124 - accuracy: 0.2935\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6111 - accuracy: 0.2935\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6100 - accuracy: 0.2935\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6088 - accuracy: 0.2935\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6076 - accuracy: 0.2935\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6066 - accuracy: 0.2935\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6055 - accuracy: 0.2935\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6045 - accuracy: 0.2935\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6036 - accuracy: 0.2935\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6027 - accuracy: 0.2935\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6017 - accuracy: 0.2935\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6008 - accuracy: 0.2935\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6000 - accuracy: 0.2935\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5991 - accuracy: 0.2935\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5983 - accuracy: 0.2935\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5975 - accuracy: 0.2935\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5967 - accuracy: 0.2935\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5960 - accuracy: 0.2935\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5954 - accuracy: 0.2935\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5946 - accuracy: 0.2935\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5940 - accuracy: 0.2935\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5933 - accuracy: 0.2935\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5926 - accuracy: 0.2935\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5920 - accuracy: 0.2935\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5926 - accuracy: 0.2928\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5911 - accuracy: 0.2928\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5906 - accuracy: 0.2928\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6586 - accuracy: 0.2928\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6693 - accuracy: 0.2921\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6347 - accuracy: 0.2935\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6419 - accuracy: 0.2921\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5925 - accuracy: 0.2928\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5918 - accuracy: 0.2928\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5913 - accuracy: 0.2928\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5908 - accuracy: 0.2928\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5904 - accuracy: 0.2928\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5900 - accuracy: 0.2928\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5895 - accuracy: 0.2928\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5891 - accuracy: 0.2928\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5887 - accuracy: 0.2928\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5883 - accuracy: 0.2928\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5880 - accuracy: 0.2928\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5876 - accuracy: 0.2928\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5872 - accuracy: 0.2928\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5868 - accuracy: 0.2928\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5865 - accuracy: 0.2928\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5862 - accuracy: 0.2928\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5858 - accuracy: 0.2928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd28693748>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.12430939226519337\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0 77]\n",
      " [ 0  0  0  0 99]\n",
      " [ 0  0  0  0 59]\n",
      " [ 0  0  0  0 82]\n",
      " [ 0  0  0  0 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        99\n",
      "         3.0       0.00      0.00      0.00        59\n",
      "         4.0       0.00      0.00      0.00        82\n",
      "         5.0       0.12      1.00      0.22        45\n",
      "\n",
      "    accuracy                           0.12       362\n",
      "   macro avg       0.02      0.20      0.04       362\n",
      "weighted avg       0.02      0.12      0.03       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_610 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_611 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_612 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_613 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_614 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,058\n",
      "Trainable params: 2,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 1047.3651 - accuracy: 0.1961\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.1634 - accuracy: 0.2942\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9639 - accuracy: 0.2894\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9407 - accuracy: 0.2921\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8660 - accuracy: 0.2928\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8444 - accuracy: 0.2928\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8291 - accuracy: 0.2928\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8148 - accuracy: 0.2928\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8017 - accuracy: 0.2928\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7892 - accuracy: 0.2928\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7778 - accuracy: 0.2928\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7671 - accuracy: 0.2928\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7572 - accuracy: 0.2928\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7479 - accuracy: 0.2928\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7393 - accuracy: 0.2928\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7313 - accuracy: 0.2928\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7238 - accuracy: 0.2928\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7168 - accuracy: 0.2928\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7102 - accuracy: 0.2928\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7041 - accuracy: 0.2928\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6983 - accuracy: 0.2928\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6929 - accuracy: 0.2928\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6879 - accuracy: 0.2928\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6831 - accuracy: 0.2928\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6786 - accuracy: 0.2928\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6744 - accuracy: 0.2928\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6703 - accuracy: 0.2928\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6666 - accuracy: 0.2928\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6631 - accuracy: 0.2928\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6598 - accuracy: 0.2928\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6565 - accuracy: 0.2928\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6535 - accuracy: 0.2928\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6507 - accuracy: 0.2928\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6479 - accuracy: 0.2928\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6453 - accuracy: 0.2928\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6429 - accuracy: 0.2928\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6405 - accuracy: 0.2928\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6383 - accuracy: 0.2928\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6361 - accuracy: 0.2928\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6341 - accuracy: 0.2928\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6321 - accuracy: 0.2928\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6302 - accuracy: 0.2928\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6284 - accuracy: 0.2928\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6267 - accuracy: 0.2928\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6251 - accuracy: 0.2928\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6234 - accuracy: 0.2928\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6220 - accuracy: 0.2928\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6204 - accuracy: 0.2928\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6191 - accuracy: 0.2928\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6177 - accuracy: 0.2928\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6164 - accuracy: 0.2928\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6151 - accuracy: 0.2928\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6138 - accuracy: 0.2928\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6127 - accuracy: 0.2928\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6116 - accuracy: 0.2928\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6105 - accuracy: 0.2928\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6094 - accuracy: 0.2928\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6084 - accuracy: 0.2928\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6074 - accuracy: 0.2928\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6065 - accuracy: 0.2928\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6056 - accuracy: 0.2928\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6047 - accuracy: 0.2928\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6037 - accuracy: 0.2928\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6030 - accuracy: 0.2928\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6021 - accuracy: 0.2928\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6013 - accuracy: 0.2928\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6005 - accuracy: 0.2928\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5998 - accuracy: 0.2928\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5992 - accuracy: 0.2928\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5985 - accuracy: 0.2928\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5978 - accuracy: 0.2928\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5971 - accuracy: 0.2928\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5965 - accuracy: 0.2928\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5958 - accuracy: 0.2928\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5952 - accuracy: 0.2928\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5946 - accuracy: 0.2928\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5941 - accuracy: 0.2928\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5935 - accuracy: 0.2928\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5930 - accuracy: 0.2928\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5924 - accuracy: 0.2928\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5919 - accuracy: 0.2928\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5915 - accuracy: 0.2928\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5911 - accuracy: 0.2928\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5904 - accuracy: 0.2928\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5900 - accuracy: 0.2928\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5896 - accuracy: 0.2928\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5891 - accuracy: 0.2928\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5887 - accuracy: 0.2928\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5883 - accuracy: 0.2928\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5879 - accuracy: 0.2928\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5874 - accuracy: 0.2928\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5870 - accuracy: 0.2928\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5867 - accuracy: 0.2928\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5864 - accuracy: 0.2928\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5860 - accuracy: 0.2928\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5856 - accuracy: 0.2928\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5853 - accuracy: 0.2928\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5849 - accuracy: 0.2928\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5846 - accuracy: 0.2928\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5844 - accuracy: 0.2928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd299a2b88>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.12430939226519337\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[36 24 13  4  0]\n",
      " [14 45 36  4  0]\n",
      " [12 19 19  5  4]\n",
      " [ 6 13 14 30 19]\n",
      " [ 5  5  6 11 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        99\n",
      "         3.0       0.00      0.00      0.00        59\n",
      "         4.0       0.00      0.00      0.00        82\n",
      "         5.0       0.12      1.00      0.22        45\n",
      "\n",
      "    accuracy                           0.12       362\n",
      "   macro avg       0.02      0.20      0.04       362\n",
      "weighted avg       0.02      0.12      0.03       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 36, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_615 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_616 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_617 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_618 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_619 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,757\n",
      "Trainable params: 21,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6934 - accuracy: 0.2030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd29dfd748>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.19337016574585636\n",
      "Tasa de aciertos balanceada regresión logística: 0.19\n",
      "Matriz de confusión:\n",
      "[[ 0  0 59 18  0  0]\n",
      " [ 0  0 58 41  0  0]\n",
      " [ 0  0 25 34  0  0]\n",
      " [ 0  0 36 45  0  1]\n",
      " [ 0  0 27 18  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        99\n",
      "         3.0       0.12      0.42      0.19        59\n",
      "         4.0       0.29      0.55      0.38        82\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.19       362\n",
      "   macro avg       0.07      0.16      0.09       362\n",
      "weighted avg       0.09      0.19      0.12       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_620 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_621 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_622 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_623 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_624 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,895\n",
      "Trainable params: 9,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 13.5358 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5990 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1726 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1383 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd2b224648>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0 77]\n",
      " [ 0  0  0  0  0 99]\n",
      " [ 0  0  0  0  0 59]\n",
      " [ 0  0  0  0  0 82]\n",
      " [ 0  0  0  0  0 45]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00      99.0\n",
      "         3.0       0.00      0.00      0.00      59.0\n",
      "         4.0       0.00      0.00      0.00      82.0\n",
      "         5.0       0.00      0.00      0.00      45.0\n",
      "         6.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00     362.0\n",
      "   macro avg       0.00      0.00      0.00     362.0\n",
      "weighted avg       0.00      0.00      0.00     362.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_625 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_626 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_627 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_628 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_629 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,159\n",
      "Trainable params: 3,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 8.9538 - accuracy: 0.0615\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3171 - accuracy: 0.0532\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3279 - accuracy: 0.0580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd2b587108>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1132596685082873\n",
      "Tasa de aciertos balanceada regresión logística: 0.10\n",
      "Matriz de confusión:\n",
      "[[ 0  0 59 18  0  0]\n",
      " [ 0  0 58 41  0  0]\n",
      " [ 0  0 25 34  0  0]\n",
      " [ 0  0 36 45  0  1]\n",
      " [ 0  0 27 18  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        99\n",
      "         3.0       0.00      0.00      0.00        59\n",
      "         4.0       0.18      0.50      0.27        82\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.11       362\n",
      "   macro avg       0.03      0.08      0.04       362\n",
      "weighted avg       0.04      0.11      0.06       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 36, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_630 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_631 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_632 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_633 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_634 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_635 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_636 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_637 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_638 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_639 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,819\n",
      "Trainable params: 12,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 11.6830 - accuracy: 0.1250\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0184 - accuracy: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd2ca796c8>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.16298342541436464\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 0  0 77  0  0]\n",
      " [ 0  0 99  0  0]\n",
      " [ 0  0 59  0  0]\n",
      " [ 0  0 82  0  0]\n",
      " [ 0  0 45  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        99\n",
      "         3.0       0.16      1.00      0.28        59\n",
      "         4.0       0.00      0.00      0.00        82\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.16       362\n",
      "   macro avg       0.03      0.20      0.06       362\n",
      "weighted avg       0.03      0.16      0.05       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_640 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_641 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_642 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_643 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_644 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_645 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_646 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_647 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_648 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_649 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,175\n",
      "Trainable params: 6,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0519 - accuracy: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd2146ddc8>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.16298342541436464\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 0  0 77  0  0]\n",
      " [ 0  0 99  0  0]\n",
      " [ 0  0 59  0  0]\n",
      " [ 0  0 82  0  0]\n",
      " [ 0  0 45  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        99\n",
      "         3.0       0.16      1.00      0.28        59\n",
      "         4.0       0.00      0.00      0.00        82\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.16       362\n",
      "   macro avg       0.03      0.20      0.06       362\n",
      "weighted avg       0.03      0.16      0.05       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_650 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_651 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_652 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_653 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_654 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_655 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_656 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_657 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_658 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_659 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,193\n",
      "Trainable params: 2,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4564 - accuracy: 0.1975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd1fea6048>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.27348066298342544\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 0  0 77  0  0]\n",
      " [ 0  0 99  0  0]\n",
      " [ 0  0 59  0  0]\n",
      " [ 0  0 82  0  0]\n",
      " [ 0  0 45  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.27      1.00      0.43        99\n",
      "         3.0       0.00      0.00      0.00        59\n",
      "         4.0       0.00      0.00      0.00        82\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.27       362\n",
      "   macro avg       0.05      0.20      0.09       362\n",
      "weighted avg       0.07      0.27      0.12       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_660 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_661 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_662 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_663 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_664 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,465\n",
      "Trainable params: 11,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 1550.9365 - accuracy: 0.1588\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 435.0669 - accuracy: 0.2403\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 275.4953 - accuracy: 0.2541\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 206.2518 - accuracy: 0.2742\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 156.5647 - accuracy: 0.2673\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 124.8083 - accuracy: 0.2631\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 105.2138 - accuracy: 0.2666\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.5894 - accuracy: 0.2742\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.7934 - accuracy: 0.2838\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.1967 - accuracy: 0.2797\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.3845 - accuracy: 0.3011\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.6737 - accuracy: 0.3177\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.7098 - accuracy: 0.3170\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.5468 - accuracy: 0.3218\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.8887 - accuracy: 0.3425\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.8292 - accuracy: 0.3646\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.6715 - accuracy: 0.3702\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.3006 - accuracy: 0.3736\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.8708 - accuracy: 0.3874\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.1664 - accuracy: 0.3867\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.5839 - accuracy: 0.3999\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.9675 - accuracy: 0.3950\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.0744 - accuracy: 0.4019\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.6666 - accuracy: 0.3860\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.8419 - accuracy: 0.4206\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.0121 - accuracy: 0.4109\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.9227 - accuracy: 0.4109\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.4819 - accuracy: 0.4289\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.8010 - accuracy: 0.4178\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.9166 - accuracy: 0.4344\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.4109 - accuracy: 0.4296\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.8827 - accuracy: 0.4213\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.1293 - accuracy: 0.4434\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.8894 - accuracy: 0.4275\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.0444 - accuracy: 0.4420\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.0886 - accuracy: 0.4378\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.2992 - accuracy: 0.4282\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.1413 - accuracy: 0.4378\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.5956 - accuracy: 0.4468\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.7815 - accuracy: 0.4461\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.2813 - accuracy: 0.4399\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 21.5901 - accuracy: 0.4378\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 21.1906 - accuracy: 0.4510\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 21.1745 - accuracy: 0.4489\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.3159 - accuracy: 0.4530\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.8634 - accuracy: 0.4530\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.5005 - accuracy: 0.4434\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.3765 - accuracy: 0.4606\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.0657 - accuracy: 0.4565\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.3635 - accuracy: 0.4448\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.0042 - accuracy: 0.4385\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.7936 - accuracy: 0.4510\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.5451 - accuracy: 0.4579\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.4358 - accuracy: 0.4634\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.3078 - accuracy: 0.4620\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.1862 - accuracy: 0.4613\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.5894 - accuracy: 0.4744\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.6197 - accuracy: 0.4662\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.2542 - accuracy: 0.4593\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.2376 - accuracy: 0.4606\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.4613 - accuracy: 0.4689\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.1438 - accuracy: 0.4724\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.7320 - accuracy: 0.4744\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.0179 - accuracy: 0.4800\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.5331 - accuracy: 0.4744\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.4420 - accuracy: 0.4717\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.2338 - accuracy: 0.4648\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.0875 - accuracy: 0.4751\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.1123 - accuracy: 0.4758\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.7773 - accuracy: 0.4827\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.7303 - accuracy: 0.4896\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.9564 - accuracy: 0.4620\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.5443 - accuracy: 0.4910\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6091 - accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.3593 - accuracy: 0.4910\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.6434 - accuracy: 0.4724\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.0547 - accuracy: 0.4827\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.2287 - accuracy: 0.4779\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.0067 - accuracy: 0.4910\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.2050 - accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.0847 - accuracy: 0.4910\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1572 - accuracy: 0.4744\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5854 - accuracy: 0.4814\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.8055 - accuracy: 0.4890\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.4791 - accuracy: 0.4924\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5098 - accuracy: 0.4945\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.4162 - accuracy: 0.4883\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.6626 - accuracy: 0.4924\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.4604 - accuracy: 0.4820\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0482 - accuracy: 0.4959\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.1909 - accuracy: 0.4931\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.9912 - accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2439 - accuracy: 0.4779\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0532 - accuracy: 0.4959\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.9172 - accuracy: 0.4896\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6928 - accuracy: 0.4890\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.7073 - accuracy: 0.4910\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4164 - accuracy: 0.5028\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.5118 - accuracy: 0.4986\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.7410 - accuracy: 0.4952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd042fa988>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3784530386740331\n",
      "Tasa de aciertos balanceada regresión logística: 0.40\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0 51 15  4  5  1  1]\n",
      " [ 0 33 27  5 16 17  1]\n",
      " [ 0  8 12  9 10 20  0]\n",
      " [ 1  3 14 15 18 30  1]\n",
      " [ 0  1  1  4  7 32  0]\n",
      " [ 0  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.53      0.66      0.59        77\n",
      "         2.0       0.39      0.27      0.32        99\n",
      "         3.0       0.24      0.15      0.19        59\n",
      "         4.0       0.32      0.22      0.26        82\n",
      "         5.0       0.32      0.71      0.44        45\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.38       362\n",
      "   macro avg       0.26      0.29      0.26       362\n",
      "weighted avg       0.37      0.38      0.36       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_665 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_666 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_667 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_668 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_669 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,612\n",
      "Trainable params: 5,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 1005.8800 - accuracy: 0.2224\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 547.4642 - accuracy: 0.2265\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 384.9006 - accuracy: 0.2141\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 280.1198 - accuracy: 0.2210\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 218.1380 - accuracy: 0.2155\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 172.7020 - accuracy: 0.2286\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 150.9776 - accuracy: 0.2424\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 138.9411 - accuracy: 0.2362\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 128.9563 - accuracy: 0.2307\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 119.7051 - accuracy: 0.2410\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 110.8664 - accuracy: 0.2362\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 103.1069 - accuracy: 0.2355\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 95.8470 - accuracy: 0.2459\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.0924 - accuracy: 0.2472\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.1884 - accuracy: 0.2507\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.1700 - accuracy: 0.2452\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.7064 - accuracy: 0.2624\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.1341 - accuracy: 0.2493\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.2331 - accuracy: 0.2493\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.8678 - accuracy: 0.2479\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.9126 - accuracy: 0.2569\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.4950 - accuracy: 0.2548\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.7578 - accuracy: 0.2583\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.8492 - accuracy: 0.2590\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.7978 - accuracy: 0.2555\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.8624 - accuracy: 0.2528\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.3335 - accuracy: 0.2465\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.2877 - accuracy: 0.2472\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.2719 - accuracy: 0.2486\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.9317 - accuracy: 0.2417\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.7246 - accuracy: 0.2514\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.1598 - accuracy: 0.2452\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.2506 - accuracy: 0.2431\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.8315 - accuracy: 0.2465\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.1753 - accuracy: 0.2465\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.8888 - accuracy: 0.2465\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.9887 - accuracy: 0.2417\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.9953 - accuracy: 0.2452\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.1160 - accuracy: 0.2438\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.7837 - accuracy: 0.2431\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.3451 - accuracy: 0.2417\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.2686 - accuracy: 0.2486\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.8254 - accuracy: 0.2403\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.4286 - accuracy: 0.2445\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.0061 - accuracy: 0.2424\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.5235 - accuracy: 0.2459\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.0458 - accuracy: 0.2410\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.8455 - accuracy: 0.2445\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.1512 - accuracy: 0.2514\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0465 - accuracy: 0.2493\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.8594 - accuracy: 0.2438\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.8603 - accuracy: 0.2500\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.8881 - accuracy: 0.2410\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.7627 - accuracy: 0.2493\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.8389 - accuracy: 0.2479\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.5409 - accuracy: 0.2555\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.2301 - accuracy: 0.2528\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.0562 - accuracy: 0.2528\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.4114 - accuracy: 0.2562\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.0290 - accuracy: 0.2479\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.8516 - accuracy: 0.2652\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.4435 - accuracy: 0.2583\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.0376 - accuracy: 0.2597\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.4332 - accuracy: 0.2597\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.4127 - accuracy: 0.2590\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.3539 - accuracy: 0.2597\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.9266 - accuracy: 0.2617\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.8259 - accuracy: 0.2617\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.3850 - accuracy: 0.2631\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.2160 - accuracy: 0.2624\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.9795 - accuracy: 0.2638\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.8380 - accuracy: 0.2617\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.2176 - accuracy: 0.2645\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.2567 - accuracy: 0.2624\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.7681 - accuracy: 0.2769\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.7158 - accuracy: 0.2693\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.6756 - accuracy: 0.2666\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.1224 - accuracy: 0.2624\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.1507 - accuracy: 0.2638\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.0879 - accuracy: 0.2659\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.7991 - accuracy: 0.2707\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.7936 - accuracy: 0.2645\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.4675 - accuracy: 0.2610\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.1242 - accuracy: 0.2645\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.9599 - accuracy: 0.2707\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.8611 - accuracy: 0.2693\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.5659 - accuracy: 0.2721\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.5889 - accuracy: 0.2645\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.4627 - accuracy: 0.2673\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.1744 - accuracy: 0.2631\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.1751 - accuracy: 0.2631\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.0257 - accuracy: 0.2790\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.5273 - accuracy: 0.2735\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.4823 - accuracy: 0.2742\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.5172 - accuracy: 0.2776\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.4167 - accuracy: 0.2749\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.0014 - accuracy: 0.2693\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.0615 - accuracy: 0.2673\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.6327 - accuracy: 0.2645\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.9608 - accuracy: 0.2735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd04684388>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.19337016574585636\n",
      "Tasa de aciertos balanceada regresión logística: 0.22\n",
      "Matriz de confusión:\n",
      "[[22  5  1 17 32]\n",
      " [15  8  7 24 45]\n",
      " [ 9  8  3 12 27]\n",
      " [ 9 15  8 15 35]\n",
      " [ 7  7  0  9 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.35      0.29      0.32        77\n",
      "         2.0       0.19      0.08      0.11        99\n",
      "         3.0       0.16      0.05      0.08        59\n",
      "         4.0       0.19      0.18      0.19        82\n",
      "         5.0       0.14      0.49      0.21        45\n",
      "\n",
      "    accuracy                           0.19       362\n",
      "   macro avg       0.21      0.22      0.18       362\n",
      "weighted avg       0.21      0.19      0.18       362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_670 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_671 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_672 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_673 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_674 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,058\n",
      "Trainable params: 2,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 2130.3237 - accuracy: 0.1830\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1150.5387 - accuracy: 0.1678\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 824.5975 - accuracy: 0.1644\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 603.2881 - accuracy: 0.1595\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 437.5221 - accuracy: 0.1664\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 332.2354 - accuracy: 0.1692\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 261.2895 - accuracy: 0.1927\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 211.2623 - accuracy: 0.1996\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 171.1995 - accuracy: 0.2044\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 138.8470 - accuracy: 0.2113\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 116.7406 - accuracy: 0.2251\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 99.8886 - accuracy: 0.2279\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.2778 - accuracy: 0.2355\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.0477 - accuracy: 0.2224\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 68.6737 - accuracy: 0.2286\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.6906 - accuracy: 0.2279\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.7913 - accuracy: 0.2327\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.0851 - accuracy: 0.2307\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.3211 - accuracy: 0.2293\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.3255 - accuracy: 0.2334\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.8462 - accuracy: 0.2251\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.8519 - accuracy: 0.2182\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.0654 - accuracy: 0.2224\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.0821 - accuracy: 0.2162\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.2293 - accuracy: 0.2120\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.6354 - accuracy: 0.2099\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.2943 - accuracy: 0.2224\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.9342 - accuracy: 0.2652\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.5169 - accuracy: 0.2624\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.1574 - accuracy: 0.2673\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.9617 - accuracy: 0.2721\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.8214 - accuracy: 0.2686\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.8407 - accuracy: 0.2700\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.8252 - accuracy: 0.2686\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.8963 - accuracy: 0.2707\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.9784 - accuracy: 0.2735\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.1771 - accuracy: 0.2762\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.3206 - accuracy: 0.2756\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.2958 - accuracy: 0.2797\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.2321 - accuracy: 0.2804\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.2549 - accuracy: 0.2797\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5786 - accuracy: 0.2762\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.9990 - accuracy: 0.2769\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.5583 - accuracy: 0.2790\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1584 - accuracy: 0.2790\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6878 - accuracy: 0.2797\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.3062 - accuracy: 0.2825\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9871 - accuracy: 0.2825\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6498 - accuracy: 0.2845\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.3433 - accuracy: 0.2859\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0355 - accuracy: 0.2838\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6787 - accuracy: 0.2859\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3816 - accuracy: 0.2866\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1467 - accuracy: 0.2866\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8427 - accuracy: 0.2866\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5808 - accuracy: 0.2845\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2765 - accuracy: 0.2866\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9927 - accuracy: 0.2859\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5955 - accuracy: 0.2901\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3254 - accuracy: 0.2901\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0792 - accuracy: 0.2894\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7959 - accuracy: 0.2873\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5978 - accuracy: 0.2880\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3726 - accuracy: 0.2838\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1544 - accuracy: 0.2866\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8498 - accuracy: 0.2873\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4859 - accuracy: 0.2859\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1474 - accuracy: 0.2859\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8368 - accuracy: 0.2852\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4796 - accuracy: 0.2845\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1685 - accuracy: 0.2845\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9206 - accuracy: 0.2838\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6752 - accuracy: 0.2866\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4716 - accuracy: 0.2838\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2866 - accuracy: 0.2845\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1625 - accuracy: 0.2845\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9950 - accuracy: 0.2859\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8698 - accuracy: 0.2838\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7311 - accuracy: 0.2831\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6033 - accuracy: 0.2838\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4426 - accuracy: 0.2838\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3444 - accuracy: 0.2825\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3020 - accuracy: 0.2825\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2239 - accuracy: 0.2831\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1552 - accuracy: 0.2825\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0909 - accuracy: 0.2831\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0226 - accuracy: 0.2825\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9853 - accuracy: 0.2811\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9198 - accuracy: 0.2825\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8483 - accuracy: 0.2831\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7789 - accuracy: 0.2825\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7206 - accuracy: 0.2838\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6796 - accuracy: 0.2831\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6092 - accuracy: 0.2825\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5713 - accuracy: 0.2838\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5101 - accuracy: 0.2838\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.4727 - accuracy: 0.2838\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3966 - accuracy: 0.2845\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3870 - accuracy: 0.2845\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3571 - accuracy: 0.2852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd30e60748>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.12430939226519337\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0 51 15  4  5  1  1]\n",
      " [ 0 33 27  5 16 17  1]\n",
      " [ 0  8 12  9 10 20  0]\n",
      " [ 1  3 14 15 18 30  1]\n",
      " [ 0  1  1  4  7 32  0]\n",
      " [ 0  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.13      0.02      0.04        99\n",
      "         3.0       0.00      0.00      0.00        59\n",
      "         4.0       0.00      0.00      0.00        82\n",
      "         5.0       0.12      0.96      0.22        45\n",
      "\n",
      "    accuracy                           0.12       362\n",
      "   macro avg       0.05      0.20      0.05       362\n",
      "weighted avg       0.05      0.12      0.04       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_675 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_676 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_677 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_678 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_679 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,757\n",
      "Trainable params: 21,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 11.0719 - accuracy: 0.1885\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0454 - accuracy: 0.1865\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0455 - accuracy: 0.1865\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0455 - accuracy: 0.1865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd311e1988>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2154696132596685\n",
      "Tasa de aciertos balanceada regresión logística: 0.22\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 2 69  0  0  0  6]\n",
      " [ 1 86  0  0  0 12]\n",
      " [ 0 53  0  0  0  6]\n",
      " [ 3 71  0  0  0  8]\n",
      " [ 0 36  0  0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.22      0.90      0.35        77\n",
      "         2.0       0.00      0.00      0.00        99\n",
      "         3.0       0.00      0.00      0.00        59\n",
      "         4.0       0.00      0.00      0.00        82\n",
      "         5.0       0.22      0.20      0.21        45\n",
      "\n",
      "    accuracy                           0.22       362\n",
      "   macro avg       0.07      0.18      0.09       362\n",
      "weighted avg       0.07      0.22      0.10       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_680 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_681 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_682 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_683 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_684 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,895\n",
      "Trainable params: 9,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7358 - accuracy: 0.1637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd325d9308>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.212707182320442\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[77  0  0  0  0]\n",
      " [99  0  0  0  0]\n",
      " [59  0  0  0  0]\n",
      " [82  0  0  0  0]\n",
      " [45  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.21      1.00      0.35        77\n",
      "         2.0       0.00      0.00      0.00        99\n",
      "         3.0       0.00      0.00      0.00        59\n",
      "         4.0       0.00      0.00      0.00        82\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.21       362\n",
      "   macro avg       0.04      0.20      0.07       362\n",
      "weighted avg       0.05      0.21      0.07       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_685 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_686 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_687 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_688 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_689 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,159\n",
      "Trainable params: 3,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 8.3906 - accuracy: 0.1989\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4775 - accuracy: 0.1982\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4211 - accuracy: 0.1975\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3528 - accuracy: 0.1982\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3191 - accuracy: 0.1975\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1965 - accuracy: 0.1975\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1716 - accuracy: 0.1975\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1742 - accuracy: 0.1975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd329c8688>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.27348066298342544\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 2 69  0  0  0  6]\n",
      " [ 1 86  0  0  0 12]\n",
      " [ 0 53  0  0  0  6]\n",
      " [ 3 71  0  0  0  8]\n",
      " [ 0 36  0  0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.27      1.00      0.43        99\n",
      "         3.0       0.00      0.00      0.00        59\n",
      "         4.0       0.00      0.00      0.00        82\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.27       362\n",
      "   macro avg       0.05      0.20      0.09       362\n",
      "weighted avg       0.07      0.27      0.12       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_690 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_691 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_692 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_693 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_694 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_695 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_696 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_697 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_698 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_699 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,819\n",
      "Trainable params: 12,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3538 - accuracy: 6.9061e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd33d3ac88>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0 77]\n",
      " [ 0  0  0  0  0 99]\n",
      " [ 0  0  0  0  0 59]\n",
      " [ 0  0  0  0  0 82]\n",
      " [ 0  0  0  0  0 45]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00      99.0\n",
      "         3.0       0.00      0.00      0.00      59.0\n",
      "         4.0       0.00      0.00      0.00      82.0\n",
      "         5.0       0.00      0.00      0.00      45.0\n",
      "         6.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00     362.0\n",
      "   macro avg       0.00      0.00      0.00     362.0\n",
      "weighted avg       0.00      0.00      0.00     362.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_700 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_701 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_702 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_703 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_704 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_705 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_706 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_707 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_708 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_709 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,175\n",
      "Trainable params: 6,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 3.8960 - accuracy: 0.1264\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3841 - accuracy: 0.1264\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9568 - accuracy: 0.1257\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2097 - accuracy: 0.1257\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8573 - accuracy: 0.1250\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4914 - accuracy: 0.1250\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5001 - accuracy: 0.1250\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5368 - accuracy: 0.1243\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5558 - accuracy: 0.1243\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5557 - accuracy: 0.1243\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5560 - accuracy: 0.1250\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5683 - accuracy: 0.1250\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5171 - accuracy: 0.1243\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5015 - accuracy: 0.1250\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4282 - accuracy: 0.1243\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3675 - accuracy: 0.1250\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3756 - accuracy: 0.1250\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3835 - accuracy: 0.1250\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3838 - accuracy: 0.1243\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3827 - accuracy: 0.1243\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3838 - accuracy: 0.1243\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3824 - accuracy: 0.1243\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3709 - accuracy: 0.1243\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3816 - accuracy: 0.1250\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3809 - accuracy: 0.1250\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3844 - accuracy: 0.1250\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3726 - accuracy: 0.1250\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4621 - accuracy: 0.1257\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4984 - accuracy: 0.1264\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5018 - accuracy: 0.1243\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2978 - accuracy: 0.1250\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0961 - accuracy: 0.1264\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0284 - accuracy: 0.1257\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0257 - accuracy: 0.1250\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0761 - accuracy: 0.1243\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0505 - accuracy: 0.1250\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0864 - accuracy: 0.1250\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0759 - accuracy: 0.1250\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9698 - accuracy: 0.1250\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9374 - accuracy: 0.1250\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9212 - accuracy: 0.1243\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8823 - accuracy: 0.1243\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8777 - accuracy: 0.1243\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8587 - accuracy: 0.1250\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8468 - accuracy: 0.1250\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8551 - accuracy: 0.1250\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8546 - accuracy: 0.1250\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8542 - accuracy: 0.1250\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8538 - accuracy: 0.1250\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8535 - accuracy: 0.1250\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8531 - accuracy: 0.1250\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8528 - accuracy: 0.1250\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8526 - accuracy: 0.1250\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8522 - accuracy: 0.1250\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8520 - accuracy: 0.1250\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8519 - accuracy: 0.1250\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8516 - accuracy: 0.1250\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8513 - accuracy: 0.1250\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8509 - accuracy: 0.1250\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8511 - accuracy: 0.1250\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8509 - accuracy: 0.1250\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8504 - accuracy: 0.1250\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8506 - accuracy: 0.1250\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8502 - accuracy: 0.1250\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8518 - accuracy: 0.1250\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8511 - accuracy: 0.1250\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8504 - accuracy: 0.1250\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8501 - accuracy: 0.1250\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8498 - accuracy: 0.1250\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8495 - accuracy: 0.1250\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8492 - accuracy: 0.1250\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8489 - accuracy: 0.1250\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8486 - accuracy: 0.1250\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8482 - accuracy: 0.1250\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8482 - accuracy: 0.1250\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8482 - accuracy: 0.1250\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8481 - accuracy: 0.1250\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8478 - accuracy: 0.1250\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8479 - accuracy: 0.1250\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8478 - accuracy: 0.1250\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8477 - accuracy: 0.1250\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8474 - accuracy: 0.1250\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8478 - accuracy: 0.1250\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8473 - accuracy: 0.1250\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8478 - accuracy: 0.1250\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8475 - accuracy: 0.1250\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8472 - accuracy: 0.1250\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8473 - accuracy: 0.1250\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8473 - accuracy: 0.1250\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8470 - accuracy: 0.1250\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8470 - accuracy: 0.1250\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8470 - accuracy: 0.1250\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8469 - accuracy: 0.1250\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8468 - accuracy: 0.1250\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8467 - accuracy: 0.1250\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8466 - accuracy: 0.1250\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8466 - accuracy: 0.1250\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8465 - accuracy: 0.1250\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8466 - accuracy: 0.1250\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8464 - accuracy: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd342ce748>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.16298342541436464\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 0  0 77  0  0]\n",
      " [ 0  0 99  0  0]\n",
      " [ 0  0 59  0  0]\n",
      " [ 0  0 82  0  0]\n",
      " [ 0  0 45  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        77\n",
      "         2.0       0.00      0.00      0.00        99\n",
      "         3.0       0.16      1.00      0.28        59\n",
      "         4.0       0.00      0.00      0.00        82\n",
      "         5.0       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.16       362\n",
      "   macro avg       0.03      0.20      0.06       362\n",
      "weighted avg       0.03      0.16      0.05       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_710 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_711 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_712 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_713 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_714 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_715 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_716 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_717 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_718 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_719 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,193\n",
      "Trainable params: 2,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9631 - accuracy: 0.0076\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9631 - accuracy: 0.0076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd3579b948>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0 77]\n",
      " [ 0  0  0  0  0 99]\n",
      " [ 0  0  0  0  0 59]\n",
      " [ 0  0  0  0  0 82]\n",
      " [ 0  0  0  0  0 45]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00      77.0\n",
      "         2.0       0.00      0.00      0.00      99.0\n",
      "         3.0       0.00      0.00      0.00      59.0\n",
      "         4.0       0.00      0.00      0.00      82.0\n",
      "         5.0       0.00      0.00      0.00      45.0\n",
      "         6.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00     362.0\n",
      "   macro avg       0.00      0.00      0.00     362.0\n",
      "weighted avg       0.00      0.00      0.00     362.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERVALO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.578249</td>\n",
       "      <td>0.135279</td>\n",
       "      <td>0.135279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.262599</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.111406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.159151</td>\n",
       "      <td>0.196286</td>\n",
       "      <td>0.079576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.474801</td>\n",
       "      <td>0.381963</td>\n",
       "      <td>0.135279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.159151</td>\n",
       "      <td>0.122016</td>\n",
       "      <td>0.079576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.204244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.578249     0.135279     0.135279\n",
       "Experimento 2- RELU+ADAM         0.262599     0.034483     0.111406\n",
       "Experimento 3- RELU+ADAM         0.159151     0.196286     0.079576\n",
       "Experimento 1- RELU+ADAGRAD      0.474801     0.381963     0.135279\n",
       "Experimento 2- RELU+ADAGRAD      0.159151     0.122016     0.079576\n",
       "Experimento 3- RELU+ADAGRAD      0.204244     0.000000     0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['100 Neuronas'] = None\n",
    "df1['64 Neuronas'] = None\n",
    "df1['32 Neuronas'] = None\n",
    "df1.loc['Experimento 1- RELU+ADAM'] = [0.5782493368700266,0.13527851458885942,0.13527851458885942]\n",
    "df1.loc['Experimento 2- RELU+ADAM'] = [0.2625994694960212,0.034482758620689655,0.11140583554376658]\n",
    "df1.loc['Experimento 3- RELU+ADAM'] = [0.15915119363395225,0.1962864721485411,0.07957559681697612]\n",
    "df1.loc['Experimento 1- RELU+ADAGRAD'] = [0.47480106100795755,0.3819628647214854, 0.13527851458885942]\n",
    "df1.loc['Experimento 2- RELU+ADAGRAD'] = [0.15915119363395225,0.1220159151193634,0.07957559681697612]\n",
    "df1.loc['Experimento 3- RELU+ADAGRAD'] = [0.20424403183023873,0.0,0.0]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>0.122951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.122951</td>\n",
       "      <td>0.068306</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.259563</td>\n",
       "      <td>0.210383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.382514</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.210383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120219</td>\n",
       "      <td>0.297814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.161202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.409836     0.344262     0.122951\n",
       "Experimento 2- RELU+ADAM         0.122951     0.068306     0.000000\n",
       "Experimento 3- RELU+ADAM         0.010929     0.259563     0.210383\n",
       "Experimento 1- RELU+ADAGRAD      0.382514     0.229508     0.210383\n",
       "Experimento 2- RELU+ADAGRAD      0.000000     0.120219     0.297814\n",
       "Experimento 3- RELU+ADAGRAD      0.161202     0.000000     0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['100 Neuronas'] = None\n",
    "df2['64 Neuronas'] = None\n",
    "df2['32 Neuronas'] = None\n",
    "df2.loc['Experimento 1- RELU+ADAM'] = [0.4098360655737705,0.3442622950819672,0.12295081967213115]\n",
    "df2.loc['Experimento 2- RELU+ADAM'] = [0.12295081967213115,0.06830601092896176,0.0]\n",
    "df2.loc['Experimento 3- RELU+ADAM'] = [0.01092896174863388,0.25956284153005466, 0.2103825136612022]\n",
    "df2.loc['Experimento 1- RELU+ADAGRAD'] = [0.3825136612021858,0.22950819672131148,0.2103825136612022]\n",
    "df2.loc['Experimento 2- RELU+ADAGRAD'] = [0.0,0.12021857923497267,0.2978142076502732]\n",
    "df2.loc['Experimento 3- RELU+ADAGRAD'] = [0.16120218579234974,0.0,0.0]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.408840</td>\n",
       "      <td>0.124309</td>\n",
       "      <td>0.124309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.193370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.162983</td>\n",
       "      <td>0.162983</td>\n",
       "      <td>0.273481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.378453</td>\n",
       "      <td>0.193370</td>\n",
       "      <td>0.124309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.215470</td>\n",
       "      <td>0.212707</td>\n",
       "      <td>0.273481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162983</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.408840     0.124309     0.124309\n",
       "Experimento 2- RELU+ADAM         0.193370     0.000000     0.113260\n",
       "Experimento 3- RELU+ADAM         0.162983     0.162983     0.273481\n",
       "Experimento 1- RELU+ADAGRAD      0.378453     0.193370     0.124309\n",
       "Experimento 2- RELU+ADAGRAD      0.215470     0.212707     0.273481\n",
       "Experimento 3- RELU+ADAGRAD      0.000000     0.162983     0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame()\n",
    "df3['100 Neuronas'] = None\n",
    "df3['64 Neuronas'] = None\n",
    "df3['32 Neuronas'] = None\n",
    "df3.loc['Experimento 1- RELU+ADAM'] = [0.4088397790055249,0.12430939226519337,0.12430939226519337]\n",
    "df3.loc['Experimento 2- RELU+ADAM'] = [0.19337016574585636,0.0,0.1132596685082873]\n",
    "df3.loc['Experimento 3- RELU+ADAM'] = [0.16298342541436464,0.16298342541436464,0.27348066298342544]\n",
    "df3.loc['Experimento 1- RELU+ADAGRAD'] = [0.3784530386740331,0.19337016574585636,0.12430939226519337]\n",
    "df3.loc['Experimento 2- RELU+ADAGRAD'] = [0.2154696132596685,0.212707182320442,0.27348066298342544]\n",
    "df3.loc['Experimento 3- RELU+ADAGRAD'] = [0.0,0.16298342541436464,0.0]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16476f251c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,20))\n",
    "fig.add_subplot(2,2,1)\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 1')\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM' ,color ='red')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 2')\n",
    "fig.add_subplot(2,2,3)\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 3')\n",
    "plt.legend(bbox_to_anchor = (2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
