{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense intervalos - datos 5 dias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run 5dias-porintervalos1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix,balanced_accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subida(list):\n",
    "    resultado = []\n",
    "    for i in range(1,len(list)):\n",
    "        if  (list)[i] > (list)[i-1]:\n",
    "            resultado.append(1)\n",
    "        else:\n",
    "            resultado.append(0)\n",
    "    return resultado\n",
    "\n",
    "def acierto(list1,list2):\n",
    "    sum = 0\n",
    "    for i in range(0,len(list1)):\n",
    "        if(list1[i]==list2[i]):\n",
    "            sum = sum +1\n",
    "    a = sum/len(list1)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 12, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 25)                850       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,065\n",
      "Trainable params: 9,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 661.5793 - accuracy: 0.1746\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.9610 - accuracy: 0.2308\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.8240 - accuracy: 0.2672\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.6202 - accuracy: 0.2751\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2817 - accuracy: 0.2725\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1773 - accuracy: 0.2685\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1430 - accuracy: 0.2705\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0064 - accuracy: 0.2712\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9778 - accuracy: 0.2665\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8649 - accuracy: 0.2659\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8398 - accuracy: 0.2632\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8270 - accuracy: 0.2652\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8180 - accuracy: 0.2652\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8053 - accuracy: 0.2679\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8227 - accuracy: 0.2586\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8032 - accuracy: 0.2606\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7878 - accuracy: 0.2632\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7914 - accuracy: 0.2632\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7880 - accuracy: 0.2632\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7849 - accuracy: 0.2659\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7732 - accuracy: 0.2652\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7712 - accuracy: 0.2692\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7816 - accuracy: 0.2612\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7645 - accuracy: 0.2672\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7640 - accuracy: 0.2672\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7572 - accuracy: 0.2685\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7522 - accuracy: 0.2718\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7609 - accuracy: 0.2659\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7536 - accuracy: 0.2698\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7527 - accuracy: 0.2685\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7440 - accuracy: 0.2705\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7524 - accuracy: 0.2738\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7454 - accuracy: 0.2738\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7723 - accuracy: 0.2738\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9799 - accuracy: 0.2652\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7717 - accuracy: 0.2546\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7679 - accuracy: 0.2553\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7672 - accuracy: 0.2553\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7658 - accuracy: 0.2553\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7649 - accuracy: 0.2553\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7639 - accuracy: 0.2553\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7629 - accuracy: 0.2553\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7620 - accuracy: 0.2553\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7612 - accuracy: 0.2553\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7604 - accuracy: 0.2553\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7597 - accuracy: 0.2553\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7589 - accuracy: 0.2553\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7582 - accuracy: 0.2553\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7575 - accuracy: 0.2553\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7570 - accuracy: 0.2553\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7563 - accuracy: 0.2553\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7557 - accuracy: 0.2553\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7551 - accuracy: 0.2553\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7546 - accuracy: 0.2553\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7540 - accuracy: 0.2553\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7534 - accuracy: 0.2553\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7529 - accuracy: 0.2553\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7526 - accuracy: 0.2553\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7520 - accuracy: 0.2553\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7516 - accuracy: 0.2553\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7511 - accuracy: 0.2553\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7507 - accuracy: 0.2553\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7503 - accuracy: 0.2553\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7499 - accuracy: 0.2553\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7495 - accuracy: 0.2553\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 983us/step - loss: 1.7491 - accuracy: 0.2553\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7487 - accuracy: 0.2553\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7483 - accuracy: 0.2553\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 1.7480 - accuracy: 0.2553\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7477 - accuracy: 0.2553\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7474 - accuracy: 0.2553\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7470 - accuracy: 0.2553\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7467 - accuracy: 0.2553\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7464 - accuracy: 0.2553\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7462 - accuracy: 0.2553\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7459 - accuracy: 0.2553\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7456 - accuracy: 0.2553\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7454 - accuracy: 0.2553\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 1.7451 - accuracy: 0.2553\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7448 - accuracy: 0.2553\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7446 - accuracy: 0.2553\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7443 - accuracy: 0.2553\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7441 - accuracy: 0.2553\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7438 - accuracy: 0.2553\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7436 - accuracy: 0.2553\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 1.7434 - accuracy: 0.2553\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7431 - accuracy: 0.2553\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7430 - accuracy: 0.2553\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7427 - accuracy: 0.2553\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7426 - accuracy: 0.2553\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7423 - accuracy: 0.2553\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.7422 - accuracy: 0.2553\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7421 - accuracy: 0.2553\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7419 - accuracy: 0.2553\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7416 - accuracy: 0.2553\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7415 - accuracy: 0.2553\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7413 - accuracy: 0.2553\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7412 - accuracy: 0.2553\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7411 - accuracy: 0.2553\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7408 - accuracy: 0.2553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f491c075c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2671957671957672\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  32   0   0]\n",
      " [  0   0   0  69   0   0]\n",
      " [  0   0   0 109   0   0]\n",
      " [  0   0   0 101   0   0]\n",
      " [  0   0   0  49   0   0]\n",
      " [  0   0   0  18   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       109\n",
      "         4.0       0.27      1.00      0.42       101\n",
      "         5.0       0.00      0.00      0.00        49\n",
      "         6.0       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.27       378\n",
      "   macro avg       0.04      0.17      0.07       378\n",
      "weighted avg       0.07      0.27      0.11       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 64)                832       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 21)                693       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                352       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,076\n",
      "Trainable params: 4,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 539.7265 - accuracy: 0.2077\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 98.6995 - accuracy: 0.2011\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 72.7133 - accuracy: 0.2275\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 53.2525 - accuracy: 0.2447\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 33.7111 - accuracy: 0.2500\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 41.9026 - accuracy: 0.2659\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 31.4995 - accuracy: 0.2910\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.7139 - accuracy: 0.2884\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 27.7839 - accuracy: 0.2467\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42.6812 - accuracy: 0.2639\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.4359 - accuracy: 0.2837\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.0238 - accuracy: 0.3082\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.2513 - accuracy: 0.2864\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.4200 - accuracy: 0.3003\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.9058 - accuracy: 0.3115\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.7311 - accuracy: 0.2989\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.7568 - accuracy: 0.2923\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.8203 - accuracy: 0.3221\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.9679 - accuracy: 0.3294\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.0216 - accuracy: 0.3003\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.3864 - accuracy: 0.3181\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.4098 - accuracy: 0.2943\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.4752 - accuracy: 0.3075\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7264 - accuracy: 0.3307\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5600 - accuracy: 0.3161\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.1460 - accuracy: 0.3102\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.0444 - accuracy: 0.3241\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8339 - accuracy: 0.3194\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8086 - accuracy: 0.3201\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.1888 - accuracy: 0.3492\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.4386 - accuracy: 0.2851\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.9904 - accuracy: 0.2937\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.2055 - accuracy: 0.3300\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.5015 - accuracy: 0.3247\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1552 - accuracy: 0.3267\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.5757 - accuracy: 0.3347\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.6290 - accuracy: 0.3366\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.4194 - accuracy: 0.3532\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 12.7834 - accuracy: 0.3399\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 8.7498 - accuracy: 0.3638\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 7.4555 - accuracy: 0.3433\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 7.3664 - accuracy: 0.3406\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1328 - accuracy: 0.4021\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9182 - accuracy: 0.3406\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 7.8474 - accuracy: 0.3604\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 6.4886 - accuracy: 0.3684\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 9.3050 - accuracy: 0.3247\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 5.7064 - accuracy: 0.3803\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.1281 - accuracy: 0.4041\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 4.9121 - accuracy: 0.3803\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 5.2014 - accuracy: 0.4067\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1771 - accuracy: 0.3803\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 949us/step - loss: 4.3395 - accuracy: 0.4233\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 8.9893 - accuracy: 0.3466\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 4.6704 - accuracy: 0.2646\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 4.0650 - accuracy: 0.2216\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.9361 - accuracy: 0.2857\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.6749 - accuracy: 0.3585\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 3.1616 - accuracy: 0.3082\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.7710 - accuracy: 0.2877\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 3.0511 - accuracy: 0.2877\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.6911 - accuracy: 0.2844\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.5580 - accuracy: 0.2884\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.5907 - accuracy: 0.2870\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 2.7646 - accuracy: 0.2745\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 2.0972 - accuracy: 0.2665\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 1.8484 - accuracy: 0.2639\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7576 - accuracy: 0.2639\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7475 - accuracy: 0.2632\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7318 - accuracy: 0.2646\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7211 - accuracy: 0.2718\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7164 - accuracy: 0.2731\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7113 - accuracy: 0.2698\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7088 - accuracy: 0.2745\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 1.7026 - accuracy: 0.2731\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 1.6994 - accuracy: 0.2751\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7020 - accuracy: 0.2771\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 1.6950 - accuracy: 0.2745\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 1.6818 - accuracy: 0.2765\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 1.6866 - accuracy: 0.2758\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 1.6862 - accuracy: 0.2771\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6835 - accuracy: 0.2791\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.8528 - accuracy: 0.2910\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7049 - accuracy: 0.2930\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6891 - accuracy: 0.2950\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6906 - accuracy: 0.2930\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6861 - accuracy: 0.2937\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6856 - accuracy: 0.2937\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6800 - accuracy: 0.2943\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6854 - accuracy: 0.2943\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6785 - accuracy: 0.2956\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6763 - accuracy: 0.2976\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6768 - accuracy: 0.2970\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6788 - accuracy: 0.2950\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6943 - accuracy: 0.2917\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6794 - accuracy: 0.2930\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6771 - accuracy: 0.2923\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6747 - accuracy: 0.2950\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6720 - accuracy: 0.2937\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6776 - accuracy: 0.2943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f49318d9c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.25132275132275134\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  3   2   0  26   0   1]\n",
      " [  0   2   0  65   0   2]\n",
      " [  0   1   0 101   0   7]\n",
      " [  0   0   0  86   0  15]\n",
      " [  0   0   0  31   0  18]\n",
      " [  0   0   0  14   0   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.09      0.17        32\n",
      "         2.0       0.40      0.03      0.05        69\n",
      "         3.0       0.00      0.00      0.00       109\n",
      "         4.0       0.27      0.85      0.41       101\n",
      "         5.0       0.00      0.00      0.00        49\n",
      "         6.0       0.09      0.22      0.12        18\n",
      "\n",
      "    accuracy                           0.25       378\n",
      "   macro avg       0.29      0.20      0.13       378\n",
      "weighted avg       0.23      0.25      0.14       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 32)                416       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 11)                187       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,290\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 1ms/step - loss: 2880.3748 - accuracy: 0.1303\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 165.6574 - accuracy: 0.2467\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.6394 - accuracy: 0.2560\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9273 - accuracy: 0.2560\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9142 - accuracy: 0.2560\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9017 - accuracy: 0.2560\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.8901 - accuracy: 0.2560\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.8792 - accuracy: 0.2560\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8692 - accuracy: 0.2560\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.8614 - accuracy: 0.2560\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8542 - accuracy: 0.2560\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8474 - accuracy: 0.2560\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.8410 - accuracy: 0.2560\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.8352 - accuracy: 0.2560\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.8299 - accuracy: 0.2560\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.8250 - accuracy: 0.2560\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.8204 - accuracy: 0.2560\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8161 - accuracy: 0.2560\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.8121 - accuracy: 0.2560\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.8085 - accuracy: 0.2560\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.8051 - accuracy: 0.2560\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.8019 - accuracy: 0.2560\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7990 - accuracy: 0.2560\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7963 - accuracy: 0.2560\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7938 - accuracy: 0.2560\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7914 - accuracy: 0.2560\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7892 - accuracy: 0.2560\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7871 - accuracy: 0.2566\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7852 - accuracy: 0.2560\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7834 - accuracy: 0.2566\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7816 - accuracy: 0.2560\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7800 - accuracy: 0.2566\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7785 - accuracy: 0.2560\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7768 - accuracy: 0.2566\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7755 - accuracy: 0.2560\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7741 - accuracy: 0.2566\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7730 - accuracy: 0.2560\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7721 - accuracy: 0.2560\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7709 - accuracy: 0.2560\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7697 - accuracy: 0.2560\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7687 - accuracy: 0.2560\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7676 - accuracy: 0.2560\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7666 - accuracy: 0.2560\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7658 - accuracy: 0.2560\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7647 - accuracy: 0.2560\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7639 - accuracy: 0.2560\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7630 - accuracy: 0.2560\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7623 - accuracy: 0.2560\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2938 - accuracy: 0.2566\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7985 - accuracy: 0.2553\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7588 - accuracy: 0.2560\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7582 - accuracy: 0.2560\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7575 - accuracy: 0.2560\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7567 - accuracy: 0.2560\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7561 - accuracy: 0.2560\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7555 - accuracy: 0.2560\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7549 - accuracy: 0.2560\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7543 - accuracy: 0.2560\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7538 - accuracy: 0.2560\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7532 - accuracy: 0.2560\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7527 - accuracy: 0.2566\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7522 - accuracy: 0.2566\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7517 - accuracy: 0.2566\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7512 - accuracy: 0.2566\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7507 - accuracy: 0.2566\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7503 - accuracy: 0.2566\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7499 - accuracy: 0.2566\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7493 - accuracy: 0.2566\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7490 - accuracy: 0.2566\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7486 - accuracy: 0.2566\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7482 - accuracy: 0.2566\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7478 - accuracy: 0.2566\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7474 - accuracy: 0.2566\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7471 - accuracy: 0.2566\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7467 - accuracy: 0.2566\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7464 - accuracy: 0.2566\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7460 - accuracy: 0.2566\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7457 - accuracy: 0.2566\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7454 - accuracy: 0.2566\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7450 - accuracy: 0.2566\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7448 - accuracy: 0.2566\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7445 - accuracy: 0.2566\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7441 - accuracy: 0.2566\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7439 - accuracy: 0.2566\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7436 - accuracy: 0.2566\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7434 - accuracy: 0.2566\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7431 - accuracy: 0.2566\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7428 - accuracy: 0.2566\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7426 - accuracy: 0.2566\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7423 - accuracy: 0.2566\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7421 - accuracy: 0.2566\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7419 - accuracy: 0.2566\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7416 - accuracy: 0.2566\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7415 - accuracy: 0.2566\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7413 - accuracy: 0.2566\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7410 - accuracy: 0.2566\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7408 - accuracy: 0.2566\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7406 - accuracy: 0.2566\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7404 - accuracy: 0.2566\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7402 - accuracy: 0.2566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4946e0388>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2671957671957672\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  32   0   0]\n",
      " [  0   0   0  69   0   0]\n",
      " [  0   0   0 109   0   0]\n",
      " [  0   0   0 101   0   0]\n",
      " [  0   0   0  49   0   0]\n",
      " [  0   0   0  18   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       109\n",
      "         4.0       0.27      1.00      0.42       101\n",
      "         5.0       0.00      0.00      0.00        49\n",
      "         6.0       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.27       378\n",
      "   macro avg       0.04      0.17      0.07       378\n",
      "weighted avg       0.07      0.27      0.11       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 12, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,357\n",
      "Trainable params: 19,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 6.1762 - accuracy: 0.1614\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5462 - accuracy: 0.1409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f494b07948>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.12962962962962962\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  32   0]\n",
      " [  0   0   0   0  69   0]\n",
      " [  0   0   0   0 109   0]\n",
      " [  0   0   0   0 101   0]\n",
      " [  0   0   0   0  49   0]\n",
      " [  0   0   0   0  18   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       109\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.13      1.00      0.23        49\n",
      "         6.0       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.13       378\n",
      "   macro avg       0.02      0.17      0.04       378\n",
      "weighted avg       0.02      0.13      0.03       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 64)                832       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,359\n",
      "Trainable params: 8,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 4.6616 - accuracy: 0.2401\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5884 - accuracy: 0.2302\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6174 - accuracy: 0.2302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f495ee7548>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.28835978835978837\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0  32   0   0   0]\n",
      " [  0   0  69   0   0   0]\n",
      " [  0   0 109   0   0   0]\n",
      " [  0   0 101   0   0   0]\n",
      " [  0   0  49   0   0   0]\n",
      " [  0   0  18   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.29      1.00      0.45       109\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.00      0.00      0.00        49\n",
      "         6.0       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.29       378\n",
      "   macro avg       0.05      0.17      0.07       378\n",
      "weighted avg       0.08      0.29      0.13       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 32)                416       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,391\n",
      "Trainable params: 2,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 3.5652 - accuracy: 0.1217\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5721 - accuracy: 0.1204\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.8933 - accuracy: 0.1323\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.2782 - accuracy: 0.1706\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.4880 - accuracy: 0.2116\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.5659 - accuracy: 0.2103\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7014 - accuracy: 0.2070\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7157 - accuracy: 0.2110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f49730fa08>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2328042328042328\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  32   0]\n",
      " [  0   0   0   0  69   0]\n",
      " [  0   0   0   0 109   0]\n",
      " [  0   0   0   0 101   0]\n",
      " [  0   0   0   0  49   0]\n",
      " [  0   0   0   0  18   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.19      0.62      0.30        69\n",
      "         3.0       0.29      0.41      0.34       109\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.00      0.00      0.00        49\n",
      "         6.0       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.23       378\n",
      "   macro avg       0.08      0.17      0.11       378\n",
      "weighted avg       0.12      0.23      0.15       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 12, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 25)                850       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 20)                520       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 17)                357       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 14)                252       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 12)                180       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 11)                143       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,419\n",
      "Trainable params: 10,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 11.3015 - accuracy: 0.1481\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2364 - accuracy: 0.1462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f495edf0c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.12962962962962962\n",
      "Tasa de aciertos balanceada regresión logística: 0.15\n",
      "Matriz de confusión:\n",
      "[[ 0  0  2  0 30  0]\n",
      " [ 0  0  9  0 60  0]\n",
      " [ 0  0 10  0 99  0]\n",
      " [ 0  0 14  0 87  0]\n",
      " [ 0  0 10  0 39  0]\n",
      " [ 0  0  3  0 15  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.21      0.09      0.13       109\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.12      0.80      0.21        49\n",
      "         6.0       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.13       378\n",
      "   macro avg       0.05      0.15      0.06       378\n",
      "weighted avg       0.08      0.13      0.06       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 64)                832       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 21)                693       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 16)                352       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 13)                221       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 11)                154       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,639\n",
      "Trainable params: 4,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 7.2289 - accuracy: 0.2255\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2387 - accuracy: 0.2302\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2387 - accuracy: 0.2302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f498aa2948>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.28835978835978837\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0  32   0   0   0]\n",
      " [  0   0  69   0   0   0]\n",
      " [  0   0 109   0   0   0]\n",
      " [  0   0 101   0   0   0]\n",
      " [  0   0  49   0   0   0]\n",
      " [  0   0  18   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.29      1.00      0.45       109\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.00      0.00      0.00        49\n",
      "         6.0       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.29       378\n",
      "   macro avg       0.05      0.17      0.07       378\n",
      "weighted avg       0.08      0.29      0.13       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 32)                416       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 11)                187       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,425\n",
      "Trainable params: 1,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 3.9641 - accuracy: 0.0483\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f49a00f988>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[ 0  0  2  0 30  0]\n",
      " [ 0  0  9  0 60  0]\n",
      " [ 0  0 10  0 99  0]\n",
      " [ 0  0 14  0 87  0]\n",
      " [ 0  0 10  0 39  0]\n",
      " [ 0  0  3  0 15  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      32.0\n",
      "         2.0       0.00      0.00      0.00      69.0\n",
      "         3.0       0.00      0.00      0.00     109.0\n",
      "         4.0       0.00      0.00      0.00     101.0\n",
      "         5.0       0.00      0.00      0.00      49.0\n",
      "         6.0       0.00      0.00      0.00      18.0\n",
      "\n",
      "    accuracy                           0.00     378.0\n",
      "   macro avg       0.00      0.00      0.00     378.0\n",
      "weighted avg       0.00      0.00      0.00     378.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 25)                850       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,065\n",
      "Trainable params: 9,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 1615.5903 - accuracy: 0.2315\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 550.9211 - accuracy: 0.2632\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 380.1419 - accuracy: 0.2606\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 274.9723 - accuracy: 0.2282\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 219.7020 - accuracy: 0.2130\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 177.1375 - accuracy: 0.2189\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 146.3709 - accuracy: 0.2275\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 133.0859 - accuracy: 0.2566\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 120.6804 - accuracy: 0.2665\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 114.9937 - accuracy: 0.2632\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 104.1197 - accuracy: 0.2626\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 99.6309 - accuracy: 0.2758\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 92.6722 - accuracy: 0.2864\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 86.9348 - accuracy: 0.2778\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 83.4125 - accuracy: 0.2864\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 80.9511 - accuracy: 0.3049\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 77.2969 - accuracy: 0.3022\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 75.3108 - accuracy: 0.2937\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 71.1550 - accuracy: 0.3161\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 68.9890 - accuracy: 0.3036\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 67.2137 - accuracy: 0.3029\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 64.2246 - accuracy: 0.3155\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 62.4382 - accuracy: 0.3188\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 58.6235 - accuracy: 0.3115\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 58.2793 - accuracy: 0.3155\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 55.1939 - accuracy: 0.3188\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 53.0640 - accuracy: 0.3161\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 51.3778 - accuracy: 0.3115\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 49.6452 - accuracy: 0.3056\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 47.8125 - accuracy: 0.3108\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.5098 - accuracy: 0.2983\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.4248 - accuracy: 0.2943\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.6020 - accuracy: 0.3201\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43.8288 - accuracy: 0.3108\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43.0975 - accuracy: 0.3122\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42.5089 - accuracy: 0.3089\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42.8191 - accuracy: 0.3181\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 41.7151 - accuracy: 0.3108\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 40.6870 - accuracy: 0.3049\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 40.6671 - accuracy: 0.3148\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 40.1339 - accuracy: 0.3142\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 40.1562 - accuracy: 0.3221\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.1613 - accuracy: 0.3267\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.2825 - accuracy: 0.3280\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.0981 - accuracy: 0.3300\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 36.6548 - accuracy: 0.3135\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.3189 - accuracy: 0.3333\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.4772 - accuracy: 0.3399\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.9419 - accuracy: 0.3287\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.2052 - accuracy: 0.3360\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.5405 - accuracy: 0.3386\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.0000 - accuracy: 0.3413\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.3564 - accuracy: 0.3241\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.1133 - accuracy: 0.3247\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.2486 - accuracy: 0.3300\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 33.0035 - accuracy: 0.3333\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.2867 - accuracy: 0.3320\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.6977 - accuracy: 0.3386\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.1697 - accuracy: 0.3466\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.6690 - accuracy: 0.3393\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.7866 - accuracy: 0.3399\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.2847 - accuracy: 0.3254\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.1269 - accuracy: 0.3439\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 29.9161 - accuracy: 0.3254\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.3452 - accuracy: 0.3446\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 29.7150 - accuracy: 0.3366\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 29.6298 - accuracy: 0.3413\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 28.7007 - accuracy: 0.3426\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.1833 - accuracy: 0.3519\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 28.8838 - accuracy: 0.3433\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 28.9352 - accuracy: 0.3307\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 27.7164 - accuracy: 0.3446\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 28.8657 - accuracy: 0.3433\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 28.5371 - accuracy: 0.3267\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 27.2357 - accuracy: 0.3452\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 26.9952 - accuracy: 0.3373\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 27.3526 - accuracy: 0.3512\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 26.9078 - accuracy: 0.3426\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 27.2987 - accuracy: 0.3413\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.4813 - accuracy: 0.3413\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.3151 - accuracy: 0.3499\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.4140 - accuracy: 0.3538\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.9802 - accuracy: 0.3492\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.8565 - accuracy: 0.3433\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.2063 - accuracy: 0.3512\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.6632 - accuracy: 0.3519\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.1148 - accuracy: 0.3485\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.4100 - accuracy: 0.3413\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.8420 - accuracy: 0.3545\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.1075 - accuracy: 0.3466\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.6950 - accuracy: 0.3545\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.7477 - accuracy: 0.3485\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.7999 - accuracy: 0.3485\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.4453 - accuracy: 0.3578\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.1099 - accuracy: 0.3578\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.7839 - accuracy: 0.3485\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.3074 - accuracy: 0.3419\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.3413 - accuracy: 0.3519\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.7140 - accuracy: 0.3618\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.5632 - accuracy: 0.3545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f49b50aa48>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3439153439153439\n",
      "Tasa de aciertos balanceada regresión logística: 0.35\n",
      "Matriz de confusión:\n",
      "[[12 14  4  1  0  1]\n",
      " [13 21 13 21  0  1]\n",
      " [11 16 22 51  7  2]\n",
      " [12  3 13 51 17  5]\n",
      " [ 1  0  3 15 17 13]\n",
      " [ 1  0  2  3  5  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.24      0.38      0.29        32\n",
      "         2.0       0.39      0.30      0.34        69\n",
      "         3.0       0.39      0.20      0.27       109\n",
      "         4.0       0.36      0.50      0.42       101\n",
      "         5.0       0.37      0.35      0.36        49\n",
      "         6.0       0.24      0.39      0.30        18\n",
      "\n",
      "    accuracy                           0.34       378\n",
      "   macro avg       0.33      0.35      0.33       378\n",
      "weighted avg       0.36      0.34      0.34       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_65 (Dense)            (None, 64)                832       \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 21)                693       \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 16)                352       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,076\n",
      "Trainable params: 4,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 2594.6606 - accuracy: 0.1858\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1211.7944 - accuracy: 0.1839\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 671.4568 - accuracy: 0.1978\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 344.4783 - accuracy: 0.2282\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 237.9030 - accuracy: 0.2315\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 187.6293 - accuracy: 0.2368\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 162.0087 - accuracy: 0.2526\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 146.5521 - accuracy: 0.2619\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 134.6790 - accuracy: 0.2778\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 130.7151 - accuracy: 0.2692\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 121.9549 - accuracy: 0.2692\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 117.1328 - accuracy: 0.2791\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 112.7248 - accuracy: 0.2698\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 109.6607 - accuracy: 0.2758\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 104.3784 - accuracy: 0.2771\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 102.7973 - accuracy: 0.2731\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 98.6964 - accuracy: 0.2798\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 95.5310 - accuracy: 0.2824\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 91.8238 - accuracy: 0.2824\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 90.1312 - accuracy: 0.2923\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 87.0402 - accuracy: 0.2884\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 84.3194 - accuracy: 0.2930\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 82.7989 - accuracy: 0.2930\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 80.1142 - accuracy: 0.2983\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 78.5348 - accuracy: 0.2844\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 76.0770 - accuracy: 0.2745\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 74.9141 - accuracy: 0.2837\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 72.9162 - accuracy: 0.2884\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 70.9707 - accuracy: 0.2970\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 69.4687 - accuracy: 0.2976\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 68.8718 - accuracy: 0.2903\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 67.8603 - accuracy: 0.2837\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 66.5328 - accuracy: 0.2923\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 64.4177 - accuracy: 0.3062\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 63.9907 - accuracy: 0.2844\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 62.2713 - accuracy: 0.3042\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 61.2196 - accuracy: 0.2996\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 60.0636 - accuracy: 0.2976\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 59.5906 - accuracy: 0.2884\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 58.5971 - accuracy: 0.3075\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 57.6653 - accuracy: 0.2897\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 56.1007 - accuracy: 0.3049\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 55.5385 - accuracy: 0.3135\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 54.4539 - accuracy: 0.3042\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 54.1163 - accuracy: 0.3022\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 54.0756 - accuracy: 0.3082\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 52.6918 - accuracy: 0.3128\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 52.5749 - accuracy: 0.3122\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 51.3518 - accuracy: 0.2943\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 50.7073 - accuracy: 0.3115\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 50.2994 - accuracy: 0.3029\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 49.6071 - accuracy: 0.3188\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 49.2191 - accuracy: 0.3095\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 48.7840 - accuracy: 0.3135\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 47.3408 - accuracy: 0.3115\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.8010 - accuracy: 0.3194\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.2988 - accuracy: 0.3082\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 45.6616 - accuracy: 0.3234\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.9015 - accuracy: 0.3221\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.6564 - accuracy: 0.3188\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43.6052 - accuracy: 0.3234\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43.7566 - accuracy: 0.3148\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43.0702 - accuracy: 0.3280\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42.6446 - accuracy: 0.3095\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42.4411 - accuracy: 0.3161\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 41.3551 - accuracy: 0.3340\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 41.3980 - accuracy: 0.3254\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 41.1884 - accuracy: 0.3241\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 41.2015 - accuracy: 0.3353\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 40.5592 - accuracy: 0.3254\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 39.7940 - accuracy: 0.3287\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 39.8742 - accuracy: 0.3333\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 39.2093 - accuracy: 0.3261\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 39.3252 - accuracy: 0.3360\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 38.8028 - accuracy: 0.3419\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 38.6764 - accuracy: 0.3228\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.8863 - accuracy: 0.3228\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.9918 - accuracy: 0.3287\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.2910 - accuracy: 0.3300\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.0750 - accuracy: 0.3366\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 36.8490 - accuracy: 0.3419\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 36.1166 - accuracy: 0.3426\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 36.1804 - accuracy: 0.3472\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.6101 - accuracy: 0.3446\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.6719 - accuracy: 0.3413\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.4982 - accuracy: 0.3413\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.6807 - accuracy: 0.3353\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.2500 - accuracy: 0.3466\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.9802 - accuracy: 0.3446\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.6804 - accuracy: 0.3499\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.7229 - accuracy: 0.3439\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.7913 - accuracy: 0.3333\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.9224 - accuracy: 0.3485\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.9103 - accuracy: 0.3426\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.6907 - accuracy: 0.3479\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.9456 - accuracy: 0.3439\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.3729 - accuracy: 0.3393\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 33.1576 - accuracy: 0.3558\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.7090 - accuracy: 0.3452\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.6055 - accuracy: 0.3452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f49b86db48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2619047619047619\n",
      "Tasa de aciertos balanceada regresión logística: 0.28\n",
      "Matriz de confusión:\n",
      "[[19  5  7  1  0  0]\n",
      " [17 11 28  7  2  4]\n",
      " [17 26 39 17  5  5]\n",
      " [14 20 26 15 15 11]\n",
      " [ 6  7  4 14 11  7]\n",
      " [ 1  1  1  4  7  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.26      0.59      0.36        32\n",
      "         2.0       0.16      0.16      0.16        69\n",
      "         3.0       0.37      0.36      0.36       109\n",
      "         4.0       0.26      0.15      0.19       101\n",
      "         5.0       0.28      0.22      0.25        49\n",
      "         6.0       0.13      0.22      0.16        18\n",
      "\n",
      "    accuracy                           0.26       378\n",
      "   macro avg       0.24      0.28      0.25       378\n",
      "weighted avg       0.27      0.26      0.25       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_70 (Dense)            (None, 32)                416       \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 11)                187       \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,290\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 862.2048 - accuracy: 0.1581\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 201.6754 - accuracy: 0.2593\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 140.9650 - accuracy: 0.2526\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 105.0936 - accuracy: 0.2407\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 81.8622 - accuracy: 0.2222\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 67.9344 - accuracy: 0.2143\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 57.0631 - accuracy: 0.2030\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 49.3912 - accuracy: 0.1984\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43.4197 - accuracy: 0.1997\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 39.3002 - accuracy: 0.1905\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.4932 - accuracy: 0.1918\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.3024 - accuracy: 0.1931\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.7869 - accuracy: 0.1858\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 27.8313 - accuracy: 0.1845\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.0211 - accuracy: 0.1892\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.8343 - accuracy: 0.1839\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.8236 - accuracy: 0.1786\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.7220 - accuracy: 0.1720\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.7065 - accuracy: 0.1687\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.9040 - accuracy: 0.1614\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.1820 - accuracy: 0.1594\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.2772 - accuracy: 0.1561\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.6282 - accuracy: 0.1534\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.9662 - accuracy: 0.1554\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.4347 - accuracy: 0.1567\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.0161 - accuracy: 0.1541\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.4675 - accuracy: 0.1528\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.0823 - accuracy: 0.1521\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6684 - accuracy: 0.1481\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.3056 - accuracy: 0.1488\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.8588 - accuracy: 0.1481\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5902 - accuracy: 0.1481\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.2734 - accuracy: 0.1468\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.8248 - accuracy: 0.1422\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.4696 - accuracy: 0.1481\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.2025 - accuracy: 0.1435\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.9306 - accuracy: 0.1409\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.5911 - accuracy: 0.1448\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.3872 - accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.1104 - accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.8609 - accuracy: 0.1488\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5575 - accuracy: 0.1481\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2776 - accuracy: 0.1468\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.1130 - accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9493 - accuracy: 0.1442\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7452 - accuracy: 0.1435\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.5320 - accuracy: 0.1422\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.3619 - accuracy: 0.1429\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.2217 - accuracy: 0.1415\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0496 - accuracy: 0.1442\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8747 - accuracy: 0.1415\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.7132 - accuracy: 0.1448\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.5605 - accuracy: 0.1442\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.4326 - accuracy: 0.1448\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.2898 - accuracy: 0.1468\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.1700 - accuracy: 0.1442\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.0529 - accuracy: 0.1422\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9069 - accuracy: 0.1442\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.7947 - accuracy: 0.1422\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.6458 - accuracy: 0.1442\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.4942 - accuracy: 0.1429\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.4006 - accuracy: 0.1415\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2591 - accuracy: 0.1422\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.1238 - accuracy: 0.1389\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.0268 - accuracy: 0.1422\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.8728 - accuracy: 0.1435\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.7494 - accuracy: 0.1389\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.6427 - accuracy: 0.1409\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.5679 - accuracy: 0.1415\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.4358 - accuracy: 0.1422\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.3427 - accuracy: 0.1415\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2962 - accuracy: 0.1415\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1603 - accuracy: 0.1396\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.0834 - accuracy: 0.1409\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.0042 - accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.8977 - accuracy: 0.1435\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.8051 - accuracy: 0.1448\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7302 - accuracy: 0.1435\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.6293 - accuracy: 0.1435\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5481 - accuracy: 0.1435\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4822 - accuracy: 0.1435\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4286 - accuracy: 0.1448\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.3565 - accuracy: 0.1481\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.2263 - accuracy: 0.1475\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1540 - accuracy: 0.1481\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1142 - accuracy: 0.1495\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.0161 - accuracy: 0.1481\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.9338 - accuracy: 0.1495\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8618 - accuracy: 0.1475\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7958 - accuracy: 0.1508\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7153 - accuracy: 0.1495\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.6570 - accuracy: 0.1534\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5856 - accuracy: 0.1515\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5232 - accuracy: 0.1534\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.4716 - accuracy: 0.1548\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.4034 - accuracy: 0.1534\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.3266 - accuracy: 0.1567\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.2819 - accuracy: 0.1554\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.2269 - accuracy: 0.1554\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.1699 - accuracy: 0.1581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f49a265a88>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0582010582010582\n",
      "Tasa de aciertos balanceada regresión logística: 0.16\n",
      "Matriz de confusión:\n",
      "[[12 14  4  1  0  1]\n",
      " [13 21 13 21  0  1]\n",
      " [11 16 22 51  7  2]\n",
      " [12  3 13 51 17  5]\n",
      " [ 1  0  3 15 17 13]\n",
      " [ 1  0  2  3  5  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.25      0.12      0.17        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.08      0.01      0.02       109\n",
      "         4.0       0.18      0.02      0.04       101\n",
      "         5.0       0.00      0.00      0.00        49\n",
      "         6.0       0.05      0.83      0.09        18\n",
      "\n",
      "    accuracy                           0.06       378\n",
      "   macro avg       0.08      0.14      0.04       378\n",
      "weighted avg       0.10      0.06      0.03       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_75 (Dense)            (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,357\n",
      "Trainable params: 19,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7573 - accuracy: 0.1409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f49767c548>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.12962962962962962\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  32   0]\n",
      " [  0   0   0   0  69   0]\n",
      " [  0   0   0   0 109   0]\n",
      " [  0   0   0   0 101   0]\n",
      " [  0   0   0   0  49   0]\n",
      " [  0   0   0   0  18   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       109\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.13      1.00      0.23        49\n",
      "         6.0       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.13       378\n",
      "   macro avg       0.02      0.17      0.04       378\n",
      "weighted avg       0.02      0.13      0.03       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 64)                832       \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,359\n",
      "Trainable params: 8,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 5.4750 - accuracy: 0.0952\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 6.5557 - accuracy: 0.0946\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5241 - accuracy: 0.0933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f49d250948>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.047619047619047616\n",
      "Tasa de aciertos balanceada regresión logística: 0.09\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [14 18  0  0  0  0  0]\n",
      " [16 53  0  0  0  0  0]\n",
      " [19 90  0  0  0  0  0]\n",
      " [18 83  0  0  0  0  0]\n",
      " [ 9 40  0  0  0  0  0]\n",
      " [ 0 18  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.06      0.56      0.11        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       109\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.00      0.00      0.00        49\n",
      "         6.0       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.05       378\n",
      "   macro avg       0.01      0.08      0.02       378\n",
      "weighted avg       0.01      0.05      0.01       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_85 (Dense)            (None, 32)                416       \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,391\n",
      "Trainable params: 2,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 1ms/step - loss: 7.1790 - accuracy: 0.0026\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.1151 - accuracy: 0.0026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f49e609808>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  32   0]\n",
      " [  0   0   0   0  69   0]\n",
      " [  0   0   0   0 109   0]\n",
      " [  0   0   0   0 101   0]\n",
      " [  0   0   0   0  49   0]\n",
      " [  0   0   0   0  18   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      32.0\n",
      "         2.0       0.00      0.00      0.00      69.0\n",
      "         3.0       0.00      0.00      0.00     109.0\n",
      "         4.0       0.00      0.00      0.00     101.0\n",
      "         5.0       0.00      0.00      0.00      49.0\n",
      "         6.0       0.00      0.00      0.00      18.0\n",
      "\n",
      "    accuracy                           0.00     378.0\n",
      "   macro avg       0.00      0.00      0.00     378.0\n",
      "weighted avg       0.00      0.00      0.00     378.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 25)                850       \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 20)                520       \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 17)                357       \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 14)                252       \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 12)                180       \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 11)                143       \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,419\n",
      "Trainable params: 10,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 11.0330 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8640 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8399 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9080 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.1323 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.1496 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.0059 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.1391 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.1989 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.1770 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.1365 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.0985 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.0174 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.0274 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.0278 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.0276 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.0376 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.1454 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.1617 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2075 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.1081 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7650 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7608 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7611 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7715 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7610 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7610 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7609 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7608 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7606 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7608 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7606 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7608 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7604 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7606 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7599 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7598 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7592 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7590 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7705 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7722 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7722 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7723 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7722 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7721 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7720 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7720 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7720 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7720 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7720 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7720 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7720 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7720 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7720 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7720 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7720 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7719 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.7720 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f49f9705c8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [ 32   0   0   0   0   0   0]\n",
      " [ 69   0   0   0   0   0   0]\n",
      " [109   0   0   0   0   0   0]\n",
      " [101   0   0   0   0   0   0]\n",
      " [ 49   0   0   0   0   0   0]\n",
      " [ 18   0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      32.0\n",
      "         2.0       0.00      0.00      0.00      69.0\n",
      "         3.0       0.00      0.00      0.00     109.0\n",
      "         4.0       0.00      0.00      0.00     101.0\n",
      "         5.0       0.00      0.00      0.00      49.0\n",
      "         6.0       0.00      0.00      0.00      18.0\n",
      "\n",
      "    accuracy                           0.00     378.0\n",
      "   macro avg       0.00      0.00      0.00     378.0\n",
      "weighted avg       0.00      0.00      0.00     378.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,639\n",
      "Trainable params: 4,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 2ms/step - loss: 6.7677 - accuracy: 0.2275\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.6421 - accuracy: 0.2057\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2381 - accuracy: 0.2302\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.3106 - accuracy: 0.2024\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.2442 - accuracy: 0.2328\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.2704 - accuracy: 0.2341\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.2913 - accuracy: 0.2341\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.2369 - accuracy: 0.2341\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1851 - accuracy: 0.2341\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1835 - accuracy: 0.2341\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1687 - accuracy: 0.2341\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1451 - accuracy: 0.2341\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.0721 - accuracy: 0.2335\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.0886 - accuracy: 0.2348\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.0956 - accuracy: 0.2341\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1014 - accuracy: 0.2341\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.9687 - accuracy: 0.2328\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7948 - accuracy: 0.2308\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8345 - accuracy: 0.2308\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8316 - accuracy: 0.2328\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8286 - accuracy: 0.2328\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8263 - accuracy: 0.2335\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8234 - accuracy: 0.2341\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7848 - accuracy: 0.2341\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.2156 - accuracy: 0.2341\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.9199 - accuracy: 0.2354\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.9290 - accuracy: 0.2348\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.9677 - accuracy: 0.2348\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.9622 - accuracy: 0.2354\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8732 - accuracy: 0.2354\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8734 - accuracy: 0.2354\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8809 - accuracy: 0.2354\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.9171 - accuracy: 0.2354\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.9202 - accuracy: 0.2354\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8290 - accuracy: 0.2341\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8271 - accuracy: 0.2341\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8248 - accuracy: 0.2341\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8170 - accuracy: 0.2341\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8168 - accuracy: 0.2341\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8257 - accuracy: 0.2341\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8428 - accuracy: 0.2341\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8424 - accuracy: 0.2341\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8539 - accuracy: 0.2341\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8527 - accuracy: 0.2341\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8520 - accuracy: 0.2341\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8250 - accuracy: 0.2341\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8162 - accuracy: 0.2341\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8158 - accuracy: 0.2341\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8180 - accuracy: 0.2341\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8206 - accuracy: 0.2341\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8161 - accuracy: 0.2341\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8144 - accuracy: 0.2341\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8145 - accuracy: 0.2341\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8142 - accuracy: 0.2341\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8231 - accuracy: 0.2348\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8255 - accuracy: 0.2348\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8270 - accuracy: 0.2354\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8221 - accuracy: 0.2354\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8207 - accuracy: 0.2354\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8193 - accuracy: 0.2354\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8193 - accuracy: 0.2354\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8184 - accuracy: 0.2354\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8174 - accuracy: 0.2354\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8218 - accuracy: 0.2354\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8330 - accuracy: 0.2354\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8312 - accuracy: 0.2354\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8287 - accuracy: 0.2354\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8273 - accuracy: 0.2354\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8263 - accuracy: 0.2354\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8251 - accuracy: 0.2354\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8244 - accuracy: 0.2354\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7903 - accuracy: 0.2341\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6466 - accuracy: 0.2354\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6373 - accuracy: 0.2354\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6345 - accuracy: 0.2354\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6329 - accuracy: 0.2354\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6333 - accuracy: 0.2354\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 4.6313 - accuracy: 0.2354\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6304 - accuracy: 0.2354\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5872 - accuracy: 0.2354\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5953 - accuracy: 0.2354\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5938 - accuracy: 0.2354\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6238 - accuracy: 0.2354\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5958 - accuracy: 0.2354\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5956 - accuracy: 0.2354\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5947 - accuracy: 0.2354\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5957 - accuracy: 0.2354\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5825 - accuracy: 0.2361\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.5794 - accuracy: 0.2361\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6083 - accuracy: 0.2361\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6261 - accuracy: 0.2361\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6259 - accuracy: 0.2361\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6488 - accuracy: 0.2361\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6459 - accuracy: 0.2361\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6163 - accuracy: 0.2361\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6381 - accuracy: 0.2361\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6367 - accuracy: 0.2361\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6735 - accuracy: 0.2361\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6797 - accuracy: 0.2361\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6848 - accuracy: 0.2354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f49fec4288>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.20634920634920634\n",
      "Tasa de aciertos balanceada regresión logística: 0.18\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  8 24  0]\n",
      " [ 0  0  0 23 46  0]\n",
      " [ 0  0  0 40 69  0]\n",
      " [ 0  0  0 46 55  0]\n",
      " [ 0  0  0 17 32  0]\n",
      " [ 0  0  0  9  9  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       109\n",
      "         4.0       0.32      0.46      0.38       101\n",
      "         5.0       0.14      0.65      0.23        49\n",
      "         6.0       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.21       378\n",
      "   macro avg       0.08      0.18      0.10       378\n",
      "weighted avg       0.10      0.21      0.13       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_110 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,425\n",
      "Trainable params: 1,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7842 - accuracy: 0.1078\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7841 - accuracy: 0.1078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4a13885c8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.18253968253968253\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [ 32   0   0   0   0   0   0]\n",
      " [ 69   0   0   0   0   0   0]\n",
      " [109   0   0   0   0   0   0]\n",
      " [101   0   0   0   0   0   0]\n",
      " [ 49   0   0   0   0   0   0]\n",
      " [ 18   0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.18      1.00      0.31        69\n",
      "         3.0       0.00      0.00      0.00       109\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.00      0.00      0.00        49\n",
      "         6.0       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.18       378\n",
      "   macro avg       0.03      0.17      0.05       378\n",
      "weighted avg       0.03      0.18      0.06       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 22, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,065\n",
      "Trainable params: 10,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 1144.5789 - accuracy: 0.2037\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 217.9248 - accuracy: 0.2514\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 195.9275 - accuracy: 0.2602\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 153.1853 - accuracy: 0.2881\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 178.0685 - accuracy: 0.2650\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 127.3310 - accuracy: 0.3236\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 140.6054 - accuracy: 0.2875\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 143.9651 - accuracy: 0.3004\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 139.9870 - accuracy: 0.3127\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 94.2336 - accuracy: 0.3399\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 74.0177 - accuracy: 0.3651\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 69.7006 - accuracy: 0.3638\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 62.4107 - accuracy: 0.3883\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.1362 - accuracy: 0.3665\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.0365 - accuracy: 0.4162\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 71.0835 - accuracy: 0.3440\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 54.4341 - accuracy: 0.3774\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 59.4572 - accuracy: 0.3699\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.8482 - accuracy: 0.3815\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.7819 - accuracy: 0.3999\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.7197 - accuracy: 0.4271\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.4573 - accuracy: 0.4101\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.3424 - accuracy: 0.4087\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.0679 - accuracy: 0.4407\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.5224 - accuracy: 0.4074\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.0956 - accuracy: 0.3828\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.4959 - accuracy: 0.3699\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.6938 - accuracy: 0.3658\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.7648 - accuracy: 0.4033\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.9512 - accuracy: 0.4033\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.4592 - accuracy: 0.3706\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.6167 - accuracy: 0.3958\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.2371 - accuracy: 0.3910\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.2300 - accuracy: 0.4292\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.3955 - accuracy: 0.3849\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.9315 - accuracy: 0.3937\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.2726 - accuracy: 0.4264\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.1621 - accuracy: 0.4421\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.9673 - accuracy: 0.4237\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.9221 - accuracy: 0.4176\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.0782 - accuracy: 0.4074\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.2771 - accuracy: 0.4401\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.4940 - accuracy: 0.4366\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.6524 - accuracy: 0.4292\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.4243 - accuracy: 0.4080\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.8871 - accuracy: 0.4046\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.4698 - accuracy: 0.4183\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.4016 - accuracy: 0.4673\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.0120 - accuracy: 0.4210\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.6105 - accuracy: 0.4326\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.3454 - accuracy: 0.4666\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.6632 - accuracy: 0.4605\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.2053 - accuracy: 0.4707\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.4341 - accuracy: 0.4428\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.9957 - accuracy: 0.4387\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.5996 - accuracy: 0.4557\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.5999 - accuracy: 0.4448\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.3722 - accuracy: 0.4407\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2559 - accuracy: 0.4605\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2276 - accuracy: 0.4591\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6384 - accuracy: 0.4591\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.3235 - accuracy: 0.4421\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9080 - accuracy: 0.4768\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2995 - accuracy: 0.4244\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7681 - accuracy: 0.4673\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.1413 - accuracy: 0.4734\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.3167 - accuracy: 0.4898\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6156 - accuracy: 0.4353\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.8828 - accuracy: 0.4257\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.3687 - accuracy: 0.4305\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.1264 - accuracy: 0.4728\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0743 - accuracy: 0.4687\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7384 - accuracy: 0.4557\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8643 - accuracy: 0.4564\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.4644 - accuracy: 0.4237\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4994 - accuracy: 0.4469\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.7524 - accuracy: 0.4523\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8228 - accuracy: 0.4591\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6855 - accuracy: 0.4673\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0252 - accuracy: 0.4544\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3376 - accuracy: 0.4789\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.1366 - accuracy: 0.4407\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2786 - accuracy: 0.4455\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4279 - accuracy: 0.4210\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8235 - accuracy: 0.4591\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4588 - accuracy: 0.4775\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4743 - accuracy: 0.4271\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4288 - accuracy: 0.4319\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7441 - accuracy: 0.4789\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0753 - accuracy: 0.4625\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0576 - accuracy: 0.4441\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8404 - accuracy: 0.4591\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9640 - accuracy: 0.4673\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1162 - accuracy: 0.4605\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8956 - accuracy: 0.4632\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0156 - accuracy: 0.4469\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3977 - accuracy: 0.4394\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9076 - accuracy: 0.4142\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0687 - accuracy: 0.4659\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1831 - accuracy: 0.4768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f49f95adc8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3787465940054496\n",
      "Tasa de aciertos balanceada regresión logística: 0.38\n",
      "Matriz de confusión:\n",
      "[[16  6  9  1  0  0]\n",
      " [ 2  8 41 16  2  0]\n",
      " [ 0  0 37 60  9  1]\n",
      " [ 0  1 10 50 30  8]\n",
      " [ 0  0  1  9 23 11]\n",
      " [ 0  0  0  3  8  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.89      0.50      0.64        32\n",
      "         2.0       0.53      0.12      0.19        69\n",
      "         3.0       0.38      0.35      0.36       107\n",
      "         4.0       0.36      0.51      0.42        99\n",
      "         5.0       0.32      0.52      0.40        44\n",
      "         6.0       0.20      0.31      0.24        16\n",
      "\n",
      "    accuracy                           0.38       367\n",
      "   macro avg       0.45      0.38      0.38       367\n",
      "weighted avg       0.43      0.38      0.37       367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_125 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,716\n",
      "Trainable params: 4,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 987.3215 - accuracy: 0.1240\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0004 - accuracy: 0.2153\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1028 - accuracy: 0.2561\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0687 - accuracy: 0.2568\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9543 - accuracy: 0.2595\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8992 - accuracy: 0.2609\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8949 - accuracy: 0.2595\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8796 - accuracy: 0.2589\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8583 - accuracy: 0.2595\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8498 - accuracy: 0.2595\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8423 - accuracy: 0.2589\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8358 - accuracy: 0.2589\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8299 - accuracy: 0.2589\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8245 - accuracy: 0.2595\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8189 - accuracy: 0.2602\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8140 - accuracy: 0.2602\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8091 - accuracy: 0.2602\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8048 - accuracy: 0.2602\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8005 - accuracy: 0.2602\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7977 - accuracy: 0.2602\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7939 - accuracy: 0.2602\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7910 - accuracy: 0.2602\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7879 - accuracy: 0.2602\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7855 - accuracy: 0.2602\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7828 - accuracy: 0.2602\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7806 - accuracy: 0.2609\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7792 - accuracy: 0.2602\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7766 - accuracy: 0.2609\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7752 - accuracy: 0.2602\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7724 - accuracy: 0.2616\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8720 - accuracy: 0.2595\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7979 - accuracy: 0.2568\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7744 - accuracy: 0.2575\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7729 - accuracy: 0.2575\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7716 - accuracy: 0.2575\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7703 - accuracy: 0.2575\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7690 - accuracy: 0.2575\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7679 - accuracy: 0.2575\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7668 - accuracy: 0.2575\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7657 - accuracy: 0.2575\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7647 - accuracy: 0.2575\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7637 - accuracy: 0.2575\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7627 - accuracy: 0.2575\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7617 - accuracy: 0.2575\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7608 - accuracy: 0.2575\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7601 - accuracy: 0.2575\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7592 - accuracy: 0.2575\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7585 - accuracy: 0.2575\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7577 - accuracy: 0.2575\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7569 - accuracy: 0.2575\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7562 - accuracy: 0.2575\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7556 - accuracy: 0.2575\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7549 - accuracy: 0.2575\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7542 - accuracy: 0.2575\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7536 - accuracy: 0.2575\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7530 - accuracy: 0.2575\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7524 - accuracy: 0.2575\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7518 - accuracy: 0.2575\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7513 - accuracy: 0.2575\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7508 - accuracy: 0.2575\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7503 - accuracy: 0.2575\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7498 - accuracy: 0.2575\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7493 - accuracy: 0.2575\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7488 - accuracy: 0.2575\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7484 - accuracy: 0.2575\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7479 - accuracy: 0.2575\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7475 - accuracy: 0.2575\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7470 - accuracy: 0.2575\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7466 - accuracy: 0.2575\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7463 - accuracy: 0.2575\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7458 - accuracy: 0.2575\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7455 - accuracy: 0.2575\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7451 - accuracy: 0.2575\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7448 - accuracy: 0.2575\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7446 - accuracy: 0.2575\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7441 - accuracy: 0.2575\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7437 - accuracy: 0.2575\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7435 - accuracy: 0.2575\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7431 - accuracy: 0.2575\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7428 - accuracy: 0.2575\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7426 - accuracy: 0.2575\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7422 - accuracy: 0.2575\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7420 - accuracy: 0.2575\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7418 - accuracy: 0.2575\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7414 - accuracy: 0.2575\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7412 - accuracy: 0.2575\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7409 - accuracy: 0.2575\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7407 - accuracy: 0.2575\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7404 - accuracy: 0.2575\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7402 - accuracy: 0.2575\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7401 - accuracy: 0.2575\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7398 - accuracy: 0.2575\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7395 - accuracy: 0.2575\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7393 - accuracy: 0.2575\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7391 - accuracy: 0.2575\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7389 - accuracy: 0.2575\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7387 - accuracy: 0.2575\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7385 - accuracy: 0.2575\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7383 - accuracy: 0.2575\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7381 - accuracy: 0.2575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4a1369e88>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.26975476839237056\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  32   0   0]\n",
      " [  0   0   0  69   0   0]\n",
      " [  0   0   0 107   0   0]\n",
      " [  0   0   0  99   0   0]\n",
      " [  0   0   0  44   0   0]\n",
      " [  0   0   0  16   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.27      1.00      0.42        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.27       367\n",
      "   macro avg       0.04      0.17      0.07       367\n",
      "weighted avg       0.07      0.27      0.11       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,610\n",
      "Trainable params: 1,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 4571.1665 - accuracy: 0.1172  \n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 466.8358 - accuracy: 0.1431\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 166.7682 - accuracy: 0.1580\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 95.3887 - accuracy: 0.1315\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.2631 - accuracy: 0.1383\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.9499 - accuracy: 0.1540\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.5602 - accuracy: 0.1887\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6549 - accuracy: 0.2084\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7342 - accuracy: 0.2248\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2246 - accuracy: 0.2228\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1823 - accuracy: 0.2425\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5917 - accuracy: 0.2595\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7639 - accuracy: 0.2534\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7121 - accuracy: 0.2480\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2479 - accuracy: 0.2554\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1620 - accuracy: 0.2568\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2556 - accuracy: 0.2554\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0656 - accuracy: 0.2643\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0442 - accuracy: 0.2616\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0047 - accuracy: 0.2582\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0253 - accuracy: 0.2589\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9803 - accuracy: 0.2609\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9824 - accuracy: 0.2623\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9810 - accuracy: 0.2643\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0212 - accuracy: 0.2561\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9837 - accuracy: 0.2575\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3197 - accuracy: 0.2534\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9563 - accuracy: 0.2541\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8696 - accuracy: 0.2650\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8335 - accuracy: 0.2629\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8887 - accuracy: 0.2595\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8195 - accuracy: 0.2623\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8041 - accuracy: 0.2623\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8030 - accuracy: 0.2636\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7995 - accuracy: 0.2623\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7863 - accuracy: 0.2623\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7851 - accuracy: 0.2623\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7841 - accuracy: 0.2623\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7772 - accuracy: 0.2623\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7896 - accuracy: 0.2623\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7692 - accuracy: 0.2629\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7633 - accuracy: 0.2643\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7634 - accuracy: 0.2643\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7662 - accuracy: 0.2650\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7643 - accuracy: 0.2657\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7573 - accuracy: 0.2670\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7550 - accuracy: 0.2691\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7564 - accuracy: 0.2684\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7544 - accuracy: 0.2684\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7550 - accuracy: 0.2670\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7538 - accuracy: 0.2663\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7529 - accuracy: 0.2670\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7521 - accuracy: 0.2670\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7513 - accuracy: 0.2670\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7506 - accuracy: 0.2670\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7498 - accuracy: 0.2670\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7490 - accuracy: 0.2670\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7484 - accuracy: 0.2670\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7478 - accuracy: 0.2670\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7471 - accuracy: 0.2670\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7465 - accuracy: 0.2670\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7459 - accuracy: 0.2670\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7453 - accuracy: 0.2670\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7447 - accuracy: 0.2670\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7441 - accuracy: 0.2670\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7436 - accuracy: 0.2670\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7432 - accuracy: 0.2670\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7426 - accuracy: 0.2670\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7420 - accuracy: 0.2670\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7417 - accuracy: 0.2670\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7411 - accuracy: 0.2670\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7407 - accuracy: 0.2670\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7403 - accuracy: 0.2670\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7398 - accuracy: 0.2670\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7394 - accuracy: 0.2670\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7390 - accuracy: 0.2670\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7385 - accuracy: 0.2670\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7383 - accuracy: 0.2670\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7378 - accuracy: 0.2670\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7374 - accuracy: 0.2670\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7371 - accuracy: 0.2670\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7368 - accuracy: 0.2670\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7364 - accuracy: 0.2670\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7362 - accuracy: 0.2670\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7358 - accuracy: 0.2670\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7355 - accuracy: 0.2670\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7352 - accuracy: 0.2670\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7348 - accuracy: 0.2670\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7346 - accuracy: 0.2670\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7343 - accuracy: 0.2670\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7340 - accuracy: 0.2670\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7338 - accuracy: 0.2670\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7335 - accuracy: 0.2670\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7332 - accuracy: 0.2670\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7330 - accuracy: 0.2670\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7327 - accuracy: 0.2670\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7325 - accuracy: 0.2670\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7322 - accuracy: 0.2670\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7320 - accuracy: 0.2670\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7325 - accuracy: 0.2670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4a3d7b108>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2506811989100817\n",
      "Tasa de aciertos balanceada regresión logística: 0.15\n",
      "Matriz de confusión:\n",
      "[[16  6  9  1  0  0]\n",
      " [ 2  8 41 16  2  0]\n",
      " [ 0  0 37 60  9  1]\n",
      " [ 0  1 10 50 30  8]\n",
      " [ 0  0  1  9 23 11]\n",
      " [ 0  0  0  3  8  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.27      0.93      0.42        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.25       367\n",
      "   macro avg       0.05      0.15      0.07       367\n",
      "weighted avg       0.07      0.25      0.11       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 22, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_135 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,357\n",
      "Trainable params: 20,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4599 - accuracy: 0.2193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4a41a7188>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.13896457765667575\n",
      "Tasa de aciertos balanceada regresión logística: 0.09\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [19  0  0  0 13  0  0]\n",
      " [40  0  0  0 29  0  0]\n",
      " [60  0  0  0 47  0  0]\n",
      " [48  0  0  0 51  0  0]\n",
      " [27  0  0  0 17  0  0]\n",
      " [ 6  0  0  0 10  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.31      0.52      0.38        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.14       367\n",
      "   macro avg       0.04      0.07      0.05       367\n",
      "weighted avg       0.08      0.14      0.10       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_140 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,999\n",
      "Trainable params: 8,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 13.8430 - accuracy: 0.1049\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0999 - accuracy: 0.1049\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0745 - accuracy: 0.1049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4a5570408>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.08719346049046321\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 32   0   0   0   0   0]\n",
      " [ 69   0   0   0   0   0]\n",
      " [107   0   0   0   0   0]\n",
      " [ 99   0   0   0   0   0]\n",
      " [ 44   0   0   0   0   0]\n",
      " [ 16   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.09      1.00      0.16        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.09       367\n",
      "   macro avg       0.01      0.17      0.03       367\n",
      "weighted avg       0.01      0.09      0.01       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_145 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,711\n",
      "Trainable params: 2,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 14.2089 - accuracy: 0.0020\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6491 - accuracy: 0.0395\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6128 - accuracy: 0.0409\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6129 - accuracy: 0.0409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4a59d0308>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.01634877384196185\n",
      "Tasa de aciertos balanceada regresión logística: 0.06\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [19  0  0  0 13  0  0]\n",
      " [40  0  0  0 29  0  0]\n",
      " [60  0  0  0 47  0  0]\n",
      " [48  0  0  0 51  0  0]\n",
      " [27  0  0  0 17  0  0]\n",
      " [ 6  0  0  0 10  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.03      0.38      0.06        16\n",
      "\n",
      "    accuracy                           0.02       367\n",
      "   macro avg       0.00      0.05      0.01       367\n",
      "weighted avg       0.00      0.02      0.00       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 22, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_150 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,419\n",
      "Trainable params: 11,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0351 - accuracy: 0.2343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4a6dc8448>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.29155313351498635\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0  32   0   0   0]\n",
      " [  0   0  69   0   0   0]\n",
      " [  0   0 107   0   0   0]\n",
      " [  0   0  99   0   0   0]\n",
      " [  0   0  44   0   0   0]\n",
      " [  0   0  16   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.29      1.00      0.45       107\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.29       367\n",
      "   macro avg       0.05      0.17      0.08       367\n",
      "weighted avg       0.09      0.29      0.13       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,279\n",
      "Trainable params: 5,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6683 - accuracy: 0.1049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4a821eb08>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.08719346049046321\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 32   0   0   0   0   0]\n",
      " [ 69   0   0   0   0   0]\n",
      " [107   0   0   0   0   0]\n",
      " [ 99   0   0   0   0   0]\n",
      " [ 44   0   0   0   0   0]\n",
      " [ 16   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.09      1.00      0.16        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.09       367\n",
      "   macro avg       0.01      0.17      0.03       367\n",
      "weighted avg       0.01      0.09      0.01       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_170 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,745\n",
      "Trainable params: 1,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4076 - accuracy: 0.1417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4a58bf848>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.11989100817438691\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0  32   0   0   0]\n",
      " [  0   0  69   0   0   0]\n",
      " [  0   0 107   0   0   0]\n",
      " [  0   0  99   0   0   0]\n",
      " [  0   0  44   0   0   0]\n",
      " [  0   0  16   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.12      1.00      0.21        44\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.12       367\n",
      "   macro avg       0.02      0.17      0.04       367\n",
      "weighted avg       0.01      0.12      0.03       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_180 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,065\n",
      "Trainable params: 10,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 1844.5706 - accuracy: 0.1281\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 475.7647 - accuracy: 0.1873\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 263.8096 - accuracy: 0.2003\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 187.5008 - accuracy: 0.2377\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 147.2752 - accuracy: 0.2384\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 120.1361 - accuracy: 0.2541\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 105.9240 - accuracy: 0.2432\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 97.1174 - accuracy: 0.2473\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.0831 - accuracy: 0.2486\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 84.4212 - accuracy: 0.2507\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.5666 - accuracy: 0.2459\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.4809 - accuracy: 0.2446\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.9260 - accuracy: 0.2595\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.9056 - accuracy: 0.2466\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.4267 - accuracy: 0.2650\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.8828 - accuracy: 0.2466\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 61.5179 - accuracy: 0.2595\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 58.4779 - accuracy: 0.2691\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.1065 - accuracy: 0.2813\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.2901 - accuracy: 0.2589\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.3338 - accuracy: 0.2691\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.9366 - accuracy: 0.2807\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.8005 - accuracy: 0.2698\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.1696 - accuracy: 0.2582\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.4465 - accuracy: 0.2745\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.6386 - accuracy: 0.2895\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.2368 - accuracy: 0.2711\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.6576 - accuracy: 0.2595\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 41.5322 - accuracy: 0.2820\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 40.8183 - accuracy: 0.2807\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 39.7713 - accuracy: 0.2786\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 39.2838 - accuracy: 0.2847\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.9683 - accuracy: 0.2875\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 37.8474 - accuracy: 0.2841\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 37.5845 - accuracy: 0.2881\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.6098 - accuracy: 0.2841\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 36.1239 - accuracy: 0.3038\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 35.9525 - accuracy: 0.2909\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 35.6252 - accuracy: 0.2881\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 35.1056 - accuracy: 0.2984\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.9591 - accuracy: 0.2963\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 34.3590 - accuracy: 0.2950\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 33.8122 - accuracy: 0.2922\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 33.3737 - accuracy: 0.3120\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 33.1246 - accuracy: 0.2902\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 33.4055 - accuracy: 0.2834\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 32.3972 - accuracy: 0.2922\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 32.6813 - accuracy: 0.2936\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 32.2365 - accuracy: 0.2984\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 31.7074 - accuracy: 0.2922\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.3738 - accuracy: 0.3004\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.1613 - accuracy: 0.3011\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.4983 - accuracy: 0.2984\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.3503 - accuracy: 0.3025\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.1931 - accuracy: 0.3140\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.9658 - accuracy: 0.2827\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.5231 - accuracy: 0.3059\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.4712 - accuracy: 0.3004\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.2059 - accuracy: 0.3011\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.9130 - accuracy: 0.3147\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.4214 - accuracy: 0.3025\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.5100 - accuracy: 0.3038\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.0847 - accuracy: 0.3161\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.6359 - accuracy: 0.2916\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.6770 - accuracy: 0.3052\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.4924 - accuracy: 0.2990\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.2021 - accuracy: 0.3147\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.6732 - accuracy: 0.3011\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.4905 - accuracy: 0.3079\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.2612 - accuracy: 0.3072\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.2175 - accuracy: 0.2936\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.0591 - accuracy: 0.3004\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.7273 - accuracy: 0.3154\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.5254 - accuracy: 0.3025\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.3843 - accuracy: 0.3304\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.2904 - accuracy: 0.3099\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.9779 - accuracy: 0.3038\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.5169 - accuracy: 0.3168\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.7432 - accuracy: 0.3106\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.2157 - accuracy: 0.3127\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.9415 - accuracy: 0.3031\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.2371 - accuracy: 0.3161\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.7730 - accuracy: 0.3072\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.5594 - accuracy: 0.3113\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.4679 - accuracy: 0.3099\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.5924 - accuracy: 0.3093\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.2932 - accuracy: 0.3140\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.9201 - accuracy: 0.3052\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.9858 - accuracy: 0.3134\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.7208 - accuracy: 0.3168\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.4061 - accuracy: 0.3215\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.3799 - accuracy: 0.3140\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.2202 - accuracy: 0.3086\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.2511 - accuracy: 0.3147\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.1424 - accuracy: 0.3188\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.5235 - accuracy: 0.3256\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.7222 - accuracy: 0.3147\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.6500 - accuracy: 0.3277\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.4552 - accuracy: 0.3277\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.2349 - accuracy: 0.3229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4a9c1d088>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2670299727520436\n",
      "Tasa de aciertos balanceada regresión logística: 0.30\n",
      "Matriz de confusión:\n",
      "[[25  2  4  0  1  0]\n",
      " [26 18  3 16  4  2]\n",
      " [30 18 16 28 11  4]\n",
      " [22 15 16 30 11  5]\n",
      " [ 5  4 11  7  7 10]\n",
      " [ 0  1  7  3  3  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.23      0.78      0.36        32\n",
      "         2.0       0.31      0.26      0.28        69\n",
      "         3.0       0.28      0.15      0.20       107\n",
      "         4.0       0.36      0.30      0.33        99\n",
      "         5.0       0.19      0.16      0.17        44\n",
      "         6.0       0.09      0.12      0.10        16\n",
      "\n",
      "    accuracy                           0.27       367\n",
      "   macro avg       0.24      0.30      0.24       367\n",
      "weighted avg       0.28      0.27      0.25       367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_185 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,716\n",
      "Trainable params: 4,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 2465.4883 - accuracy: 0.0879\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 664.0541 - accuracy: 0.1076\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 351.1673 - accuracy: 0.1764\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 243.8749 - accuracy: 0.1860\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 195.1500 - accuracy: 0.2016\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 172.6589 - accuracy: 0.2193\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 157.8084 - accuracy: 0.2091\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 149.7241 - accuracy: 0.2275\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 141.5620 - accuracy: 0.2255\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 132.3542 - accuracy: 0.2214\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 124.3130 - accuracy: 0.2452\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 118.8377 - accuracy: 0.2282\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 115.1738 - accuracy: 0.2343\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 108.4368 - accuracy: 0.2316\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 105.2932 - accuracy: 0.2350\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 101.0586 - accuracy: 0.2411\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 98.8393 - accuracy: 0.2357\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 96.2746 - accuracy: 0.2398\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.5589 - accuracy: 0.2514\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 89.7306 - accuracy: 0.2554\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.6264 - accuracy: 0.2507\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.2579 - accuracy: 0.2493\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.2699 - accuracy: 0.2520\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.2040 - accuracy: 0.2629\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.5786 - accuracy: 0.2602\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 77.9752 - accuracy: 0.2718\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.0279 - accuracy: 0.2650\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.4007 - accuracy: 0.2507\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.2678 - accuracy: 0.2684\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.2901 - accuracy: 0.2636\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.4412 - accuracy: 0.2759\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 67.2301 - accuracy: 0.2793\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.3860 - accuracy: 0.2779\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.0898 - accuracy: 0.2745\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.2910 - accuracy: 0.2820\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.8374 - accuracy: 0.2807\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.8383 - accuracy: 0.2895\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.6265 - accuracy: 0.2902\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.5243 - accuracy: 0.2916\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.8685 - accuracy: 0.2970\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.2884 - accuracy: 0.2977\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.2641 - accuracy: 0.3025\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.4911 - accuracy: 0.2984\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.4138 - accuracy: 0.3018\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.2241 - accuracy: 0.3127\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.4442 - accuracy: 0.3140\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.8379 - accuracy: 0.3188\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.8421 - accuracy: 0.3134\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.4854 - accuracy: 0.3277\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.1965 - accuracy: 0.3154\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.6014 - accuracy: 0.3222\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.0658 - accuracy: 0.3283\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.4944 - accuracy: 0.3270\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.0377 - accuracy: 0.3379\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.4030 - accuracy: 0.3365\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0602 - accuracy: 0.3372\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0109 - accuracy: 0.3420\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.5236 - accuracy: 0.3351\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.7948 - accuracy: 0.3495\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.2251 - accuracy: 0.3338\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 35.9782 - accuracy: 0.3338\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 35.5038 - accuracy: 0.3331\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.1213 - accuracy: 0.3467\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.8187 - accuracy: 0.3481\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.6900 - accuracy: 0.3474\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.2280 - accuracy: 0.3454\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.1844 - accuracy: 0.3433\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.0955 - accuracy: 0.3467\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.2370 - accuracy: 0.3420\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 33.4332 - accuracy: 0.3474\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 33.5313 - accuracy: 0.3426\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 33.0349 - accuracy: 0.3399\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 33.0244 - accuracy: 0.3529\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 32.5141 - accuracy: 0.3386\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 32.6801 - accuracy: 0.3481\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 32.3196 - accuracy: 0.3413\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 32.2374 - accuracy: 0.3556\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 32.0092 - accuracy: 0.3440\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.9461 - accuracy: 0.3358\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 31.5042 - accuracy: 0.3386\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 31.5977 - accuracy: 0.3454\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 31.6395 - accuracy: 0.3460\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 31.6109 - accuracy: 0.3440\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 31.1272 - accuracy: 0.3488\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 30.9732 - accuracy: 0.3447\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 31.1025 - accuracy: 0.3426\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 30.8076 - accuracy: 0.3331\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 30.9074 - accuracy: 0.3474\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 30.8034 - accuracy: 0.3426\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.9859 - accuracy: 0.3624\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.3809 - accuracy: 0.3501\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.2171 - accuracy: 0.3508\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.3531 - accuracy: 0.3467\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 30.2776 - accuracy: 0.3508\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.8220 - accuracy: 0.3535\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.0462 - accuracy: 0.3495\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.6691 - accuracy: 0.3440\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.5612 - accuracy: 0.3542\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.2356 - accuracy: 0.3440\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.2556 - accuracy: 0.3481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4a9fd93c8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2506811989100817\n",
      "Tasa de aciertos balanceada regresión logística: 0.29\n",
      "Matriz de confusión:\n",
      "[[18  0  9  0  3  2]\n",
      " [10  0 41  4  5  9]\n",
      " [ 8  0 52 10 21 16]\n",
      " [ 3  3 27 13 16 37]\n",
      " [ 2  0  5 11  0 26]\n",
      " [ 0  0  2  4  1  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.44      0.56      0.49        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.38      0.49      0.43       107\n",
      "         4.0       0.31      0.13      0.18        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.09      0.56      0.16        16\n",
      "\n",
      "    accuracy                           0.25       367\n",
      "   macro avg       0.20      0.29      0.21       367\n",
      "weighted avg       0.24      0.25      0.22       367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_190 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,610\n",
      "Trainable params: 1,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 7246.7744 - accuracy: 0.2241\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4757.7476 - accuracy: 0.2350\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3263.9663 - accuracy: 0.2405\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2208.1169 - accuracy: 0.2732\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1496.3152 - accuracy: 0.2432\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1035.8010 - accuracy: 0.2432\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 769.3830 - accuracy: 0.2398\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 594.3729 - accuracy: 0.2466\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 476.3575 - accuracy: 0.2452\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 387.0341 - accuracy: 0.2330\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 314.6711 - accuracy: 0.2234\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 256.3182 - accuracy: 0.2200\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 211.1228 - accuracy: 0.2037\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 177.1830 - accuracy: 0.1969\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 150.5905 - accuracy: 0.1901\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 128.7585 - accuracy: 0.1846\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 110.7821 - accuracy: 0.1757\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 94.8682 - accuracy: 0.1730\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.7710 - accuracy: 0.1703\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.5301 - accuracy: 0.1689\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.7401 - accuracy: 0.1628\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.4960 - accuracy: 0.1567\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.1640 - accuracy: 0.1437\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.4415 - accuracy: 0.1437\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.9707 - accuracy: 0.1431\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 21.3075 - accuracy: 0.1424\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 17.9937 - accuracy: 0.1431\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 15.3887 - accuracy: 0.1451\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.2730 - accuracy: 0.1458\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.5206 - accuracy: 0.1478\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.8054 - accuracy: 0.1492\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3861 - accuracy: 0.1499\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4625 - accuracy: 0.1505\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9468 - accuracy: 0.1526\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 6.4690 - accuracy: 0.1505\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0815 - accuracy: 0.1526\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7558 - accuracy: 0.1526\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4549 - accuracy: 0.1540\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1707 - accuracy: 0.1533\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8985 - accuracy: 0.1540\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6048 - accuracy: 0.1553\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3222 - accuracy: 0.1540\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0448 - accuracy: 0.1546\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7611 - accuracy: 0.1553\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.4916 - accuracy: 0.1533\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3465 - accuracy: 0.1553\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2941 - accuracy: 0.1553\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2583 - accuracy: 0.1560\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2275 - accuracy: 0.1567\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1932 - accuracy: 0.1560\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1658 - accuracy: 0.1567\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1320 - accuracy: 0.1574\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1043 - accuracy: 0.1567\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0824 - accuracy: 0.1574\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0557 - accuracy: 0.1574\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0339 - accuracy: 0.1574\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0090 - accuracy: 0.1580\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0041 - accuracy: 0.1594\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0002 - accuracy: 0.1587\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9884 - accuracy: 0.1587\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9873 - accuracy: 0.1587\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9755 - accuracy: 0.1574\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9695 - accuracy: 0.1587\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9672 - accuracy: 0.1587\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9588 - accuracy: 0.1587\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9563 - accuracy: 0.1587\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9501 - accuracy: 0.1580\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9455 - accuracy: 0.1574\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9396 - accuracy: 0.1580\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9342 - accuracy: 0.1567\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9278 - accuracy: 0.1574\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9234 - accuracy: 0.1574\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9207 - accuracy: 0.1574\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9141 - accuracy: 0.1574\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9069 - accuracy: 0.1574\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9049 - accuracy: 0.1574\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8975 - accuracy: 0.1567\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8959 - accuracy: 0.1580\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8930 - accuracy: 0.1580\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8881 - accuracy: 0.1580\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8832 - accuracy: 0.1580\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8810 - accuracy: 0.1580\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8745 - accuracy: 0.1580\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8718 - accuracy: 0.1580\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8663 - accuracy: 0.1580\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8657 - accuracy: 0.1580\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8630 - accuracy: 0.1580\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8560 - accuracy: 0.1580\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8536 - accuracy: 0.1580\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8501 - accuracy: 0.1580\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8449 - accuracy: 0.1580\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8433 - accuracy: 0.1580\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8388 - accuracy: 0.1580\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8329 - accuracy: 0.1580\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8326 - accuracy: 0.1580\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8269 - accuracy: 0.1580\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 2.8266 - accuracy: 0.1580\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 2.8207 - accuracy: 0.1580\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8164 - accuracy: 0.1580\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8136 - accuracy: 0.1587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4ab363b08>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.04632152588555858\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[25  2  4  0  1  0]\n",
      " [26 18  3 16  4  2]\n",
      " [30 18 16 28 11  4]\n",
      " [22 15 16 30 11  5]\n",
      " [ 5  4 11  7  7 10]\n",
      " [ 0  1  7  3  3  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.06      0.12        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.04      0.94      0.08        16\n",
      "\n",
      "    accuracy                           0.05       367\n",
      "   macro avg       0.15      0.14      0.03       367\n",
      "weighted avg       0.09      0.05      0.01       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_195 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,357\n",
      "Trainable params: 20,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 7.0628 - accuracy: 0.1567\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 7.0628 - accuracy: 0.1567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4ab746b08>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.043596730245231606\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0  32]\n",
      " [  0   0   0   0   0  69]\n",
      " [  0   0   0   0   0 107]\n",
      " [  0   0   0   0   0  99]\n",
      " [  0   0   0   0   0  44]\n",
      " [  0   0   0   0   0  16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.04      1.00      0.08        16\n",
      "\n",
      "    accuracy                           0.04       367\n",
      "   macro avg       0.01      0.17      0.01       367\n",
      "weighted avg       0.00      0.04      0.00       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_200 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,999\n",
      "Trainable params: 8,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 873us/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3160 - accuracy: 0.1383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4aca1be48>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1362397820163488\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   1  31   0]\n",
      " [  0   0   0   2  67   0]\n",
      " [  0   0   0   4 103   0]\n",
      " [  0   0   0   8  91   0]\n",
      " [  0   0   0   2  42   0]\n",
      " [  0   0   0   1  15   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.44      0.08      0.14        99\n",
      "         5.0       0.12      0.95      0.21        44\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.14       367\n",
      "   macro avg       0.09      0.17      0.06       367\n",
      "weighted avg       0.13      0.14      0.06       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_205 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,711\n",
      "Trainable params: 2,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 7.4524 - accuracy: 0.1853\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9642 - accuracy: 0.1819\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0404 - accuracy: 0.1826\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.0970 - accuracy: 0.1826\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.0970 - accuracy: 0.1826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4acd6c648>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.11989100817438691\n",
      "Tasa de aciertos balanceada regresión logística: 0.07\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0  32]\n",
      " [  0   0   0   0   0  69]\n",
      " [  0   0   0   0   0 107]\n",
      " [  0   0   0   0   0  99]\n",
      " [  0   0   0   0   0  44]\n",
      " [  0   0   0   0   0  16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.34      0.44      0.38        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.12       367\n",
      "   macro avg       0.05      0.06      0.05       367\n",
      "weighted avg       0.09      0.12      0.10       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_210 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,419\n",
      "Trainable params: 11,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 4.7799 - accuracy: 0.2568\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7790 - accuracy: 0.2568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4ae1c5508>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.26975476839237056\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  32   0   0]\n",
      " [  0   0   0  69   0   0]\n",
      " [  0   0   0 107   0   0]\n",
      " [  0   0   0  99   0   0]\n",
      " [  0   0   0  44   0   0]\n",
      " [  0   0   0  16   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.27      1.00      0.42        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.27       367\n",
      "   macro avg       0.04      0.17      0.07       367\n",
      "weighted avg       0.07      0.27      0.11       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_220 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,279\n",
      "Trainable params: 5,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 9.2137 - accuracy: 0.2173\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5707 - accuracy: 0.2200\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6866 - accuracy: 0.2282\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7409 - accuracy: 0.2282\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7406 - accuracy: 0.2282\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7406 - accuracy: 0.2282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4af6d4048>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1880108991825613\n",
      "Tasa de aciertos balanceada regresión logística: 0.21\n",
      "Matriz de confusión:\n",
      "[[27  0  0  5  0  0]\n",
      " [49  0  0 20  0  0]\n",
      " [71  0  0 36  0  0]\n",
      " [57  0  0 42  0  0]\n",
      " [32  0  0 12  0  0]\n",
      " [ 9  0  0  7  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.11      0.84      0.19        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.34      0.42      0.38        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.19       367\n",
      "   macro avg       0.08      0.21      0.10       367\n",
      "weighted avg       0.10      0.19      0.12       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_230 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,745\n",
      "Trainable params: 1,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4651 - accuracy: 0.1049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4afb64d88>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.08719346049046321\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  32   0   0]\n",
      " [  0   0   0  69   0   0]\n",
      " [  0   0   0 107   0   0]\n",
      " [  0   0   0  99   0   0]\n",
      " [  0   0   0  44   0   0]\n",
      " [  0   0   0  16   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.09      1.00      0.16        32\n",
      "         2.0       0.00      0.00      0.00        69\n",
      "         3.0       0.00      0.00      0.00       107\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00        44\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.09       367\n",
      "   macro avg       0.01      0.17      0.03       367\n",
      "weighted avg       0.01      0.09      0.01       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 36, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_240 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,465\n",
      "Trainable params: 11,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 1100.8707 - accuracy: 0.1777\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.8388 - accuracy: 0.1701\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5987 - accuracy: 0.1295\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9059 - accuracy: 0.1350\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2679 - accuracy: 0.2080\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6990 - accuracy: 0.2569\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5244 - accuracy: 0.2576\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9239 - accuracy: 0.2583\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4979 - accuracy: 0.2590\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7888 - accuracy: 0.2583\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7770 - accuracy: 0.2583\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7701 - accuracy: 0.2583\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7644 - accuracy: 0.2583\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7598 - accuracy: 0.2583\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7561 - accuracy: 0.2583\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7528 - accuracy: 0.2583\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7503 - accuracy: 0.2583\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7480 - accuracy: 0.2583\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7461 - accuracy: 0.2583\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7446 - accuracy: 0.2583\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7432 - accuracy: 0.2583\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7419 - accuracy: 0.2583\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7409 - accuracy: 0.2583\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7400 - accuracy: 0.2583\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7392 - accuracy: 0.2583\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7385 - accuracy: 0.2583\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7378 - accuracy: 0.2583\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7373 - accuracy: 0.2583\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7368 - accuracy: 0.2583\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7364 - accuracy: 0.2583\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7359 - accuracy: 0.2583\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7355 - accuracy: 0.2583\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7352 - accuracy: 0.2583\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7349 - accuracy: 0.2583\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7348 - accuracy: 0.2583\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7345 - accuracy: 0.2583\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7341 - accuracy: 0.2583\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7341 - accuracy: 0.2583\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7339 - accuracy: 0.2583\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7336 - accuracy: 0.2583\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7335 - accuracy: 0.2583\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7333 - accuracy: 0.2583\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7331 - accuracy: 0.2583\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7331 - accuracy: 0.2583\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7332 - accuracy: 0.2583\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7329 - accuracy: 0.2583\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7328 - accuracy: 0.2583\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7326 - accuracy: 0.2583\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7325 - accuracy: 0.2583\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7325 - accuracy: 0.2583\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7324 - accuracy: 0.2583\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7323 - accuracy: 0.2583\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7322 - accuracy: 0.2583\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7324 - accuracy: 0.2583\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7321 - accuracy: 0.2583\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7321 - accuracy: 0.2583\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7320 - accuracy: 0.2583\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7319 - accuracy: 0.2583\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7318 - accuracy: 0.2583\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7318 - accuracy: 0.2583\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7317 - accuracy: 0.2583\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7319 - accuracy: 0.2583\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7318 - accuracy: 0.2583\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7318 - accuracy: 0.2583\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7316 - accuracy: 0.2583\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7317 - accuracy: 0.2583\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7317 - accuracy: 0.2583\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7315 - accuracy: 0.2583\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7315 - accuracy: 0.2583\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7316 - accuracy: 0.2583\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7315 - accuracy: 0.2583\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7315 - accuracy: 0.2583\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7314 - accuracy: 0.2583\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7314 - accuracy: 0.2583\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7314 - accuracy: 0.2583\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7314 - accuracy: 0.2583\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7313 - accuracy: 0.2583\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7313 - accuracy: 0.2583\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7313 - accuracy: 0.2583\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7312 - accuracy: 0.2583\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7313 - accuracy: 0.2583\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7313 - accuracy: 0.2583\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7312 - accuracy: 0.2583\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7312 - accuracy: 0.2583\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7313 - accuracy: 0.2583\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7311 - accuracy: 0.2583\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7312 - accuracy: 0.2583\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7311 - accuracy: 0.2583\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7312 - accuracy: 0.2583\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7311 - accuracy: 0.2583\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7311 - accuracy: 0.2583\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7310 - accuracy: 0.2583\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7312 - accuracy: 0.2583\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7311 - accuracy: 0.2583\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7310 - accuracy: 0.2583\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7311 - accuracy: 0.2583\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7311 - accuracy: 0.2583\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7312 - accuracy: 0.2583\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7311 - accuracy: 0.2583\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7310 - accuracy: 0.2583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4a9c30bc8>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2727272727272727\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  32   0   0]\n",
      " [  0   0   0  68   0   0]\n",
      " [  0   0   0 105   0   0]\n",
      " [  0   0   0  99   0   0]\n",
      " [  0   0   0  43   0   0]\n",
      " [  0   0   0  16   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        68\n",
      "         3.0       0.00      0.00      0.00       105\n",
      "         4.0       0.27      1.00      0.43        99\n",
      "         5.0       0.00      0.00      0.00        43\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.27       363\n",
      "   macro avg       0.05      0.17      0.07       363\n",
      "weighted avg       0.07      0.27      0.12       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_245 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,612\n",
      "Trainable params: 5,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 1672.8743 - accuracy: 0.1832\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6677 - accuracy: 0.1501\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9287 - accuracy: 0.1550\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9106 - accuracy: 0.2300\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8988 - accuracy: 0.2376\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8880 - accuracy: 0.2590\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8780 - accuracy: 0.2590\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8685 - accuracy: 0.2590\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8600 - accuracy: 0.2590\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8521 - accuracy: 0.2590\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8447 - accuracy: 0.2590\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8380 - accuracy: 0.2590\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8318 - accuracy: 0.2590\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8260 - accuracy: 0.2590\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8207 - accuracy: 0.2590\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8159 - accuracy: 0.2590\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8114 - accuracy: 0.2590\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8073 - accuracy: 0.2590\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8035 - accuracy: 0.2590\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8000 - accuracy: 0.2590\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7967 - accuracy: 0.2590\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7938 - accuracy: 0.2590\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7911 - accuracy: 0.2590\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7885 - accuracy: 0.2590\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7861 - accuracy: 0.2590\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7839 - accuracy: 0.2590\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7818 - accuracy: 0.2590\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7799 - accuracy: 0.2590\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7781 - accuracy: 0.2590\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7764 - accuracy: 0.2590\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7747 - accuracy: 0.2590\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7733 - accuracy: 0.2590\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7718 - accuracy: 0.2590\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7704 - accuracy: 0.2590\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7692 - accuracy: 0.2590\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7679 - accuracy: 0.2590\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7668 - accuracy: 0.2590\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7656 - accuracy: 0.2590\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7646 - accuracy: 0.2590\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7636 - accuracy: 0.2590\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7626 - accuracy: 0.2590\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7617 - accuracy: 0.2590\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7608 - accuracy: 0.2590\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7599 - accuracy: 0.2590\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7590 - accuracy: 0.2590\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7582 - accuracy: 0.2590\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7575 - accuracy: 0.2590\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7567 - accuracy: 0.2590\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7560 - accuracy: 0.2590\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7553 - accuracy: 0.2590\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7546 - accuracy: 0.2590\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7541 - accuracy: 0.2590\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7533 - accuracy: 0.2590\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7527 - accuracy: 0.2590\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7522 - accuracy: 0.2590\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7516 - accuracy: 0.2590\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7511 - accuracy: 0.2590\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7505 - accuracy: 0.2590\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7500 - accuracy: 0.2590\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7495 - accuracy: 0.2590\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7490 - accuracy: 0.2590\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7485 - accuracy: 0.2590\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7481 - accuracy: 0.2590\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7476 - accuracy: 0.2590\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7472 - accuracy: 0.2590\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7468 - accuracy: 0.2590\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7464 - accuracy: 0.2590\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7460 - accuracy: 0.2590\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7456 - accuracy: 0.2590\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7453 - accuracy: 0.2590\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7449 - accuracy: 0.2590\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7445 - accuracy: 0.2590\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7442 - accuracy: 0.2590\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7439 - accuracy: 0.2590\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7436 - accuracy: 0.2590\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7432 - accuracy: 0.2590\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7429 - accuracy: 0.2590\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7426 - accuracy: 0.2590\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7424 - accuracy: 0.2590\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7420 - accuracy: 0.2590\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7417 - accuracy: 0.2590\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7415 - accuracy: 0.2590\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7413 - accuracy: 0.2590\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7410 - accuracy: 0.2590\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7407 - accuracy: 0.2590\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7405 - accuracy: 0.2590\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7402 - accuracy: 0.2590\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7400 - accuracy: 0.2590\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7397 - accuracy: 0.2590\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7395 - accuracy: 0.2590\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7394 - accuracy: 0.2590\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7391 - accuracy: 0.2590\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7390 - accuracy: 0.2590\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7387 - accuracy: 0.2590\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7386 - accuracy: 0.2590\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7383 - accuracy: 0.2590\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7381 - accuracy: 0.2590\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7380 - accuracy: 0.2590\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7378 - accuracy: 0.2590\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7376 - accuracy: 0.2590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b0ed8bc8>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2727272727272727\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  32   0   0]\n",
      " [  0   0   0  68   0   0]\n",
      " [  0   0   0 105   0   0]\n",
      " [  0   0   0  99   0   0]\n",
      " [  0   0   0  43   0   0]\n",
      " [  0   0   0  16   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        68\n",
      "         3.0       0.00      0.00      0.00       105\n",
      "         4.0       0.27      1.00      0.43        99\n",
      "         5.0       0.00      0.00      0.00        43\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.27       363\n",
      "   macro avg       0.05      0.17      0.07       363\n",
      "weighted avg       0.07      0.27      0.12       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_250 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,058\n",
      "Trainable params: 2,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 2492.9028 - accuracy: 0.2445\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 239.9196 - accuracy: 0.1894\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.8598 - accuracy: 0.1990\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.5917 - accuracy: 0.1467\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9388 - accuracy: 0.1467\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3940 - accuracy: 0.2555\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3073 - accuracy: 0.2569\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3230 - accuracy: 0.2562\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2218 - accuracy: 0.2576\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2786 - accuracy: 0.2590\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1769 - accuracy: 0.2596\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3528 - accuracy: 0.2596\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0637 - accuracy: 0.2596\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0298 - accuracy: 0.2569\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9802 - accuracy: 0.2583\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9363 - accuracy: 0.2583\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9925 - accuracy: 0.2583\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9300 - accuracy: 0.2583\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9397 - accuracy: 0.2569\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9002 - accuracy: 0.2583\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8925 - accuracy: 0.2583\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8838 - accuracy: 0.2583\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8729 - accuracy: 0.2590\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8686 - accuracy: 0.2576\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8512 - accuracy: 0.2583\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8575 - accuracy: 0.2583\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8626 - accuracy: 0.2590\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8293 - accuracy: 0.2576\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8924 - accuracy: 0.2576\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8610 - accuracy: 0.2590\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8095 - accuracy: 0.2590\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7993 - accuracy: 0.2583\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7980 - accuracy: 0.2583\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7957 - accuracy: 0.2590\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7949 - accuracy: 0.2583\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7920 - accuracy: 0.2583\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7908 - accuracy: 0.2583\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7923 - accuracy: 0.2590\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7872 - accuracy: 0.2583\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7831 - accuracy: 0.2583\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7857 - accuracy: 0.2583\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8919 - accuracy: 0.2583\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7998 - accuracy: 0.2583\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7857 - accuracy: 0.2590\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7834 - accuracy: 0.2583\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7792 - accuracy: 0.2590\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7766 - accuracy: 0.2590\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7736 - accuracy: 0.2583\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7710 - accuracy: 0.2583\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7682 - accuracy: 0.2583\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7684 - accuracy: 0.2583\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7663 - accuracy: 0.2590\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7655 - accuracy: 0.2583\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7694 - accuracy: 0.2603\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7618 - accuracy: 0.2583\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7635 - accuracy: 0.2583\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7606 - accuracy: 0.2583\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7599 - accuracy: 0.2583\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7599 - accuracy: 0.2583\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7597 - accuracy: 0.2583\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7581 - accuracy: 0.2583\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7566 - accuracy: 0.2583\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7560 - accuracy: 0.2590\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7590 - accuracy: 0.2583\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8367 - accuracy: 0.2590\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2323 - accuracy: 0.2645\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9232 - accuracy: 0.2576\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7659 - accuracy: 0.2583\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7666 - accuracy: 0.2583\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7639 - accuracy: 0.2583\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7611 - accuracy: 0.2583\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7582 - accuracy: 0.2583\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7555 - accuracy: 0.2583\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7571 - accuracy: 0.2583\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7541 - accuracy: 0.2583\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7551 - accuracy: 0.2583\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7558 - accuracy: 0.2583\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7500 - accuracy: 0.2583\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7438 - accuracy: 0.2583\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7421 - accuracy: 0.2583\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7419 - accuracy: 0.2583\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7416 - accuracy: 0.2583\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7414 - accuracy: 0.2583\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7412 - accuracy: 0.2583\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7409 - accuracy: 0.2583\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7407 - accuracy: 0.2583\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7405 - accuracy: 0.2583\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7403 - accuracy: 0.2583\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7401 - accuracy: 0.2583\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7398 - accuracy: 0.2583\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7397 - accuracy: 0.2583\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7395 - accuracy: 0.2583\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7393 - accuracy: 0.2583\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7391 - accuracy: 0.2583\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7389 - accuracy: 0.2583\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7388 - accuracy: 0.2583\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7386 - accuracy: 0.2583\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7384 - accuracy: 0.2583\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7383 - accuracy: 0.2583\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7381 - accuracy: 0.2583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b22dcd88>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2727272727272727\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  32   0   0]\n",
      " [  0   0   0  68   0   0]\n",
      " [  0   0   0 105   0   0]\n",
      " [  0   0   0  99   0   0]\n",
      " [  0   0   0  43   0   0]\n",
      " [  0   0   0  16   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        68\n",
      "         3.0       0.00      0.00      0.00       105\n",
      "         4.0       0.27      1.00      0.43        99\n",
      "         5.0       0.00      0.00      0.00        43\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.27       363\n",
      "   macro avg       0.05      0.17      0.07       363\n",
      "weighted avg       0.07      0.27      0.12       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 36, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_255 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_256 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,757\n",
      "Trainable params: 21,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 13.5899 - accuracy: 0.0675\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.3524 - accuracy: 0.0737\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2058 - accuracy: 0.1109\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2039 - accuracy: 0.1109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b3718708>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.15151515151515152\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0 14  0  0 18  0]\n",
      " [ 0 29  0  0 39  0]\n",
      " [ 0 47  0  0 58  0]\n",
      " [ 0 54  0  0 45  0]\n",
      " [ 0 17  0  0 26  0]\n",
      " [ 0 10  0  0  6  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.17      0.43      0.24        68\n",
      "         3.0       0.00      0.00      0.00       105\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.14      0.60      0.22        43\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.15       363\n",
      "   macro avg       0.05      0.17      0.08       363\n",
      "weighted avg       0.05      0.15      0.07       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_260 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_261 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_262 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_264 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,895\n",
      "Trainable params: 9,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 13.5778 - accuracy: 0.1033\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0797 - accuracy: 0.1067\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0883 - accuracy: 0.1067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b3b70048>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.18732782369146006\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0  32   0   0   0   0]\n",
      " [  0  68   0   0   0   0]\n",
      " [  0 105   0   0   0   0]\n",
      " [  0  99   0   0   0   0]\n",
      " [  0  43   0   0   0   0]\n",
      " [  0  16   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.19      1.00      0.32        68\n",
      "         3.0       0.00      0.00      0.00       105\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00        43\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.19       363\n",
      "   macro avg       0.03      0.17      0.05       363\n",
      "weighted avg       0.04      0.19      0.06       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_265 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,159\n",
      "Trainable params: 3,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 9.2929 - accuracy: 0.2183\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.1581 - accuracy: 0.2328\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6140 - accuracy: 0.0510\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4345 - accuracy: 0.1253\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3707 - accuracy: 0.1371\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5537 - accuracy: 0.1377\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5619 - accuracy: 0.1343\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8578 - accuracy: 0.2321\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5878 - accuracy: 0.2342\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.9794 - accuracy: 0.2342\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9794 - accuracy: 0.2342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b4f3b1c8>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2892561983471074\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0 14  0  0 18  0]\n",
      " [ 0 29  0  0 39  0]\n",
      " [ 0 47  0  0 58  0]\n",
      " [ 0 54  0  0 45  0]\n",
      " [ 0 17  0  0 26  0]\n",
      " [ 0 10  0  0  6  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        68\n",
      "         3.0       0.29      1.00      0.45       105\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00        43\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.29       363\n",
      "   macro avg       0.05      0.17      0.07       363\n",
      "weighted avg       0.08      0.29      0.13       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 36, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_270 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_271 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_272 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_274 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_277 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_278 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_279 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,819\n",
      "Trainable params: 12,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 5.9292 - accuracy: 0.1377\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5821 - accuracy: 0.1405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b5325e88>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1184573002754821\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  32   0]\n",
      " [  0   0   0   0  68   0]\n",
      " [  0   0   0   0 105   0]\n",
      " [  0   0   0   0  99   0]\n",
      " [  0   0   0   0  43   0]\n",
      " [  0   0   0   0  16   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        68\n",
      "         3.0       0.00      0.00      0.00       105\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.12      1.00      0.21        43\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.12       363\n",
      "   macro avg       0.02      0.17      0.04       363\n",
      "weighted avg       0.01      0.12      0.03       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_280 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_282 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,175\n",
      "Trainable params: 6,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.1191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b696f888>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.14600550964187328\n",
      "Tasa de aciertos balanceada regresión logística: 0.14\n",
      "Matriz de confusión:\n",
      "[[ 2 27  0  0  3  0]\n",
      " [ 2 48  0  0 18  0]\n",
      " [ 6 70  0  0 29  0]\n",
      " [ 5 65  4  0 25  0]\n",
      " [ 5 34  1  0  3  0]\n",
      " [ 0  9  0  0  7  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.10      0.06      0.08        32\n",
      "         2.0       0.19      0.71      0.30        68\n",
      "         3.0       0.00      0.00      0.00       105\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.04      0.07      0.05        43\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.15       363\n",
      "   macro avg       0.05      0.14      0.07       363\n",
      "weighted avg       0.05      0.15      0.07       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_290 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_292 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_294 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,193\n",
      "Trainable params: 2,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 8.0371 - accuracy: 0.0923\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0366 - accuracy: 0.0778\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1210 - accuracy: 0.0964\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6639 - accuracy: 0.0909\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4216 - accuracy: 0.0055\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b7eb40c8>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  32   0]\n",
      " [  0   0   0   0  68   0]\n",
      " [  0   0   0   0 105   0]\n",
      " [  0   0   0   0  99   0]\n",
      " [  0   0   0   0  43   0]\n",
      " [  0   0   0   0  16   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      32.0\n",
      "         2.0       0.00      0.00      0.00      68.0\n",
      "         3.0       0.00      0.00      0.00     105.0\n",
      "         4.0       0.00      0.00      0.00      99.0\n",
      "         5.0       0.00      0.00      0.00      43.0\n",
      "         6.0       0.00      0.00      0.00      16.0\n",
      "\n",
      "    accuracy                           0.00     363.0\n",
      "   macro avg       0.00      0.00      0.00     363.0\n",
      "weighted avg       0.00      0.00      0.00     363.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_300 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_301 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_302 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_303 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_304 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,465\n",
      "Trainable params: 11,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 1118.7134 - accuracy: 0.2293\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 300.6566 - accuracy: 0.2472\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 212.4821 - accuracy: 0.2734\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 179.0931 - accuracy: 0.2686\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 160.5123 - accuracy: 0.2624\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 149.9838 - accuracy: 0.2720\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 144.0560 - accuracy: 0.2831\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 134.6718 - accuracy: 0.2837\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 124.6855 - accuracy: 0.3010\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 122.1213 - accuracy: 0.2803\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 115.8263 - accuracy: 0.2948\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 113.8910 - accuracy: 0.3030\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 110.4857 - accuracy: 0.2906\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 109.2032 - accuracy: 0.2865\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 104.9627 - accuracy: 0.3037\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 103.6240 - accuracy: 0.2955\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 100.0839 - accuracy: 0.3065\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 97.0659 - accuracy: 0.3030\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 93.1416 - accuracy: 0.3168\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 91.3039 - accuracy: 0.3113\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 91.6664 - accuracy: 0.2948\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 89.8162 - accuracy: 0.3037\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 87.6172 - accuracy: 0.3175\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.2978 - accuracy: 0.3065\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.4061 - accuracy: 0.3099\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.1019 - accuracy: 0.3223\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.9824 - accuracy: 0.3065\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.0129 - accuracy: 0.3003\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.4154 - accuracy: 0.3168\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.9575 - accuracy: 0.3189\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 76.3304 - accuracy: 0.3216\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.7120 - accuracy: 0.3306\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.6410 - accuracy: 0.3368\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.3277 - accuracy: 0.3161\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.8679 - accuracy: 0.3209\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.7521 - accuracy: 0.3258\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.5235 - accuracy: 0.3196\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.8147 - accuracy: 0.3306\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.9387 - accuracy: 0.3306\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.3914 - accuracy: 0.3168\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.3537 - accuracy: 0.3216\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.2135 - accuracy: 0.3354\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.2029 - accuracy: 0.3347\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.7284 - accuracy: 0.3285\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.3972 - accuracy: 0.3416\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.0346 - accuracy: 0.3299\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.3157 - accuracy: 0.3464\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.7823 - accuracy: 0.3333\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.5509 - accuracy: 0.3313\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.3252 - accuracy: 0.3388\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.1321 - accuracy: 0.3382\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.7212 - accuracy: 0.3375\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.7841 - accuracy: 0.3285\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.2063 - accuracy: 0.3347\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.6166 - accuracy: 0.3354\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.3812 - accuracy: 0.3450\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.6153 - accuracy: 0.3368\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.8161 - accuracy: 0.3416\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.8521 - accuracy: 0.3416\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.4398 - accuracy: 0.3430\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.9855 - accuracy: 0.3485\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.8871 - accuracy: 0.3416\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.4094 - accuracy: 0.3478\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.4735 - accuracy: 0.3375\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.2518 - accuracy: 0.3464\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.0256 - accuracy: 0.3464\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.8643 - accuracy: 0.3499\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.8281 - accuracy: 0.3526\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.5697 - accuracy: 0.3506\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.5344 - accuracy: 0.3499\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.2476 - accuracy: 0.3519\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.5041 - accuracy: 0.3540\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.3484 - accuracy: 0.3437\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.1096 - accuracy: 0.3478\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.4589 - accuracy: 0.3547\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.5934 - accuracy: 0.3574\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.4916 - accuracy: 0.3581\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.5071 - accuracy: 0.3616\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.3234 - accuracy: 0.3526\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.5611 - accuracy: 0.3643\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.7412 - accuracy: 0.3588\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.3027 - accuracy: 0.3430\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.0234 - accuracy: 0.3567\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.0909 - accuracy: 0.3574\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.6605 - accuracy: 0.3609\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.6323 - accuracy: 0.3561\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.0682 - accuracy: 0.3643\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.0999 - accuracy: 0.3629\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.4292 - accuracy: 0.3629\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.6178 - accuracy: 0.3602\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.0430 - accuracy: 0.3705\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.5700 - accuracy: 0.3726\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.8257 - accuracy: 0.3657\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.4571 - accuracy: 0.3747\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.0700 - accuracy: 0.3567\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.9544 - accuracy: 0.3650\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.8636 - accuracy: 0.3712\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.1927 - accuracy: 0.3795\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.8403 - accuracy: 0.3726\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.6483 - accuracy: 0.3726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b93c6d88>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2975206611570248\n",
      "Tasa de aciertos balanceada regresión logística: 0.28\n",
      "Matriz de confusión:\n",
      "[[10  4  3 14  0  1]\n",
      " [ 3  7 25 28  3  2]\n",
      " [ 0 11 61 20  5  8]\n",
      " [ 2  7 44 18 14 14]\n",
      " [ 1  0 22  6  7  7]\n",
      " [ 0  0  7  0  4  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.62      0.31      0.42        32\n",
      "         2.0       0.24      0.10      0.14        68\n",
      "         3.0       0.38      0.58      0.46       105\n",
      "         4.0       0.21      0.18      0.19        99\n",
      "         5.0       0.21      0.16      0.18        43\n",
      "         6.0       0.14      0.31      0.19        16\n",
      "\n",
      "    accuracy                           0.30       363\n",
      "   macro avg       0.30      0.28      0.26       363\n",
      "weighted avg       0.30      0.30      0.28       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_305 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_306 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,612\n",
      "Trainable params: 5,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 764.7410 - accuracy: 0.2390\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 292.8655 - accuracy: 0.2376\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 201.5016 - accuracy: 0.2287\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 156.8944 - accuracy: 0.2328\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 132.2053 - accuracy: 0.2259\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 117.0001 - accuracy: 0.2231\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 105.1007 - accuracy: 0.2231\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 96.0995 - accuracy: 0.2259\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 89.9537 - accuracy: 0.2231\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.7371 - accuracy: 0.2287\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.8714 - accuracy: 0.2245\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 76.5999 - accuracy: 0.2149\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.5227 - accuracy: 0.2190\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.2249 - accuracy: 0.2266\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.7159 - accuracy: 0.2300\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.1783 - accuracy: 0.2369\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.9336 - accuracy: 0.2300\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.9653 - accuracy: 0.2300\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.8966 - accuracy: 0.2397\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.4259 - accuracy: 0.2335\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.6364 - accuracy: 0.2293\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.1255 - accuracy: 0.2472\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.1970 - accuracy: 0.2307\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.1246 - accuracy: 0.2369\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.2912 - accuracy: 0.2390\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.7083 - accuracy: 0.2452\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.6366 - accuracy: 0.2376\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.2500 - accuracy: 0.2397\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.0887 - accuracy: 0.2293\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.1831 - accuracy: 0.2383\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.0954 - accuracy: 0.2369\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 43.8388 - accuracy: 0.2231\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 43.0771 - accuracy: 0.2397\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 41.7534 - accuracy: 0.2348\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.4318 - accuracy: 0.2445\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.1545 - accuracy: 0.2390\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 39.6680 - accuracy: 0.2390\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0611 - accuracy: 0.2486\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.8280 - accuracy: 0.2555\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.1866 - accuracy: 0.2424\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 37.7568 - accuracy: 0.2514\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.4128 - accuracy: 0.2459\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.0399 - accuracy: 0.2583\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.5782 - accuracy: 0.2528\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 35.7144 - accuracy: 0.2534\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 35.7731 - accuracy: 0.2548\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.1991 - accuracy: 0.2369\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.5039 - accuracy: 0.2521\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.7869 - accuracy: 0.2472\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.5790 - accuracy: 0.2590\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.5253 - accuracy: 0.2617\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.8407 - accuracy: 0.2569\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.6307 - accuracy: 0.2617\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.0574 - accuracy: 0.2665\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.2197 - accuracy: 0.2713\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.8216 - accuracy: 0.2514\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.7269 - accuracy: 0.2521\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.4433 - accuracy: 0.2528\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.9914 - accuracy: 0.2679\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.8432 - accuracy: 0.2507\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.6217 - accuracy: 0.2679\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.4856 - accuracy: 0.2603\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.3155 - accuracy: 0.2748\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.9383 - accuracy: 0.2521\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.8376 - accuracy: 0.2679\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.4893 - accuracy: 0.2734\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.3529 - accuracy: 0.2748\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.6855 - accuracy: 0.2700\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.6300 - accuracy: 0.2720\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.8399 - accuracy: 0.2624\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.5063 - accuracy: 0.2775\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.6448 - accuracy: 0.2727\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.2783 - accuracy: 0.2769\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.9742 - accuracy: 0.2645\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.9478 - accuracy: 0.2658\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.3227 - accuracy: 0.2693\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.1441 - accuracy: 0.2796\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.4766 - accuracy: 0.2762\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.1461 - accuracy: 0.2755\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.2752 - accuracy: 0.2624\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.2692 - accuracy: 0.2810\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.9060 - accuracy: 0.2686\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.8091 - accuracy: 0.2796\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.7561 - accuracy: 0.2762\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.4008 - accuracy: 0.2927\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.4617 - accuracy: 0.2844\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.1893 - accuracy: 0.2810\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.2126 - accuracy: 0.2796\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.9898 - accuracy: 0.2789\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.7101 - accuracy: 0.2789\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.8512 - accuracy: 0.2762\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.5396 - accuracy: 0.2865\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.7978 - accuracy: 0.2789\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.2759 - accuracy: 0.2796\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.1952 - accuracy: 0.2858\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.1463 - accuracy: 0.2810\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.9551 - accuracy: 0.2865\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.7148 - accuracy: 0.2941\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.1982 - accuracy: 0.2769\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.8541 - accuracy: 0.2906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b97a1608>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.23415977961432508\n",
      "Tasa de aciertos balanceada regresión logística: 0.22\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 5 11  1  2  9  4  0]\n",
      " [10  5  4 16 21 12  0]\n",
      " [ 4  4  6 31 36 23  1]\n",
      " [ 7  4  6 31 30 19  2]\n",
      " [ 3  0  6 10 12  6  6]\n",
      " [ 1  2  1  3  4  2  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.42      0.34      0.38        32\n",
      "         2.0       0.17      0.06      0.09        68\n",
      "         3.0       0.33      0.30      0.31       105\n",
      "         4.0       0.27      0.30      0.28        99\n",
      "         5.0       0.09      0.14      0.11        43\n",
      "         6.0       0.25      0.19      0.21        16\n",
      "\n",
      "    accuracy                           0.23       363\n",
      "   macro avg       0.22      0.19      0.20       363\n",
      "weighted avg       0.26      0.23      0.24       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_310 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_312 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,058\n",
      "Trainable params: 2,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 1018.5654 - accuracy: 0.1226\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 610.8435 - accuracy: 0.1164\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 413.8275 - accuracy: 0.1157\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 301.8652 - accuracy: 0.1081\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 242.0970 - accuracy: 0.1040\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 201.8526 - accuracy: 0.1067\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 174.0374 - accuracy: 0.1129\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 153.1082 - accuracy: 0.1178\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 137.2402 - accuracy: 0.1267\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 125.2529 - accuracy: 0.1253\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 115.5519 - accuracy: 0.1253\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 107.7147 - accuracy: 0.1247\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 100.7483 - accuracy: 0.1267\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 94.3177 - accuracy: 0.1260\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 88.6573 - accuracy: 0.1309\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.4977 - accuracy: 0.1295\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.4772 - accuracy: 0.1295\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.9487 - accuracy: 0.1274\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.6505 - accuracy: 0.1391\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.0650 - accuracy: 0.1329\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.4370 - accuracy: 0.1371\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.1027 - accuracy: 0.1384\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.7633 - accuracy: 0.1405\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.4892 - accuracy: 0.1322\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.4161 - accuracy: 0.1364\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.3886 - accuracy: 0.1371\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.6829 - accuracy: 0.1350\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.1028 - accuracy: 0.1391\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.7148 - accuracy: 0.1419\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.5043 - accuracy: 0.1433\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.4789 - accuracy: 0.1501\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.7590 - accuracy: 0.1584\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.1064 - accuracy: 0.1756\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.7014 - accuracy: 0.1804\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.5052 - accuracy: 0.1811\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.5738 - accuracy: 0.1818\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.5642 - accuracy: 0.1846\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.8627 - accuracy: 0.1784\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.0392 - accuracy: 0.1894\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.2920 - accuracy: 0.1880\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.5650 - accuracy: 0.1915\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.8802 - accuracy: 0.1915\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.2703 - accuracy: 0.1880\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.6065 - accuracy: 0.1894\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.0180 - accuracy: 0.1901\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.3600 - accuracy: 0.1949\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.7636 - accuracy: 0.1921\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 19.1839 - accuracy: 0.1873\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 18.6391 - accuracy: 0.1997\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 18.0390 - accuracy: 0.1949\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 17.5556 - accuracy: 0.1915\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 17.0177 - accuracy: 0.1956\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 16.4848 - accuracy: 0.1928\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 16.0591 - accuracy: 0.1921\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 15.7437 - accuracy: 0.1997\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 15.2927 - accuracy: 0.2087\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 15.0722 - accuracy: 0.2032\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 14.8225 - accuracy: 0.2073\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.5721 - accuracy: 0.2087\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4348 - accuracy: 0.2156\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.2834 - accuracy: 0.2156\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1351 - accuracy: 0.2101\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0105 - accuracy: 0.2101\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.8741 - accuracy: 0.2163\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7545 - accuracy: 0.2149\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6321 - accuracy: 0.2149\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5252 - accuracy: 0.2135\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.4145 - accuracy: 0.2087\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.3047 - accuracy: 0.2156\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2147 - accuracy: 0.2107\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0646 - accuracy: 0.2142\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9579 - accuracy: 0.2163\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9137 - accuracy: 0.2149\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.8392 - accuracy: 0.2101\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7619 - accuracy: 0.2163\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6594 - accuracy: 0.2080\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.5872 - accuracy: 0.2183\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.5014 - accuracy: 0.2121\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4002 - accuracy: 0.2135\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.3392 - accuracy: 0.2149\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2502 - accuracy: 0.2128\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2150 - accuracy: 0.2142\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.1212 - accuracy: 0.2156\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0097 - accuracy: 0.2101\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9913 - accuracy: 0.2149\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9204 - accuracy: 0.2114\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.8374 - accuracy: 0.2094\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.7984 - accuracy: 0.2135\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6920 - accuracy: 0.2121\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6533 - accuracy: 0.2135\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.5837 - accuracy: 0.2163\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.5459 - accuracy: 0.2094\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.4522 - accuracy: 0.2073\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3632 - accuracy: 0.2114\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.2998 - accuracy: 0.2218\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.2432 - accuracy: 0.2121\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1935 - accuracy: 0.2176\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1189 - accuracy: 0.2163\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0484 - accuracy: 0.2094\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0036 - accuracy: 0.2225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4baabd588>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1928374655647383\n",
      "Tasa de aciertos balanceada regresión logística: 0.19\n",
      "Matriz de confusión:\n",
      "[[10  4  3 14  0  1]\n",
      " [ 3  7 25 28  3  2]\n",
      " [ 0 11 61 20  5  8]\n",
      " [ 2  7 44 18 14 14]\n",
      " [ 1  0 22  6  7  7]\n",
      " [ 0  0  7  0  4  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.17      0.16      0.16        32\n",
      "         2.0       0.00      0.00      0.00        68\n",
      "         3.0       0.24      0.09      0.13       105\n",
      "         4.0       0.28      0.45      0.34        99\n",
      "         5.0       0.06      0.14      0.09        43\n",
      "         6.0       0.14      0.31      0.19        16\n",
      "\n",
      "    accuracy                           0.19       363\n",
      "   macro avg       0.15      0.19      0.15       363\n",
      "weighted avg       0.17      0.19      0.16       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_315 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_316 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_318 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,757\n",
      "Trainable params: 21,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 13.0162 - accuracy: 0.1391\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7441 - accuracy: 0.1061\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7441 - accuracy: 0.1061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b52b7548>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.03856749311294766\n",
      "Tasa de aciertos balanceada regresión logística: 0.05\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [24  0  0  0  0  8  0]\n",
      " [45  0  0  0  0 23  0]\n",
      " [65  0  0  0  0 40  0]\n",
      " [54  0  0  0  0 45  0]\n",
      " [29  0  0  0  0 14  0]\n",
      " [ 8  0  0  0  0  8  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        68\n",
      "         3.0       0.00      0.00      0.00       105\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.10      0.33      0.15        43\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.04       363\n",
      "   macro avg       0.01      0.05      0.02       363\n",
      "weighted avg       0.01      0.04      0.02       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_320 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,895\n",
      "Trainable params: 9,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 8.1096 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8794 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b7e910c8>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [ 32   0   0   0   0   0   0]\n",
      " [ 68   0   0   0   0   0   0]\n",
      " [105   0   0   0   0   0   0]\n",
      " [ 99   0   0   0   0   0   0]\n",
      " [ 43   0   0   0   0   0   0]\n",
      " [ 16   0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      32.0\n",
      "         2.0       0.00      0.00      0.00      68.0\n",
      "         3.0       0.00      0.00      0.00     105.0\n",
      "         4.0       0.00      0.00      0.00      99.0\n",
      "         5.0       0.00      0.00      0.00      43.0\n",
      "         6.0       0.00      0.00      0.00      16.0\n",
      "\n",
      "    accuracy                           0.00     363.0\n",
      "   macro avg       0.00      0.00      0.00     363.0\n",
      "weighted avg       0.00      0.00      0.00     363.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_325 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_328 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,159\n",
      "Trainable params: 3,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3508 - accuracy: 0.2342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4a854f288>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2892561983471074\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [24  0  0  0  0  8  0]\n",
      " [45  0  0  0  0 23  0]\n",
      " [65  0  0  0  0 40  0]\n",
      " [54  0  0  0  0 45  0]\n",
      " [29  0  0  0  0 14  0]\n",
      " [ 8  0  0  0  0  8  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        68\n",
      "         3.0       0.29      1.00      0.45       105\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00        43\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.29       363\n",
      "   macro avg       0.05      0.17      0.07       363\n",
      "weighted avg       0.08      0.29      0.13       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_330 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,819\n",
      "Trainable params: 12,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 9.1626 - accuracy: 0.1040\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7965 - accuracy: 0.1054\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2406 - accuracy: 0.1061\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2936 - accuracy: 0.1061\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3873 - accuracy: 0.1061\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8283 - accuracy: 0.1061\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5693 - accuracy: 0.1061\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5651 - accuracy: 0.1061\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6429 - accuracy: 0.1061\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6668 - accuracy: 0.1061\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6238 - accuracy: 0.1061\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5991 - accuracy: 0.1061\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5972 - accuracy: 0.1061\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6397 - accuracy: 0.1061\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6275 - accuracy: 0.1061\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6675 - accuracy: 0.1061\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5296 - accuracy: 0.1061\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5475 - accuracy: 0.1061\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5476 - accuracy: 0.1061\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5392 - accuracy: 0.1061\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4639 - accuracy: 0.1061\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4747 - accuracy: 0.1061\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4840 - accuracy: 0.1061\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5545 - accuracy: 0.1061\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9477 - accuracy: 0.1061\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9373 - accuracy: 0.1061\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9372 - accuracy: 0.1061\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9360 - accuracy: 0.1061\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9560 - accuracy: 0.1061\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.0480 - accuracy: 0.1061\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.0662 - accuracy: 0.1061\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.0586 - accuracy: 0.1061\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9593 - accuracy: 0.1074\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9582 - accuracy: 0.1067\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9581 - accuracy: 0.1067\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9580 - accuracy: 0.1067\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9580 - accuracy: 0.1067\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9579 - accuracy: 0.1067\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9579 - accuracy: 0.1074\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9675 - accuracy: 0.1067\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9664 - accuracy: 0.1067\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9663 - accuracy: 0.1067\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9662 - accuracy: 0.1067\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9655 - accuracy: 0.1067\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9654 - accuracy: 0.1074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4bc6fb708>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0881542699724518\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 32   0   0   0   0   0]\n",
      " [ 68   0   0   0   0   0]\n",
      " [105   0   0   0   0   0]\n",
      " [ 99   0   0   0   0   0]\n",
      " [ 43   0   0   0   0   0]\n",
      " [ 16   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.09      1.00      0.16        32\n",
      "         2.0       0.00      0.00      0.00        68\n",
      "         3.0       0.00      0.00      0.00       105\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00        43\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.09       363\n",
      "   macro avg       0.01      0.17      0.03       363\n",
      "weighted avg       0.01      0.09      0.01       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_340 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_342 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_343 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_344 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_345 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_346 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_348 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_349 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,175\n",
      "Trainable params: 6,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 12.6565 - accuracy: 0.1054\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4440 - accuracy: 0.1646\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9579 - accuracy: 0.2583\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9573 - accuracy: 0.2583\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9576 - accuracy: 0.2583\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9467 - accuracy: 0.2583\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9557 - accuracy: 0.2583\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9569 - accuracy: 0.2583\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9555 - accuracy: 0.2583\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9554 - accuracy: 0.2583\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9554 - accuracy: 0.2583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4bdbd1988>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2727272727272727\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  32   0   0]\n",
      " [  0   0   0  68   0   0]\n",
      " [  0   0   0 105   0   0]\n",
      " [  0   0   0  99   0   0]\n",
      " [  0   0   0  43   0   0]\n",
      " [  0   0   0  16   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        68\n",
      "         3.0       0.00      0.00      0.00       105\n",
      "         4.0       0.27      1.00      0.43        99\n",
      "         5.0       0.00      0.00      0.00        43\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.27       363\n",
      "   macro avg       0.05      0.17      0.07       363\n",
      "weighted avg       0.07      0.27      0.12       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_350 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_351 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_352 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_353 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_354 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_355 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_356 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_357 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_358 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,193\n",
      "Trainable params: 2,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 6.0071 - accuracy: 0.0723\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6347 - accuracy: 0.0730\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.9677 - accuracy: 0.0517\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1475 - accuracy: 0.0372\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1190 - accuracy: 0.0372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4bf128508>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07988980716253444\n",
      "Tasa de aciertos balanceada regresión logística: 0.11\n",
      "Matriz de confusión:\n",
      "[[ 32   0   0   0   0   0]\n",
      " [ 68   0   0   0   0   0]\n",
      " [105   0   0   0   0   0]\n",
      " [ 99   0   0   0   0   0]\n",
      " [ 43   0   0   0   0   0]\n",
      " [ 16   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00        68\n",
      "         3.0       0.00      0.00      0.00       105\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.13      0.67      0.22        43\n",
      "         6.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.08       363\n",
      "   macro avg       0.02      0.10      0.03       363\n",
      "weighted avg       0.02      0.08      0.03       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERVALO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.267196</td>\n",
       "      <td>0.251323</td>\n",
       "      <td>0.267196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.288360</td>\n",
       "      <td>0.232804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.288360</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.343915</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.058201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.182540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.267196     0.251323     0.267196\n",
       "Experimento 2- RELU+ADAM         0.129630     0.288360     0.232804\n",
       "Experimento 3- RELU+ADAM         0.129630     0.288360     0.000000\n",
       "Experimento 1- RELU+ADAGRAD      0.343915     0.261905     0.058201\n",
       "Experimento 2- RELU+ADAGRAD      0.129630     0.047619     0.000000\n",
       "Experimento 3- RELU+ADAGRAD      0.000000     0.206349     0.182540"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['100 Neuronas'] = None\n",
    "df1['64 Neuronas'] = None\n",
    "df1['32 Neuronas'] = None\n",
    "df1.loc['Experimento 1- RELU+ADAM'] = [0.2671957671957672,0.25132275132275134,0.2671957671957672]\n",
    "df1.loc['Experimento 2- RELU+ADAM'] = [0.12962962962962962,0.28835978835978837, 0.2328042328042328]\n",
    "df1.loc['Experimento 3- RELU+ADAM'] = [0.12962962962962962,0.28835978835978837,0.0]\n",
    "df1.loc['Experimento 1- RELU+ADAGRAD'] =[0.3439153439153439,0.2619047619047619,0.0582010582010582]\n",
    "df1.loc['Experimento 2- RELU+ADAGRAD'] =[0.12962962962962962,0.047619047619047616,0.0]\n",
    "df1.loc['Experimento 3- RELU+ADAGRAD'] = [0.0,0.20634920634920634,0.18253968253968253]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.378747</td>\n",
       "      <td>0.269755</td>\n",
       "      <td>0.250681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.138965</td>\n",
       "      <td>0.087193</td>\n",
       "      <td>0.016349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.291553</td>\n",
       "      <td>0.087193</td>\n",
       "      <td>0.119891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.267030</td>\n",
       "      <td>0.250681</td>\n",
       "      <td>0.046322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.043597</td>\n",
       "      <td>0.136240</td>\n",
       "      <td>0.119891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.269755</td>\n",
       "      <td>0.188011</td>\n",
       "      <td>0.087193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.378747     0.269755     0.250681\n",
       "Experimento 2- RELU+ADAM         0.138965     0.087193     0.016349\n",
       "Experimento 3- RELU+ADAM         0.291553     0.087193     0.119891\n",
       "Experimento 1- RELU+ADAGRAD      0.267030     0.250681     0.046322\n",
       "Experimento 2- RELU+ADAGRAD      0.043597     0.136240     0.119891\n",
       "Experimento 3- RELU+ADAGRAD      0.269755     0.188011     0.087193"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['100 Neuronas'] = None\n",
    "df2['64 Neuronas'] = None\n",
    "df2['32 Neuronas'] = None\n",
    "df2.loc['Experimento 1- RELU+ADAM'] =[0.3787465940054496,0.26975476839237056,0.2506811989100817]\n",
    "df2.loc['Experimento 2- RELU+ADAM'] =[0.13896457765667575,0.08719346049046321,0.01634877384196185]\n",
    "df2.loc['Experimento 3- RELU+ADAM'] = [0.29155313351498635,0.08719346049046321,0.11989100817438691]\n",
    "df2.loc['Experimento 1- RELU+ADAGRAD'] = [0.2670299727520436,0.2506811989100817,0.04632152588555858]\n",
    "df2.loc['Experimento 2- RELU+ADAGRAD'] = [0.043596730245231606,0.1362397820163488,0.11989100817438691]\n",
    "df2.loc['Experimento 3- RELU+ADAGRAD'] = [0.26975476839237056,0.1880108991825613,0.08719346049046321]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.187328</td>\n",
       "      <td>0.289256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.118457</td>\n",
       "      <td>0.146006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.297521</td>\n",
       "      <td>0.234160</td>\n",
       "      <td>0.192837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.038567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.088154</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.079890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.272727     0.272727     0.272727\n",
       "Experimento 2- RELU+ADAM         0.151515     0.187328     0.289256\n",
       "Experimento 3- RELU+ADAM         0.118457     0.146006     0.000000\n",
       "Experimento 1- RELU+ADAGRAD      0.297521     0.234160     0.192837\n",
       "Experimento 2- RELU+ADAGRAD      0.038567     0.000000     0.289256\n",
       "Experimento 3- RELU+ADAGRAD      0.088154     0.272727     0.079890"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame()\n",
    "df3['100 Neuronas'] = None\n",
    "df3['64 Neuronas'] = None\n",
    "df3['32 Neuronas'] = None\n",
    "df3.loc['Experimento 1- RELU+ADAM'] = [0.2727272727272727,0.2727272727272727,0.2727272727272727]\n",
    "df3.loc['Experimento 2- RELU+ADAM'] =[0.15151515151515152,0.18732782369146006,0.2892561983471074]\n",
    "df3.loc['Experimento 3- RELU+ADAM'] = [0.1184573002754821,0.14600550964187328,0.0]\n",
    "df3.loc['Experimento 1- RELU+ADAGRAD'] = [0.2975206611570248,0.23415977961432508,0.1928374655647383]\n",
    "df3.loc['Experimento 2- RELU+ADAGRAD'] = [0.03856749311294766,0.0,0.2892561983471074]\n",
    "df3.loc['Experimento 3- RELU+ADAGRAD'] = [0.0881542699724518,0.2727272727272727,0.07988980716253444]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1da4d3bd0c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,20))\n",
    "fig.add_subplot(2,2,1)\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 1')\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM' ,color ='red')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 2')\n",
    "fig.add_subplot(2,2,3)\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 3')\n",
    "plt.legend(bbox_to_anchor = (2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run 5dias-porintervalos2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix,balanced_accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subida(list):\n",
    "    resultado = []\n",
    "    for i in range(1,len(list)):\n",
    "        if  (list)[i] > (list)[i-1]:\n",
    "            resultado.append(1)\n",
    "        else:\n",
    "            resultado.append(0)\n",
    "    return resultado\n",
    "\n",
    "def acierto(list1,list2):\n",
    "    sum = 0\n",
    "    for i in range(0,len(list1)):\n",
    "        if(list1[i]==list2[i]):\n",
    "            sum = sum +1\n",
    "    a = sum/len(list1)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 12, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_360 (Dense)           (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_361 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_362 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_363 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_364 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,065\n",
      "Trainable params: 9,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 719.5534 - accuracy: 0.2407\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 97.2684 - accuracy: 0.2831\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 92.6948 - accuracy: 0.3022\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 82.7616 - accuracy: 0.3089\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 79.7404 - accuracy: 0.3267\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 66.1814 - accuracy: 0.3267\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 49.1647 - accuracy: 0.3690\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 39.3296 - accuracy: 0.3664\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 40.5632 - accuracy: 0.3684\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 39.3097 - accuracy: 0.3690\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.9990 - accuracy: 0.4048\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 49.0398 - accuracy: 0.3770\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.9812 - accuracy: 0.4451\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.9940 - accuracy: 0.3730\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.6371 - accuracy: 0.3889\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.9649 - accuracy: 0.4001\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.4494 - accuracy: 0.4167\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.1489 - accuracy: 0.4220\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.8073 - accuracy: 0.4583\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.7780 - accuracy: 0.4292\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 41.7505 - accuracy: 0.3810\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 28.1640 - accuracy: 0.4339\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.7453 - accuracy: 0.4358\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.6052 - accuracy: 0.4438\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.8971 - accuracy: 0.4544\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.5930 - accuracy: 0.4557\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.8591 - accuracy: 0.4187\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 27.7327 - accuracy: 0.3929\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.7969 - accuracy: 0.4471\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.3975 - accuracy: 0.4332\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.1033 - accuracy: 0.4259\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.3182 - accuracy: 0.4048\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.4905 - accuracy: 0.4239\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.3689 - accuracy: 0.3823\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.5276 - accuracy: 0.4259\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1479 - accuracy: 0.4160\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.5760 - accuracy: 0.4246\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1061 - accuracy: 0.4405\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 8.9447 - accuracy: 0.4649\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.4888 - accuracy: 0.4669\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.5053 - accuracy: 0.4411\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.0637 - accuracy: 0.4716\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.8809 - accuracy: 0.4656\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.4488 - accuracy: 0.4649\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.5195 - accuracy: 0.4742\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.9170 - accuracy: 0.4874\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.8576 - accuracy: 0.4623\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.4211 - accuracy: 0.4696\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.9246 - accuracy: 0.4398\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7028 - accuracy: 0.4901\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.4128 - accuracy: 0.4835\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.1974 - accuracy: 0.4544\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.4050 - accuracy: 0.4821\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.0967 - accuracy: 0.5212\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.3011 - accuracy: 0.5053\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.3601 - accuracy: 0.4874\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.3813 - accuracy: 0.4901\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.6857 - accuracy: 0.4974\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.8077 - accuracy: 0.4795\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.4073 - accuracy: 0.5066\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.5154 - accuracy: 0.4894\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.6023 - accuracy: 0.4861\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.0331 - accuracy: 0.4960\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.0527 - accuracy: 0.4524\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.9291 - accuracy: 0.4861\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2870 - accuracy: 0.5132\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9502 - accuracy: 0.5311\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1879 - accuracy: 0.5073\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.8927 - accuracy: 0.4484\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0605 - accuracy: 0.5370\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2565 - accuracy: 0.4974\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9337 - accuracy: 0.5106\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1665 - accuracy: 0.4934\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0252 - accuracy: 0.5013\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9456 - accuracy: 0.4888\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9572 - accuracy: 0.5013\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8264 - accuracy: 0.5172\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0923 - accuracy: 0.4683\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9874 - accuracy: 0.4749\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8160 - accuracy: 0.5020\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6348 - accuracy: 0.5245\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6994 - accuracy: 0.5066\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2203 - accuracy: 0.4683\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5296 - accuracy: 0.5463\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4923 - accuracy: 0.5351\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8831 - accuracy: 0.4689\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4707 - accuracy: 0.5390\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4755 - accuracy: 0.5298\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4808 - accuracy: 0.5212\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4096 - accuracy: 0.5324\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3824 - accuracy: 0.5430\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8165 - accuracy: 0.4802\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0052 - accuracy: 0.4854\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4649 - accuracy: 0.5351\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7163 - accuracy: 0.4848\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9796 - accuracy: 0.4544\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5729 - accuracy: 0.5225\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6463 - accuracy: 0.5179\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5319 - accuracy: 0.5146\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4887 - accuracy: 0.5245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c1296548>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5132275132275133\n",
      "Tasa de aciertos balanceada regresión logística: 0.48\n",
      "Matriz de confusión:\n",
      "[[18 11  1  2  0]\n",
      " [ 4 88 22 12  1]\n",
      " [ 0 31 14 35  1]\n",
      " [ 0  6 11 61 27]\n",
      " [ 0  4  3 13 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.82      0.56      0.67        32\n",
      "         2.0       0.63      0.69      0.66       127\n",
      "         3.0       0.27      0.17      0.21        81\n",
      "         4.0       0.50      0.58      0.54       105\n",
      "         5.0       0.31      0.39      0.35        33\n",
      "\n",
      "    accuracy                           0.51       378\n",
      "   macro avg       0.51      0.48      0.48       378\n",
      "weighted avg       0.50      0.51      0.50       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_365 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_366 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_368 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_369 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,076\n",
      "Trainable params: 4,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 1252.2535 - accuracy: 0.1984\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 205.0339 - accuracy: 0.2632\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 112.0722 - accuracy: 0.2434\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 64.9513 - accuracy: 0.2817\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 40.9763 - accuracy: 0.2917\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 27.0894 - accuracy: 0.3294\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 28.9618 - accuracy: 0.3188\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.8164 - accuracy: 0.3492\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.9675 - accuracy: 0.3525\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.0337 - accuracy: 0.3340\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.5638 - accuracy: 0.3254\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.7401 - accuracy: 0.3525\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9488 - accuracy: 0.3737\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.6270 - accuracy: 0.3261\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.0685 - accuracy: 0.3419\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.7666 - accuracy: 0.3638\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.6393 - accuracy: 0.3737\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.1589 - accuracy: 0.3757\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.7575 - accuracy: 0.3175\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.0175 - accuracy: 0.3763\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.1371 - accuracy: 0.3624\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.5090 - accuracy: 0.3492\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 11.6152 - accuracy: 0.3519\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 9.4444 - accuracy: 0.3591\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 9.2704 - accuracy: 0.3532\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 9.2942 - accuracy: 0.3604\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 9.2331 - accuracy: 0.3380\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 8.4251 - accuracy: 0.3671\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 6.5950 - accuracy: 0.3876\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7249 - accuracy: 0.3743\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 4.9748 - accuracy: 0.3902\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7378 - accuracy: 0.3803\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 5.6826 - accuracy: 0.3869\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.2842 - accuracy: 0.3776\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 5.6543 - accuracy: 0.3783\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 5.5580 - accuracy: 0.3836\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.1173 - accuracy: 0.4015\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 4.7406 - accuracy: 0.3737\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.9301 - accuracy: 0.3743\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 4.3445 - accuracy: 0.3763\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.5781 - accuracy: 0.4074\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 3.0570 - accuracy: 0.4160\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 3.4163 - accuracy: 0.4286\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 7.0888 - accuracy: 0.3380\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 4.9636 - accuracy: 0.3757\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 3.8748 - accuracy: 0.4061\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 3.6476 - accuracy: 0.4193\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 3.0551 - accuracy: 0.4015\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 3.8205 - accuracy: 0.3902\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.3361 - accuracy: 0.4563\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 2.7735 - accuracy: 0.4101\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 2.1229 - accuracy: 0.4636\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 2.4491 - accuracy: 0.4299\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 2.1538 - accuracy: 0.4557\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2162 - accuracy: 0.4749\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.1541 - accuracy: 0.4517\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.4168 - accuracy: 0.4312\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9792 - accuracy: 0.4802\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.3996 - accuracy: 0.4325\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 3.0485 - accuracy: 0.3869\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.0525 - accuracy: 0.4438\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9171 - accuracy: 0.4623\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.2861 - accuracy: 0.3684\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 3.6027 - accuracy: 0.3843\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6445 - accuracy: 0.4881\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9964 - accuracy: 0.4583\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6965 - accuracy: 0.4702\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6333 - accuracy: 0.4868\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0318 - accuracy: 0.4451\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6662 - accuracy: 0.4835\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7944 - accuracy: 0.4431\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.0780 - accuracy: 0.4392\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9147 - accuracy: 0.4418\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.8157 - accuracy: 0.4464\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.9323 - accuracy: 0.4504\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7369 - accuracy: 0.4735\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5840 - accuracy: 0.4491\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7602 - accuracy: 0.4544\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.9821 - accuracy: 0.4385\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4606 - accuracy: 0.4795\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.3970 - accuracy: 0.4967\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4108 - accuracy: 0.4610\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7025 - accuracy: 0.4583\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.3560 - accuracy: 0.4914\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.4814 - accuracy: 0.4755\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.5796 - accuracy: 0.4663\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6694 - accuracy: 0.4365\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7597 - accuracy: 0.4663\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5585 - accuracy: 0.4702\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6236 - accuracy: 0.4570\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.4626 - accuracy: 0.5026\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.5567 - accuracy: 0.4491\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6087 - accuracy: 0.4193\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6601 - accuracy: 0.4345\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 997us/step - loss: 1.6456 - accuracy: 0.4193\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.7602 - accuracy: 0.4048\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.1952 - accuracy: 0.3327\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.7314 - accuracy: 0.3571\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.6595 - accuracy: 0.3558\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 1.5329 - accuracy: 0.3737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f48500b588>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.30423280423280424\n",
      "Tasa de aciertos balanceada regresión logística: 0.23\n",
      "Matriz de confusión:\n",
      "[[ 3 25  1  3  0]\n",
      " [26 18  4 79  0]\n",
      " [20  3  1 57  0]\n",
      " [12  0  0 93  0]\n",
      " [ 6  0  0 27  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.04      0.09      0.06        32\n",
      "         2.0       0.39      0.14      0.21       127\n",
      "         3.0       0.17      0.01      0.02        81\n",
      "         4.0       0.36      0.89      0.51       105\n",
      "         5.0       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.30       378\n",
      "   macro avg       0.19      0.23      0.16       378\n",
      "weighted avg       0.27      0.30      0.22       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_370 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_371 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_372 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_373 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_374 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,290\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 391.2009 - accuracy: 0.1964\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.7350 - accuracy: 0.1964\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5815 - accuracy: 0.2011\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7890 - accuracy: 0.2070\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7353 - accuracy: 0.2024\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.7142 - accuracy: 0.2110\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7010 - accuracy: 0.2149\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6827 - accuracy: 0.2189\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6696 - accuracy: 0.2467\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6582 - accuracy: 0.2440\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6497 - accuracy: 0.2520\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6486 - accuracy: 0.2672\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6378 - accuracy: 0.2599\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6311 - accuracy: 0.2751\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6248 - accuracy: 0.2758\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6278 - accuracy: 0.2679\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6223 - accuracy: 0.2725\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6151 - accuracy: 0.2758\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6066 - accuracy: 0.2798\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6053 - accuracy: 0.2798\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6093 - accuracy: 0.2725\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5969 - accuracy: 0.2837\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5970 - accuracy: 0.2831\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5953 - accuracy: 0.2851\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5923 - accuracy: 0.2824\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5914 - accuracy: 0.2837\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5947 - accuracy: 0.2824\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5885 - accuracy: 0.2837\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5908 - accuracy: 0.2831\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5847 - accuracy: 0.2837\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5848 - accuracy: 0.2851\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5855 - accuracy: 0.2844\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5892 - accuracy: 0.2791\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5880 - accuracy: 0.2811\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5809 - accuracy: 0.2824\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5819 - accuracy: 0.2831\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5793 - accuracy: 0.2851\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5792 - accuracy: 0.2857\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5797 - accuracy: 0.2831\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5776 - accuracy: 0.2857\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5794 - accuracy: 0.2851\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5770 - accuracy: 0.2851\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5755 - accuracy: 0.2851\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5771 - accuracy: 0.2844\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5761 - accuracy: 0.2844\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5744 - accuracy: 0.2851\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5744 - accuracy: 0.2844\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5759 - accuracy: 0.2851\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5731 - accuracy: 0.2864\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5719 - accuracy: 0.2851\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5733 - accuracy: 0.2870\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5768 - accuracy: 0.2831\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5740 - accuracy: 0.2851\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5722 - accuracy: 0.2857\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5707 - accuracy: 0.2864\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5713 - accuracy: 0.2844\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5684 - accuracy: 0.2837\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5703 - accuracy: 0.2851\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5726 - accuracy: 0.2870\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5814 - accuracy: 0.2870\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.6010 - accuracy: 0.2817\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5731 - accuracy: 0.2817\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5763 - accuracy: 0.2817\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5722 - accuracy: 0.2817\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5810 - accuracy: 0.2817\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5695 - accuracy: 0.2817\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5705 - accuracy: 0.2817\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5756 - accuracy: 0.2817\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5746 - accuracy: 0.2811\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5714 - accuracy: 0.2817\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5801 - accuracy: 0.2811\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5668 - accuracy: 0.2817\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5688 - accuracy: 0.2817\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5651 - accuracy: 0.2864\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5668 - accuracy: 0.2824\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5674 - accuracy: 0.2817\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5694 - accuracy: 0.2817\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5659 - accuracy: 0.2817\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5663 - accuracy: 0.2817\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5648 - accuracy: 0.2817\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5652 - accuracy: 0.2817\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5651 - accuracy: 0.2817\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5642 - accuracy: 0.2824\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5711 - accuracy: 0.2831\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5636 - accuracy: 0.2817\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5636 - accuracy: 0.2817\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5625 - accuracy: 0.2817\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5631 - accuracy: 0.2817\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5616 - accuracy: 0.2817\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5632 - accuracy: 0.2817\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5635 - accuracy: 0.2817\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5643 - accuracy: 0.2817\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5625 - accuracy: 0.2864\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5637 - accuracy: 0.2857\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5603 - accuracy: 0.2870\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5598 - accuracy: 0.2870\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5602 - accuracy: 0.2877\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5587 - accuracy: 0.2884\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5583 - accuracy: 0.2903\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.5599 - accuracy: 0.2890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c0c5dd88>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.23544973544973544\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[18 11  1  2  0]\n",
      " [ 4 88 22 12  1]\n",
      " [ 0 31 14 35  1]\n",
      " [ 0  6 11 61 27]\n",
      " [ 0  4  3 13 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.00      0.00      0.00        81\n",
      "         4.0       0.29      0.77      0.42       105\n",
      "         5.0       0.09      0.24      0.13        33\n",
      "\n",
      "    accuracy                           0.24       378\n",
      "   macro avg       0.07      0.20      0.11       378\n",
      "weighted avg       0.09      0.24      0.13       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 12, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_375 (Dense)           (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_376 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_378 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,357\n",
      "Trainable params: 19,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7591 - accuracy: 0.1052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c1084708>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.08465608465608465\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 32   0   0   0   0]\n",
      " [127   0   0   0   0]\n",
      " [ 81   0   0   0   0]\n",
      " [105   0   0   0   0]\n",
      " [ 33   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.08      1.00      0.16        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.00      0.00      0.00        81\n",
      "         4.0       0.00      0.00      0.00       105\n",
      "         5.0       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.08       378\n",
      "   macro avg       0.02      0.20      0.03       378\n",
      "weighted avg       0.01      0.08      0.01       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_380 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_381 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_382 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_383 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_384 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,359\n",
      "Trainable params: 8,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 3s 2ms/step - loss: 7.7968 - accuracy: 0.2546\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.9544 - accuracy: 0.2831\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7923 - accuracy: 0.2599\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1878\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.7571 - accuracy: 0.1845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c367c0c8>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.26455026455026454\n",
      "Tasa de aciertos balanceada regresión logística: 0.22\n",
      "Matriz de confusión:\n",
      "[[ 0 26  0  0  6]\n",
      " [ 0 87  0  0 40]\n",
      " [ 0 47  0  0 34]\n",
      " [ 0 68  0  0 37]\n",
      " [ 0 20  0  0 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.35      0.69      0.46       127\n",
      "         3.0       0.00      0.00      0.00        81\n",
      "         4.0       0.00      0.00      0.00       105\n",
      "         5.0       0.10      0.39      0.16        33\n",
      "\n",
      "    accuracy                           0.26       378\n",
      "   macro avg       0.09      0.22      0.12       378\n",
      "weighted avg       0.13      0.26      0.17       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_385 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_386 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_387 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_388 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_389 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,391\n",
      "Trainable params: 2,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 4.9245 - accuracy: 0.2302\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.7553 - accuracy: 0.2315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4bdb41748>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2751322751322751\n",
      "Tasa de aciertos balanceada regresión logística: 0.19\n",
      "Matriz de confusión:\n",
      "[[ 32   0   0   0   0]\n",
      " [127   0   0   0   0]\n",
      " [ 81   0   0   0   0]\n",
      " [105   0   0   0   0]\n",
      " [ 33   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.32      0.78      0.46       127\n",
      "         3.0       0.00      0.00      0.00        81\n",
      "         4.0       0.00      0.00      0.00       105\n",
      "         5.0       0.07      0.15      0.10        33\n",
      "\n",
      "    accuracy                           0.28       378\n",
      "   macro avg       0.08      0.19      0.11       378\n",
      "weighted avg       0.11      0.28      0.16       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 12, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_390 (Dense)           (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_391 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_392 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_393 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_394 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_395 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_396 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_397 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_398 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_399 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,419\n",
      "Trainable params: 10,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 8.0821 - accuracy: 0.2269\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.9867 - accuracy: 0.2817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4bc749a08>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2777777777777778\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  32   0]\n",
      " [  0   0   0 127   0]\n",
      " [  0   0   0  81   0]\n",
      " [  0   0   0 105   0]\n",
      " [  0   0   0  33   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.00      0.00      0.00        81\n",
      "         4.0       0.28      1.00      0.43       105\n",
      "         5.0       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.28       378\n",
      "   macro avg       0.06      0.20      0.09       378\n",
      "weighted avg       0.08      0.28      0.12       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_400 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_401 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_402 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_403 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_404 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_405 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_406 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_407 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_408 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_409 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,639\n",
      "Trainable params: 4,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 4.6400 - accuracy: 0.0714\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9562 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c4d79348>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0]\n",
      " [ 32   0   0   0   0   0]\n",
      " [127   0   0   0   0   0]\n",
      " [ 81   0   0   0   0   0]\n",
      " [105   0   0   0   0   0]\n",
      " [ 33   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      32.0\n",
      "         2.0       0.00      0.00      0.00     127.0\n",
      "         3.0       0.00      0.00      0.00      81.0\n",
      "         4.0       0.00      0.00      0.00     105.0\n",
      "         5.0       0.00      0.00      0.00      33.0\n",
      "\n",
      "    accuracy                           0.00     378.0\n",
      "   macro avg       0.00      0.00      0.00     378.0\n",
      "weighted avg       0.00      0.00      0.00     378.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_410 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_411 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_412 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_413 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_414 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_415 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_416 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_417 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_418 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_419 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,425\n",
      "Trainable params: 1,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 2ms/step - loss: 12.4349 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.0421 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2972 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4019 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.4116 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c6377888>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  32   0]\n",
      " [  0   0   0 127   0]\n",
      " [  0   0   0  81   0]\n",
      " [  0   0   0 105   0]\n",
      " [  0   0   0  33   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      32.0\n",
      "         2.0       0.00      0.00      0.00     127.0\n",
      "         3.0       0.00      0.00      0.00      81.0\n",
      "         4.0       0.00      0.00      0.00     105.0\n",
      "         5.0       0.00      0.00      0.00      33.0\n",
      "\n",
      "    accuracy                           0.00     378.0\n",
      "   macro avg       0.00      0.00      0.00     378.0\n",
      "weighted avg       0.00      0.00      0.00     378.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_420 (Dense)           (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_421 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_422 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_423 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_424 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,065\n",
      "Trainable params: 9,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 477.8337 - accuracy: 0.1931\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 170.0984 - accuracy: 0.1958\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 126.0356 - accuracy: 0.2083\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 106.9327 - accuracy: 0.1984\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 87.0914 - accuracy: 0.1978\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 76.7508 - accuracy: 0.1892\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 68.4938 - accuracy: 0.1878\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 58.1065 - accuracy: 0.1885\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 54.7865 - accuracy: 0.1819\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 48.5894 - accuracy: 0.1786\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 47.1730 - accuracy: 0.1799\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.5971 - accuracy: 0.1779\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 41.8179 - accuracy: 0.1991\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 40.1930 - accuracy: 0.1911\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 38.8068 - accuracy: 0.1997\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.6618 - accuracy: 0.2050\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.8648 - accuracy: 0.2090\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.2914 - accuracy: 0.2262\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.0508 - accuracy: 0.2169\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.7688 - accuracy: 0.2216\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.4048 - accuracy: 0.2183\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.4987 - accuracy: 0.2282\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.1992 - accuracy: 0.2202\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 27.9256 - accuracy: 0.2249\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 28.1688 - accuracy: 0.2467\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 27.1733 - accuracy: 0.2328\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 27.9438 - accuracy: 0.2209\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.7862 - accuracy: 0.2315\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.9120 - accuracy: 0.2374\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.4388 - accuracy: 0.2275\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.5864 - accuracy: 0.2315\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.3306 - accuracy: 0.2467\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.4099 - accuracy: 0.2513\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.5319 - accuracy: 0.2493\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.6295 - accuracy: 0.2381\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 22.9960 - accuracy: 0.2440\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 22.7272 - accuracy: 0.2487\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 22.4781 - accuracy: 0.2454\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.9603 - accuracy: 0.2480\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.8792 - accuracy: 0.2421\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.3901 - accuracy: 0.2487\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.8003 - accuracy: 0.2546\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.6093 - accuracy: 0.2546\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.9314 - accuracy: 0.2546\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.5952 - accuracy: 0.2586\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.8267 - accuracy: 0.2632\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.7807 - accuracy: 0.2639\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 19.9491 - accuracy: 0.2586\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.1025 - accuracy: 0.2632\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.0667 - accuracy: 0.2725\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.0387 - accuracy: 0.2639\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.2908 - accuracy: 0.2685\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.5951 - accuracy: 0.2639\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.3731 - accuracy: 0.2606\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.9607 - accuracy: 0.2817\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.9471 - accuracy: 0.2864\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.4473 - accuracy: 0.2771\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.0591 - accuracy: 0.2745\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.7595 - accuracy: 0.2923\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.2401 - accuracy: 0.2698\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.6386 - accuracy: 0.2791\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.8979 - accuracy: 0.2784\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5618 - accuracy: 0.2877\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.6753 - accuracy: 0.2844\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.1069 - accuracy: 0.2751\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.0404 - accuracy: 0.2646\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.0589 - accuracy: 0.2784\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.9589 - accuracy: 0.2817\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.4376 - accuracy: 0.2811\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.8388 - accuracy: 0.2837\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.0228 - accuracy: 0.2937\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.4241 - accuracy: 0.2884\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.2095 - accuracy: 0.2837\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.3967 - accuracy: 0.2963\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.5773 - accuracy: 0.2950\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9752 - accuracy: 0.2943\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.2028 - accuracy: 0.2910\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.8350 - accuracy: 0.2870\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.1426 - accuracy: 0.3022\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.4524 - accuracy: 0.3029\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.0400 - accuracy: 0.3049\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.8614 - accuracy: 0.3009\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.7109 - accuracy: 0.2890\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.1653 - accuracy: 0.2910\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.8518 - accuracy: 0.3056\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.2406 - accuracy: 0.3029\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4990 - accuracy: 0.3022\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4188 - accuracy: 0.3016\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9063 - accuracy: 0.3075\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1347 - accuracy: 0.2950\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.8961 - accuracy: 0.2923\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4582 - accuracy: 0.3135\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.5230 - accuracy: 0.3089\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.6949 - accuracy: 0.3194\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.5429 - accuracy: 0.3115\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.9441 - accuracy: 0.3075\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4726 - accuracy: 0.3036\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.3033 - accuracy: 0.3135\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.7727 - accuracy: 0.2976\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0858 - accuracy: 0.2976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c77ada08>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.35185185185185186\n",
      "Tasa de aciertos balanceada regresión logística: 0.32\n",
      "Matriz de confusión:\n",
      "[[15 10  0  6  1]\n",
      " [17 49  5 56  0]\n",
      " [ 5 20  1 55  0]\n",
      " [ 0 27  6 65  7]\n",
      " [ 1 12  2 15  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.39      0.47      0.43        32\n",
      "         2.0       0.42      0.39      0.40       127\n",
      "         3.0       0.07      0.01      0.02        81\n",
      "         4.0       0.33      0.62      0.43       105\n",
      "         5.0       0.27      0.09      0.14        33\n",
      "\n",
      "    accuracy                           0.35       378\n",
      "   macro avg       0.30      0.32      0.28       378\n",
      "weighted avg       0.30      0.35      0.31       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_425 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_426 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_427 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_428 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_429 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,076\n",
      "Trainable params: 4,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 1905.3143 - accuracy: 0.1402\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 866.3337 - accuracy: 0.2335\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 661.1085 - accuracy: 0.2401\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 534.7661 - accuracy: 0.2328\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 454.0583 - accuracy: 0.2169\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 392.6670 - accuracy: 0.2090\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 346.6732 - accuracy: 0.2070\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 308.4663 - accuracy: 0.2044\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 279.6241 - accuracy: 0.2063\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 255.1194 - accuracy: 0.1885\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 233.0523 - accuracy: 0.2090\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 216.6965 - accuracy: 0.2110\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 199.8256 - accuracy: 0.2077\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 184.1812 - accuracy: 0.2156\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 171.2956 - accuracy: 0.2163\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 158.0662 - accuracy: 0.2163\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 145.4421 - accuracy: 0.2143\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 134.1092 - accuracy: 0.2196\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 123.1518 - accuracy: 0.2242\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 112.4513 - accuracy: 0.2189\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 101.8679 - accuracy: 0.2222\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 93.8562 - accuracy: 0.2269\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 86.5449 - accuracy: 0.2520\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 81.1762 - accuracy: 0.2454\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 76.5523 - accuracy: 0.2474\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 72.6817 - accuracy: 0.2401\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 69.2018 - accuracy: 0.2560\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 66.4269 - accuracy: 0.2579\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 63.5670 - accuracy: 0.2500\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 60.9877 - accuracy: 0.2606\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 57.7355 - accuracy: 0.2507\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 56.2618 - accuracy: 0.2599\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 53.8814 - accuracy: 0.2553\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 52.6119 - accuracy: 0.2440\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 51.8310 - accuracy: 0.2487\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 51.0500 - accuracy: 0.2361\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 49.8634 - accuracy: 0.2414\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 48.8362 - accuracy: 0.2480\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 47.7362 - accuracy: 0.2401\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 47.6851 - accuracy: 0.2440\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.9994 - accuracy: 0.2302\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.6969 - accuracy: 0.2474\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.2187 - accuracy: 0.2520\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 45.9362 - accuracy: 0.2434\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.8255 - accuracy: 0.2480\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.4033 - accuracy: 0.2526\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43.8820 - accuracy: 0.2560\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 43.2927 - accuracy: 0.2474\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42.8165 - accuracy: 0.2632\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42.4688 - accuracy: 0.2560\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 42.2496 - accuracy: 0.2553\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 41.8396 - accuracy: 0.2586\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 41.3459 - accuracy: 0.2533\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 40.8365 - accuracy: 0.2546\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 40.1141 - accuracy: 0.2626\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 39.4239 - accuracy: 0.2440\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 39.2601 - accuracy: 0.2619\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 38.4584 - accuracy: 0.2665\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 38.3027 - accuracy: 0.2632\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 38.7906 - accuracy: 0.2639\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.6671 - accuracy: 0.2751\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 38.1401 - accuracy: 0.2639\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 37.0384 - accuracy: 0.2665\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 36.6873 - accuracy: 0.2652\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 36.6723 - accuracy: 0.2579\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 36.3615 - accuracy: 0.2606\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 36.1901 - accuracy: 0.2619\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.7395 - accuracy: 0.2593\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.8923 - accuracy: 0.2652\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 35.0313 - accuracy: 0.2612\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.3265 - accuracy: 0.2784\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.0656 - accuracy: 0.2718\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.7370 - accuracy: 0.2870\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.2825 - accuracy: 0.2738\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.6241 - accuracy: 0.2771\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.3929 - accuracy: 0.2566\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.7562 - accuracy: 0.2712\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.7827 - accuracy: 0.2745\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.4161 - accuracy: 0.2679\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.4930 - accuracy: 0.2698\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.1833 - accuracy: 0.2771\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.2853 - accuracy: 0.2665\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.5047 - accuracy: 0.2778\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.3640 - accuracy: 0.2639\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.6331 - accuracy: 0.2765\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.2377 - accuracy: 0.2692\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 31.2041 - accuracy: 0.2712\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.7083 - accuracy: 0.2778\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.2952 - accuracy: 0.2837\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.2979 - accuracy: 0.2771\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.4016 - accuracy: 0.2804\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.1145 - accuracy: 0.2765\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.8760 - accuracy: 0.2698\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.9621 - accuracy: 0.2751\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.4412 - accuracy: 0.2784\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.4361 - accuracy: 0.2791\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.5483 - accuracy: 0.2877\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.3325 - accuracy: 0.2771\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 28.9955 - accuracy: 0.2831\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.1141 - accuracy: 0.2712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c7b75948>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3386243386243386\n",
      "Tasa de aciertos balanceada regresión logística: 0.32\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0 17  8  1  4  2]\n",
      " [ 0 20 48  3 51  5]\n",
      " [ 0  4 36  4 35  2]\n",
      " [ 1  0 35  9 55  5]\n",
      " [ 0  0  8  5 16  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.41      0.53      0.47        32\n",
      "         2.0       0.36      0.38      0.37       127\n",
      "         3.0       0.18      0.05      0.08        81\n",
      "         4.0       0.34      0.52      0.41       105\n",
      "         5.0       0.22      0.12      0.16        33\n",
      "\n",
      "    accuracy                           0.34       378\n",
      "   macro avg       0.25      0.27      0.25       378\n",
      "weighted avg       0.31      0.34      0.31       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_430 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_431 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_432 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_433 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_434 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,290\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 3554.6145 - accuracy: 0.1376\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1943.3380 - accuracy: 0.1746\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1457.6392 - accuracy: 0.1614\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1198.4919 - accuracy: 0.1528\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1020.8210 - accuracy: 0.1515\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 887.4818 - accuracy: 0.1475\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 785.1147 - accuracy: 0.1376\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 701.5282 - accuracy: 0.1429\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 631.7079 - accuracy: 0.1329\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 572.1322 - accuracy: 0.1316\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 519.9066 - accuracy: 0.1310\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 473.1183 - accuracy: 0.1369\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 431.2714 - accuracy: 0.1204\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 394.0081 - accuracy: 0.1296\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 359.2952 - accuracy: 0.1283\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 327.8213 - accuracy: 0.1290\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 297.4329 - accuracy: 0.1283\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 269.2698 - accuracy: 0.1316\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 242.7725 - accuracy: 0.1402\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 218.5809 - accuracy: 0.1448\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 195.6813 - accuracy: 0.1462\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 175.1155 - accuracy: 0.1541\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 156.2121 - accuracy: 0.1601\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 138.8425 - accuracy: 0.1594\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 124.4919 - accuracy: 0.1673\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 112.6716 - accuracy: 0.1720\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 102.0793 - accuracy: 0.1733\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 93.1210 - accuracy: 0.1792\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 85.3224 - accuracy: 0.1878\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 79.0491 - accuracy: 0.1997\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 73.9601 - accuracy: 0.2030\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 69.2542 - accuracy: 0.2149\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 65.0871 - accuracy: 0.2196\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 61.2429 - accuracy: 0.2282\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 57.7157 - accuracy: 0.2288\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 54.5145 - accuracy: 0.2321\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 51.6301 - accuracy: 0.2321\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 48.9907 - accuracy: 0.2368\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 46.5251 - accuracy: 0.2381\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.1417 - accuracy: 0.2421\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 41.8885 - accuracy: 0.2414\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 39.8488 - accuracy: 0.2440\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 38.0726 - accuracy: 0.2414\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 36.3424 - accuracy: 0.2354\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 34.8528 - accuracy: 0.2341\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 33.4441 - accuracy: 0.2341\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.1644 - accuracy: 0.2302\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 30.9863 - accuracy: 0.2262\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.8815 - accuracy: 0.2242\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 28.8983 - accuracy: 0.2216\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 27.9670 - accuracy: 0.2149\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 27.1101 - accuracy: 0.2143\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.2757 - accuracy: 0.2103\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 25.4757 - accuracy: 0.2116\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 24.7240 - accuracy: 0.2097\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.9984 - accuracy: 0.2083\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.2728 - accuracy: 0.2090\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.6200 - accuracy: 0.2083\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.9526 - accuracy: 0.2083\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.3913 - accuracy: 0.2070\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.8151 - accuracy: 0.2057\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.3073 - accuracy: 0.2063\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.7578 - accuracy: 0.2070\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 19.2504 - accuracy: 0.2063\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.7761 - accuracy: 0.2050\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.3478 - accuracy: 0.2024\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.9167 - accuracy: 0.2011\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.4914 - accuracy: 0.2004\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.0889 - accuracy: 0.2004\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.7037 - accuracy: 0.2004\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.2918 - accuracy: 0.1971\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.9599 - accuracy: 0.1978\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.5858 - accuracy: 0.1964\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.2170 - accuracy: 0.1964\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.8502 - accuracy: 0.1964\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.4942 - accuracy: 0.1958\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.1784 - accuracy: 0.1944\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.8533 - accuracy: 0.1944\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.5463 - accuracy: 0.1931\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.2862 - accuracy: 0.1925\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0338 - accuracy: 0.1918\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.7957 - accuracy: 0.1918\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.5530 - accuracy: 0.1918\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.3355 - accuracy: 0.1911\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.1156 - accuracy: 0.1911\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.8984 - accuracy: 0.1905\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.6890 - accuracy: 0.1905\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.4823 - accuracy: 0.1905\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2749 - accuracy: 0.1905\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.0749 - accuracy: 0.1911\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8836 - accuracy: 0.1918\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.6926 - accuracy: 0.1925\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.5108 - accuracy: 0.1918\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.3450 - accuracy: 0.1911\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 10.1684 - accuracy: 0.1898\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 9.9995 - accuracy: 0.1878\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8258 - accuracy: 0.1892\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6445 - accuracy: 0.1885\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.4694 - accuracy: 0.1878\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.2989 - accuracy: 0.1878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c8eb0108>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.20899470899470898\n",
      "Tasa de aciertos balanceada regresión logística: 0.19\n",
      "Matriz de confusión:\n",
      "[[15 10  0  6  1]\n",
      " [17 49  5 56  0]\n",
      " [ 5 20  1 55  0]\n",
      " [ 0 27  6 65  7]\n",
      " [ 1 12  2 15  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.44      0.06      0.11       127\n",
      "         3.0       0.21      0.88      0.33        81\n",
      "         4.0       0.00      0.00      0.00       105\n",
      "         5.0       0.00      0.00      0.00        33\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.21       378\n",
      "   macro avg       0.11      0.16      0.07       378\n",
      "weighted avg       0.19      0.21      0.11       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_435 (Dense)           (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_436 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_437 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_438 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_439 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,357\n",
      "Trainable params: 19,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8545 - accuracy: 0.2037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c91f4848>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0873015873015873\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  32]\n",
      " [  0   0   0   0 127]\n",
      " [  0   0   0   0  81]\n",
      " [  0   0   0   0 105]\n",
      " [  0   0   0   0  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.00      0.00      0.00        81\n",
      "         4.0       0.00      0.00      0.00       105\n",
      "         5.0       0.09      1.00      0.16        33\n",
      "\n",
      "    accuracy                           0.09       378\n",
      "   macro avg       0.02      0.20      0.03       378\n",
      "weighted avg       0.01      0.09      0.01       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_440 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_441 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_442 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_443 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_444 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,359\n",
      "Trainable params: 8,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 10.8068 - accuracy: 0.2037\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 10.9112 - accuracy: 0.2037\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 10.9112 - accuracy: 0.2037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4ca615948>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0873015873015873\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  32]\n",
      " [  0   0   0   0 127]\n",
      " [  0   0   0   0  81]\n",
      " [  0   0   0   0 105]\n",
      " [  0   0   0   0  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.00      0.00      0.00        81\n",
      "         4.0       0.00      0.00      0.00       105\n",
      "         5.0       0.09      1.00      0.16        33\n",
      "\n",
      "    accuracy                           0.09       378\n",
      "   macro avg       0.02      0.20      0.03       378\n",
      "weighted avg       0.01      0.09      0.01       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_445 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_446 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_447 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_448 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_449 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,391\n",
      "Trainable params: 2,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 9.9184 - accuracy: 0.1052\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8972 - accuracy: 0.1052\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0207 - accuracy: 0.1052\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 10.0196 - accuracy: 0.1052\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 10.0196 - accuracy: 0.1052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4caa0b388>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.08465608465608465\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  32]\n",
      " [  0   0   0   0 127]\n",
      " [  0   0   0   0  81]\n",
      " [  0   0   0   0 105]\n",
      " [  0   0   0   0  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.08      1.00      0.16        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.00      0.00      0.00        81\n",
      "         4.0       0.00      0.00      0.00       105\n",
      "         5.0       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.08       378\n",
      "   macro avg       0.02      0.20      0.03       378\n",
      "weighted avg       0.01      0.08      0.01       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_450 (Dense)           (None, 100)               1300      \n",
      "                                                                 \n",
      " dense_451 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_452 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_453 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_454 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_455 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_456 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_457 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_458 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_459 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,419\n",
      "Trainable params: 10,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 2ms/step - loss: 11.5421 - accuracy: 0.2817\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.5773 - accuracy: 0.2817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4cbd8f388>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2777777777777778\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  32   0]\n",
      " [  0   0   0 127   0]\n",
      " [  0   0   0  81   0]\n",
      " [  0   0   0 105   0]\n",
      " [  0   0   0  33   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.00      0.00      0.00        81\n",
      "         4.0       0.28      1.00      0.43       105\n",
      "         5.0       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.28       378\n",
      "   macro avg       0.06      0.20      0.09       378\n",
      "weighted avg       0.08      0.28      0.12       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_460 (Dense)           (None, 64)                832       \n",
      "                                                                 \n",
      " dense_461 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_462 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_463 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_464 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_465 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_466 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_467 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_468 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_469 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,639\n",
      "Trainable params: 4,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 2ms/step - loss: 13.7414 - accuracy: 0.1151\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.2278 - accuracy: 0.1759\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1607 - accuracy: 0.1819\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1515 - accuracy: 0.1819\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1403 - accuracy: 0.1819\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1391 - accuracy: 0.1819\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1220 - accuracy: 0.1819\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1160 - accuracy: 0.1819\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1443 - accuracy: 0.1819\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1647 - accuracy: 0.1819\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1504 - accuracy: 0.1832\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1264 - accuracy: 0.1839\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0800 - accuracy: 0.1852\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1007 - accuracy: 0.1865\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0958 - accuracy: 0.1865\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0804 - accuracy: 0.1865\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0975 - accuracy: 0.1845\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1077 - accuracy: 0.1839\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0969 - accuracy: 0.1845\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0895 - accuracy: 0.1845\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0783 - accuracy: 0.1858\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0740 - accuracy: 0.1872\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0942 - accuracy: 0.1885\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0940 - accuracy: 0.1885\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0927 - accuracy: 0.1885\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0924 - accuracy: 0.1885\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0827 - accuracy: 0.1885\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0654 - accuracy: 0.1885\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0515 - accuracy: 0.1898\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0665 - accuracy: 0.1885\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0846 - accuracy: 0.1885\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0744 - accuracy: 0.1878\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0844 - accuracy: 0.1878\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0932 - accuracy: 0.1865\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1016 - accuracy: 0.1865\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0795 - accuracy: 0.1878\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.9973 - accuracy: 0.1885\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 12.9935 - accuracy: 0.1885\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.0644 - accuracy: 0.1852\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1552 - accuracy: 0.1839\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1551 - accuracy: 0.1839\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 13.1550 - accuracy: 0.1839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4cd254108>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.21428571428571427\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0  32   0   0]\n",
      " [  0   0 127   0   0]\n",
      " [  0   0  81   0   0]\n",
      " [  0   0 105   0   0]\n",
      " [  0   0  33   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.21      1.00      0.35        81\n",
      "         4.0       0.00      0.00      0.00       105\n",
      "         5.0       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.21       378\n",
      "   macro avg       0.04      0.20      0.07       378\n",
      "weighted avg       0.05      0.21      0.08       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_470 (Dense)           (None, 32)                416       \n",
      "                                                                 \n",
      " dense_471 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_472 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_473 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_474 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_475 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_476 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_477 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_478 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_479 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,425\n",
      "Trainable params: 1,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.6799 - accuracy: 0.2037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4cd7d7708>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0873015873015873\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0  32   0]\n",
      " [  0   0   0 127   0]\n",
      " [  0   0   0  81   0]\n",
      " [  0   0   0 105   0]\n",
      " [  0   0   0  33   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.00      0.00      0.00        81\n",
      "         4.0       0.00      0.00      0.00       105\n",
      "         5.0       0.09      1.00      0.16        33\n",
      "\n",
      "    accuracy                           0.09       378\n",
      "   macro avg       0.02      0.20      0.03       378\n",
      "weighted avg       0.01      0.09      0.01       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 22, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_480 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_481 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_482 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_483 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_484 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,065\n",
      "Trainable params: 10,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 733.6959 - accuracy: 0.2241\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 91.9971 - accuracy: 0.2568\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.2608 - accuracy: 0.2343\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 65.0328 - accuracy: 0.2589\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.9377 - accuracy: 0.2718\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.4683 - accuracy: 0.2534\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.4754 - accuracy: 0.2657\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.6484 - accuracy: 0.2922\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.1606 - accuracy: 0.2970\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.5138 - accuracy: 0.2834\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.6663 - accuracy: 0.2813\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.5287 - accuracy: 0.3215\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5700 - accuracy: 0.3236\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.7608 - accuracy: 0.3154\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6829 - accuracy: 0.3202\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.9050 - accuracy: 0.3195\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3259 - accuracy: 0.3270\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2498 - accuracy: 0.3188\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8135 - accuracy: 0.3249\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6528 - accuracy: 0.3447\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.4506 - accuracy: 0.2875\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.8365 - accuracy: 0.3345\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8671 - accuracy: 0.3488\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4452 - accuracy: 0.3760\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6374 - accuracy: 0.3426\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1690 - accuracy: 0.3208\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6379 - accuracy: 0.4319\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8439 - accuracy: 0.4040\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6811 - accuracy: 0.3937\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.9817 - accuracy: 0.3924\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7830 - accuracy: 0.4080\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3891 - accuracy: 0.3678\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6962 - accuracy: 0.3808\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9992 - accuracy: 0.3699\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6470 - accuracy: 0.3842\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4860 - accuracy: 0.3713\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6393 - accuracy: 0.3733\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5430 - accuracy: 0.3869\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1438 - accuracy: 0.3713\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9353 - accuracy: 0.4108\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3970 - accuracy: 0.3706\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7824 - accuracy: 0.4121\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5419 - accuracy: 0.4257\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0283 - accuracy: 0.3713\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7291 - accuracy: 0.3610\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1067 - accuracy: 0.3958\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6258 - accuracy: 0.3597\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1793 - accuracy: 0.3665\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0724 - accuracy: 0.3685\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7799 - accuracy: 0.4223\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6623 - accuracy: 0.4026\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2638 - accuracy: 0.3985\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0145 - accuracy: 0.3931\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6246 - accuracy: 0.4203\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2314 - accuracy: 0.3822\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2527 - accuracy: 0.3937\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7270 - accuracy: 0.4046\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7905 - accuracy: 0.3801\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8505 - accuracy: 0.4257\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0041 - accuracy: 0.3822\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7613 - accuracy: 0.4026\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5156 - accuracy: 0.4530\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7460 - accuracy: 0.4155\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9022 - accuracy: 0.3426\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9759 - accuracy: 0.3604\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6407 - accuracy: 0.3447\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1740 - accuracy: 0.3896\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8444 - accuracy: 0.3924\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0443 - accuracy: 0.3985\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3629 - accuracy: 0.3488\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7513 - accuracy: 0.3781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3585 - accuracy: 0.3426\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0099 - accuracy: 0.3508\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6410 - accuracy: 0.3856\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9823 - accuracy: 0.3760\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3143 - accuracy: 0.2698\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1380 - accuracy: 0.3426\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8512 - accuracy: 0.3726\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7894 - accuracy: 0.3658\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6586 - accuracy: 0.3781\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4168 - accuracy: 0.3106\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6745 - accuracy: 0.3849\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5300 - accuracy: 0.4353\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3698 - accuracy: 0.4353\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.4862 - accuracy: 0.4605\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9506 - accuracy: 0.3495\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5486 - accuracy: 0.3147\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8391 - accuracy: 0.3508\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7502 - accuracy: 0.3822\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0352 - accuracy: 0.3488\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.3405 - accuracy: 0.3038\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5570 - accuracy: 0.3277\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5929 - accuracy: 0.3896\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9258 - accuracy: 0.3488\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6108 - accuracy: 0.4128\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5073 - accuracy: 0.3992\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8352 - accuracy: 0.3678\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5199 - accuracy: 0.4108\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7074 - accuracy: 0.3529\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5253 - accuracy: 0.4019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4cecc43c8>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3569482288828338\n",
      "Tasa de aciertos balanceada regresión logística: 0.38\n",
      "Matriz de confusión:\n",
      "[[ 11   0  21   0   0]\n",
      " [  0   0 126   1   0]\n",
      " [  0   0  75   4   0]\n",
      " [  0   0  54  39   5]\n",
      " [  0   0  15  10   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.34      0.51        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.26      0.95      0.41        79\n",
      "         4.0       0.72      0.40      0.51        98\n",
      "         5.0       0.55      0.19      0.29        31\n",
      "\n",
      "    accuracy                           0.36       367\n",
      "   macro avg       0.51      0.38      0.34       367\n",
      "weighted avg       0.38      0.36      0.29       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_485 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_486 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_487 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_488 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_489 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,716\n",
      "Trainable params: 4,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 1547.0521 - accuracy: 0.2084  \n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 127.6696 - accuracy: 0.2616\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.4894 - accuracy: 0.2725\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 62.0996 - accuracy: 0.2820\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 54.3176 - accuracy: 0.2847\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.3291 - accuracy: 0.2984\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.1027 - accuracy: 0.2956\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.5613 - accuracy: 0.2990\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.4933 - accuracy: 0.3229\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.1530 - accuracy: 0.3154\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.0614 - accuracy: 0.3338\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.5330 - accuracy: 0.3358\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.2042 - accuracy: 0.3386\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.1781 - accuracy: 0.3426\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.6892 - accuracy: 0.3174\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.9742 - accuracy: 0.3433\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.1820 - accuracy: 0.3488\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.4348 - accuracy: 0.3120\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.6916 - accuracy: 0.3093\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.5093 - accuracy: 0.3324\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.1574 - accuracy: 0.3569\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6591 - accuracy: 0.3631\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.9900 - accuracy: 0.3181\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.8510 - accuracy: 0.3420\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.9834 - accuracy: 0.3590\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.7805 - accuracy: 0.3426\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6157 - accuracy: 0.3631\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.7903 - accuracy: 0.3426\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.9567 - accuracy: 0.3944\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.5467 - accuracy: 0.3345\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.6292 - accuracy: 0.3549\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6413 - accuracy: 0.3549\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.6305 - accuracy: 0.3726\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.9113 - accuracy: 0.3719\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.0550 - accuracy: 0.3713\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.6504 - accuracy: 0.3753\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7439 - accuracy: 0.4046\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7656 - accuracy: 0.3992\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.8103 - accuracy: 0.4183\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1380 - accuracy: 0.4046\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.4282 - accuracy: 0.3999\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1485 - accuracy: 0.3978\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.1031 - accuracy: 0.3794\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.5367 - accuracy: 0.3965\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2214 - accuracy: 0.3692\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.5592 - accuracy: 0.3971\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9430 - accuracy: 0.4067\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3919 - accuracy: 0.3917\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2035 - accuracy: 0.3828\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6006 - accuracy: 0.4135\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5227 - accuracy: 0.4244\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8609 - accuracy: 0.4176\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.1727 - accuracy: 0.3917\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6009 - accuracy: 0.4387\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4526 - accuracy: 0.3999\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8813 - accuracy: 0.4319\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9966 - accuracy: 0.4169\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0781 - accuracy: 0.4360\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3705 - accuracy: 0.4394\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1872 - accuracy: 0.4612\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7335 - accuracy: 0.4305\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2055 - accuracy: 0.4366\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.6788 - accuracy: 0.3801\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8773 - accuracy: 0.4407\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1081 - accuracy: 0.3985\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3623 - accuracy: 0.3678\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3296 - accuracy: 0.4278\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5337 - accuracy: 0.4101\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3897 - accuracy: 0.4162\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4904 - accuracy: 0.4373\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3560 - accuracy: 0.4196\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5447 - accuracy: 0.4441\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1599 - accuracy: 0.4332\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9718 - accuracy: 0.4401\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0815 - accuracy: 0.4135\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4746 - accuracy: 0.4435\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4041 - accuracy: 0.4366\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3615 - accuracy: 0.4932\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3221 - accuracy: 0.4625\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9495 - accuracy: 0.4251\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.5165 - accuracy: 0.4598\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8167 - accuracy: 0.4687\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.9569 - accuracy: 0.4503\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.6665 - accuracy: 0.4734\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 5.2222 - accuracy: 0.4482\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7781 - accuracy: 0.4387\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 5.4047 - accuracy: 0.4257\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.0058 - accuracy: 0.4612\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.1378 - accuracy: 0.4639\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3968 - accuracy: 0.4298\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8272 - accuracy: 0.4653\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.5801 - accuracy: 0.4496\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.6717 - accuracy: 0.4510\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.2970 - accuracy: 0.4605\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8281 - accuracy: 0.4680\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.2892 - accuracy: 0.4530\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.1547 - accuracy: 0.4496\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3947 - accuracy: 0.4993\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5604 - accuracy: 0.4796\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4929 - accuracy: 0.4707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4d00c4148>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3896457765667575\n",
      "Tasa de aciertos balanceada regresión logística: 0.27\n",
      "Matriz de confusión:\n",
      "[[ 3 27  2  0  0]\n",
      " [ 1 93 15 18  0]\n",
      " [ 0 47  3 26  3]\n",
      " [ 0 54  0 43  1]\n",
      " [ 0 14  0 16  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.75      0.09      0.17        32\n",
      "         2.0       0.40      0.73      0.51       127\n",
      "         3.0       0.15      0.04      0.06        79\n",
      "         4.0       0.42      0.44      0.43        98\n",
      "         5.0       0.20      0.03      0.06        31\n",
      "\n",
      "    accuracy                           0.39       367\n",
      "   macro avg       0.38      0.27      0.24       367\n",
      "weighted avg       0.36      0.39      0.32       367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_490 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_491 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_492 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_493 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_494 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,610\n",
      "Trainable params: 1,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 1018.0948 - accuracy: 0.2296\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 159.4366 - accuracy: 0.2514\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.8893 - accuracy: 0.2500\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.4545 - accuracy: 0.2493\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.0112 - accuracy: 0.2520\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.3637 - accuracy: 0.2214\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1317 - accuracy: 0.1614\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9829 - accuracy: 0.1356\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1344 - accuracy: 0.1594\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8337 - accuracy: 0.2657\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8896 - accuracy: 0.2670\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5469 - accuracy: 0.2732\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3215 - accuracy: 0.2752\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0041 - accuracy: 0.2854\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9637 - accuracy: 0.2807\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9092 - accuracy: 0.2820\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8611 - accuracy: 0.2861\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8317 - accuracy: 0.2827\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7928 - accuracy: 0.2847\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8087 - accuracy: 0.2807\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8802 - accuracy: 0.2847\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7703 - accuracy: 0.2813\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7528 - accuracy: 0.2868\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7646 - accuracy: 0.2827\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7520 - accuracy: 0.2793\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7260 - accuracy: 0.2861\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6953 - accuracy: 0.2854\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7046 - accuracy: 0.2861\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7036 - accuracy: 0.2847\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8195 - accuracy: 0.2820\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7000 - accuracy: 0.2800\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7758 - accuracy: 0.2813\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7249 - accuracy: 0.2834\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6669 - accuracy: 0.2841\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7064 - accuracy: 0.2834\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6845 - accuracy: 0.2854\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6720 - accuracy: 0.2854\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6859 - accuracy: 0.2813\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7158 - accuracy: 0.2820\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6453 - accuracy: 0.2827\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6739 - accuracy: 0.2861\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6837 - accuracy: 0.2834\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7151 - accuracy: 0.2772\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6753 - accuracy: 0.2820\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6178 - accuracy: 0.2861\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6840 - accuracy: 0.2813\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6492 - accuracy: 0.2827\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6262 - accuracy: 0.2868\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6309 - accuracy: 0.2834\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6381 - accuracy: 0.2841\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6510 - accuracy: 0.2841\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6250 - accuracy: 0.2841\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6066 - accuracy: 0.2861\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6085 - accuracy: 0.2861\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6881 - accuracy: 0.2786\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6019 - accuracy: 0.2854\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6051 - accuracy: 0.2841\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6237 - accuracy: 0.2827\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5995 - accuracy: 0.2895\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6688 - accuracy: 0.2820\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6231 - accuracy: 0.2854\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8586 - accuracy: 0.2698\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6093 - accuracy: 0.2807\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6090 - accuracy: 0.2875\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5941 - accuracy: 0.2861\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6064 - accuracy: 0.2854\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5962 - accuracy: 0.2861\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5911 - accuracy: 0.2861\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5886 - accuracy: 0.2854\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6162 - accuracy: 0.2861\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5887 - accuracy: 0.2861\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5846 - accuracy: 0.2861\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5906 - accuracy: 0.2861\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5866 - accuracy: 0.2861\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5838 - accuracy: 0.2861\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5829 - accuracy: 0.2861\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5808 - accuracy: 0.2861\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5848 - accuracy: 0.2854\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5953 - accuracy: 0.2868\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5827 - accuracy: 0.2861\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5808 - accuracy: 0.2861\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5804 - accuracy: 0.2854\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5812 - accuracy: 0.2854\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6019 - accuracy: 0.2854\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5792 - accuracy: 0.2861\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5788 - accuracy: 0.2868\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.5782 - accuracy: 0.2861\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5769 - accuracy: 0.2861\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5754 - accuracy: 0.2881\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5738 - accuracy: 0.2909\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5782 - accuracy: 0.2854\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5850 - accuracy: 0.2834\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.5825 - accuracy: 0.2834\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.5806 - accuracy: 0.2834\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5786 - accuracy: 0.2834\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.5825 - accuracy: 0.2834\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.5790 - accuracy: 0.2834\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5784 - accuracy: 0.2834\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5766 - accuracy: 0.2834\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5784 - accuracy: 0.2834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4d03dcf08>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2670299727520436\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 11   0  21   0   0]\n",
      " [  0   0 126   1   0]\n",
      " [  0   0  75   4   0]\n",
      " [  0   0  54  39   5]\n",
      " [  0   0  15  10   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.27      1.00      0.42        98\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.27       367\n",
      "   macro avg       0.05      0.20      0.08       367\n",
      "weighted avg       0.07      0.27      0.11       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 22, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_495 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_496 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_497 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_498 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_499 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,357\n",
      "Trainable params: 20,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1863 - accuracy: 0.0477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4d03d4ec8>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07629427792915532\n",
      "Tasa de aciertos balanceada regresión logística: 0.07\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [11  0  0 21  0  0]\n",
      " [63  0  0 64  0  0]\n",
      " [51  0  0 28  0  0]\n",
      " [67  0  0 31  0  0]\n",
      " [23  0  0  8  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.18      0.35      0.24        79\n",
      "         4.0       0.00      0.00      0.00        98\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.08       367\n",
      "   macro avg       0.03      0.06      0.04       367\n",
      "weighted avg       0.04      0.08      0.05       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_500 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_501 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_502 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_503 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_504 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,999\n",
      "Trainable params: 8,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 9.9821 - accuracy: 0.2248\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.7425 - accuracy: 0.2248\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4948 - accuracy: 0.2248\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4948 - accuracy: 0.2248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c77c3188>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3460490463215259\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0  32   0   0   0]\n",
      " [  0 127   0   0   0]\n",
      " [  0  79   0   0   0]\n",
      " [  0  98   0   0   0]\n",
      " [  0  31   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.35      1.00      0.51       127\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.00      0.00      0.00        98\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.35       367\n",
      "   macro avg       0.07      0.20      0.10       367\n",
      "weighted avg       0.12      0.35      0.18       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_505 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_506 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_507 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_508 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_509 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,711\n",
      "Trainable params: 2,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 10.2662 - accuracy: 0.1601\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5576 - accuracy: 0.1948\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4289 - accuracy: 0.1621\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5243 - accuracy: 0.1914\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.2513 - accuracy: 0.2016\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2602 - accuracy: 0.1880\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6726 - accuracy: 0.1880\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6939 - accuracy: 0.1880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4cbdcc948>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.21525885558583105\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [11  0  0 21  0  0]\n",
      " [63  0  0 64  0  0]\n",
      " [51  0  0 28  0  0]\n",
      " [67  0  0 31  0  0]\n",
      " [23  0  0  8  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.22      1.00      0.35        79\n",
      "         4.0       0.00      0.00      0.00        98\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.22       367\n",
      "   macro avg       0.04      0.20      0.07       367\n",
      "weighted avg       0.05      0.22      0.08       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 22, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_510 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_511 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_512 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_513 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_514 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_515 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_516 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_517 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_518 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_519 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,419\n",
      "Trainable params: 11,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 9.2929 - accuracy: 0.1989\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3551 - accuracy: 0.1989\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3567 - accuracy: 0.1989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4d2d452c8>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.08446866485013624\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  32]\n",
      " [  0   0   0   0 127]\n",
      " [  0   0   0   0  79]\n",
      " [  0   0   0   0  98]\n",
      " [  0   0   0   0  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.00      0.00      0.00        98\n",
      "         5.0       0.08      1.00      0.16        31\n",
      "\n",
      "    accuracy                           0.08       367\n",
      "   macro avg       0.02      0.20      0.03       367\n",
      "weighted avg       0.01      0.08      0.01       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_520 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_521 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_522 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_523 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_524 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_525 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_526 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_527 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_528 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_529 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,279\n",
      "Trainable params: 5,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3830 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4d42cf548>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0]\n",
      " [ 32   0   0   0   0   0]\n",
      " [127   0   0   0   0   0]\n",
      " [ 79   0   0   0   0   0]\n",
      " [ 98   0   0   0   0   0]\n",
      " [ 31   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      32.0\n",
      "         2.0       0.00      0.00      0.00     127.0\n",
      "         3.0       0.00      0.00      0.00      79.0\n",
      "         4.0       0.00      0.00      0.00      98.0\n",
      "         5.0       0.00      0.00      0.00      31.0\n",
      "\n",
      "    accuracy                           0.00     367.0\n",
      "   macro avg       0.00      0.00      0.00     367.0\n",
      "weighted avg       0.00      0.00      0.00     367.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_530 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_531 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_532 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_533 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_534 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_535 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_536 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_537 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_538 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_539 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,745\n",
      "Trainable params: 1,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 4.2187 - accuracy: 0.0613\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6892 - accuracy: 0.0525\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4209 - accuracy: 0.0416\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2601 - accuracy: 0.0388\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3108 - accuracy: 0.0395\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2321 - accuracy: 0.0347\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3298 - accuracy: 0.0347\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3956 - accuracy: 0.0450\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2117 - accuracy: 0.0354\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1016 - accuracy: 0.0313\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7082 - accuracy: 0.0211\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4d589d808>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  32]\n",
      " [  0   0   0   0 127]\n",
      " [  0   0   0   0  79]\n",
      " [  0   0   0   0  98]\n",
      " [  0   0   0   0  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      32.0\n",
      "         2.0       0.00      0.00      0.00     127.0\n",
      "         3.0       0.00      0.00      0.00      79.0\n",
      "         4.0       0.00      0.00      0.00      98.0\n",
      "         5.0       0.00      0.00      0.00      31.0\n",
      "\n",
      "    accuracy                           0.00     367.0\n",
      "   macro avg       0.00      0.00      0.00     367.0\n",
      "weighted avg       0.00      0.00      0.00     367.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_540 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_541 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_542 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_543 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_544 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,065\n",
      "Trainable params: 10,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 1107.1136 - accuracy: 0.1948\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 339.7852 - accuracy: 0.2228\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 278.6592 - accuracy: 0.2439\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 229.7661 - accuracy: 0.2582\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 214.4972 - accuracy: 0.2534\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 189.7482 - accuracy: 0.2772\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 174.2141 - accuracy: 0.2854\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 171.8175 - accuracy: 0.2718\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 157.9108 - accuracy: 0.2936\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 154.3883 - accuracy: 0.2963\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 142.3159 - accuracy: 0.3079\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 140.6295 - accuracy: 0.3079\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 134.9913 - accuracy: 0.3093\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 131.4656 - accuracy: 0.3099\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 129.2540 - accuracy: 0.3134\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 119.9281 - accuracy: 0.3174\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 120.5171 - accuracy: 0.3222\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 113.9219 - accuracy: 0.3392\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 114.4848 - accuracy: 0.3283\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 109.7906 - accuracy: 0.3413\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 108.2407 - accuracy: 0.3454\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 105.9255 - accuracy: 0.3386\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 105.7207 - accuracy: 0.3501\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 101.3495 - accuracy: 0.3508\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 100.2295 - accuracy: 0.3583\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 99.4295 - accuracy: 0.3467\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 97.4673 - accuracy: 0.3508\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 95.0311 - accuracy: 0.3522\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.5760 - accuracy: 0.3713\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.8692 - accuracy: 0.3604\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.2515 - accuracy: 0.3624\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.1764 - accuracy: 0.3685\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.3648 - accuracy: 0.3685\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 87.4190 - accuracy: 0.3740\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.8063 - accuracy: 0.3692\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.3500 - accuracy: 0.3733\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.4019 - accuracy: 0.3685\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.0268 - accuracy: 0.3849\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.8091 - accuracy: 0.3787\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.5829 - accuracy: 0.3815\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.3086 - accuracy: 0.3801\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.9584 - accuracy: 0.3753\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.3208 - accuracy: 0.3849\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 76.2754 - accuracy: 0.3842\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.1240 - accuracy: 0.3903\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.4603 - accuracy: 0.3767\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.5054 - accuracy: 0.3931\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.1227 - accuracy: 0.3787\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.4539 - accuracy: 0.3924\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.3609 - accuracy: 0.3890\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.3788 - accuracy: 0.3835\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.5500 - accuracy: 0.3978\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.7923 - accuracy: 0.4012\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.6380 - accuracy: 0.3917\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.9378 - accuracy: 0.4040\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.5941 - accuracy: 0.3787\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.0153 - accuracy: 0.3862\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.5193 - accuracy: 0.4080\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 70.7472 - accuracy: 0.3985\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.4784 - accuracy: 0.4012\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.4456 - accuracy: 0.3917\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.8537 - accuracy: 0.3965\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 68.3627 - accuracy: 0.3951\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.6514 - accuracy: 0.3985\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.0935 - accuracy: 0.4080\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.0803 - accuracy: 0.4040\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.9617 - accuracy: 0.3958\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.6082 - accuracy: 0.3985\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 65.4414 - accuracy: 0.4121\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 65.9755 - accuracy: 0.3890\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 64.2505 - accuracy: 0.4026\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 66.4700 - accuracy: 0.4040\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 63.9505 - accuracy: 0.4053\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.4252 - accuracy: 0.4026\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.7602 - accuracy: 0.4060\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.5277 - accuracy: 0.4005\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.3614 - accuracy: 0.4149\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.0655 - accuracy: 0.4053\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.2784 - accuracy: 0.4101\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.4512 - accuracy: 0.4135\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.0388 - accuracy: 0.4033\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.3436 - accuracy: 0.4074\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.0473 - accuracy: 0.3999\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.3047 - accuracy: 0.4121\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.2211 - accuracy: 0.4114\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 61.3094 - accuracy: 0.4040\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.1477 - accuracy: 0.4067\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.3940 - accuracy: 0.4108\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.8544 - accuracy: 0.4046\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.0217 - accuracy: 0.4183\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.3751 - accuracy: 0.4203\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.6551 - accuracy: 0.4176\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.4174 - accuracy: 0.4012\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.0232 - accuracy: 0.4203\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.0713 - accuracy: 0.4074\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.8753 - accuracy: 0.4285\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.6711 - accuracy: 0.4128\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.0140 - accuracy: 0.4053\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.5917 - accuracy: 0.4114\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.3904 - accuracy: 0.4026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4d5deb308>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.335149863760218\n",
      "Tasa de aciertos balanceada regresión logística: 0.33\n",
      "Matriz de confusión:\n",
      "[[15 13  4  0  0]\n",
      " [19 65 16 24  3]\n",
      " [ 4 25 11 36  3]\n",
      " [ 2 30 17 22 27]\n",
      " [ 1  3  5 12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.37      0.47      0.41        32\n",
      "         2.0       0.48      0.51      0.49       127\n",
      "         3.0       0.21      0.14      0.17        79\n",
      "         4.0       0.23      0.22      0.23        98\n",
      "         5.0       0.23      0.32      0.27        31\n",
      "\n",
      "    accuracy                           0.34       367\n",
      "   macro avg       0.30      0.33      0.31       367\n",
      "weighted avg       0.32      0.34      0.33       367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_545 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_546 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_547 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_548 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_549 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,716\n",
      "Trainable params: 4,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 507.0517 - accuracy: 0.1894\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 222.3348 - accuracy: 0.2193\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 171.9856 - accuracy: 0.2187\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 138.1487 - accuracy: 0.2384\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 123.4328 - accuracy: 0.2330\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 112.3546 - accuracy: 0.2480\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 106.9999 - accuracy: 0.2405\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 101.9237 - accuracy: 0.2371\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 97.6427 - accuracy: 0.2330\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.9670 - accuracy: 0.2268\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 89.4061 - accuracy: 0.2371\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.4111 - accuracy: 0.2309\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.4195 - accuracy: 0.2446\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.8592 - accuracy: 0.2595\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.2677 - accuracy: 0.2384\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.9921 - accuracy: 0.2411\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.6944 - accuracy: 0.2514\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.3865 - accuracy: 0.2595\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.9318 - accuracy: 0.2466\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.1118 - accuracy: 0.2575\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.5743 - accuracy: 0.2616\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.6527 - accuracy: 0.2650\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.9223 - accuracy: 0.2725\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.0173 - accuracy: 0.2623\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.6671 - accuracy: 0.2602\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.0181 - accuracy: 0.2711\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.3635 - accuracy: 0.2841\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.8092 - accuracy: 0.2738\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.0326 - accuracy: 0.2759\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.8804 - accuracy: 0.2691\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.4461 - accuracy: 0.3004\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.0381 - accuracy: 0.2888\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.8035 - accuracy: 0.2922\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.0505 - accuracy: 0.2888\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.2255 - accuracy: 0.2929\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.6628 - accuracy: 0.2956\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.2190 - accuracy: 0.2895\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.3004 - accuracy: 0.3031\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.5891 - accuracy: 0.3099\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.7645 - accuracy: 0.2909\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.2204 - accuracy: 0.3038\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.8658 - accuracy: 0.3045\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.6889 - accuracy: 0.3099\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.5111 - accuracy: 0.3161\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.8319 - accuracy: 0.3113\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.2057 - accuracy: 0.3134\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.0817 - accuracy: 0.3195\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.4468 - accuracy: 0.3106\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.9509 - accuracy: 0.3174\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.8455 - accuracy: 0.3229\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.8594 - accuracy: 0.3106\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.9937 - accuracy: 0.3188\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.0097 - accuracy: 0.3086\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.1604 - accuracy: 0.3174\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.7392 - accuracy: 0.3181\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.7907 - accuracy: 0.3311\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 47.5699 - accuracy: 0.3270\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.1533 - accuracy: 0.3168\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.5187 - accuracy: 0.3304\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.8435 - accuracy: 0.3120\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.0188 - accuracy: 0.3297\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.6842 - accuracy: 0.3215\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.1431 - accuracy: 0.3283\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 46.0041 - accuracy: 0.3243\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 45.5355 - accuracy: 0.3249\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 45.2136 - accuracy: 0.3277\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 45.0520 - accuracy: 0.3345\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 44.4645 - accuracy: 0.3270\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 44.6348 - accuracy: 0.3188\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 44.5565 - accuracy: 0.3222\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 44.4552 - accuracy: 0.3304\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 43.5697 - accuracy: 0.3351\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.6380 - accuracy: 0.3399\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.1584 - accuracy: 0.3365\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.9605 - accuracy: 0.3372\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.7344 - accuracy: 0.3392\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.9173 - accuracy: 0.3406\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.3737 - accuracy: 0.3372\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.5920 - accuracy: 0.3474\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.8516 - accuracy: 0.3495\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.5201 - accuracy: 0.3392\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.6042 - accuracy: 0.3447\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.6369 - accuracy: 0.3474\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.6742 - accuracy: 0.3433\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.3797 - accuracy: 0.3495\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.6963 - accuracy: 0.3413\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.8439 - accuracy: 0.3392\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.7377 - accuracy: 0.3426\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.5583 - accuracy: 0.3488\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.5168 - accuracy: 0.3406\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.2695 - accuracy: 0.3420\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.1111 - accuracy: 0.3481\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.2388 - accuracy: 0.3474\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.9294 - accuracy: 0.3535\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.3242 - accuracy: 0.3651\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.2875 - accuracy: 0.3590\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.9098 - accuracy: 0.3535\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0294 - accuracy: 0.3529\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.8723 - accuracy: 0.3542\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.9405 - accuracy: 0.3515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4d712b548>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3024523160762943\n",
      "Tasa de aciertos balanceada regresión logística: 0.30\n",
      "Matriz de confusión:\n",
      "[[16 13  2  1  0  0]\n",
      " [42 34 16 31  3  1]\n",
      " [22 14 10 31  1  1]\n",
      " [16 18  7 48  9  0]\n",
      " [ 3  2  5 18  3  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.16      0.50      0.24        32\n",
      "         2.0       0.42      0.27      0.33       127\n",
      "         3.0       0.25      0.13      0.17        79\n",
      "         4.0       0.37      0.49      0.42        98\n",
      "         5.0       0.19      0.10      0.13        31\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.30       367\n",
      "   macro avg       0.23      0.25      0.21       367\n",
      "weighted avg       0.33      0.30      0.29       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_550 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_551 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_552 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_553 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_554 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,610\n",
      "Trainable params: 1,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 2587.2834 - accuracy: 0.2010\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1227.8483 - accuracy: 0.1996\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 717.7888 - accuracy: 0.1996\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 441.6663 - accuracy: 0.1928\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 311.3382 - accuracy: 0.1792\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 245.4760 - accuracy: 0.1778\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 198.2646 - accuracy: 0.1819\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 160.2759 - accuracy: 0.2010\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 128.8166 - accuracy: 0.1996\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 102.7656 - accuracy: 0.1921\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.4599 - accuracy: 0.1866\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.7614 - accuracy: 0.1894\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.8492 - accuracy: 0.2003\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.6125 - accuracy: 0.2010\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.5020 - accuracy: 0.2003\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.1580 - accuracy: 0.1982\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 34.9522 - accuracy: 0.1989\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.3985 - accuracy: 0.1996\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.4328 - accuracy: 0.2023\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.9690 - accuracy: 0.1982\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.8197 - accuracy: 0.2010\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.9844 - accuracy: 0.2003\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.1849 - accuracy: 0.1996\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.4557 - accuracy: 0.1996\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.9237 - accuracy: 0.1996\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.6248 - accuracy: 0.1982\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4003 - accuracy: 0.1969\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2280 - accuracy: 0.1982\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0295 - accuracy: 0.1996\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1428 - accuracy: 0.1996\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3387 - accuracy: 0.1996\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6775 - accuracy: 0.2003\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1540 - accuracy: 0.2003\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7023 - accuracy: 0.1996\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3446 - accuracy: 0.2010\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9660 - accuracy: 0.2010\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7347 - accuracy: 0.2023\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5392 - accuracy: 0.2016\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3085 - accuracy: 0.2003\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0838 - accuracy: 0.1982\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8842 - accuracy: 0.1996\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7226 - accuracy: 0.1996\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5174 - accuracy: 0.1989\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3250 - accuracy: 0.1982\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1684 - accuracy: 0.1989\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0006 - accuracy: 0.1989\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7851 - accuracy: 0.1989\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5269 - accuracy: 0.1982\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3166 - accuracy: 0.1989\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1286 - accuracy: 0.1982\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0156 - accuracy: 0.1989\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9456 - accuracy: 0.1982\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8591 - accuracy: 0.1989\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7584 - accuracy: 0.1982\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6354 - accuracy: 0.1982\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 4.3846 - accuracy: 0.1982\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1804 - accuracy: 0.1982\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9899 - accuracy: 0.1975\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8747 - accuracy: 0.1989\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7864 - accuracy: 0.1989\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7068 - accuracy: 0.1982\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.6345 - accuracy: 0.1989\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.5631 - accuracy: 0.1989\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.4942 - accuracy: 0.1989\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.4285 - accuracy: 0.1989\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.3781 - accuracy: 0.1989\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.2833 - accuracy: 0.1989\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.2160 - accuracy: 0.1989\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.1519 - accuracy: 0.1996\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.0866 - accuracy: 0.1996\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.0217 - accuracy: 0.1996\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9589 - accuracy: 0.1996\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 2.8967 - accuracy: 0.2003\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8450 - accuracy: 0.2003\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8001 - accuracy: 0.2003\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7576 - accuracy: 0.1996\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7117 - accuracy: 0.2003\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6736 - accuracy: 0.1996\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6255 - accuracy: 0.2003\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 2.5830 - accuracy: 0.1996\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5463 - accuracy: 0.2003\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5132 - accuracy: 0.2003\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4768 - accuracy: 0.2003\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4446 - accuracy: 0.1989\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4162 - accuracy: 0.2003\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3833 - accuracy: 0.1996\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3544 - accuracy: 0.2003\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3410 - accuracy: 0.1996\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3361 - accuracy: 0.1996\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3312 - accuracy: 0.1996\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3264 - accuracy: 0.1996\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3216 - accuracy: 0.1996\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3168 - accuracy: 0.1989\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3122 - accuracy: 0.1996\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3079 - accuracy: 0.1989\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3038 - accuracy: 0.1989\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2997 - accuracy: 0.1989\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2956 - accuracy: 0.1989\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2917 - accuracy: 0.1989\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2876 - accuracy: 0.1989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4d749c5c8>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.08446866485013624\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[15 13  4  0  0]\n",
      " [19 65 16 24  3]\n",
      " [ 4 25 11 36  3]\n",
      " [ 2 30 17 22 27]\n",
      " [ 1  3  5 12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.00      0.00      0.00        98\n",
      "         5.0       0.08      1.00      0.16        31\n",
      "\n",
      "    accuracy                           0.08       367\n",
      "   macro avg       0.02      0.20      0.03       367\n",
      "weighted avg       0.01      0.08      0.01       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_555 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_556 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_557 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_558 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_559 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,357\n",
      "Trainable params: 20,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 12.4842 - accuracy: 0.1560\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7490 - accuracy: 0.1553\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7490 - accuracy: 0.1553\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7490 - accuracy: 0.1553\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7490 - accuracy: 0.1553\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7490 - accuracy: 0.1553\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7491 - accuracy: 0.1553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4d87df1c8>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.09536784741144415\n",
      "Tasa de aciertos balanceada regresión logística: 0.09\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [23  0  0  9  0  0]\n",
      " [81  0  0 46  0  0]\n",
      " [44  0  0 35  0  0]\n",
      " [57  0  0 41  0  0]\n",
      " [14  0  0 17  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.24      0.44      0.31        79\n",
      "         4.0       0.00      0.00      0.00        98\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.10       367\n",
      "   macro avg       0.04      0.07      0.05       367\n",
      "weighted avg       0.05      0.10      0.07       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_560 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_561 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_562 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_563 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_564 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,999\n",
      "Trainable params: 8,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8828 - accuracy: 0.0014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4d8bcf408>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0  32]\n",
      " [  1   0   0   0   0 126]\n",
      " [  3   0   0   0   0  76]\n",
      " [  2   0   0   0   0  96]\n",
      " [  0   0   0   0   0  31]\n",
      " [  0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00      32.0\n",
      "         2.0       0.00      0.00      0.00     127.0\n",
      "         3.0       0.00      0.00      0.00      79.0\n",
      "         4.0       0.00      0.00      0.00      98.0\n",
      "         5.0       0.00      0.00      0.00      31.0\n",
      "         6.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00     367.0\n",
      "   macro avg       0.00      0.00      0.00     367.0\n",
      "weighted avg       0.00      0.00      0.00     367.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_565 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_566 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_567 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_568 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_569 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,711\n",
      "Trainable params: 2,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 9.3220 - accuracy: 0.0620\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - accuracy: 0.0620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4d9f89048>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.14986376021798364\n",
      "Tasa de aciertos balanceada regresión logística: 0.11\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [23  0  0  9  0  0]\n",
      " [81  0  0 46  0  0]\n",
      " [44  0  0 35  0  0]\n",
      " [57  0  0 41  0  0]\n",
      " [14  0  0 17  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.27      0.56      0.36        98\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.15       367\n",
      "   macro avg       0.04      0.09      0.06       367\n",
      "weighted avg       0.07      0.15      0.10       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_570 (Dense)           (None, 100)               2300      \n",
      "                                                                 \n",
      " dense_571 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_572 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_573 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_574 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_575 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_576 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_577 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_578 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_579 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,419\n",
      "Trainable params: 11,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 13.0546 - accuracy: 0.0109\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.1222 - accuracy: 0.0334\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.7685 - accuracy: 0.0736\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6034 - accuracy: 0.0722\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6948 - accuracy: 0.0654\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4000 - accuracy: 0.0967\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.2329 - accuracy: 0.1090\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3447 - accuracy: 0.0974\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3546 - accuracy: 0.0974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4da367448>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1008174386920981\n",
      "Tasa de aciertos balanceada regresión logística: 0.06\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [28  0  4  0  0  0]\n",
      " [91  0 36  0  0  0]\n",
      " [47  0 29  0  0  3]\n",
      " [66  0 27  0  0  5]\n",
      " [19  0 11  0  0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.34      0.28      0.31       127\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.00      0.00      0.00        98\n",
      "         5.0       0.11      0.03      0.05        31\n",
      "\n",
      "    accuracy                           0.10       367\n",
      "   macro avg       0.07      0.05      0.06       367\n",
      "weighted avg       0.13      0.10      0.11       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_580 (Dense)           (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_581 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_582 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_583 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_584 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_585 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_586 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_587 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_588 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_589 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,279\n",
      "Trainable params: 5,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1599 - accuracy: 0.1376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4db751088>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.24795640326975477\n",
      "Tasa de aciertos balanceada regresión logística: 0.14\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 3  0 29  0  0  0]\n",
      " [36  0 91  0  0  0]\n",
      " [31  0 48  0  0  0]\n",
      " [27  0 71  0  0  0]\n",
      " [11  0 20  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.35      0.72      0.47       127\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.00      0.00      0.00        98\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.25       367\n",
      "   macro avg       0.06      0.12      0.08       367\n",
      "weighted avg       0.12      0.25      0.16       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_590 (Dense)           (None, 32)                736       \n",
      "                                                                 \n",
      " dense_591 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_592 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_593 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_594 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_595 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_596 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_597 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_598 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_599 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,745\n",
      "Trainable params: 1,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9803 - accuracy: 0.1989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4dcd04a88>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.08446866485013624\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [28  0  4  0  0  0]\n",
      " [91  0 36  0  0  0]\n",
      " [47  0 29  0  0  3]\n",
      " [66  0 27  0  0  5]\n",
      " [19  0 11  0  0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       127\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.00      0.00      0.00        98\n",
      "         5.0       0.08      1.00      0.16        31\n",
      "\n",
      "    accuracy                           0.08       367\n",
      "   macro avg       0.02      0.20      0.03       367\n",
      "weighted avg       0.01      0.08      0.01       367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 36, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_600 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_601 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_602 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_603 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_604 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,465\n",
      "Trainable params: 11,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 1636.7673 - accuracy: 0.1501\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 160.3486 - accuracy: 0.2410\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.0814 - accuracy: 0.2713\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.5676 - accuracy: 0.3092\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.1516 - accuracy: 0.3127\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.2859 - accuracy: 0.3120\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.2095 - accuracy: 0.3354\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.1127 - accuracy: 0.3678\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.5348 - accuracy: 0.3499\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.4226 - accuracy: 0.3561\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.9638 - accuracy: 0.3457\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.1864 - accuracy: 0.3671\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.2979 - accuracy: 0.3678\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.7119 - accuracy: 0.3623\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1002 - accuracy: 0.4449\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.5780 - accuracy: 0.3871\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.3212 - accuracy: 0.3864\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.8945 - accuracy: 0.3822\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.3137 - accuracy: 0.3988\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.2694 - accuracy: 0.3685\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.6062 - accuracy: 0.4298\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.3366 - accuracy: 0.3705\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.3904 - accuracy: 0.4132\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.7590 - accuracy: 0.4132\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.4171 - accuracy: 0.4174\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.9575 - accuracy: 0.4284\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.1583 - accuracy: 0.3299\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6186 - accuracy: 0.4401\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.4388 - accuracy: 0.4050\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.6213 - accuracy: 0.4539\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9719 - accuracy: 0.4373\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9004 - accuracy: 0.4187\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0407 - accuracy: 0.4656\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.6174 - accuracy: 0.4242\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.3942 - accuracy: 0.4008\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4606 - accuracy: 0.4621\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.2005 - accuracy: 0.4807\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.5912 - accuracy: 0.4408\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9049 - accuracy: 0.4318\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1198 - accuracy: 0.4380\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0857 - accuracy: 0.4731\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9403 - accuracy: 0.4518\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.0034 - accuracy: 0.4828\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4535 - accuracy: 0.4311\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.4151 - accuracy: 0.4532\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9691 - accuracy: 0.4215\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1100 - accuracy: 0.4215\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6729 - accuracy: 0.4766\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0829 - accuracy: 0.4428\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5084 - accuracy: 0.4807\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.0751 - accuracy: 0.4525\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4990 - accuracy: 0.4532\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2772 - accuracy: 0.5124\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2662 - accuracy: 0.4387\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1656 - accuracy: 0.4587\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0076 - accuracy: 0.4105\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8687 - accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9467 - accuracy: 0.4683\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4238 - accuracy: 0.4821\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0504 - accuracy: 0.4766\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7761 - accuracy: 0.4814\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2175 - accuracy: 0.4146\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0161 - accuracy: 0.4325\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2951 - accuracy: 0.5028\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4710 - accuracy: 0.4656\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7200 - accuracy: 0.5165\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7165 - accuracy: 0.4394\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3148 - accuracy: 0.4676\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6756 - accuracy: 0.4552\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3877 - accuracy: 0.4690\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2322 - accuracy: 0.4566\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2669 - accuracy: 0.5076\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7256 - accuracy: 0.4470\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6194 - accuracy: 0.4559\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6632 - accuracy: 0.4904\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2825 - accuracy: 0.4787\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7545 - accuracy: 0.4766\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6893 - accuracy: 0.4442\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3787 - accuracy: 0.4635\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8867 - accuracy: 0.4725\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7662 - accuracy: 0.5124\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8516 - accuracy: 0.5289\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8461 - accuracy: 0.5028\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1071 - accuracy: 0.4883\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9037 - accuracy: 0.5055\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8984 - accuracy: 0.4711\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2804 - accuracy: 0.4456\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3354 - accuracy: 0.4435\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1055 - accuracy: 0.4725\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3046 - accuracy: 0.4745\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1071 - accuracy: 0.4821\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3222 - accuracy: 0.4821\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8484 - accuracy: 0.4656\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5480 - accuracy: 0.4910\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0903 - accuracy: 0.4421\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7120 - accuracy: 0.4304\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7470 - accuracy: 0.4869\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9205 - accuracy: 0.4656\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8101 - accuracy: 0.4483\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6750 - accuracy: 0.4649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4c0c2c608>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3939393939393939\n",
      "Tasa de aciertos balanceada regresión logística: 0.43\n",
      "Matriz de confusión:\n",
      "[[25  1  5  1  0]\n",
      " [21 16 57 29  1]\n",
      " [ 0  0 43 34  2]\n",
      " [ 0  1 31 55 10]\n",
      " [ 0  0 13 14  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.54      0.78      0.64        32\n",
      "         2.0       0.89      0.13      0.23       124\n",
      "         3.0       0.29      0.54      0.38        79\n",
      "         4.0       0.41      0.57      0.48        97\n",
      "         5.0       0.24      0.13      0.17        31\n",
      "\n",
      "    accuracy                           0.39       363\n",
      "   macro avg       0.47      0.43      0.38       363\n",
      "weighted avg       0.54      0.39      0.36       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_605 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_606 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_607 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_608 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_609 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,612\n",
      "Trainable params: 5,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 2338.3396 - accuracy: 0.1990\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 217.2359 - accuracy: 0.2142\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 136.9371 - accuracy: 0.2335\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 102.1875 - accuracy: 0.2555\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 97.4724 - accuracy: 0.2548\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.8203 - accuracy: 0.2865\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.6709 - accuracy: 0.3058\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.7168 - accuracy: 0.3003\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.9506 - accuracy: 0.3209\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 69.9769 - accuracy: 0.3244\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 49.7917 - accuracy: 0.3512\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.8325 - accuracy: 0.3140\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.7541 - accuracy: 0.3395\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.3624 - accuracy: 0.3526\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.4601 - accuracy: 0.3478\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.6687 - accuracy: 0.3795\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.6531 - accuracy: 0.3939\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 40.4296 - accuracy: 0.3905\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.7487 - accuracy: 0.3967\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.0931 - accuracy: 0.3933\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.5437 - accuracy: 0.4132\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.8602 - accuracy: 0.4208\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.3396 - accuracy: 0.4380\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.6147 - accuracy: 0.4194\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.7080 - accuracy: 0.4325\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.8965 - accuracy: 0.4050\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 21.3788 - accuracy: 0.4573\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.4885 - accuracy: 0.4270\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.5872 - accuracy: 0.4339\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.1886 - accuracy: 0.4339\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 19.0057 - accuracy: 0.4291\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 19.4940 - accuracy: 0.4304\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.9224 - accuracy: 0.4738\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.0163 - accuracy: 0.4174\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.4930 - accuracy: 0.4828\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.2804 - accuracy: 0.4380\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2718 - accuracy: 0.4745\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.6895 - accuracy: 0.4614\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7114 - accuracy: 0.4580\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3406 - accuracy: 0.4904\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.9673 - accuracy: 0.4318\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.7025 - accuracy: 0.4635\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9007 - accuracy: 0.4635\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8866 - accuracy: 0.4614\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7276 - accuracy: 0.4876\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0807 - accuracy: 0.4738\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.5710 - accuracy: 0.3994\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1872 - accuracy: 0.4270\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0158 - accuracy: 0.4711\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.8757 - accuracy: 0.4552\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.1385 - accuracy: 0.4766\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3939 - accuracy: 0.4711\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0055 - accuracy: 0.4601\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0565 - accuracy: 0.4855\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5623 - accuracy: 0.4711\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.9304 - accuracy: 0.3843\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2998 - accuracy: 0.4394\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1240 - accuracy: 0.4236\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.1245 - accuracy: 0.5076\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.8333 - accuracy: 0.4504\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9214 - accuracy: 0.4904\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6256 - accuracy: 0.4731\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.4959 - accuracy: 0.4532\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.9625 - accuracy: 0.4525\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.6585 - accuracy: 0.4387\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.6754 - accuracy: 0.4435\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7226 - accuracy: 0.5145\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2225 - accuracy: 0.4304\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3499 - accuracy: 0.5200\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1401 - accuracy: 0.4304\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8330 - accuracy: 0.4442\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7346 - accuracy: 0.4628\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7449 - accuracy: 0.4945\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7247 - accuracy: 0.4532\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1608 - accuracy: 0.4656\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3394 - accuracy: 0.4635\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3088 - accuracy: 0.4573\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9881 - accuracy: 0.4663\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7654 - accuracy: 0.4490\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3921 - accuracy: 0.4938\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3424 - accuracy: 0.4890\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7445 - accuracy: 0.4236\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6236 - accuracy: 0.4738\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2390 - accuracy: 0.4594\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9457 - accuracy: 0.5014\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2504 - accuracy: 0.4835\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0203 - accuracy: 0.4945\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0769 - accuracy: 0.4525\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4925 - accuracy: 0.5179\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2217 - accuracy: 0.4621\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5688 - accuracy: 0.4236\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5405 - accuracy: 0.4814\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7509 - accuracy: 0.4848\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4842 - accuracy: 0.4745\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2825 - accuracy: 0.3912\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1013 - accuracy: 0.4552\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3361 - accuracy: 0.4931\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7724 - accuracy: 0.4931\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3746 - accuracy: 0.5152\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9688 - accuracy: 0.5213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4de56e148>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.5482093663911846\n",
      "Tasa de aciertos balanceada regresión logística: 0.50\n",
      "Matriz de confusión:\n",
      "[[21  9  0  0  2]\n",
      " [11 74 30  9  0]\n",
      " [ 1 13 29 32  4]\n",
      " [ 0  2 12 71 12]\n",
      " [ 0  2  6 19  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.64      0.66      0.65        32\n",
      "         2.0       0.74      0.60      0.66       124\n",
      "         3.0       0.38      0.37      0.37        79\n",
      "         4.0       0.54      0.73      0.62        97\n",
      "         5.0       0.18      0.13      0.15        31\n",
      "\n",
      "    accuracy                           0.55       363\n",
      "   macro avg       0.50      0.50      0.49       363\n",
      "weighted avg       0.55      0.55      0.54       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_610 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_611 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_612 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_613 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_614 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,058\n",
      "Trainable params: 2,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 1667.4067 - accuracy: 0.1908\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.5867 - accuracy: 0.2817\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1676 - accuracy: 0.2837\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3413 - accuracy: 0.2810\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1216 - accuracy: 0.2817\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0223 - accuracy: 0.2817\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9993 - accuracy: 0.2817\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9863 - accuracy: 0.2817\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0204 - accuracy: 0.2817\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9396 - accuracy: 0.2817\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8409 - accuracy: 0.2817\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9037 - accuracy: 0.2817\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8685 - accuracy: 0.2817\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7978 - accuracy: 0.2817\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8724 - accuracy: 0.2817\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7750 - accuracy: 0.2824\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8213 - accuracy: 0.2817\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7382 - accuracy: 0.2817\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7137 - accuracy: 0.2824\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7073 - accuracy: 0.2824\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7012 - accuracy: 0.2824\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6955 - accuracy: 0.2824\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6902 - accuracy: 0.2824\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6852 - accuracy: 0.2824\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6805 - accuracy: 0.2824\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6760 - accuracy: 0.2824\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6718 - accuracy: 0.2824\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6678 - accuracy: 0.2824\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6640 - accuracy: 0.2824\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6605 - accuracy: 0.2824\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6571 - accuracy: 0.2824\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6538 - accuracy: 0.2824\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6508 - accuracy: 0.2824\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6478 - accuracy: 0.2824\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6451 - accuracy: 0.2824\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6424 - accuracy: 0.2824\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6399 - accuracy: 0.2824\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6374 - accuracy: 0.2824\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6351 - accuracy: 0.2824\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6329 - accuracy: 0.2824\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6308 - accuracy: 0.2824\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6287 - accuracy: 0.2824\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6268 - accuracy: 0.2824\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6250 - accuracy: 0.2824\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6237 - accuracy: 0.2824\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6220 - accuracy: 0.2824\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6203 - accuracy: 0.2824\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6187 - accuracy: 0.2824\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6171 - accuracy: 0.2824\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6157 - accuracy: 0.2824\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6145 - accuracy: 0.2824\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6133 - accuracy: 0.2824\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6118 - accuracy: 0.2824\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6106 - accuracy: 0.2824\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6103 - accuracy: 0.2824\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6090 - accuracy: 0.2824\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6079 - accuracy: 0.2824\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6065 - accuracy: 0.2824\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6054 - accuracy: 0.2824\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6042 - accuracy: 0.2824\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6032 - accuracy: 0.2824\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6026 - accuracy: 0.2824\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6018 - accuracy: 0.2824\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6009 - accuracy: 0.2824\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6000 - accuracy: 0.2824\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5993 - accuracy: 0.2824\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5985 - accuracy: 0.2824\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5977 - accuracy: 0.2824\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5969 - accuracy: 0.2824\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5962 - accuracy: 0.2824\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5956 - accuracy: 0.2824\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5949 - accuracy: 0.2824\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5942 - accuracy: 0.2824\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5936 - accuracy: 0.2824\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5931 - accuracy: 0.2824\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5924 - accuracy: 0.2824\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5917 - accuracy: 0.2824\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5912 - accuracy: 0.2824\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5906 - accuracy: 0.2824\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5900 - accuracy: 0.2824\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5895 - accuracy: 0.2824\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5890 - accuracy: 0.2824\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5885 - accuracy: 0.2824\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5880 - accuracy: 0.2824\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5876 - accuracy: 0.2824\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5871 - accuracy: 0.2824\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5867 - accuracy: 0.2824\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5862 - accuracy: 0.2824\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5858 - accuracy: 0.2824\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5854 - accuracy: 0.2824\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5850 - accuracy: 0.2824\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5846 - accuracy: 0.2824\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5842 - accuracy: 0.2824\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5839 - accuracy: 0.2824\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5834 - accuracy: 0.2824\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5831 - accuracy: 0.2824\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5827 - accuracy: 0.2824\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5824 - accuracy: 0.2824\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5822 - accuracy: 0.2824\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5818 - accuracy: 0.2824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4de87f948>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.25895316804407714\n",
      "Tasa de aciertos balanceada regresión logística: 0.19\n",
      "Matriz de confusión:\n",
      "[[25  1  5  1  0]\n",
      " [21 16 57 29  1]\n",
      " [ 0  0 43 34  2]\n",
      " [ 0  1 31 55 10]\n",
      " [ 0  0 13 14  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       124\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.27      0.97      0.42        97\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.26       363\n",
      "   macro avg       0.05      0.16      0.07       363\n",
      "weighted avg       0.07      0.26      0.11       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 36, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_615 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_616 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_617 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_618 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_619 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,757\n",
      "Trainable params: 21,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3189 - accuracy: 0.1901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4dfd3c0c8>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.21763085399449036\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0  32   0   0]\n",
      " [  0   0 124   0   0]\n",
      " [  0   0  79   0   0]\n",
      " [  0   0  97   0   0]\n",
      " [  0   0  31   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       124\n",
      "         3.0       0.22      1.00      0.36        79\n",
      "         4.0       0.00      0.00      0.00        97\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.22       363\n",
      "   macro avg       0.04      0.20      0.07       363\n",
      "weighted avg       0.05      0.22      0.08       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_620 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_621 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_622 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_623 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_624 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,895\n",
      "Trainable params: 9,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3622 - accuracy: 0.1942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4e1123308>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1928374655647383\n",
      "Tasa de aciertos balanceada regresión logística: 0.13\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [17  0 10  0  5  0]\n",
      " [54  0 34  0 36  0]\n",
      " [28  0 27  0 24  0]\n",
      " [26  0 35  0 36  0]\n",
      " [ 8  0 13  0 10  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.29      0.27      0.28       124\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.32      0.37      0.35        97\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.19       363\n",
      "   macro avg       0.10      0.11      0.10       363\n",
      "weighted avg       0.18      0.19      0.19       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_625 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_626 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_627 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_628 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_629 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,159\n",
      "Trainable params: 3,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 13.6095 - accuracy: 0.0826\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.3448 - accuracy: 0.0764\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.5553 - accuracy: 0.0565\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.9758 - accuracy: 0.0620\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0325 - accuracy: 0.0634\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0323 - accuracy: 0.0634\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0323 - accuracy: 0.0634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4e142bfc8>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0743801652892562\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0  32   0   0]\n",
      " [  0   0 124   0   0]\n",
      " [  0   0  79   0   0]\n",
      " [  0   0  97   0   0]\n",
      " [  0   0  31   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.11      0.84      0.20        32\n",
      "         2.0       0.00      0.00      0.00       124\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.00      0.00      0.00        97\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.07       363\n",
      "   macro avg       0.02      0.14      0.03       363\n",
      "weighted avg       0.01      0.07      0.02       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 36, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_630 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_631 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_632 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_633 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_634 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_635 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_636 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_637 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_638 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_639 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,819\n",
      "Trainable params: 12,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 9.3101 - accuracy: 0.1860\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2687 - accuracy: 0.1970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4d5835f08>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.08539944903581267\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  32]\n",
      " [  0   0   0   0 124]\n",
      " [  0   0   0   0  79]\n",
      " [  0   0   0   0  97]\n",
      " [  0   0   0   0  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       124\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.00      0.00      0.00        97\n",
      "         5.0       0.09      1.00      0.16        31\n",
      "\n",
      "    accuracy                           0.09       363\n",
      "   macro avg       0.02      0.20      0.03       363\n",
      "weighted avg       0.01      0.09      0.01       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_640 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_641 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_642 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_643 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_644 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_645 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_646 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_647 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_648 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_649 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,175\n",
      "Trainable params: 6,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 13.0368 - accuracy: 0.1012\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0380 - accuracy: 0.1061\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0380 - accuracy: 0.1061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4de485788>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0881542699724518\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 32   0   0   0   0]\n",
      " [124   0   0   0   0]\n",
      " [ 79   0   0   0   0]\n",
      " [ 97   0   0   0   0]\n",
      " [ 31   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.09      1.00      0.16        32\n",
      "         2.0       0.00      0.00      0.00       124\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.00      0.00      0.00        97\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.09       363\n",
      "   macro avg       0.02      0.20      0.03       363\n",
      "weighted avg       0.01      0.09      0.01       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_650 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_651 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_652 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_653 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_654 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_655 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_656 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_657 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_658 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_659 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,193\n",
      "Trainable params: 2,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 3ms/step - loss: 6.9999 - accuracy: 0.1860\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.1901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4bad7a288>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.21763085399449036\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0  32]\n",
      " [  0   0   0   0 124]\n",
      " [  0   0   0   0  79]\n",
      " [  0   0   0   0  97]\n",
      " [  0   0   0   0  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       124\n",
      "         3.0       0.22      1.00      0.36        79\n",
      "         4.0       0.00      0.00      0.00        97\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.22       363\n",
      "   macro avg       0.04      0.20      0.07       363\n",
      "weighted avg       0.05      0.22      0.08       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_660 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_661 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_662 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_663 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_664 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,465\n",
      "Trainable params: 11,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 1773.1967 - accuracy: 0.2094\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 636.6418 - accuracy: 0.2293\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 396.9919 - accuracy: 0.2307\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 309.4119 - accuracy: 0.2266\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 257.1439 - accuracy: 0.2163\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 207.2959 - accuracy: 0.2245\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 176.2536 - accuracy: 0.2273\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 155.8232 - accuracy: 0.2417\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 138.3792 - accuracy: 0.2424\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 134.7160 - accuracy: 0.2603\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 121.6050 - accuracy: 0.2617\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 121.3549 - accuracy: 0.2796\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 110.5673 - accuracy: 0.2748\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 111.0814 - accuracy: 0.2617\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 104.3722 - accuracy: 0.2775\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 99.3468 - accuracy: 0.2720\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 94.5539 - accuracy: 0.2961\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 95.9838 - accuracy: 0.2941\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 96.0062 - accuracy: 0.2955\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 93.5781 - accuracy: 0.3099\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.4812 - accuracy: 0.2989\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.2296 - accuracy: 0.3017\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 88.1398 - accuracy: 0.2927\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.3359 - accuracy: 0.3189\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.7368 - accuracy: 0.3196\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.2577 - accuracy: 0.3154\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.5236 - accuracy: 0.3168\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.8776 - accuracy: 0.3175\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.4115 - accuracy: 0.3140\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4110 - accuracy: 0.3092\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.0007 - accuracy: 0.3457\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.9217 - accuracy: 0.3320\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.1675 - accuracy: 0.3051\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 76.4188 - accuracy: 0.3230\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 74.2917 - accuracy: 0.3223\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.1199 - accuracy: 0.3258\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.0125 - accuracy: 0.3306\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.5559 - accuracy: 0.3251\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.7211 - accuracy: 0.3430\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.5656 - accuracy: 0.3437\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.8109 - accuracy: 0.3320\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.1020 - accuracy: 0.3361\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.5995 - accuracy: 0.3299\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.9044 - accuracy: 0.3499\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.4383 - accuracy: 0.3361\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.6964 - accuracy: 0.3430\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.1806 - accuracy: 0.3361\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.7703 - accuracy: 0.3554\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.4537 - accuracy: 0.3485\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.1293 - accuracy: 0.3547\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.3094 - accuracy: 0.3402\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.6893 - accuracy: 0.3423\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.8541 - accuracy: 0.3519\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.9844 - accuracy: 0.3478\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.8374 - accuracy: 0.3444\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.1056 - accuracy: 0.3457\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.6933 - accuracy: 0.3629\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.8477 - accuracy: 0.3588\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.9194 - accuracy: 0.3506\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.4935 - accuracy: 0.3512\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.0368 - accuracy: 0.3368\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.3801 - accuracy: 0.3512\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.1248 - accuracy: 0.3492\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 60.7011 - accuracy: 0.3554\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.2865 - accuracy: 0.3567\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.8272 - accuracy: 0.3533\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.9818 - accuracy: 0.3519\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.2170 - accuracy: 0.3485\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.2923 - accuracy: 0.3733\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.4132 - accuracy: 0.3609\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.4947 - accuracy: 0.3574\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.9427 - accuracy: 0.3595\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.7925 - accuracy: 0.3712\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.7907 - accuracy: 0.3636\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.1950 - accuracy: 0.3705\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.6715 - accuracy: 0.3602\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.9313 - accuracy: 0.3526\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.9482 - accuracy: 0.3650\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.5539 - accuracy: 0.3595\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.6628 - accuracy: 0.3712\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.3178 - accuracy: 0.3650\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.5538 - accuracy: 0.3678\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.7969 - accuracy: 0.3726\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.7189 - accuracy: 0.3691\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.8530 - accuracy: 0.3705\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.5660 - accuracy: 0.3657\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.7361 - accuracy: 0.3671\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.9127 - accuracy: 0.3664\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.9681 - accuracy: 0.3753\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.1891 - accuracy: 0.3685\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.4013 - accuracy: 0.3815\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.2225 - accuracy: 0.3809\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.0435 - accuracy: 0.3657\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.0094 - accuracy: 0.3609\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.1919 - accuracy: 0.3760\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.7029 - accuracy: 0.3760\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.6143 - accuracy: 0.3719\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.4328 - accuracy: 0.3829\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.1454 - accuracy: 0.3815\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.7701 - accuracy: 0.3802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4bb2ba348>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.22865013774104684\n",
      "Tasa de aciertos balanceada regresión logística: 0.28\n",
      "Matriz de confusión:\n",
      "[[13  3 11  4  1]\n",
      " [31  4 25 48 16]\n",
      " [ 9  2 12 50  6]\n",
      " [12  1 10 43 31]\n",
      " [ 4  0  2 14 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.19      0.41      0.26        32\n",
      "         2.0       0.40      0.03      0.06       124\n",
      "         3.0       0.20      0.15      0.17        79\n",
      "         4.0       0.27      0.44      0.34        97\n",
      "         5.0       0.17      0.35      0.23        31\n",
      "\n",
      "    accuracy                           0.23       363\n",
      "   macro avg       0.25      0.28      0.21       363\n",
      "weighted avg       0.28      0.23      0.19       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_665 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_666 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_667 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_668 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_669 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,612\n",
      "Trainable params: 5,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 1ms/step - loss: 2412.7039 - accuracy: 0.2087\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 711.0648 - accuracy: 0.2183\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 392.3934 - accuracy: 0.2342\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 252.2493 - accuracy: 0.2507\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 194.3739 - accuracy: 0.2479\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 153.5179 - accuracy: 0.2603\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 127.5364 - accuracy: 0.2658\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 113.7531 - accuracy: 0.2720\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 105.6777 - accuracy: 0.2707\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 99.9268 - accuracy: 0.2596\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 95.7216 - accuracy: 0.2645\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 89.8874 - accuracy: 0.2741\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 84.8892 - accuracy: 0.2693\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 80.8113 - accuracy: 0.2686\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.2537 - accuracy: 0.2658\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.9586 - accuracy: 0.2624\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.4006 - accuracy: 0.2748\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.4306 - accuracy: 0.2686\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.2308 - accuracy: 0.2803\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.8408 - accuracy: 0.2831\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.0155 - accuracy: 0.2775\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.6317 - accuracy: 0.2865\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.0048 - accuracy: 0.2886\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.7665 - accuracy: 0.2996\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.4620 - accuracy: 0.2913\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 57.9165 - accuracy: 0.2879\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.2864 - accuracy: 0.2899\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.8705 - accuracy: 0.2762\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 54.7359 - accuracy: 0.2906\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.9379 - accuracy: 0.2844\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.9225 - accuracy: 0.2913\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.0930 - accuracy: 0.2906\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.0025 - accuracy: 0.2927\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.6069 - accuracy: 0.2948\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.7640 - accuracy: 0.2886\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.0252 - accuracy: 0.2865\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.4721 - accuracy: 0.2934\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.7494 - accuracy: 0.2906\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.3104 - accuracy: 0.2886\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.5354 - accuracy: 0.3120\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.0133 - accuracy: 0.2865\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.9538 - accuracy: 0.2872\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.1523 - accuracy: 0.2941\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.8748 - accuracy: 0.2948\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.2343 - accuracy: 0.2961\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.8913 - accuracy: 0.2948\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.1856 - accuracy: 0.2989\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.7305 - accuracy: 0.2844\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.6448 - accuracy: 0.2989\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.8275 - accuracy: 0.2975\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.8452 - accuracy: 0.2899\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.5127 - accuracy: 0.2865\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0358 - accuracy: 0.2941\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.7959 - accuracy: 0.3030\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.0692 - accuracy: 0.2872\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.8184 - accuracy: 0.3065\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.3601 - accuracy: 0.3003\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.7117 - accuracy: 0.2872\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.8546 - accuracy: 0.2927\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.1661 - accuracy: 0.2913\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.8848 - accuracy: 0.2899\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.5568 - accuracy: 0.3010\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.1619 - accuracy: 0.3065\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.2498 - accuracy: 0.3003\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.5135 - accuracy: 0.2899\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.1086 - accuracy: 0.2899\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.1439 - accuracy: 0.2955\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.7553 - accuracy: 0.2982\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.1760 - accuracy: 0.3079\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.3641 - accuracy: 0.2934\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.6725 - accuracy: 0.3044\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.5755 - accuracy: 0.3010\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.1364 - accuracy: 0.3037\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.9722 - accuracy: 0.3017\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.4063 - accuracy: 0.3065\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.2491 - accuracy: 0.3065\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.4602 - accuracy: 0.3051\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.3064 - accuracy: 0.3065\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.7963 - accuracy: 0.2948\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.1608 - accuracy: 0.3030\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.4721 - accuracy: 0.2968\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.8664 - accuracy: 0.3154\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.7778 - accuracy: 0.2975\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.1222 - accuracy: 0.3092\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.9273 - accuracy: 0.3175\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.1469 - accuracy: 0.3079\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.2897 - accuracy: 0.2961\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.4281 - accuracy: 0.3134\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.9761 - accuracy: 0.2975\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.0868 - accuracy: 0.2989\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.4879 - accuracy: 0.3106\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.4409 - accuracy: 0.3147\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.5855 - accuracy: 0.3079\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.9836 - accuracy: 0.3230\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.1186 - accuracy: 0.2996\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.9033 - accuracy: 0.3120\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.4283 - accuracy: 0.3161\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.3895 - accuracy: 0.3072\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.9627 - accuracy: 0.3113\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.0348 - accuracy: 0.3127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4e59f4288>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.32231404958677684\n",
      "Tasa de aciertos balanceada regresión logística: 0.28\n",
      "Matriz de confusión:\n",
      "[[ 4 10 13  4  1]\n",
      " [11 50 42 13  8]\n",
      " [ 4 16 24 29  6]\n",
      " [ 1 20 24 32 20]\n",
      " [ 2  3  8 11  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.18      0.12      0.15        32\n",
      "         2.0       0.51      0.40      0.45       124\n",
      "         3.0       0.22      0.30      0.25        79\n",
      "         4.0       0.36      0.33      0.34        97\n",
      "         5.0       0.17      0.23      0.19        31\n",
      "\n",
      "    accuracy                           0.32       363\n",
      "   macro avg       0.29      0.28      0.28       363\n",
      "weighted avg       0.35      0.32      0.33       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_670 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_671 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_672 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_673 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_674 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,058\n",
      "Trainable params: 2,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 5203.1963 - accuracy: 0.2824\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2320.4258 - accuracy: 0.2824\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1229.3523 - accuracy: 0.2652\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 737.8929 - accuracy: 0.2679\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 517.3680 - accuracy: 0.2300\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 441.2490 - accuracy: 0.2328\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 394.2116 - accuracy: 0.2335\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 356.8955 - accuracy: 0.2335\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 326.3555 - accuracy: 0.2362\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 300.6942 - accuracy: 0.2493\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 276.5262 - accuracy: 0.2472\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 255.3275 - accuracy: 0.2472\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 236.4981 - accuracy: 0.2590\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 219.8196 - accuracy: 0.2555\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 203.6947 - accuracy: 0.2610\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 187.7207 - accuracy: 0.2472\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 172.5208 - accuracy: 0.2521\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 158.7340 - accuracy: 0.2431\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 147.6337 - accuracy: 0.2390\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 138.6254 - accuracy: 0.2472\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 130.5261 - accuracy: 0.2521\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 122.4931 - accuracy: 0.2562\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 115.2939 - accuracy: 0.2541\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 108.3074 - accuracy: 0.2555\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 102.3563 - accuracy: 0.2528\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 96.4014 - accuracy: 0.2417\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.9660 - accuracy: 0.2472\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 86.0127 - accuracy: 0.2438\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.4060 - accuracy: 0.2486\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 76.8107 - accuracy: 0.2438\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.4816 - accuracy: 0.2390\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.3230 - accuracy: 0.2390\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.6622 - accuracy: 0.2417\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.9412 - accuracy: 0.2362\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.6897 - accuracy: 0.2348\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.4967 - accuracy: 0.2321\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.4518 - accuracy: 0.2321\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.6800 - accuracy: 0.2328\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.0626 - accuracy: 0.2307\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.8017 - accuracy: 0.2314\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.6757 - accuracy: 0.2348\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.8405 - accuracy: 0.2342\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.1744 - accuracy: 0.2321\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.6677 - accuracy: 0.2376\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.2801 - accuracy: 0.2348\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.9844 - accuracy: 0.2410\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.8048 - accuracy: 0.2397\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.7142 - accuracy: 0.2383\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.7186 - accuracy: 0.2383\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.7624 - accuracy: 0.2369\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.9441 - accuracy: 0.2362\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.0882 - accuracy: 0.2424\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.2935 - accuracy: 0.2404\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.5098 - accuracy: 0.2362\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.7610 - accuracy: 0.2342\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.9969 - accuracy: 0.2342\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.2925 - accuracy: 0.2376\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.6459 - accuracy: 0.2397\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.0521 - accuracy: 0.2342\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.4456 - accuracy: 0.2362\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.8976 - accuracy: 0.2369\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.3599 - accuracy: 0.2376\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.8539 - accuracy: 0.2335\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.3456 - accuracy: 0.2348\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.8515 - accuracy: 0.2328\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.3760 - accuracy: 0.2335\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.8851 - accuracy: 0.2348\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.4163 - accuracy: 0.2335\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.9460 - accuracy: 0.2335\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.5201 - accuracy: 0.2321\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.1006 - accuracy: 0.2314\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.6913 - accuracy: 0.2273\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.3070 - accuracy: 0.2300\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.9105 - accuracy: 0.2273\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5085 - accuracy: 0.2266\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.1020 - accuracy: 0.2259\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.7182 - accuracy: 0.2238\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.3291 - accuracy: 0.2245\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.9959 - accuracy: 0.2245\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6919 - accuracy: 0.2225\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.4215 - accuracy: 0.2238\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1426 - accuracy: 0.2211\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.8573 - accuracy: 0.2218\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5958 - accuracy: 0.2204\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.3550 - accuracy: 0.2211\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0978 - accuracy: 0.2176\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.8434 - accuracy: 0.2197\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.5918 - accuracy: 0.2218\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3160 - accuracy: 0.2231\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0537 - accuracy: 0.2245\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7990 - accuracy: 0.2259\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5700 - accuracy: 0.2252\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3275 - accuracy: 0.2259\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0988 - accuracy: 0.2266\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8727 - accuracy: 0.2259\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6423 - accuracy: 0.2238\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4378 - accuracy: 0.2231\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2255 - accuracy: 0.2238\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0327 - accuracy: 0.2245\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8579 - accuracy: 0.2245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4e6ca4048>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2865013774104683\n",
      "Tasa de aciertos balanceada regresión logística: 0.22\n",
      "Matriz de confusión:\n",
      "[[13  3 11  4  1]\n",
      " [31  4 25 48 16]\n",
      " [ 9  2 12 50  6]\n",
      " [12  1 10 43 31]\n",
      " [ 4  0  2 14 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.34      0.68      0.46       124\n",
      "         3.0       0.17      0.10      0.13        79\n",
      "         4.0       0.18      0.04      0.07        97\n",
      "         5.0       0.16      0.26      0.20        31\n",
      "\n",
      "    accuracy                           0.29       363\n",
      "   macro avg       0.17      0.22      0.17       363\n",
      "weighted avg       0.22      0.29      0.22       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_675 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_676 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_677 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_678 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_679 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,757\n",
      "Trainable params: 21,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 14.2540 - accuracy: 0.1061\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4086 - accuracy: 0.1061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4e70a7208>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0881542699724518\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 32   0   0   0   0]\n",
      " [124   0   0   0   0]\n",
      " [ 79   0   0   0   0]\n",
      " [ 97   0   0   0   0]\n",
      " [ 31   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.09      1.00      0.16        32\n",
      "         2.0       0.00      0.00      0.00       124\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.00      0.00      0.00        97\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.09       363\n",
      "   macro avg       0.02      0.20      0.03       363\n",
      "weighted avg       0.01      0.09      0.01       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_680 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_681 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_682 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_683 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_684 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,895\n",
      "Trainable params: 9,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 12.2940 - accuracy: 0.1198\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9902 - accuracy: 0.1205\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9314 - accuracy: 0.1288\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5945 - accuracy: 0.1357\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7178 - accuracy: 0.1309\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6223 - accuracy: 0.1295\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8326 - accuracy: 0.1274\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6847 - accuracy: 0.1219\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6847 - accuracy: 0.1219\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6846 - accuracy: 0.1219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4e846f0c8>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.24242424242424243\n",
      "Tasa de aciertos balanceada regresión logística: 0.14\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 4  0 28  0  0  0]\n",
      " [36  0 88  0  0  0]\n",
      " [32  0 47  0  0  0]\n",
      " [30  0 67  0  0  0]\n",
      " [11  0 20  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.35      0.71      0.47       124\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.00      0.00      0.00        97\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.24       363\n",
      "   macro avg       0.06      0.12      0.08       363\n",
      "weighted avg       0.12      0.24      0.16       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_685 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_686 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_687 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_688 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_689 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,159\n",
      "Trainable params: 3,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 1ms/step - loss: 7.7911 - accuracy: 0.1921\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6989 - accuracy: 0.2011\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6944 - accuracy: 0.2018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4e88593c8>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.1322314049586777\n",
      "Tasa de aciertos balanceada regresión logística: 0.18\n",
      "Matriz de confusión:\n",
      "[[ 32   0   0   0   0]\n",
      " [124   0   0   0   0]\n",
      " [ 79   0   0   0   0]\n",
      " [ 97   0   0   0   0]\n",
      " [ 31   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       124\n",
      "         3.0       0.26      0.42      0.32        79\n",
      "         4.0       0.00      0.00      0.00        97\n",
      "         5.0       0.07      0.48      0.12        31\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.13       363\n",
      "   macro avg       0.05      0.15      0.07       363\n",
      "weighted avg       0.06      0.13      0.08       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_690 (Dense)           (None, 100)               3700      \n",
      "                                                                 \n",
      " dense_691 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_692 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_693 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_694 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_695 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_696 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_697 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_698 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_699 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,819\n",
      "Trainable params: 12,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 13.7321 - accuracy: 0.1901\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7475 - accuracy: 0.1901\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7475 - accuracy: 0.1901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4e9c07cc8>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.21763085399449036\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0  32   0   0]\n",
      " [  0   0 124   0   0]\n",
      " [  0   0  79   0   0]\n",
      " [  0   0  97   0   0]\n",
      " [  0   0  31   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       124\n",
      "         3.0       0.22      1.00      0.36        79\n",
      "         4.0       0.00      0.00      0.00        97\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.22       363\n",
      "   macro avg       0.04      0.20      0.07       363\n",
      "weighted avg       0.05      0.22      0.08       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_700 (Dense)           (None, 64)                2368      \n",
      "                                                                 \n",
      " dense_701 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_702 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_703 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_704 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_705 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_706 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_707 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_708 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_709 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,175\n",
      "Trainable params: 6,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 2ms/step - loss: 10.2585 - accuracy: 0.1901\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5341 - accuracy: 0.1901\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5341 - accuracy: 0.1901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4ea0251c8>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.21763085399449036\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0  32   0   0]\n",
      " [  0   0 124   0   0]\n",
      " [  0   0  79   0   0]\n",
      " [  0   0  97   0   0]\n",
      " [  0   0  31   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       124\n",
      "         3.0       0.22      1.00      0.36        79\n",
      "         4.0       0.00      0.00      0.00        97\n",
      "         5.0       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.22       363\n",
      "   macro avg       0.04      0.20      0.07       363\n",
      "weighted avg       0.05      0.22      0.08       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_710 (Dense)           (None, 32)                1184      \n",
      "                                                                 \n",
      " dense_711 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_712 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_713 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_714 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_715 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_716 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_717 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_718 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_719 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,193\n",
      "Trainable params: 2,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.2245 - accuracy: 0.1970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4eb5d8708>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.08539944903581267\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0  32   0   0]\n",
      " [  0   0 124   0   0]\n",
      " [  0   0  79   0   0]\n",
      " [  0   0  97   0   0]\n",
      " [  0   0  31   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        32\n",
      "         2.0       0.00      0.00      0.00       124\n",
      "         3.0       0.00      0.00      0.00        79\n",
      "         4.0       0.00      0.00      0.00        97\n",
      "         5.0       0.09      1.00      0.16        31\n",
      "\n",
      "    accuracy                           0.09       363\n",
      "   macro avg       0.02      0.20      0.03       363\n",
      "weighted avg       0.01      0.09      0.01       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERVALO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.513228</td>\n",
       "      <td>0.304233</td>\n",
       "      <td>0.235450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.084656</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>0.275132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.338624</td>\n",
       "      <td>0.208995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.084656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.087302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.513228     0.304233     0.235450\n",
       "Experimento 2- RELU+ADAM         0.084656     0.264550     0.275132\n",
       "Experimento 3- RELU+ADAM         0.277778     0.000000     0.000000\n",
       "Experimento 1- RELU+ADAGRAD      0.351852     0.338624     0.208995\n",
       "Experimento 2- RELU+ADAGRAD      0.087302     0.087302     0.084656\n",
       "Experimento 3- RELU+ADAGRAD      0.277778     0.214286     0.087302"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['100 Neuronas'] = None\n",
    "df1['64 Neuronas'] = None\n",
    "df1['32 Neuronas'] = None\n",
    "df1.loc['Experimento 1- RELU+ADAM'] = [0.5132275132275133,0.30423280423280424,0.23544973544973544]\n",
    "df1.loc['Experimento 2- RELU+ADAM'] = [0.08465608465608465,0.26455026455026454,0.2751322751322751]\n",
    "df1.loc['Experimento 3- RELU+ADAM'] = [0.2777777777777778,0.0,0.0]\n",
    "df1.loc['Experimento 1- RELU+ADAGRAD'] =[0.35185185185185186,0.3386243386243386,0.20899470899470898]\n",
    "df1.loc['Experimento 2- RELU+ADAGRAD'] =[0.0873015873015873,0.0873015873015873,0.08465608465608465]\n",
    "df1.loc['Experimento 3- RELU+ADAGRAD'] = [0.2777777777777778,0.21428571428571427,0.0873015873015873]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.356948</td>\n",
       "      <td>0.389646</td>\n",
       "      <td>0.267030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.076294</td>\n",
       "      <td>0.346049</td>\n",
       "      <td>0.215259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.084469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.335150</td>\n",
       "      <td>0.302452</td>\n",
       "      <td>0.084469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.095368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.100817</td>\n",
       "      <td>0.247956</td>\n",
       "      <td>0.084469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.356948     0.389646     0.267030\n",
       "Experimento 2- RELU+ADAM         0.076294     0.346049     0.215259\n",
       "Experimento 3- RELU+ADAM         0.084469     0.000000     0.000000\n",
       "Experimento 1- RELU+ADAGRAD      0.335150     0.302452     0.084469\n",
       "Experimento 2- RELU+ADAGRAD      0.095368     0.000000     0.149864\n",
       "Experimento 3- RELU+ADAGRAD      0.100817     0.247956     0.084469"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['100 Neuronas'] = None\n",
    "df2['64 Neuronas'] = None\n",
    "df2['32 Neuronas'] = None\n",
    "df2.loc['Experimento 1- RELU+ADAM'] =[0.3569482288828338,0.3896457765667575,0.2670299727520436]\n",
    "df2.loc['Experimento 2- RELU+ADAM'] =[0.07629427792915532,0.3460490463215259,0.21525885558583105]\n",
    "df2.loc['Experimento 3- RELU+ADAM'] = [0.08446866485013624,0.0,0.0]\n",
    "df2.loc['Experimento 1- RELU+ADAGRAD'] = [0.335149863760218,0.3024523160762943,0.08446866485013624]\n",
    "df2.loc['Experimento 2- RELU+ADAGRAD'] = [0.09536784741144415,0.0,0.14986376021798364]\n",
    "df2.loc['Experimento 3- RELU+ADAGRAD'] = [0.1008174386920981, 0.24795640326975477,0.08446866485013624]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.548209</td>\n",
       "      <td>0.258953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.217631</td>\n",
       "      <td>0.192837</td>\n",
       "      <td>0.074380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.085399</td>\n",
       "      <td>0.088154</td>\n",
       "      <td>0.217631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.228650</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.286501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.088154</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.132231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.217631</td>\n",
       "      <td>0.217631</td>\n",
       "      <td>0.085399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.393939     0.548209     0.258953\n",
       "Experimento 2- RELU+ADAM         0.217631     0.192837     0.074380\n",
       "Experimento 3- RELU+ADAM         0.085399     0.088154     0.217631\n",
       "Experimento 1- RELU+ADAGRAD      0.228650     0.322314     0.286501\n",
       "Experimento 2- RELU+ADAGRAD      0.088154     0.242424     0.132231\n",
       "Experimento 3- RELU+ADAGRAD      0.217631     0.217631     0.085399"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame()\n",
    "df3['100 Neuronas'] = None\n",
    "df3['64 Neuronas'] = None\n",
    "df3['32 Neuronas'] = None\n",
    "df3.loc['Experimento 1- RELU+ADAM'] = [0.3939393939393939,0.5482093663911846,0.25895316804407714]\n",
    "df3.loc['Experimento 2- RELU+ADAM'] =[0.21763085399449036,0.1928374655647383,0.0743801652892562]\n",
    "df3.loc['Experimento 3- RELU+ADAM'] = [0.08539944903581267,0.0881542699724518,0.21763085399449036]\n",
    "df3.loc['Experimento 1- RELU+ADAGRAD'] = [0.22865013774104684,0.32231404958677684,0.2865013774104683]\n",
    "df3.loc['Experimento 2- RELU+ADAGRAD'] = [0.0881542699724518,0.24242424242424243,0.1322314049586777]\n",
    "df3.loc['Experimento 3- RELU+ADAGRAD'] = [0.21763085399449036,0.21763085399449036,0.08539944903581267]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1da4f960c88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,20))\n",
    "fig.add_subplot(2,2,1)\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 1')\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM' ,color ='red')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 2')\n",
    "fig.add_subplot(2,2,3)\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 3')\n",
    "plt.legend(bbox_to_anchor = (2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
