{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run 1dia-porintervalos1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix,balanced_accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subida(list):\n",
    "    resultado = []\n",
    "    for i in range(1,len(list)):\n",
    "        if  (list)[i] > (list)[i-1]:\n",
    "            resultado.append(1)\n",
    "        else:\n",
    "            resultado.append(0)\n",
    "    return resultado\n",
    "\n",
    "def acierto(list1,list2):\n",
    "    sum = 0\n",
    "    for i in range(0,len(list1)):\n",
    "        if(list1[i]==list2[i]):\n",
    "            sum = sum +1\n",
    "    a = sum/len(list1)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 11, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 25)                850       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,965\n",
      "Trainable params: 8,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 4s 4ms/step - loss: 335.3395 - accuracy: 0.3353\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 126.6111 - accuracy: 0.3611\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 123.6005 - accuracy: 0.3690\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 99.7703 - accuracy: 0.3439\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 91.3987 - accuracy: 0.3426\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 58.4218 - accuracy: 0.3393\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 67.2744 - accuracy: 0.3406\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 60.7250 - accuracy: 0.3657\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 50.6443 - accuracy: 0.3399\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 65.4950 - accuracy: 0.3373\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 50.5265 - accuracy: 0.3432\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 48.2219 - accuracy: 0.3564\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 55.2602 - accuracy: 0.3604\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 45.4208 - accuracy: 0.3630\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 37.3855 - accuracy: 0.3465\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 56.3109 - accuracy: 0.3254\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 47.3760 - accuracy: 0.3624\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 42.4072 - accuracy: 0.3571\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 35.8047 - accuracy: 0.3630\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 30.9864 - accuracy: 0.3743\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 32.6561 - accuracy: 0.3558\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 32.0664 - accuracy: 0.3446\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 26.4853 - accuracy: 0.3597\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 29.4056 - accuracy: 0.3650\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 26.1765 - accuracy: 0.3584\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 36.7822 - accuracy: 0.3492\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 24.7864 - accuracy: 0.3736\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 33.6097 - accuracy: 0.3518\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 27.3456 - accuracy: 0.3597\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 22.9564 - accuracy: 0.3479\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 22.7169 - accuracy: 0.3677\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 28.1114 - accuracy: 0.3736\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 24.5796 - accuracy: 0.3492\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 21.7523 - accuracy: 0.3505\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 26.5391 - accuracy: 0.3518\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 21.8898 - accuracy: 0.3795\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 17.2799 - accuracy: 0.3505\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 25.6474 - accuracy: 0.3419\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.3681 - accuracy: 0.3604\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.7829 - accuracy: 0.3723\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 13.4084 - accuracy: 0.3597\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 19.9684 - accuracy: 0.3663\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 17.2514 - accuracy: 0.3512\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7244 - accuracy: 0.3749\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 14.3942 - accuracy: 0.3578\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 13.9805 - accuracy: 0.3710\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.4382 - accuracy: 0.3729\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.0752 - accuracy: 0.3518\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.5051 - accuracy: 0.3795\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 13.8059 - accuracy: 0.3545\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 12.0866 - accuracy: 0.3756\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.8318 - accuracy: 0.3723\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 12.8429 - accuracy: 0.3525\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.3148 - accuracy: 0.3465\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.0801 - accuracy: 0.3710\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 13.8282 - accuracy: 0.3624\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.0354 - accuracy: 0.3729\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.8517 - accuracy: 0.3762\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.8314 - accuracy: 0.3591\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.4913 - accuracy: 0.3564\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6112 - accuracy: 0.3591\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0092 - accuracy: 0.3723\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.3278 - accuracy: 0.3809\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.7803 - accuracy: 0.3591\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.5489 - accuracy: 0.3802\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.8151 - accuracy: 0.3432\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.8101 - accuracy: 0.3782\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2133 - accuracy: 0.3597\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.8289 - accuracy: 0.3485\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.6827 - accuracy: 0.3743\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.0619 - accuracy: 0.3564\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.9482 - accuracy: 0.3782\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.8989 - accuracy: 0.3650\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.8272 - accuracy: 0.3683\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.4073 - accuracy: 0.3630\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.8116 - accuracy: 0.3670\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.6519 - accuracy: 0.3716\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.4321 - accuracy: 0.3729\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.9459 - accuracy: 0.3802\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.1084 - accuracy: 0.4053\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.3880 - accuracy: 0.3815\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.2152 - accuracy: 0.3894\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.6264 - accuracy: 0.3822\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.0593 - accuracy: 0.3710\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.9081 - accuracy: 0.3861\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.8631 - accuracy: 0.4099\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.9146 - accuracy: 0.3927\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7169 - accuracy: 0.3888\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.4559 - accuracy: 0.3967\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.0345 - accuracy: 0.3927\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.3767 - accuracy: 0.3828\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.8190 - accuracy: 0.3921\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.6707 - accuracy: 0.3723\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.2232 - accuracy: 0.3927\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.7348 - accuracy: 0.3769\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.8524 - accuracy: 0.4007\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.6879 - accuracy: 0.4191\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.4563 - accuracy: 0.3822\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.2750 - accuracy: 0.3822\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.2675 - accuracy: 0.3914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226c41dd7c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.44063324538258575\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  2  1  0  0]\n",
      " [ 0  0  8  6  0  0]\n",
      " [ 0  0 84 77  0  0]\n",
      " [ 1  0 86 83  0  0]\n",
      " [ 0  0 14 13  0  0]\n",
      " [ 0  0  1  3  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.43      0.52      0.47       161\n",
      "         4.0       0.45      0.49      0.47       170\n",
      "         5.0       0.00      0.00      0.00        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.44       379\n",
      "   macro avg       0.15      0.17      0.16       379\n",
      "weighted avg       0.39      0.44      0.41       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 64)                768       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 21)                693       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                352       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,012\n",
      "Trainable params: 4,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 4s 3ms/step - loss: 1427.6570 - accuracy: 0.1908\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 41.9896 - accuracy: 0.3287\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 25.2203 - accuracy: 0.3446\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 20.6416 - accuracy: 0.3551\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.4767 - accuracy: 0.3690\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 17.5402 - accuracy: 0.3611\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 13.8110 - accuracy: 0.3657\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2397 - accuracy: 0.3795\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.6950 - accuracy: 0.3894\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 13.4984 - accuracy: 0.3716\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.9800 - accuracy: 0.3848\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.5400 - accuracy: 0.3690\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.0228 - accuracy: 0.3927\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.5459 - accuracy: 0.3756\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.3710 - accuracy: 0.3875\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6545 - accuracy: 0.3868\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4981 - accuracy: 0.3881\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4728 - accuracy: 0.3881\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4510 - accuracy: 0.3881\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4330 - accuracy: 0.3881\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4167 - accuracy: 0.3881\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4029 - accuracy: 0.3881\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3900 - accuracy: 0.3881\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3786 - accuracy: 0.3881\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3689 - accuracy: 0.3881\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3600 - accuracy: 0.3881\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3522 - accuracy: 0.3881\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3452 - accuracy: 0.3881\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3390 - accuracy: 0.4139\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3329 - accuracy: 0.4363\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3279 - accuracy: 0.4363\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3230 - accuracy: 0.4363\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3187 - accuracy: 0.4363\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3150 - accuracy: 0.4363\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3114 - accuracy: 0.4363\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3082 - accuracy: 0.4363\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3052 - accuracy: 0.4363\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3025 - accuracy: 0.4363\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3003 - accuracy: 0.4363\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2977 - accuracy: 0.4363\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2955 - accuracy: 0.4363\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2935 - accuracy: 0.4363\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2916 - accuracy: 0.4363\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2899 - accuracy: 0.4363\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2885 - accuracy: 0.4363\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2868 - accuracy: 0.4363\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2853 - accuracy: 0.4363\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2840 - accuracy: 0.4363\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2827 - accuracy: 0.4363\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2815 - accuracy: 0.4363\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2803 - accuracy: 0.4363\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2793 - accuracy: 0.4363\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2782 - accuracy: 0.4363\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2772 - accuracy: 0.4363\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2763 - accuracy: 0.4363\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2753 - accuracy: 0.4363\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2745 - accuracy: 0.4363\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2741 - accuracy: 0.4363\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2734 - accuracy: 0.4363\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2727 - accuracy: 0.4363\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2720 - accuracy: 0.4363\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2713 - accuracy: 0.4363\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2708 - accuracy: 0.4363\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2700 - accuracy: 0.4363\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2695 - accuracy: 0.4363\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2688 - accuracy: 0.4363\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2684 - accuracy: 0.4363\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2679 - accuracy: 0.4363\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2672 - accuracy: 0.4363\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2668 - accuracy: 0.4363\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2663 - accuracy: 0.4363\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2660 - accuracy: 0.4363\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2655 - accuracy: 0.4363\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2651 - accuracy: 0.4363\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2647 - accuracy: 0.4363\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2643 - accuracy: 0.4363\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2639 - accuracy: 0.4363\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2636 - accuracy: 0.4363\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2633 - accuracy: 0.4363\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2629 - accuracy: 0.4363\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2626 - accuracy: 0.4363\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2622 - accuracy: 0.4363\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2620 - accuracy: 0.4363\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2617 - accuracy: 0.4363\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.2615 - accuracy: 0.4363\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2613 - accuracy: 0.4363\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2610 - accuracy: 0.4363\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2606 - accuracy: 0.4363\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2604 - accuracy: 0.4363\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2602 - accuracy: 0.4363\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2599 - accuracy: 0.4363\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2597 - accuracy: 0.4363\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2595 - accuracy: 0.4363\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2593 - accuracy: 0.4363\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2590 - accuracy: 0.4363\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2588 - accuracy: 0.4363\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2587 - accuracy: 0.4363\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2585 - accuracy: 0.4363\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2582 - accuracy: 0.4363\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2580 - accuracy: 0.4363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226c434c648>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.42480211081794195\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  14   0   0   0]\n",
      " [  0   0 161   0   0   0]\n",
      " [  0   0 170   0   0   0]\n",
      " [  0   0  27   0   0   0]\n",
      " [  0   0   4   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.42      1.00      0.60       161\n",
      "         4.0       0.00      0.00      0.00       170\n",
      "         5.0       0.00      0.00      0.00        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       379\n",
      "   macro avg       0.07      0.17      0.10       379\n",
      "weighted avg       0.18      0.42      0.25       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 11)                187       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,258\n",
      "Trainable params: 1,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 4s 3ms/step - loss: 2244.9009 - accuracy: 0.1254\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 342.2228 - accuracy: 0.1353\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 71.0197 - accuracy: 0.1954\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.7081 - accuracy: 0.4092\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5969 - accuracy: 0.4238\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9639 - accuracy: 0.3828\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8094 - accuracy: 0.3855\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7239 - accuracy: 0.3855\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6554 - accuracy: 0.3868\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6060 - accuracy: 0.3875\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5706 - accuracy: 0.3875\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.5421 - accuracy: 0.3875\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5171 - accuracy: 0.3881\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4949 - accuracy: 0.3888\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4750 - accuracy: 0.3881\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4565 - accuracy: 0.3881\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4394 - accuracy: 0.3888\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4237 - accuracy: 0.3881\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4097 - accuracy: 0.3881\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3966 - accuracy: 0.3881\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3847 - accuracy: 0.3888\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3744 - accuracy: 0.3881\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3640 - accuracy: 0.3888\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3549 - accuracy: 0.3888\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3466 - accuracy: 0.3881\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3395 - accuracy: 0.3888\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3324 - accuracy: 0.3881\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3258 - accuracy: 0.3881\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3203 - accuracy: 0.3881\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3144 - accuracy: 0.4178\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3094 - accuracy: 0.4370\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3056 - accuracy: 0.4370\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3012 - accuracy: 0.4370\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2980 - accuracy: 0.4363\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2946 - accuracy: 0.4363\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2913 - accuracy: 0.4376\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2899 - accuracy: 0.4370\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2857 - accuracy: 0.4370\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2840 - accuracy: 0.4363\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2812 - accuracy: 0.4363\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2785 - accuracy: 0.4370\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2780 - accuracy: 0.4363\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2752 - accuracy: 0.4370\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2754 - accuracy: 0.4363\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2718 - accuracy: 0.4370\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2707 - accuracy: 0.4363\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2693 - accuracy: 0.4370\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2682 - accuracy: 0.4370\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2670 - accuracy: 0.4370\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2662 - accuracy: 0.4370\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2657 - accuracy: 0.4370\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2651 - accuracy: 0.4370\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2646 - accuracy: 0.4370\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2641 - accuracy: 0.4370\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2636 - accuracy: 0.4370\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2632 - accuracy: 0.4370\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2628 - accuracy: 0.4370\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2624 - accuracy: 0.4370\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2620 - accuracy: 0.4370\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2617 - accuracy: 0.4370\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2613 - accuracy: 0.4370\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2610 - accuracy: 0.4370\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2608 - accuracy: 0.4370\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2604 - accuracy: 0.4370\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2601 - accuracy: 0.4370\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2598 - accuracy: 0.4370\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2596 - accuracy: 0.4370\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2594 - accuracy: 0.4370\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2591 - accuracy: 0.4370\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2589 - accuracy: 0.4370\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2586 - accuracy: 0.4370\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2584 - accuracy: 0.4370\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2583 - accuracy: 0.4370\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2580 - accuracy: 0.4370\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2577 - accuracy: 0.4370\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2576 - accuracy: 0.4370\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2574 - accuracy: 0.4370\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2572 - accuracy: 0.4370\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2570 - accuracy: 0.4370\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2568 - accuracy: 0.4370\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2567 - accuracy: 0.4370\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2565 - accuracy: 0.4370\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2564 - accuracy: 0.4370\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2561 - accuracy: 0.4370\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2560 - accuracy: 0.4370\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2559 - accuracy: 0.4370\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2557 - accuracy: 0.4370\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2555 - accuracy: 0.4370\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2554 - accuracy: 0.4370\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2555 - accuracy: 0.4370\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2551 - accuracy: 0.4370\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2550 - accuracy: 0.4370\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2549 - accuracy: 0.4370\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2547 - accuracy: 0.4370\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2546 - accuracy: 0.4370\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2545 - accuracy: 0.4370\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2543 - accuracy: 0.4370\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2543 - accuracy: 0.4370\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2541 - accuracy: 0.4370\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2539 - accuracy: 0.4370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226c6b7b9c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.42480211081794195\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  2  1  0  0]\n",
      " [ 0  0  8  6  0  0]\n",
      " [ 0  0 84 77  0  0]\n",
      " [ 1  0 86 83  0  0]\n",
      " [ 0  0 14 13  0  0]\n",
      " [ 0  0  1  3  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.42      1.00      0.60       161\n",
      "         4.0       0.00      0.00      0.00       170\n",
      "         5.0       0.00      0.00      0.00        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       379\n",
      "   macro avg       0.07      0.17      0.10       379\n",
      "weighted avg       0.18      0.42      0.25       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 11, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,257\n",
      "Trainable params: 19,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.8337 - accuracy: 0.4363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226c8186608>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.42480211081794195\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  14   0   0   0]\n",
      " [  0   0 161   0   0   0]\n",
      " [  0   0 170   0   0   0]\n",
      " [  0   0  27   0   0   0]\n",
      " [  0   0   4   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.42      1.00      0.60       161\n",
      "         4.0       0.00      0.00      0.00       170\n",
      "         5.0       0.00      0.00      0.00        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       379\n",
      "   macro avg       0.07      0.17      0.10       379\n",
      "weighted avg       0.18      0.42      0.25       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,295\n",
      "Trainable params: 8,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 9.6020 - accuracy: 0.0343\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.2481 - accuracy: 0.0271\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6847 - accuracy: 0.0132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226c85862c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.005277044854881266\n",
      "Tasa de aciertos balanceada regresión logística: 0.11\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [  1   2   0   0   0   0   0]\n",
      " [  3  11   0   0   0   0   0]\n",
      " [ 44 117   0   0   0   0   0]\n",
      " [ 58 112   0   0   0   0   0]\n",
      " [  4  23   0   0   0   0   0]\n",
      " [  1   3   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.01      0.67      0.01         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.00      0.00      0.00       161\n",
      "         4.0       0.00      0.00      0.00       170\n",
      "         5.0       0.00      0.00      0.00        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.01       379\n",
      "   macro avg       0.00      0.10      0.00       379\n",
      "weighted avg       0.00      0.01      0.00       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,359\n",
      "Trainable params: 2,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 2.7715 - accuracy: 0.4363\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 2.7701 - accuracy: 0.4356\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.7701 - accuracy: 0.4356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226c99b6408>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.42216358839050133\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  14   0   0   0]\n",
      " [  0   0 161   0   0   0]\n",
      " [  0   0 170   0   0   0]\n",
      " [  0   0  27   0   0   0]\n",
      " [  0   0   4   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.42      0.99      0.59       161\n",
      "         4.0       0.00      0.00      0.00       170\n",
      "         5.0       0.00      0.00      0.00        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       379\n",
      "   macro avg       0.07      0.17      0.10       379\n",
      "weighted avg       0.18      0.42      0.25       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 11, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 25)                850       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 20)                520       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 17)                357       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 14)                252       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 12)                180       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 11)                143       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,319\n",
      "Trainable params: 10,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 16.5433 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.5559 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226c88e1948>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0   0]\n",
      " [ 14   0   0   0   0   0   0]\n",
      " [161   0   0   0   0   0   0]\n",
      " [170   0   0   0   0   0   0]\n",
      " [ 27   0   0   0   0   0   0]\n",
      " [  4   0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       3.0\n",
      "         2.0       0.00      0.00      0.00      14.0\n",
      "         3.0       0.00      0.00      0.00     161.0\n",
      "         4.0       0.00      0.00      0.00     170.0\n",
      "         5.0       0.00      0.00      0.00      27.0\n",
      "         6.0       0.00      0.00      0.00       4.0\n",
      "\n",
      "    accuracy                           0.00     379.0\n",
      "   macro avg       0.00      0.00      0.00     379.0\n",
      "weighted avg       0.00      0.00      0.00     379.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 21)                693       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 16)                352       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 13)                221       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 11)                154       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,575\n",
      "Trainable params: 4,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 5s 4ms/step - loss: 15.4705 - accuracy: 0.0350\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.5026 - accuracy: 0.0653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226cb138388>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0712401055408971\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   3   0]\n",
      " [  0   0   0   0  14   0]\n",
      " [  0   0   0   0 161   0]\n",
      " [  0   0   0   0 170   0]\n",
      " [  0   0   0   0  27   0]\n",
      " [  0   0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.00      0.00      0.00       161\n",
      "         4.0       0.00      0.00      0.00       170\n",
      "         5.0       0.07      1.00      0.13        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.07       379\n",
      "   macro avg       0.01      0.17      0.02       379\n",
      "weighted avg       0.01      0.07      0.01       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 11)                187       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 4s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 10.6210 - accuracy: 0.0238\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6210 - accuracy: 0.0238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226cc6e16c8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0079155672823219\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0   0]\n",
      " [ 14   0   0   0   0   0   0]\n",
      " [161   0   0   0   0   0   0]\n",
      " [170   0   0   0   0   0   0]\n",
      " [ 27   0   0   0   0   0   0]\n",
      " [  4   0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      1.00      0.02         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.00      0.00      0.00       161\n",
      "         4.0       0.00      0.00      0.00       170\n",
      "         5.0       0.00      0.00      0.00        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.01       379\n",
      "   macro avg       0.00      0.17      0.00       379\n",
      "weighted avg       0.00      0.01      0.00       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 25)                850       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,965\n",
      "Trainable params: 8,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 3s 3ms/step - loss: 644.5002 - accuracy: 0.2587\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 111.2328 - accuracy: 0.3492\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 78.7504 - accuracy: 0.3630\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 65.5556 - accuracy: 0.3446\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 55.6292 - accuracy: 0.3492\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 51.0864 - accuracy: 0.3630\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 48.3505 - accuracy: 0.3657\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 46.0582 - accuracy: 0.3835\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 42.9605 - accuracy: 0.3749\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 39.6145 - accuracy: 0.3756\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 39.6894 - accuracy: 0.3696\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 37.0595 - accuracy: 0.3670\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 35.8584 - accuracy: 0.3611\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 33.8825 - accuracy: 0.3736\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 33.0828 - accuracy: 0.3795\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 32.9016 - accuracy: 0.3776\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 31.2093 - accuracy: 0.3650\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 29.3626 - accuracy: 0.3703\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 30.3293 - accuracy: 0.3670\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 29.3179 - accuracy: 0.3584\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 26.7456 - accuracy: 0.3861\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 26.1370 - accuracy: 0.3789\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 25.5780 - accuracy: 0.3881\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 25.5851 - accuracy: 0.3776\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 24.2306 - accuracy: 0.3894\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 24.5661 - accuracy: 0.3848\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 23.9247 - accuracy: 0.3578\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 23.8400 - accuracy: 0.3729\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 21.6419 - accuracy: 0.3723\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 21.7575 - accuracy: 0.3802\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 22.0647 - accuracy: 0.3538\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 21.3452 - accuracy: 0.3617\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 21.4138 - accuracy: 0.3637\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.8840 - accuracy: 0.3809\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.9539 - accuracy: 0.3815\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 19.7103 - accuracy: 0.3670\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 20.5959 - accuracy: 0.3617\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 19.4372 - accuracy: 0.3743\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 19.0077 - accuracy: 0.3696\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 18.2209 - accuracy: 0.3875\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 18.4395 - accuracy: 0.3789\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 18.1278 - accuracy: 0.3677\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 18.6542 - accuracy: 0.3558\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 18.1394 - accuracy: 0.3663\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.9963 - accuracy: 0.3703\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.6822 - accuracy: 0.3894\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.8119 - accuracy: 0.3551\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 17.2566 - accuracy: 0.3703\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.8684 - accuracy: 0.3743\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.4957 - accuracy: 0.3630\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.3783 - accuracy: 0.3578\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.3622 - accuracy: 0.3690\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.9495 - accuracy: 0.3729\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.2248 - accuracy: 0.3729\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.8390 - accuracy: 0.3696\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6696 - accuracy: 0.3828\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.8319 - accuracy: 0.3650\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.9652 - accuracy: 0.3696\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.6125 - accuracy: 0.3663\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.1655 - accuracy: 0.3802\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.6604 - accuracy: 0.3624\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6809 - accuracy: 0.3861\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 16.0595 - accuracy: 0.3518\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 15.6803 - accuracy: 0.3591\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 14.9280 - accuracy: 0.3809\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.4432 - accuracy: 0.3624\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.0545 - accuracy: 0.3637\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15.0150 - accuracy: 0.3591\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.2967 - accuracy: 0.3597\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 15.3328 - accuracy: 0.3822\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.1801 - accuracy: 0.3749\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.9668 - accuracy: 0.3630\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.7141 - accuracy: 0.3749\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.3801 - accuracy: 0.3571\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5412 - accuracy: 0.3749\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.3356 - accuracy: 0.3723\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 14.6086 - accuracy: 0.3670\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.3748 - accuracy: 0.3762\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1503 - accuracy: 0.3749\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 14.5141 - accuracy: 0.3683\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.6724 - accuracy: 0.3571\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 14.8978 - accuracy: 0.3690\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.3193 - accuracy: 0.3703\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 14.2666 - accuracy: 0.3558\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7106 - accuracy: 0.3756\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.6058 - accuracy: 0.3749\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.3490 - accuracy: 0.3696\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.5224 - accuracy: 0.3716\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.6415 - accuracy: 0.3743\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.4466 - accuracy: 0.3683\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.7781 - accuracy: 0.3716\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.3422 - accuracy: 0.3578\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.4940 - accuracy: 0.3769\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 13.6284 - accuracy: 0.3729\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.4468 - accuracy: 0.3756\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1308 - accuracy: 0.3756\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 13.4535 - accuracy: 0.3756\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1152 - accuracy: 0.3769\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.9489 - accuracy: 0.3657\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 13.2831 - accuracy: 0.3848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226cdc7c108>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.40633245382585753\n",
      "Tasa de aciertos balanceada regresión logística: 0.16\n",
      "Matriz de confusión:\n",
      "[[  0   0   2   1   0   0]\n",
      " [  0   0   1  13   0   0]\n",
      " [  3  10  46  85  10   7]\n",
      " [  1   5  48 107   5   4]\n",
      " [  2   1   7  15   1   1]\n",
      " [  0   0   2   2   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.43      0.29      0.34       161\n",
      "         4.0       0.48      0.63      0.54       170\n",
      "         5.0       0.06      0.04      0.05        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.41       379\n",
      "   macro avg       0.16      0.16      0.16       379\n",
      "weighted avg       0.40      0.41      0.39       379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_65 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 21)                693       \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 16)                352       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,012\n",
      "Trainable params: 4,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 3s 3ms/step - loss: 3349.8096 - accuracy: 0.0917\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 766.7793 - accuracy: 0.2310\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 269.8904 - accuracy: 0.3175\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 157.8084 - accuracy: 0.3426\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 126.4827 - accuracy: 0.3373\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 117.4692 - accuracy: 0.3479\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 104.9757 - accuracy: 0.3617\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 96.7762 - accuracy: 0.3736\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 92.5127 - accuracy: 0.3538\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 88.6814 - accuracy: 0.3545\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 86.5640 - accuracy: 0.3525\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 80.4827 - accuracy: 0.3518\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 76.6369 - accuracy: 0.3776\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 75.4696 - accuracy: 0.3762\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 74.8777 - accuracy: 0.3789\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 73.8358 - accuracy: 0.3604\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 68.9809 - accuracy: 0.3683\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 69.1528 - accuracy: 0.3683\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 68.7115 - accuracy: 0.3512\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 66.3988 - accuracy: 0.3663\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 64.3159 - accuracy: 0.3802\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 65.4136 - accuracy: 0.3584\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 63.4062 - accuracy: 0.3578\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 61.9948 - accuracy: 0.3809\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 62.3564 - accuracy: 0.3584\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 61.7966 - accuracy: 0.3703\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 60.7079 - accuracy: 0.3657\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 59.6428 - accuracy: 0.3611\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 58.4719 - accuracy: 0.3637\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 60.5272 - accuracy: 0.3743\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 59.7081 - accuracy: 0.3578\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 58.0485 - accuracy: 0.3815\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 57.8973 - accuracy: 0.3558\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 57.5039 - accuracy: 0.3703\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 55.8830 - accuracy: 0.3802\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 55.9513 - accuracy: 0.3743\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 55.5908 - accuracy: 0.3710\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 56.1441 - accuracy: 0.3591\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 54.3478 - accuracy: 0.3815\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 57.5281 - accuracy: 0.3835\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 53.5662 - accuracy: 0.3611\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 54.6174 - accuracy: 0.3584\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 53.5172 - accuracy: 0.3749\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 53.0786 - accuracy: 0.3835\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 52.2416 - accuracy: 0.3663\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 53.1820 - accuracy: 0.3861\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 51.9621 - accuracy: 0.3789\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 52.5306 - accuracy: 0.3683\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 51.5495 - accuracy: 0.3802\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 51.3383 - accuracy: 0.3617\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 52.4795 - accuracy: 0.3683\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 51.5083 - accuracy: 0.3617\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 50.4280 - accuracy: 0.3690\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 49.8689 - accuracy: 0.3881\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 48.6833 - accuracy: 0.3736\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 51.7332 - accuracy: 0.3743\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 50.7499 - accuracy: 0.3690\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 49.9546 - accuracy: 0.3677\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 50.4922 - accuracy: 0.3663\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 49.8101 - accuracy: 0.3789\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 48.3110 - accuracy: 0.3822\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 47.7277 - accuracy: 0.3762\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 47.2604 - accuracy: 0.3842\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 47.1611 - accuracy: 0.3769\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 48.1008 - accuracy: 0.3789\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 47.9289 - accuracy: 0.3736\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 47.6007 - accuracy: 0.3729\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 47.7514 - accuracy: 0.3696\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 47.7571 - accuracy: 0.3749\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 46.6896 - accuracy: 0.3630\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 46.5085 - accuracy: 0.3809\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 47.0087 - accuracy: 0.3710\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 46.1171 - accuracy: 0.3637\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 46.3263 - accuracy: 0.3749\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 45.8692 - accuracy: 0.3657\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 45.9704 - accuracy: 0.3644\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 46.2520 - accuracy: 0.3551\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 44.2145 - accuracy: 0.3980\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 45.4527 - accuracy: 0.3842\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 44.1201 - accuracy: 0.3861\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 44.8346 - accuracy: 0.3908\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 44.5278 - accuracy: 0.3743\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 43.7910 - accuracy: 0.3782\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 43.7345 - accuracy: 0.3710\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 43.1485 - accuracy: 0.3743\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 44.6988 - accuracy: 0.3677\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 44.0801 - accuracy: 0.3868\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 43.7958 - accuracy: 0.3677\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 43.1414 - accuracy: 0.3650\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 43.0473 - accuracy: 0.3861\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 42.7845 - accuracy: 0.3736\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 42.7185 - accuracy: 0.3650\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 42.5823 - accuracy: 0.3597\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 43.1384 - accuracy: 0.3729\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 42.0165 - accuracy: 0.3710\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 42.7560 - accuracy: 0.3696\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 42.8887 - accuracy: 0.3663\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 41.6624 - accuracy: 0.3861\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 42.9584 - accuracy: 0.3644\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 41.2497 - accuracy: 0.3736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226ce04a548>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3007915567282322\n",
      "Tasa de aciertos balanceada regresión logística: 0.16\n",
      "Matriz de confusión:\n",
      "[[ 0  0  2  0  1  0]\n",
      " [ 0  2  5  6  1  0]\n",
      " [ 1 21 61 43 33  2]\n",
      " [ 2 17 76 47 26  2]\n",
      " [ 0  3 13  7  4  0]\n",
      " [ 0  0  3  0  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.05      0.14      0.07        14\n",
      "         3.0       0.38      0.38      0.38       161\n",
      "         4.0       0.46      0.28      0.34       170\n",
      "         5.0       0.06      0.15      0.09        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.30       379\n",
      "   macro avg       0.16      0.16      0.15       379\n",
      "weighted avg       0.37      0.30      0.32       379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_70 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 11)                187       \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,258\n",
      "Trainable params: 1,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 2s 3ms/step - loss: 1513.0723 - accuracy: 0.0317\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 238.0671 - accuracy: 0.0627\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 106.1288 - accuracy: 0.0759\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 44.7342 - accuracy: 0.1987\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 22.6966 - accuracy: 0.2970\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.6326 - accuracy: 0.3564\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.5871 - accuracy: 0.3736\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.4525 - accuracy: 0.3815\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.1908 - accuracy: 0.3868\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.2511 - accuracy: 0.3894\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5300 - accuracy: 0.3967\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.0240 - accuracy: 0.3980\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.6612 - accuracy: 0.4033\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.3845 - accuracy: 0.4033\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.1102 - accuracy: 0.4046\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.8612 - accuracy: 0.4040\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.6380 - accuracy: 0.4046\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.4823 - accuracy: 0.4053\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.3293 - accuracy: 0.4046\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.2190 - accuracy: 0.4079\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.1357 - accuracy: 0.4086\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.0571 - accuracy: 0.4112\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.9779 - accuracy: 0.4106\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.9010 - accuracy: 0.4086\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.8219 - accuracy: 0.4132\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.7485 - accuracy: 0.4132\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.6814 - accuracy: 0.4145\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.6218 - accuracy: 0.4145\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5650 - accuracy: 0.4172\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.5158 - accuracy: 0.4165\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.4679 - accuracy: 0.4165\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.4209 - accuracy: 0.4172\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.3801 - accuracy: 0.4172\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.3405 - accuracy: 0.4191\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.3062 - accuracy: 0.4191\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2851 - accuracy: 0.4224\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2637 - accuracy: 0.4231\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2457 - accuracy: 0.4264\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.2266 - accuracy: 0.4257\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1975 - accuracy: 0.4264\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1719 - accuracy: 0.4257\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.1442 - accuracy: 0.4271\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1225 - accuracy: 0.4271\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0880 - accuracy: 0.4251\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0872 - accuracy: 0.4277\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0681 - accuracy: 0.4290\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0593 - accuracy: 0.4284\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0538 - accuracy: 0.4297\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0492 - accuracy: 0.4304\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0443 - accuracy: 0.4304\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0397 - accuracy: 0.4310\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0350 - accuracy: 0.4290\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0307 - accuracy: 0.4323\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0268 - accuracy: 0.4310\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0234 - accuracy: 0.4317\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0193 - accuracy: 0.4323\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.0157 - accuracy: 0.4310\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0116 - accuracy: 0.4290\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0082 - accuracy: 0.4310\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0048 - accuracy: 0.4310\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 2.0009 - accuracy: 0.4304\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9978 - accuracy: 0.4317\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9949 - accuracy: 0.4317\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9919 - accuracy: 0.4317\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9889 - accuracy: 0.4323\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9868 - accuracy: 0.4323\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9840 - accuracy: 0.4323\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9813 - accuracy: 0.4323\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9790 - accuracy: 0.4323\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9764 - accuracy: 0.4330\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9738 - accuracy: 0.4330\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9706 - accuracy: 0.4310\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9683 - accuracy: 0.4330\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9659 - accuracy: 0.4330\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9629 - accuracy: 0.4330\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9606 - accuracy: 0.4330\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9579 - accuracy: 0.4330\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9554 - accuracy: 0.4330\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9530 - accuracy: 0.4330\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9509 - accuracy: 0.4330\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9488 - accuracy: 0.4330\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9469 - accuracy: 0.4330\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9454 - accuracy: 0.4330\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9434 - accuracy: 0.4330\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9416 - accuracy: 0.4323\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9396 - accuracy: 0.4323\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9377 - accuracy: 0.4323\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9360 - accuracy: 0.4337\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9341 - accuracy: 0.4323\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9322 - accuracy: 0.4330\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.9307 - accuracy: 0.4330\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9292 - accuracy: 0.4343\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9275 - accuracy: 0.4337\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9260 - accuracy: 0.4343\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9245 - accuracy: 0.4343\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9230 - accuracy: 0.4343\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9215 - accuracy: 0.4343\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9200 - accuracy: 0.4343\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9185 - accuracy: 0.4343\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9175 - accuracy: 0.4343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226cc67bac8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.41952506596306066\n",
      "Tasa de aciertos balanceada regresión logística: 0.16\n",
      "Matriz de confusión:\n",
      "[[  0   0   2   1   0   0]\n",
      " [  0   0   1  13   0   0]\n",
      " [  3  10  46  85  10   7]\n",
      " [  1   5  48 107   5   4]\n",
      " [  2   1   7  15   1   1]\n",
      " [  0   0   2   2   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.43      0.99      0.59       161\n",
      "         4.0       0.00      0.00      0.00       170\n",
      "         5.0       0.00      0.00      0.00        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       379\n",
      "   macro avg       0.07      0.16      0.10       379\n",
      "weighted avg       0.18      0.42      0.25       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_75 (Dense)            (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,257\n",
      "Trainable params: 19,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 3s 3ms/step - loss: 8.9609 - accuracy: 0.0653\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.4343 - accuracy: 0.0653\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.6742 - accuracy: 0.0653\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.6742 - accuracy: 0.0653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226cf38aac8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0712401055408971\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   3   0]\n",
      " [  0   0   0   0  14   0]\n",
      " [  0   0   0   0 161   0]\n",
      " [  0   0   0   0 170   0]\n",
      " [  0   0   0   0  27   0]\n",
      " [  0   0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.00      0.00      0.00       161\n",
      "         4.0       0.00      0.00      0.00       170\n",
      "         5.0       0.07      1.00      0.13        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.07       379\n",
      "   macro avg       0.01      0.17      0.02       379\n",
      "weighted avg       0.01      0.07      0.01       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,295\n",
      "Trainable params: 8,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 3s 3ms/step - loss: 8.7862 - accuracy: 0.4363\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.7349 - accuracy: 0.4363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d0831b88>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.42480211081794195\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  14   0   0   0]\n",
      " [  0   0 161   0   0   0]\n",
      " [  0   0 170   0   0   0]\n",
      " [  0   0  27   0   0   0]\n",
      " [  0   0   4   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.42      1.00      0.60       161\n",
      "         4.0       0.00      0.00      0.00       170\n",
      "         5.0       0.00      0.00      0.00        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       379\n",
      "   macro avg       0.07      0.17      0.10       379\n",
      "weighted avg       0.18      0.42      0.25       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_85 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,359\n",
      "Trainable params: 2,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 3s 3ms/step - loss: 10.6675 - accuracy: 0.0931\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 12.4318 - accuracy: 0.0429\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.7538 - accuracy: 0.0851\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8694 - accuracy: 0.1023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d0c56388>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.23482849604221637\n",
      "Tasa de aciertos balanceada regresión logística: 0.15\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   3   0]\n",
      " [  0   0   0   0  14   0]\n",
      " [  0   0   0   0 161   0]\n",
      " [  0   0   0   0 170   0]\n",
      " [  0   0   0   0  27   0]\n",
      " [  0   0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      0.33      0.01         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.44      0.55      0.48       161\n",
      "         4.0       0.00      0.00      0.00       170\n",
      "         5.0       0.00      0.00      0.00        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.23       379\n",
      "   macro avg       0.07      0.15      0.08       379\n",
      "weighted avg       0.19      0.23      0.21       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 25)                850       \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 20)                520       \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 17)                357       \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 14)                252       \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 12)                180       \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 11)                143       \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,319\n",
      "Trainable params: 10,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 4s 4ms/step - loss: 9.0588 - accuracy: 0.4363\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0677 - accuracy: 0.4363\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.0677 - accuracy: 0.4363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d1feabc8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.42480211081794195\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  14   0   0   0]\n",
      " [  0   0 161   0   0   0]\n",
      " [  0   0 170   0   0   0]\n",
      " [  0   0  27   0   0   0]\n",
      " [  0   0   4   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.42      1.00      0.60       161\n",
      "         4.0       0.00      0.00      0.00       170\n",
      "         5.0       0.00      0.00      0.00        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       379\n",
      "   macro avg       0.07      0.17      0.10       379\n",
      "weighted avg       0.18      0.42      0.25       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,575\n",
      "Trainable params: 4,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 4s 4ms/step - loss: 8.6582 - accuracy: 0.4356\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0004 - accuracy: 0.4363\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.7418 - accuracy: 0.4363\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.8289 - accuracy: 0.4363\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0198 - accuracy: 0.4363\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0650 - accuracy: 0.4363\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.0857 - accuracy: 0.4363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d24cc6c8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.42480211081794195\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  14   0   0   0]\n",
      " [  0   0 161   0   0   0]\n",
      " [  0   0 170   0   0   0]\n",
      " [  0   0  27   0   0   0]\n",
      " [  0   0   4   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.42      1.00      0.60       161\n",
      "         4.0       0.00      0.00      0.00       170\n",
      "         5.0       0.00      0.00      0.00        27\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       379\n",
      "   macro avg       0.07      0.17      0.10       379\n",
      "weighted avg       0.18      0.42      0.25       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_110 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 5s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d3962c88>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  14   0   0   0]\n",
      " [  0   0 161   0   0   0]\n",
      " [  0   0 170   0   0   0]\n",
      " [  0   0  27   0   0   0]\n",
      " [  0   0   4   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       3.0\n",
      "         2.0       0.00      0.00      0.00      14.0\n",
      "         3.0       0.00      0.00      0.00     161.0\n",
      "         4.0       0.00      0.00      0.00     170.0\n",
      "         5.0       0.00      0.00      0.00      27.0\n",
      "         6.0       0.00      0.00      0.00       4.0\n",
      "\n",
      "    accuracy                           0.00     379.0\n",
      "   macro avg       0.00      0.00      0.00     379.0\n",
      "weighted avg       0.00      0.00      0.00     379.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 21, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,965\n",
      "Trainable params: 9,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 850.7368 - accuracy: 0.3351\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 100.4241 - accuracy: 0.3345\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 64.5808 - accuracy: 0.3603\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 50.0494 - accuracy: 0.3739\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 40.6097 - accuracy: 0.3555\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 42.8496 - accuracy: 0.3651\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 48.7900 - accuracy: 0.3732\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 36.9932 - accuracy: 0.3678\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 47.4998 - accuracy: 0.3617\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 37.1216 - accuracy: 0.3583\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.9936 - accuracy: 0.3562\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.7215 - accuracy: 0.3719\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 18.6131 - accuracy: 0.3759\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 17.6845 - accuracy: 0.3712\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.6302 - accuracy: 0.3623\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 19.9332 - accuracy: 0.3678\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.3381 - accuracy: 0.3902\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6208 - accuracy: 0.3732\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 17.3293 - accuracy: 0.3596\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.1498 - accuracy: 0.3705\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.7347 - accuracy: 0.3773\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6252 - accuracy: 0.3549\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.8193 - accuracy: 0.3685\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.4710 - accuracy: 0.3739\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.0897 - accuracy: 0.3657\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9957 - accuracy: 0.3821\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.0739 - accuracy: 0.3610\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0767 - accuracy: 0.3671\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5177 - accuracy: 0.3827\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3289 - accuracy: 0.3698\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9989 - accuracy: 0.3562\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0736 - accuracy: 0.3746\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0506 - accuracy: 0.3834\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.1972 - accuracy: 0.3882\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.9622 - accuracy: 0.3807\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7460 - accuracy: 0.3766\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6143 - accuracy: 0.3882\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5804 - accuracy: 0.3889\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.3336 - accuracy: 0.3617\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6393 - accuracy: 0.3610\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.2780 - accuracy: 0.3821\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3439 - accuracy: 0.3685\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1323 - accuracy: 0.3827\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.0388 - accuracy: 0.3807\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6077 - accuracy: 0.3936\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7258 - accuracy: 0.3855\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.3738 - accuracy: 0.4079\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6141 - accuracy: 0.4086\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6552 - accuracy: 0.3889\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8230 - accuracy: 0.3936\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.5070 - accuracy: 0.4181\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2720 - accuracy: 0.4160\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2423 - accuracy: 0.3923\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8124 - accuracy: 0.3732\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0395 - accuracy: 0.4188\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9838 - accuracy: 0.4222\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8775 - accuracy: 0.4242\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2926 - accuracy: 0.4140\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9094 - accuracy: 0.4242\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7999 - accuracy: 0.4140\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3465 - accuracy: 0.4086\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9923 - accuracy: 0.4160\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9174 - accuracy: 0.4303\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0150 - accuracy: 0.4072\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7903 - accuracy: 0.4052\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0004 - accuracy: 0.4126\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.7228 - accuracy: 0.4228\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6354 - accuracy: 0.4188\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6896 - accuracy: 0.3936\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3535 - accuracy: 0.3875\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1556 - accuracy: 0.3916\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9594 - accuracy: 0.4147\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8824 - accuracy: 0.4256\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6361 - accuracy: 0.4181\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5699 - accuracy: 0.4276\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3205 - accuracy: 0.3800\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2976 - accuracy: 0.4011\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8884 - accuracy: 0.4181\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5460 - accuracy: 0.4058\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4624 - accuracy: 0.4290\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5716 - accuracy: 0.4126\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4930 - accuracy: 0.4133\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6219 - accuracy: 0.3868\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7094 - accuracy: 0.4058\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6394 - accuracy: 0.4181\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7657 - accuracy: 0.3929\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8150 - accuracy: 0.4113\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6064 - accuracy: 0.4126\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1061 - accuracy: 0.4072\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2449 - accuracy: 0.3943\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9365 - accuracy: 0.4072\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5673 - accuracy: 0.4099\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6989 - accuracy: 0.3841\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6433 - accuracy: 0.4106\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7580 - accuracy: 0.3997\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5170 - accuracy: 0.4283\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4798 - accuracy: 0.4106\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6113 - accuracy: 0.4140\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.2128 - accuracy: 0.3732\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4143 - accuracy: 0.3977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226cc69f6c8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4076086956521739\n",
      "Tasa de aciertos balanceada regresión logística: 0.18\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  10   1   2   0]\n",
      " [  0   0 132  10  13   0]\n",
      " [  0   0 145  14   8   0]\n",
      " [  0   0  20   2   4   0]\n",
      " [  0   0   4   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.42      0.85      0.56       155\n",
      "         4.0       0.52      0.08      0.14       167\n",
      "         5.0       0.15      0.15      0.15        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.41       368\n",
      "   macro avg       0.18      0.18      0.14       368\n",
      "weighted avg       0.42      0.41      0.31       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_125 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,652\n",
      "Trainable params: 4,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 552.0805 - accuracy: 0.3222\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0366 - accuracy: 0.4385\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8676 - accuracy: 0.4385\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8267 - accuracy: 0.4385\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7880 - accuracy: 0.4385\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7509 - accuracy: 0.4385\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7163 - accuracy: 0.4385\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6837 - accuracy: 0.4385\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6529 - accuracy: 0.4385\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6243 - accuracy: 0.4385\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5975 - accuracy: 0.4385\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5726 - accuracy: 0.4385\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5493 - accuracy: 0.4385\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5278 - accuracy: 0.4385\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5079 - accuracy: 0.4385\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4894 - accuracy: 0.4385\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4723 - accuracy: 0.4385\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4565 - accuracy: 0.4385\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4421 - accuracy: 0.4385\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4286 - accuracy: 0.4385\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4162 - accuracy: 0.4385\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4049 - accuracy: 0.4385\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3943 - accuracy: 0.4385\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3846 - accuracy: 0.4385\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3757 - accuracy: 0.4385\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3675 - accuracy: 0.4385\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3600 - accuracy: 0.4385\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3529 - accuracy: 0.4385\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3465 - accuracy: 0.4385\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3406 - accuracy: 0.4385\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3350 - accuracy: 0.4385\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3299 - accuracy: 0.4385\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3252 - accuracy: 0.4385\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3209 - accuracy: 0.4385\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3167 - accuracy: 0.4385\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3130 - accuracy: 0.4385\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3095 - accuracy: 0.4385\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3063 - accuracy: 0.4385\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3033 - accuracy: 0.4385\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3004 - accuracy: 0.4385\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2978 - accuracy: 0.4385\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2953 - accuracy: 0.4385\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2930 - accuracy: 0.4385\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2909 - accuracy: 0.4385\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2889 - accuracy: 0.4385\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2870 - accuracy: 0.4385\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2853 - accuracy: 0.4385\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2836 - accuracy: 0.4385\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2820 - accuracy: 0.4385\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2806 - accuracy: 0.4385\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2792 - accuracy: 0.4385\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2778 - accuracy: 0.4385\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2766 - accuracy: 0.4385\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2754 - accuracy: 0.4385\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2743 - accuracy: 0.4385\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2733 - accuracy: 0.4385\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2723 - accuracy: 0.4385\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2713 - accuracy: 0.4385\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2704 - accuracy: 0.4385\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2695 - accuracy: 0.4385\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2687 - accuracy: 0.4385\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2679 - accuracy: 0.4385\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2672 - accuracy: 0.4385\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2665 - accuracy: 0.4385\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2658 - accuracy: 0.4385\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2652 - accuracy: 0.4385\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2645 - accuracy: 0.4385\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2639 - accuracy: 0.4385\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2634 - accuracy: 0.4385\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2628 - accuracy: 0.4385\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2623 - accuracy: 0.4385\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2618 - accuracy: 0.4385\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2614 - accuracy: 0.4385\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2609 - accuracy: 0.4385\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2604 - accuracy: 0.4385\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2600 - accuracy: 0.4385\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2596 - accuracy: 0.4385\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2592 - accuracy: 0.4385\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2588 - accuracy: 0.4385\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2585 - accuracy: 0.4385\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2581 - accuracy: 0.4385\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2578 - accuracy: 0.4385\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2575 - accuracy: 0.4385\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2571 - accuracy: 0.4385\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2569 - accuracy: 0.4385\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2565 - accuracy: 0.4385\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2562 - accuracy: 0.4385\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2559 - accuracy: 0.4385\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2557 - accuracy: 0.4385\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2554 - accuracy: 0.4385\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2552 - accuracy: 0.4385\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2549 - accuracy: 0.4385\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2547 - accuracy: 0.4385\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2544 - accuracy: 0.4385\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2542 - accuracy: 0.4385\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2540 - accuracy: 0.4385\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2538 - accuracy: 0.4385\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2536 - accuracy: 0.4385\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2534 - accuracy: 0.4385\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2532 - accuracy: 0.4385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d50d6748>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.421195652173913\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  13   0   0   0]\n",
      " [  0   0 155   0   0   0]\n",
      " [  0   0 167   0   0   0]\n",
      " [  0   0  26   0   0   0]\n",
      " [  0   0   4   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.42      1.00      0.59       155\n",
      "         4.0       0.00      0.00      0.00       167\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       368\n",
      "   macro avg       0.07      0.17      0.10       368\n",
      "weighted avg       0.18      0.42      0.25       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,578\n",
      "Trainable params: 1,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 2ms/step - loss: 1341.4264 - accuracy: 0.1339\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.0181 - accuracy: 0.3848\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9115 - accuracy: 0.3889\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3081 - accuracy: 0.3882\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7631 - accuracy: 0.3882\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6728 - accuracy: 0.3882\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6231 - accuracy: 0.3882\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5751 - accuracy: 0.3882\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5303 - accuracy: 0.3882\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.4893 - accuracy: 0.3882\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.4524 - accuracy: 0.3882\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.4205 - accuracy: 0.3882\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3928 - accuracy: 0.3882\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3693 - accuracy: 0.3882\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3496 - accuracy: 0.3882\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3332 - accuracy: 0.3882\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3196 - accuracy: 0.3882\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3086 - accuracy: 0.3882\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2993 - accuracy: 0.3882\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2917 - accuracy: 0.4065\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2858 - accuracy: 0.4385\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2806 - accuracy: 0.4385\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2763 - accuracy: 0.4385\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2728 - accuracy: 0.4385\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2698 - accuracy: 0.4385\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2673 - accuracy: 0.4385\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2649 - accuracy: 0.4385\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2631 - accuracy: 0.4385\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2613 - accuracy: 0.4385\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2598 - accuracy: 0.4385\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2586 - accuracy: 0.4385\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2573 - accuracy: 0.4385\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2563 - accuracy: 0.4385\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2553 - accuracy: 0.4385\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2546 - accuracy: 0.4385\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2539 - accuracy: 0.4385\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2532 - accuracy: 0.4385\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2526 - accuracy: 0.4385\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2520 - accuracy: 0.4385\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2515 - accuracy: 0.4385\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2512 - accuracy: 0.4385\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2508 - accuracy: 0.4385\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2504 - accuracy: 0.4385\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2502 - accuracy: 0.4385\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2497 - accuracy: 0.4385\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2495 - accuracy: 0.4385\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2492 - accuracy: 0.4385\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2490 - accuracy: 0.4385\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2490 - accuracy: 0.4385\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2486 - accuracy: 0.4385\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2484 - accuracy: 0.4385\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2483 - accuracy: 0.4385\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2481 - accuracy: 0.4385\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2481 - accuracy: 0.4385\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2483 - accuracy: 0.4385\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2476 - accuracy: 0.4385\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2474 - accuracy: 0.4385\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2474 - accuracy: 0.4385\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2473 - accuracy: 0.4385\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2471 - accuracy: 0.4385\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2473 - accuracy: 0.4385\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2469 - accuracy: 0.4385\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2470 - accuracy: 0.4385\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2468 - accuracy: 0.4385\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2467 - accuracy: 0.4385\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2466 - accuracy: 0.4385\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2466 - accuracy: 0.4385\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2465 - accuracy: 0.4385\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2463 - accuracy: 0.4385\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2464 - accuracy: 0.4385\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2465 - accuracy: 0.4385\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2462 - accuracy: 0.4385\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2463 - accuracy: 0.4385\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2461 - accuracy: 0.4385\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2460 - accuracy: 0.4385\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2460 - accuracy: 0.4385\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2460 - accuracy: 0.4385\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2460 - accuracy: 0.4385\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2458 - accuracy: 0.4385\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2458 - accuracy: 0.4385\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2458 - accuracy: 0.4385\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2457 - accuracy: 0.4385\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2457 - accuracy: 0.4385\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2456 - accuracy: 0.4385\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2457 - accuracy: 0.4385\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2456 - accuracy: 0.4385\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2456 - accuracy: 0.4385\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2456 - accuracy: 0.4385\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2455 - accuracy: 0.4385\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2454 - accuracy: 0.4385\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2454 - accuracy: 0.4385\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2454 - accuracy: 0.4385\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2454 - accuracy: 0.4385\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2453 - accuracy: 0.4385\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2453 - accuracy: 0.4385\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2453 - accuracy: 0.4385\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2454 - accuracy: 0.4385\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2452 - accuracy: 0.4385\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2451 - accuracy: 0.4385\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2452 - accuracy: 0.4385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d647f448>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.421195652173913\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  10   1   2   0]\n",
      " [  0   0 132  10  13   0]\n",
      " [  0   0 145  14   8   0]\n",
      " [  0   0  20   2   4   0]\n",
      " [  0   0   4   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.42      1.00      0.59       155\n",
      "         4.0       0.00      0.00      0.00       167\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       368\n",
      "   macro avg       0.07      0.17      0.10       368\n",
      "weighted avg       0.18      0.42      0.25       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 21, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_135 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,257\n",
      "Trainable params: 20,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 3ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7790 - accuracy: 0.1890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d68ad988>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.13043478260869565\n",
      "Tasa de aciertos balanceada regresión logística: 0.05\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [  2   0   0   1   0   0   0]\n",
      " [  9   0   0   4   0   0   0]\n",
      " [107   0   0  48   0   0   0]\n",
      " [107   0   0  60   0   0   0]\n",
      " [ 19   0   0   7   0   0   0]\n",
      " [  2   0   0   2   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.39      0.31      0.35       155\n",
      "         4.0       0.00      0.00      0.00       167\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.13       368\n",
      "   macro avg       0.06      0.04      0.05       368\n",
      "weighted avg       0.17      0.13      0.15       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_140 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,935\n",
      "Trainable params: 8,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 3ms/step - loss: 8.3025 - accuracy: 0.3317\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7697 - accuracy: 0.1788\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7691 - accuracy: 0.1666\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7691 - accuracy: 0.1666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d6bd7908>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.16304347826086957\n",
      "Tasa de aciertos balanceada regresión logística: 0.18\n",
      "Matriz de confusión:\n",
      "[[  0   2   1   0   0   0]\n",
      " [  0  10   3   0   0   0]\n",
      " [  0  97  50   0   0   8]\n",
      " [  0 105  47   0   0  15]\n",
      " [  0  15  10   0   0   1]\n",
      " [  0   2   2   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.04      0.77      0.08        13\n",
      "         3.0       0.44      0.32      0.37       155\n",
      "         4.0       0.00      0.00      0.00       167\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.16       368\n",
      "   macro avg       0.08      0.18      0.08       368\n",
      "weighted avg       0.19      0.16      0.16       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_145 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,679\n",
      "Trainable params: 2,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4866 - accuracy: 0.3882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d80cf2c8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.453804347826087\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [  2   0   0   1   0   0   0]\n",
      " [  9   0   0   4   0   0   0]\n",
      " [107   0   0  48   0   0   0]\n",
      " [107   0   0  60   0   0   0]\n",
      " [ 19   0   0   7   0   0   0]\n",
      " [  2   0   0   2   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.00      0.00      0.00       155\n",
      "         4.0       0.45      1.00      0.62       167\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.45       368\n",
      "   macro avg       0.08      0.17      0.10       368\n",
      "weighted avg       0.21      0.45      0.28       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 21, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_150 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,319\n",
      "Trainable params: 11,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 5ms/step - loss: 3.0747 - accuracy: 0.0041\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4951 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d93e0bc8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0   0]\n",
      " [ 13   0   0   0   0   0   0]\n",
      " [155   0   0   0   0   0   0]\n",
      " [167   0   0   0   0   0   0]\n",
      " [ 26   0   0   0   0   0   0]\n",
      " [  4   0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       3.0\n",
      "         2.0       0.00      0.00      0.00      13.0\n",
      "         3.0       0.00      0.00      0.00     155.0\n",
      "         4.0       0.00      0.00      0.00     167.0\n",
      "         5.0       0.00      0.00      0.00      26.0\n",
      "         6.0       0.00      0.00      0.00       4.0\n",
      "\n",
      "    accuracy                           0.00     368.0\n",
      "   macro avg       0.00      0.00      0.00     368.0\n",
      "weighted avg       0.00      0.00      0.00     368.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,215\n",
      "Trainable params: 5,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 5s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0342 - accuracy: 0.0727\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0343 - accuracy: 0.0727\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0342 - accuracy: 0.0727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226cf48eb48>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.08152173913043478\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   3   0]\n",
      " [  0   0   0   1   0  12   0]\n",
      " [  3   0   0   5   0 147   0]\n",
      " [  2   0   0  12   0 153   0]\n",
      " [  0   0   0   1   0  25   0]\n",
      " [  0   0   0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.26      0.03      0.06       155\n",
      "         4.0       0.00      0.00      0.00       167\n",
      "         5.0       0.07      0.96      0.14        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.08       368\n",
      "   macro avg       0.05      0.14      0.03       368\n",
      "weighted avg       0.12      0.08      0.03       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_170 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,713\n",
      "Trainable params: 1,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 3ms/step - loss: 2.8981 - accuracy: 0.4222\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8874 - accuracy: 0.4385\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8874 - accuracy: 0.4385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226d63cc988>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.421195652173913\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0   0]\n",
      " [ 13   0   0   0   0   0   0]\n",
      " [155   0   0   0   0   0   0]\n",
      " [167   0   0   0   0   0   0]\n",
      " [ 26   0   0   0   0   0   0]\n",
      " [  4   0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.42      1.00      0.59       155\n",
      "         4.0       0.00      0.00      0.00       167\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       368\n",
      "   macro avg       0.07      0.17      0.10       368\n",
      "weighted avg       0.18      0.42      0.25       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_180 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,965\n",
      "Trainable params: 9,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 3ms/step - loss: 659.3296 - accuracy: 0.3542\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 279.6448 - accuracy: 0.3542\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 189.4577 - accuracy: 0.3392\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 143.4346 - accuracy: 0.3569\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 131.0941 - accuracy: 0.3576\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 114.7037 - accuracy: 0.3549\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 107.9185 - accuracy: 0.3759\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 108.1027 - accuracy: 0.3453\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 101.1115 - accuracy: 0.3623\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 94.5165 - accuracy: 0.3440\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 92.6233 - accuracy: 0.3528\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 90.6260 - accuracy: 0.3657\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.5051 - accuracy: 0.3562\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.1947 - accuracy: 0.3562\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.8778 - accuracy: 0.3725\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 83.1070 - accuracy: 0.3725\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 78.2045 - accuracy: 0.3691\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 76.8947 - accuracy: 0.3739\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 76.1958 - accuracy: 0.3875\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 74.3796 - accuracy: 0.3705\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 73.5551 - accuracy: 0.3875\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 73.2294 - accuracy: 0.3834\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 73.1657 - accuracy: 0.3637\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 70.6364 - accuracy: 0.3807\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 72.6240 - accuracy: 0.3603\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 68.7978 - accuracy: 0.3780\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 69.1442 - accuracy: 0.3623\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 68.3582 - accuracy: 0.3712\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 67.5107 - accuracy: 0.3712\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 65.8657 - accuracy: 0.3909\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 65.6367 - accuracy: 0.3664\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 64.8884 - accuracy: 0.3712\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 62.7051 - accuracy: 0.3780\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 63.7007 - accuracy: 0.3746\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 62.4463 - accuracy: 0.3732\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.6660 - accuracy: 0.3651\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 62.3552 - accuracy: 0.3827\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 60.1722 - accuracy: 0.3657\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 60.0560 - accuracy: 0.3589\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 60.0403 - accuracy: 0.3759\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 59.2782 - accuracy: 0.3814\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 59.1926 - accuracy: 0.3739\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.0462 - accuracy: 0.3882\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.4644 - accuracy: 0.3773\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.0725 - accuracy: 0.3753\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 56.3740 - accuracy: 0.3807\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 56.2868 - accuracy: 0.3916\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 56.3196 - accuracy: 0.3746\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 56.3468 - accuracy: 0.3732\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 54.7779 - accuracy: 0.3827\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 55.4627 - accuracy: 0.3739\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 54.4597 - accuracy: 0.3868\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 53.0446 - accuracy: 0.3787\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 54.6624 - accuracy: 0.3909\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 52.9714 - accuracy: 0.3807\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 52.3406 - accuracy: 0.3678\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 52.8826 - accuracy: 0.3821\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 52.6883 - accuracy: 0.3889\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.7858 - accuracy: 0.3685\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.9690 - accuracy: 0.3719\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 50.6144 - accuracy: 0.3773\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.6754 - accuracy: 0.3807\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.1391 - accuracy: 0.3759\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 50.1682 - accuracy: 0.3855\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 49.9384 - accuracy: 0.3814\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 50.5722 - accuracy: 0.3685\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.5479 - accuracy: 0.3963\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 49.3717 - accuracy: 0.3739\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 48.7928 - accuracy: 0.3712\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.9978 - accuracy: 0.3855\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 48.3042 - accuracy: 0.3800\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.0472 - accuracy: 0.3739\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.2590 - accuracy: 0.3848\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.4329 - accuracy: 0.3766\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.0835 - accuracy: 0.3753\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.8797 - accuracy: 0.3719\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 46.2150 - accuracy: 0.3848\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 46.6074 - accuracy: 0.3698\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 46.9975 - accuracy: 0.3807\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 45.6418 - accuracy: 0.3909\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.3418 - accuracy: 0.3746\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 45.4038 - accuracy: 0.3814\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.5300 - accuracy: 0.3753\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 44.7955 - accuracy: 0.3807\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.6217 - accuracy: 0.3644\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 44.4795 - accuracy: 0.3753\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.1415 - accuracy: 0.3821\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.9547 - accuracy: 0.3821\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.6307 - accuracy: 0.3759\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 43.5723 - accuracy: 0.3841\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.3726 - accuracy: 0.3773\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 42.6908 - accuracy: 0.3807\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.1178 - accuracy: 0.3759\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 42.2103 - accuracy: 0.3841\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.0220 - accuracy: 0.3895\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.6872 - accuracy: 0.3848\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.9675 - accuracy: 0.3753\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.8820 - accuracy: 0.3712\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.3757 - accuracy: 0.3923\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.1194 - accuracy: 0.3807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226dc2c53c8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3342391304347826\n",
      "Tasa de aciertos balanceada regresión logística: 0.13\n",
      "Matriz de confusión:\n",
      "[[ 0  0  1  0  2  0]\n",
      " [ 0  0  7  3  3  0]\n",
      " [ 2  3 71 53 23  3]\n",
      " [ 1  7 78 51 29  1]\n",
      " [ 1  0 18  6  1  0]\n",
      " [ 0  0  2  2  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.40      0.46      0.43       155\n",
      "         4.0       0.44      0.31      0.36       167\n",
      "         5.0       0.02      0.04      0.02        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33       368\n",
      "   macro avg       0.14      0.13      0.14       368\n",
      "weighted avg       0.37      0.33      0.35       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_185 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,652\n",
      "Trainable params: 4,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 721.7548 - accuracy: 0.4038\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 289.4989 - accuracy: 0.3494\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 229.4189 - accuracy: 0.3787\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 196.7372 - accuracy: 0.3773\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 174.1568 - accuracy: 0.3766\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 158.7927 - accuracy: 0.3834\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 143.0682 - accuracy: 0.3793\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 134.8947 - accuracy: 0.3793\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 125.5523 - accuracy: 0.3848\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 122.8549 - accuracy: 0.3848\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 114.7971 - accuracy: 0.4031\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 108.1655 - accuracy: 0.3834\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 102.9044 - accuracy: 0.3827\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 100.4497 - accuracy: 0.3848\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 96.1331 - accuracy: 0.3848\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 93.0810 - accuracy: 0.3916\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 87.9691 - accuracy: 0.3712\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.7077 - accuracy: 0.3827\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.6252 - accuracy: 0.3787\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5831 - accuracy: 0.3787\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.9308 - accuracy: 0.3821\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 75.6651 - accuracy: 0.3990\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 74.3043 - accuracy: 0.3909\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 70.5750 - accuracy: 0.3807\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 72.2045 - accuracy: 0.3902\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 69.2080 - accuracy: 0.3882\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 69.8772 - accuracy: 0.3848\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 67.5288 - accuracy: 0.3780\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 66.2513 - accuracy: 0.3943\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 67.0604 - accuracy: 0.3732\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 63.7413 - accuracy: 0.3936\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 63.6143 - accuracy: 0.3963\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 63.0264 - accuracy: 0.3841\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 63.5941 - accuracy: 0.3950\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 63.2798 - accuracy: 0.3780\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 62.8550 - accuracy: 0.3827\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 60.6396 - accuracy: 0.4018\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 60.1810 - accuracy: 0.3929\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 60.1750 - accuracy: 0.3861\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 59.3748 - accuracy: 0.3868\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.6884 - accuracy: 0.3950\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.1137 - accuracy: 0.3875\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.1804 - accuracy: 0.3970\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 57.6948 - accuracy: 0.3787\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 55.9486 - accuracy: 0.3929\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 56.3724 - accuracy: 0.3698\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 55.6159 - accuracy: 0.3814\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 54.3709 - accuracy: 0.3848\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 54.2230 - accuracy: 0.3868\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.8614 - accuracy: 0.3780\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 52.9849 - accuracy: 0.3793\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.8251 - accuracy: 0.3970\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 51.8151 - accuracy: 0.3868\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 50.7148 - accuracy: 0.3868\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 50.6700 - accuracy: 0.3773\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 49.3517 - accuracy: 0.3902\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.6998 - accuracy: 0.3834\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 48.3757 - accuracy: 0.3909\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.5345 - accuracy: 0.3698\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.5263 - accuracy: 0.3685\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.4956 - accuracy: 0.3807\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.5569 - accuracy: 0.3929\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.8660 - accuracy: 0.4004\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 47.2144 - accuracy: 0.3719\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.7960 - accuracy: 0.3963\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.8132 - accuracy: 0.3855\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.2223 - accuracy: 0.4004\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.9009 - accuracy: 0.4004\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.8980 - accuracy: 0.3970\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 45.3546 - accuracy: 0.3956\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.0868 - accuracy: 0.3943\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.8845 - accuracy: 0.3950\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.6066 - accuracy: 0.4018\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.5611 - accuracy: 0.3984\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.7152 - accuracy: 0.3956\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.6307 - accuracy: 0.3753\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.5731 - accuracy: 0.4099\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.9343 - accuracy: 0.3827\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.6782 - accuracy: 0.3984\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.8831 - accuracy: 0.3848\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.8174 - accuracy: 0.3868\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.7642 - accuracy: 0.4058\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 43.1487 - accuracy: 0.3855\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.3063 - accuracy: 0.3990\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.2043 - accuracy: 0.3923\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.7435 - accuracy: 0.3861\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 42.5941 - accuracy: 0.3868\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.2948 - accuracy: 0.3923\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.5915 - accuracy: 0.3800\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.8426 - accuracy: 0.3997\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.1363 - accuracy: 0.4072\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 42.5402 - accuracy: 0.3841\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.6813 - accuracy: 0.3882\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.8432 - accuracy: 0.4072\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.4995 - accuracy: 0.3902\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.5097 - accuracy: 0.4011\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.0529 - accuracy: 0.3956\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.2373 - accuracy: 0.3990\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.0367 - accuracy: 0.3848\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.5101 - accuracy: 0.3814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226dd5ff488>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.22010869565217392\n",
      "Tasa de aciertos balanceada regresión logística: 0.12\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  2  0]\n",
      " [ 0  2  1  6  2  2  0]\n",
      " [ 3 24 10 49 33 23 13]\n",
      " [ 1 22  9 71 26 25 13]\n",
      " [ 0  3  2  9  5  5  2]\n",
      " [ 0  0  0  2  1  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.05      0.08      0.06        13\n",
      "         3.0       0.36      0.32      0.33       155\n",
      "         4.0       0.39      0.16      0.22       167\n",
      "         5.0       0.09      0.19      0.12        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.22       368\n",
      "   macro avg       0.12      0.11      0.10       368\n",
      "weighted avg       0.33      0.22      0.25       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_190 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,578\n",
      "Trainable params: 1,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 3422.1033 - accuracy: 0.0925\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1352.7332 - accuracy: 0.1754\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 975.1986 - accuracy: 0.2284\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 782.6149 - accuracy: 0.2373\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 639.9514 - accuracy: 0.2427\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 506.5388 - accuracy: 0.2447\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 401.7873 - accuracy: 0.2447\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 337.8370 - accuracy: 0.2930\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 306.2966 - accuracy: 0.3202\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 283.9165 - accuracy: 0.3317\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 264.5704 - accuracy: 0.3290\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 247.5505 - accuracy: 0.3406\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 232.0373 - accuracy: 0.3413\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 218.3545 - accuracy: 0.3379\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 206.4081 - accuracy: 0.3379\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 196.3551 - accuracy: 0.3365\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 187.4670 - accuracy: 0.3399\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 179.6948 - accuracy: 0.3426\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 172.2878 - accuracy: 0.3399\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 165.5575 - accuracy: 0.3433\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 159.3526 - accuracy: 0.3413\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 153.5118 - accuracy: 0.3474\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 147.6090 - accuracy: 0.3508\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 141.7088 - accuracy: 0.3440\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 136.0514 - accuracy: 0.3521\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 130.5815 - accuracy: 0.3494\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 124.5817 - accuracy: 0.3555\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 119.1737 - accuracy: 0.3542\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 113.5920 - accuracy: 0.3542\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 108.0054 - accuracy: 0.3583\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 102.5190 - accuracy: 0.3589\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 97.3842 - accuracy: 0.3637\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 92.9324 - accuracy: 0.3617\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 89.4766 - accuracy: 0.3651\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.6321 - accuracy: 0.3644\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 84.3196 - accuracy: 0.3698\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.2572 - accuracy: 0.3766\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.3812 - accuracy: 0.3732\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 78.7688 - accuracy: 0.3821\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 77.3961 - accuracy: 0.3664\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 76.0114 - accuracy: 0.3719\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 74.6487 - accuracy: 0.3651\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 73.1440 - accuracy: 0.3739\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 71.8121 - accuracy: 0.3705\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 70.6054 - accuracy: 0.3678\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 69.5412 - accuracy: 0.3691\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 68.4094 - accuracy: 0.3732\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.5737 - accuracy: 0.3685\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 66.7370 - accuracy: 0.3705\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 65.8748 - accuracy: 0.3766\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 65.0924 - accuracy: 0.3712\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 64.2700 - accuracy: 0.3766\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 63.5739 - accuracy: 0.3685\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 62.8558 - accuracy: 0.3725\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 62.2599 - accuracy: 0.3719\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 61.6128 - accuracy: 0.3719\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 61.0298 - accuracy: 0.3753\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 60.3831 - accuracy: 0.3746\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 59.8671 - accuracy: 0.3705\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 59.2871 - accuracy: 0.3759\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.6934 - accuracy: 0.3753\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.2656 - accuracy: 0.3766\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 57.6864 - accuracy: 0.3766\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 57.1815 - accuracy: 0.3827\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 56.5657 - accuracy: 0.3732\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 56.0161 - accuracy: 0.3780\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 55.4834 - accuracy: 0.3814\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 54.9570 - accuracy: 0.3787\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 54.4341 - accuracy: 0.3780\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.8955 - accuracy: 0.3800\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.4668 - accuracy: 0.3787\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.8937 - accuracy: 0.3807\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 52.3050 - accuracy: 0.3868\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 51.8652 - accuracy: 0.3855\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.3615 - accuracy: 0.3868\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 50.9373 - accuracy: 0.3827\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 50.4324 - accuracy: 0.3855\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 49.9788 - accuracy: 0.3848\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 49.5481 - accuracy: 0.3889\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 49.1546 - accuracy: 0.3909\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 48.7145 - accuracy: 0.3902\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.2645 - accuracy: 0.3875\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.8138 - accuracy: 0.3916\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.3932 - accuracy: 0.3923\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.0164 - accuracy: 0.3923\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.6260 - accuracy: 0.3909\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.2386 - accuracy: 0.3990\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.8804 - accuracy: 0.3936\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.5397 - accuracy: 0.3956\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.1173 - accuracy: 0.3977\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.7706 - accuracy: 0.3956\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.4483 - accuracy: 0.3977\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.1166 - accuracy: 0.4004\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.7272 - accuracy: 0.3990\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.3535 - accuracy: 0.3970\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.9679 - accuracy: 0.3970\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.6533 - accuracy: 0.3929\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.3385 - accuracy: 0.3956\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.9563 - accuracy: 0.4018\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.6856 - accuracy: 0.3977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226dd9983c8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.41304347826086957\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  1  0  2  0]\n",
      " [ 0  0  7  3  3  0]\n",
      " [ 2  3 71 53 23  3]\n",
      " [ 1  7 78 51 29  1]\n",
      " [ 1  0 18  6  1  0]\n",
      " [ 0  0  2  2  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.25      0.08      0.12        13\n",
      "         3.0       0.34      0.14      0.19       155\n",
      "         4.0       0.44      0.77      0.56       167\n",
      "         5.0       0.11      0.04      0.06        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.41       368\n",
      "   macro avg       0.19      0.17      0.15       368\n",
      "weighted avg       0.36      0.41      0.34       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_195 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,257\n",
      "Trainable params: 20,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 4.8819 - accuracy: 0.3046\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.5196 - accuracy: 0.3066\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5196 - accuracy: 0.3066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226ded19388>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.15217391304347827\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  2   0   1   0   0   0]\n",
      " [  7   0   6   0   0   0]\n",
      " [101   0  54   0   0   0]\n",
      " [101   0  66   0   0   0]\n",
      " [ 19   0   7   0   0   0]\n",
      " [  3   0   1   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      0.67      0.02         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.40      0.35      0.37       155\n",
      "         4.0       0.00      0.00      0.00       167\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.15       368\n",
      "   macro avg       0.07      0.17      0.06       368\n",
      "weighted avg       0.17      0.15      0.16       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_200 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,935\n",
      "Trainable params: 8,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 3ms/step - loss: 6.0876 - accuracy: 0.0714\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4411 - accuracy: 0.0884\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4475 - accuracy: 0.0897\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4475 - accuracy: 0.0897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226df100508>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07880434782608696\n",
      "Tasa de aciertos balanceada regresión logística: 0.16\n",
      "Matriz de confusión:\n",
      "[[ 1  0  0  0  2  0]\n",
      " [ 7  0  0  0  6  0]\n",
      " [59  0  0 11 85  0]\n",
      " [70  0  0 14 83  0]\n",
      " [11  0  0  1 14  0]\n",
      " [ 2  0  0  1  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      0.33      0.01         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.00      0.00      0.00       155\n",
      "         4.0       0.52      0.08      0.14       167\n",
      "         5.0       0.07      0.54      0.13        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.08       368\n",
      "   macro avg       0.10      0.16      0.05       368\n",
      "weighted avg       0.24      0.08      0.07       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_205 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,679\n",
      "Trainable params: 2,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 8.5609 - accuracy: 0.0381\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5420 - accuracy: 0.0578\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5364 - accuracy: 0.0537\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4907 - accuracy: 0.0578\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4118 - accuracy: 0.0625\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4102 - accuracy: 0.0673\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 8.4102 - accuracy: 0.0673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226e04b5a88>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07608695652173914\n",
      "Tasa de aciertos balanceada regresión logística: 0.07\n",
      "Matriz de confusión:\n",
      "[[  2   0   1   0   0   0]\n",
      " [  7   0   6   0   0   0]\n",
      " [101   0  54   0   0   0]\n",
      " [101   0  66   0   0   0]\n",
      " [ 19   0   7   0   0   0]\n",
      " [  3   0   1   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.49      0.14      0.21       155\n",
      "         4.0       0.00      0.00      0.00       167\n",
      "         5.0       0.05      0.27      0.08        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.08       368\n",
      "   macro avg       0.08      0.06      0.04       368\n",
      "weighted avg       0.21      0.08      0.10       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_210 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,319\n",
      "Trainable params: 11,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 9.3067 - accuracy: 0.2590\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8414 - accuracy: 0.4065\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3081 - accuracy: 0.2148\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7896 - accuracy: 0.0537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226e0799ac8>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.021739130434782608\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  3   0   0   0   0   0]\n",
      " [ 12   0   1   0   0   0]\n",
      " [150   0   5   0   0   0]\n",
      " [166   0   1   0   0   0]\n",
      " [ 25   0   1   0   0   0]\n",
      " [  3   0   1   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      1.00      0.02         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.56      0.03      0.06       155\n",
      "         4.0       0.00      0.00      0.00       167\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.02       368\n",
      "   macro avg       0.09      0.17      0.01       368\n",
      "weighted avg       0.23      0.02      0.03       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_220 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,215\n",
      "Trainable params: 5,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 9.5155 - accuracy: 0.3773\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4890 - accuracy: 0.4024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226e1d12788>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.358695652173913\n",
      "Tasa de aciertos balanceada regresión logística: 0.14\n",
      "Matriz de confusión:\n",
      "[[  0   0   2   0   0   1]\n",
      " [  0   0  12   0   0   1]\n",
      " [  0   0 132   0   0  23]\n",
      " [  0   0 141   0   0  26]\n",
      " [  0   0  24   0   0   2]\n",
      " [  0   0   4   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.42      0.85      0.56       155\n",
      "         4.0       0.00      0.00      0.00       167\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.36       368\n",
      "   macro avg       0.07      0.14      0.09       368\n",
      "weighted avg       0.18      0.36      0.24       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_230 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,713\n",
      "Trainable params: 1,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 3ms/step - loss: 11.5197 - accuracy: 0.0204\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1646 - accuracy: 0.0170\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2479 - accuracy: 0.0156\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2516 - accuracy: 0.0143\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.0003 - accuracy: 0.0136\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8224 - accuracy: 0.0102\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6034 - accuracy: 0.0088\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0637 - accuracy: 0.0102\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8682 - accuracy: 0.0102\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8101 - accuracy: 0.0095\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0752 - accuracy: 0.0061\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8348 - accuracy: 0.0068\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9055 - accuracy: 0.0068\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5229 - accuracy: 0.0054\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2298 - accuracy: 0.0054\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6938 - accuracy: 0.0034\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4810 - accuracy: 6.7981e-04\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3955 - accuracy: 0.0014\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2839 - accuracy: 0.0014\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2446 - accuracy: 6.7981e-04\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2534 - accuracy: 6.7981e-04\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2027 - accuracy: 6.7981e-04\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1930 - accuracy: 0.0014\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1385 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0993 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0685 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0291 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0291 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0291 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0291 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0291 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0290 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0290 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0290 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0290 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0290 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0290 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0290 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0290 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0290 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0162 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9871 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9870 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9870 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9870 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9870 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9868 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9868 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9868 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9867 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9867 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9867 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9867 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9867 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9867 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9867 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9867 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9867 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0064 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9952 - accuracy: 6.7981e-04\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9870 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9870 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9870 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9870 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9870 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9870 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9870 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226e31da5c8>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  3   0   0   0   0   0]\n",
      " [ 12   0   1   0   0   0]\n",
      " [150   0   5   0   0   0]\n",
      " [166   0   1   0   0   0]\n",
      " [ 25   0   1   0   0   0]\n",
      " [  3   0   1   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       3.0\n",
      "         2.0       0.00      0.00      0.00      13.0\n",
      "         3.0       0.00      0.00      0.00     155.0\n",
      "         4.0       0.00      0.00      0.00     167.0\n",
      "         5.0       0.00      0.00      0.00      26.0\n",
      "         6.0       0.00      0.00      0.00       4.0\n",
      "\n",
      "    accuracy                           0.00     368.0\n",
      "   macro avg       0.00      0.00      0.00     368.0\n",
      "weighted avg       0.00      0.00      0.00     368.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 35, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_240 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,365\n",
      "Trainable params: 11,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 483.2169 - accuracy: 0.3237\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 108.4116 - accuracy: 0.3863\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 64.7169 - accuracy: 0.3869\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 64.1903 - accuracy: 0.3835\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 58.5107 - accuracy: 0.3601\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 43.1967 - accuracy: 0.3491\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 47.3182 - accuracy: 0.3856\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 44.8489 - accuracy: 0.3595\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 29.6053 - accuracy: 0.3753\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 34.7505 - accuracy: 0.3938\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 34.6422 - accuracy: 0.3649\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 26.5301 - accuracy: 0.3567\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.8763 - accuracy: 0.3773\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.6714 - accuracy: 0.3739\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.3509 - accuracy: 0.3959\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.0252 - accuracy: 0.3704\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6595 - accuracy: 0.3883\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.8544 - accuracy: 0.3897\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.8738 - accuracy: 0.3601\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.0607 - accuracy: 0.3842\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.9661 - accuracy: 0.3663\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.9353 - accuracy: 0.3409\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.7538 - accuracy: 0.4089\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.8271 - accuracy: 0.3732\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.2181 - accuracy: 0.3787\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.6398 - accuracy: 0.4103\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3323 - accuracy: 0.3863\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3796 - accuracy: 0.3691\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.2503 - accuracy: 0.3423\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.9104 - accuracy: 0.3938\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7852 - accuracy: 0.3938\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.5210 - accuracy: 0.3835\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.9645 - accuracy: 0.3533\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.6806 - accuracy: 0.3897\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3625 - accuracy: 0.3931\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3764 - accuracy: 0.3649\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.8466 - accuracy: 0.3931\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2206 - accuracy: 0.3842\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.2417 - accuracy: 0.3663\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0270 - accuracy: 0.3883\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4147 - accuracy: 0.3828\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9952 - accuracy: 0.3993\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.2213 - accuracy: 0.4062\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2822 - accuracy: 0.3952\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.9202 - accuracy: 0.3918\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.7949 - accuracy: 0.3457\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.4073 - accuracy: 0.3704\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.2701 - accuracy: 0.3821\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.2296 - accuracy: 0.4007\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4698 - accuracy: 0.3643\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5585 - accuracy: 0.3739\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2184 - accuracy: 0.3918\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.1483 - accuracy: 0.3759\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9423 - accuracy: 0.3787\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5451 - accuracy: 0.4247\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3367 - accuracy: 0.3924\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1941 - accuracy: 0.4096\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2432 - accuracy: 0.4165\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0356 - accuracy: 0.4000\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4642 - accuracy: 0.3973\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3003 - accuracy: 0.3931\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4575 - accuracy: 0.4220\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6692 - accuracy: 0.3966\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6048 - accuracy: 0.3918\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7714 - accuracy: 0.4021\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0124 - accuracy: 0.3966\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1246 - accuracy: 0.4206\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7546 - accuracy: 0.3993\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0821 - accuracy: 0.3959\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6895 - accuracy: 0.4186\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7438 - accuracy: 0.4172\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7209 - accuracy: 0.3863\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5849 - accuracy: 0.4007\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5876 - accuracy: 0.4144\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6814 - accuracy: 0.4096\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6271 - accuracy: 0.4151\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6723 - accuracy: 0.3993\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5814 - accuracy: 0.4103\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5511 - accuracy: 0.3993\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6500 - accuracy: 0.4089\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5986 - accuracy: 0.4172\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5402 - accuracy: 0.4131\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4589 - accuracy: 0.4103\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4441 - accuracy: 0.4227\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.3922 - accuracy: 0.4124\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4420 - accuracy: 0.3938\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4240 - accuracy: 0.4364\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4109 - accuracy: 0.4213\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4557 - accuracy: 0.4440\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5238 - accuracy: 0.4055\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4745 - accuracy: 0.4082\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4821 - accuracy: 0.4309\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3499 - accuracy: 0.4254\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4464 - accuracy: 0.4021\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4046 - accuracy: 0.4302\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3809 - accuracy: 0.4199\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4644 - accuracy: 0.4227\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4323 - accuracy: 0.3945\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5074 - accuracy: 0.4165\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5437 - accuracy: 0.4007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226dd8b5288>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4065934065934066\n",
      "Tasa de aciertos balanceada regresión logística: 0.16\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  11   2   0   0]\n",
      " [  0   0 123  29   0   0]\n",
      " [  0   0 141  25   0   0]\n",
      " [  0   0  20   6   0   0]\n",
      " [  0   0   3   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.41      0.81      0.54       152\n",
      "         4.0       0.40      0.15      0.22       166\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.41       364\n",
      "   macro avg       0.13      0.16      0.13       364\n",
      "weighted avg       0.35      0.41      0.33       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_245 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,548\n",
      "Trainable params: 5,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 3ms/step - loss: 883.2450 - accuracy: 0.3416\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 140.7110 - accuracy: 0.3574\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 87.5808 - accuracy: 0.3677\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 64.9212 - accuracy: 0.3203\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.2749 - accuracy: 0.3388\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.4096 - accuracy: 0.3780\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 32.6165 - accuracy: 0.4179\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.6727 - accuracy: 0.4179\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.1148 - accuracy: 0.4096\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.9127 - accuracy: 0.4268\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.0695 - accuracy: 0.4021\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5302 - accuracy: 0.4254\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9803 - accuracy: 0.4247\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6940 - accuracy: 0.4241\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5166 - accuracy: 0.4247\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.5978 - accuracy: 0.4179\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.8780 - accuracy: 0.4165\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.1357 - accuracy: 0.4041\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3179 - accuracy: 0.4192\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.0633 - accuracy: 0.4089\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.7737 - accuracy: 0.4124\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8468 - accuracy: 0.4296\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.9929 - accuracy: 0.4117\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.0318 - accuracy: 0.4213\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4493 - accuracy: 0.4192\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6620 - accuracy: 0.4137\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4537 - accuracy: 0.4282\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3643 - accuracy: 0.4399\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3547 - accuracy: 0.4405\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3463 - accuracy: 0.4405\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3385 - accuracy: 0.4405\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3315 - accuracy: 0.4405\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3251 - accuracy: 0.4405\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3194 - accuracy: 0.4405\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3141 - accuracy: 0.4405\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3093 - accuracy: 0.4405\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3049 - accuracy: 0.4405\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3008 - accuracy: 0.4405\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2971 - accuracy: 0.4405\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2937 - accuracy: 0.4405\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2906 - accuracy: 0.4405\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2878 - accuracy: 0.4405\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2851 - accuracy: 0.4405\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2827 - accuracy: 0.4405\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2805 - accuracy: 0.4405\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2783 - accuracy: 0.4405\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2764 - accuracy: 0.4405\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2747 - accuracy: 0.4405\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2730 - accuracy: 0.4405\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2715 - accuracy: 0.4405\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2700 - accuracy: 0.4405\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2687 - accuracy: 0.4405\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2675 - accuracy: 0.4405\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2662 - accuracy: 0.4405\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2651 - accuracy: 0.4405\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2641 - accuracy: 0.4405\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2631 - accuracy: 0.4405\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2623 - accuracy: 0.4405\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2613 - accuracy: 0.4405\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2605 - accuracy: 0.4405\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2598 - accuracy: 0.4405\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2591 - accuracy: 0.4405\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2584 - accuracy: 0.4405\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2578 - accuracy: 0.4405\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2572 - accuracy: 0.4405\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2566 - accuracy: 0.4405\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2560 - accuracy: 0.4405\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2555 - accuracy: 0.4405\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2550 - accuracy: 0.4405\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2546 - accuracy: 0.4405\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2541 - accuracy: 0.4405\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2538 - accuracy: 0.4405\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2533 - accuracy: 0.4405\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2529 - accuracy: 0.4405\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2526 - accuracy: 0.4405\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2522 - accuracy: 0.4405\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2519 - accuracy: 0.4405\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2516 - accuracy: 0.4405\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2512 - accuracy: 0.4405\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2509 - accuracy: 0.4405\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2507 - accuracy: 0.4405\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2504 - accuracy: 0.4405\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2501 - accuracy: 0.4405\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2499 - accuracy: 0.4405\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2496 - accuracy: 0.4405\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2494 - accuracy: 0.4405\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2492 - accuracy: 0.4405\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2490 - accuracy: 0.4405\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2488 - accuracy: 0.4405\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2486 - accuracy: 0.4405\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2484 - accuracy: 0.4405\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2481 - accuracy: 0.4405\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2480 - accuracy: 0.4405\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2478 - accuracy: 0.4405\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2477 - accuracy: 0.4405\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2475 - accuracy: 0.4405\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2473 - accuracy: 0.4405\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2472 - accuracy: 0.4405\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2470 - accuracy: 0.4405\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2468 - accuracy: 0.4405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226deceff08>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4175824175824176\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  13   0   0   0]\n",
      " [  0   0 152   0   0   0]\n",
      " [  0   0 166   0   0   0]\n",
      " [  0   0  26   0   0   0]\n",
      " [  0   0   4   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.42      1.00      0.59       152\n",
      "         4.0       0.00      0.00      0.00       166\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       364\n",
      "   macro avg       0.07      0.17      0.10       364\n",
      "weighted avg       0.17      0.42      0.25       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_250 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,026\n",
      "Trainable params: 2,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 256.2878 - accuracy: 0.2646\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6028 - accuracy: 0.3725\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4250 - accuracy: 0.4344\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1685 - accuracy: 0.4405\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9260 - accuracy: 0.4419\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7696 - accuracy: 0.4440\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7494 - accuracy: 0.4412\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7056 - accuracy: 0.4433\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6567 - accuracy: 0.4433\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6243 - accuracy: 0.4433\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5949 - accuracy: 0.4440\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5829 - accuracy: 0.4440\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5437 - accuracy: 0.4433\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5128 - accuracy: 0.4433\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5074 - accuracy: 0.4419\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4767 - accuracy: 0.4440\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4696 - accuracy: 0.4426\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4428 - accuracy: 0.4405\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4335 - accuracy: 0.4405\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4203 - accuracy: 0.4399\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4032 - accuracy: 0.4405\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3917 - accuracy: 0.4405\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3815 - accuracy: 0.4405\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3720 - accuracy: 0.4405\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3633 - accuracy: 0.4405\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3553 - accuracy: 0.4405\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3480 - accuracy: 0.4405\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3413 - accuracy: 0.4405\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3351 - accuracy: 0.4405\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3294 - accuracy: 0.4405\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3242 - accuracy: 0.4405\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3193 - accuracy: 0.4405\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3149 - accuracy: 0.4405\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3108 - accuracy: 0.4405\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3069 - accuracy: 0.4405\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3035 - accuracy: 0.4405\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3002 - accuracy: 0.4405\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2972 - accuracy: 0.4405\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2944 - accuracy: 0.4405\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2919 - accuracy: 0.4405\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2895 - accuracy: 0.4405\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2872 - accuracy: 0.4405\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2851 - accuracy: 0.4405\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2832 - accuracy: 0.4405\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2813 - accuracy: 0.4405\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2796 - accuracy: 0.4405\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2781 - accuracy: 0.4405\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2765 - accuracy: 0.4405\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2751 - accuracy: 0.4405\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2738 - accuracy: 0.4405\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2725 - accuracy: 0.4405\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2713 - accuracy: 0.4405\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2702 - accuracy: 0.4405\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2692 - accuracy: 0.4405\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2682 - accuracy: 0.4405\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2672 - accuracy: 0.4405\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2663 - accuracy: 0.4405\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2655 - accuracy: 0.4405\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2647 - accuracy: 0.4405\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2639 - accuracy: 0.4405\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2633 - accuracy: 0.4405\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2625 - accuracy: 0.4405\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2619 - accuracy: 0.4405\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2613 - accuracy: 0.4405\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2606 - accuracy: 0.4405\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2601 - accuracy: 0.4405\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2595 - accuracy: 0.4405\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2590 - accuracy: 0.4405\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2585 - accuracy: 0.4405\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2581 - accuracy: 0.4405\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2576 - accuracy: 0.4405\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2571 - accuracy: 0.4405\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2567 - accuracy: 0.4405\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2563 - accuracy: 0.4405\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2559 - accuracy: 0.4405\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2555 - accuracy: 0.4405\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2552 - accuracy: 0.4405\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2548 - accuracy: 0.4405\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2544 - accuracy: 0.4405\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2542 - accuracy: 0.4405\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2538 - accuracy: 0.4405\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2535 - accuracy: 0.4405\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2532 - accuracy: 0.4405\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2529 - accuracy: 0.4405\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2526 - accuracy: 0.4405\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2524 - accuracy: 0.4405\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2522 - accuracy: 0.4405\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2518 - accuracy: 0.4405\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2516 - accuracy: 0.4405\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2514 - accuracy: 0.4405\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2511 - accuracy: 0.4405\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2510 - accuracy: 0.4405\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2507 - accuracy: 0.4405\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2505 - accuracy: 0.4405\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2503 - accuracy: 0.4405\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2502 - accuracy: 0.4405\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2499 - accuracy: 0.4405\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2497 - accuracy: 0.4405\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2496 - accuracy: 0.4405\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2494 - accuracy: 0.4405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226e4a72588>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4175824175824176\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   0  11   2   0   0]\n",
      " [  0   0 123  29   0   0]\n",
      " [  0   0 141  25   0   0]\n",
      " [  0   0  20   6   0   0]\n",
      " [  0   0   3   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.42      1.00      0.59       152\n",
      "         4.0       0.00      0.00      0.00       166\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       364\n",
      "   macro avg       0.07      0.17      0.10       364\n",
      "weighted avg       0.17      0.42      0.25       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 35, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_255 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_256 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,657\n",
      "Trainable params: 21,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0798 - accuracy: 0.0337\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0798 - accuracy: 0.0337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226e5e125c8>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.016483516483516484\n",
      "Tasa de aciertos balanceada regresión logística: 0.14\n",
      "Matriz de confusión:\n",
      "[[  2   0   0   0   1   0]\n",
      " [ 10   0   0   0   3   0]\n",
      " [113   0   0   0  39   0]\n",
      " [112   0   0   0  54   0]\n",
      " [ 22   0   0   0   4   0]\n",
      " [  4   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      0.67      0.02         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.00      0.00      0.00       152\n",
      "         4.0       0.00      0.00      0.00       166\n",
      "         5.0       0.04      0.15      0.06        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.02       364\n",
      "   macro avg       0.01      0.14      0.01       364\n",
      "weighted avg       0.00      0.02      0.00       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_260 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_261 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_262 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_264 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,831\n",
      "Trainable params: 9,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 5ms/step - loss: 15.7381 - accuracy: 0.0591\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8121 - accuracy: 0.0646\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8119 - accuracy: 0.0646\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8119 - accuracy: 0.0646\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8119 - accuracy: 0.0646\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8119 - accuracy: 0.0646\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8119 - accuracy: 0.0646\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8119 - accuracy: 0.0646\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8119 - accuracy: 0.0646\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8119 - accuracy: 0.0646\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8119 - accuracy: 0.0646\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8119 - accuracy: 0.0646\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8120 - accuracy: 0.0646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226e6269548>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07142857142857142\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   3   0]\n",
      " [  0   0   0   0  13   0]\n",
      " [  0   0   0   0 152   0]\n",
      " [  0   0   0   0 166   0]\n",
      " [  0   0   0   0  26   0]\n",
      " [  0   0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.00      0.00      0.00       152\n",
      "         4.0       0.00      0.00      0.00       166\n",
      "         5.0       0.07      1.00      0.13        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.07       364\n",
      "   macro avg       0.01      0.17      0.02       364\n",
      "weighted avg       0.01      0.07      0.01       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_265 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,127\n",
      "Trainable params: 3,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.6174 - accuracy: 0.0027\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.6174 - accuracy: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226e7689048>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0027472527472527475\n",
      "Tasa de aciertos balanceada regresión logística: 0.04\n",
      "Matriz de confusión:\n",
      "[[  2   0   0   0   1   0]\n",
      " [ 10   0   0   0   3   0]\n",
      " [113   0   0   0  39   0]\n",
      " [112   0   0   0  54   0]\n",
      " [ 22   0   0   0   4   0]\n",
      " [  4   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.00      0.00      0.00       152\n",
      "         4.0       0.00      0.00      0.00       166\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.01      0.25      0.02         4\n",
      "\n",
      "    accuracy                           0.00       364\n",
      "   macro avg       0.00      0.04      0.00       364\n",
      "weighted avg       0.00      0.00      0.00       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 35, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_270 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_271 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_272 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_274 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_277 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_278 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_279 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,719\n",
      "Trainable params: 12,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 4ms/step - loss: 14.6884 - accuracy: 0.0179\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.7239 - accuracy: 0.0158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226e7ab9208>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.01098901098901099\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   3]\n",
      " [  0   0   0   0   0  13]\n",
      " [  0   0   0   0   0 152]\n",
      " [  0   0   0   0   0 166]\n",
      " [  0   0   0   0   0  26]\n",
      " [  0   0   0   0   0   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.00      0.00      0.00       152\n",
      "         4.0       0.00      0.00      0.00       166\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.01      1.00      0.02         4\n",
      "\n",
      "    accuracy                           0.01       364\n",
      "   macro avg       0.00      0.17      0.00       364\n",
      "weighted avg       0.00      0.01      0.00       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_280 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_282 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,111\n",
      "Trainable params: 6,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 4ms/step - loss: 7.8242 - accuracy: 0.2275\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.6278 - accuracy: 0.0536\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.6779 - accuracy: 0.0515\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.1005 - accuracy: 0.0158\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1005 - accuracy: 0.0158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226e8f18388>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.01098901098901099\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   3]\n",
      " [  0   0   0   0   0  13]\n",
      " [  0   0   0   0   0 152]\n",
      " [  0   0   0   0   0 166]\n",
      " [  0   0   0   0   0  26]\n",
      " [  0   0   0   0   0   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.00      0.00      0.00       152\n",
      "         4.0       0.00      0.00      0.00       166\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.01      1.00      0.02         4\n",
      "\n",
      "    accuracy                           0.01       364\n",
      "   macro avg       0.00      0.17      0.00       364\n",
      "weighted avg       0.00      0.01      0.00       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_290 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_292 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_294 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,161\n",
      "Trainable params: 2,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 4ms/step - loss: 14.5824 - accuracy: 0.0570\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5152 - accuracy: 0.0646\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.5151 - accuracy: 0.0646\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.5151 - accuracy: 0.0646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226ea52edc8>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07142857142857142\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   3]\n",
      " [  0   0   0   0   0  13]\n",
      " [  0   0   0   0   0 152]\n",
      " [  0   0   0   0   0 166]\n",
      " [  0   0   0   0   0  26]\n",
      " [  0   0   0   0   0   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.00      0.00      0.00       152\n",
      "         4.0       0.00      0.00      0.00       166\n",
      "         5.0       0.07      1.00      0.13        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.07       364\n",
      "   macro avg       0.01      0.17      0.02       364\n",
      "weighted avg       0.01      0.07      0.01       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_300 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_301 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_302 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_303 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_304 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,365\n",
      "Trainable params: 11,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 1101.9855 - accuracy: 0.2907\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 447.3885 - accuracy: 0.3718\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 263.9860 - accuracy: 0.3993\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 177.8926 - accuracy: 0.3787\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 150.8089 - accuracy: 0.3808\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 137.7531 - accuracy: 0.3918\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 138.2362 - accuracy: 0.3766\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 126.4612 - accuracy: 0.3876\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 118.2513 - accuracy: 0.3814\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 115.9410 - accuracy: 0.3773\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 107.3009 - accuracy: 0.4062\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 103.8633 - accuracy: 0.3945\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 99.5239 - accuracy: 0.3938\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 98.3037 - accuracy: 0.3959\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 95.3430 - accuracy: 0.3924\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.9295 - accuracy: 0.3931\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 93.4787 - accuracy: 0.4144\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.4435 - accuracy: 0.4007\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 85.5632 - accuracy: 0.4055\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 85.4696 - accuracy: 0.3945\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.1657 - accuracy: 0.3904\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 79.4532 - accuracy: 0.4048\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.3823 - accuracy: 0.3993\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.1894 - accuracy: 0.3849\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 78.6695 - accuracy: 0.3883\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 76.3297 - accuracy: 0.3931\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 74.8126 - accuracy: 0.3904\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 74.7616 - accuracy: 0.3904\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 74.2032 - accuracy: 0.3952\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 71.9072 - accuracy: 0.3973\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 68.3872 - accuracy: 0.4082\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 70.1544 - accuracy: 0.3945\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 70.2709 - accuracy: 0.3979\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.4385 - accuracy: 0.3835\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 67.5316 - accuracy: 0.3918\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 68.3369 - accuracy: 0.3911\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.3092 - accuracy: 0.4014\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.8568 - accuracy: 0.4034\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.2827 - accuracy: 0.3979\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 64.5391 - accuracy: 0.3876\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.1811 - accuracy: 0.3787\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.9643 - accuracy: 0.4041\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 60.3096 - accuracy: 0.3931\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 59.8886 - accuracy: 0.4055\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 60.6213 - accuracy: 0.3863\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.8822 - accuracy: 0.3938\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 59.6504 - accuracy: 0.4055\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.8750 - accuracy: 0.3966\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.1627 - accuracy: 0.3890\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.9161 - accuracy: 0.3959\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.1117 - accuracy: 0.4069\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.4492 - accuracy: 0.4007\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 57.3562 - accuracy: 0.3869\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 56.5062 - accuracy: 0.3828\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 55.5689 - accuracy: 0.3911\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 55.0511 - accuracy: 0.4000\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 54.9906 - accuracy: 0.3993\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 55.0371 - accuracy: 0.3986\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.2676 - accuracy: 0.3856\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.2425 - accuracy: 0.3904\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 52.6244 - accuracy: 0.4103\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 52.3496 - accuracy: 0.4034\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 54.8438 - accuracy: 0.3911\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 52.2773 - accuracy: 0.4041\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 53.2013 - accuracy: 0.3938\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.9210 - accuracy: 0.3890\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 50.3836 - accuracy: 0.4027\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.7483 - accuracy: 0.3938\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.2214 - accuracy: 0.3911\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 49.6692 - accuracy: 0.3938\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.3772 - accuracy: 0.4048\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 50.9263 - accuracy: 0.4055\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 50.6724 - accuracy: 0.3938\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.0935 - accuracy: 0.3973\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 49.9379 - accuracy: 0.3952\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 49.4343 - accuracy: 0.3924\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 49.9441 - accuracy: 0.3966\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 49.6526 - accuracy: 0.3938\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 49.0955 - accuracy: 0.3986\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 50.3336 - accuracy: 0.3993\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 47.9598 - accuracy: 0.4000\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.4721 - accuracy: 0.4048\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.0810 - accuracy: 0.4069\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.9403 - accuracy: 0.4062\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.6413 - accuracy: 0.4014\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.8357 - accuracy: 0.4027\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 47.8007 - accuracy: 0.4021\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.2802 - accuracy: 0.4144\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.2624 - accuracy: 0.4137\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 46.9988 - accuracy: 0.4144\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.6594 - accuracy: 0.3959\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.5451 - accuracy: 0.4014\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.7983 - accuracy: 0.3973\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.8844 - accuracy: 0.4055\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 45.3848 - accuracy: 0.4000\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.8325 - accuracy: 0.4131\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.1876 - accuracy: 0.4000\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.3977 - accuracy: 0.4034\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 44.5800 - accuracy: 0.3993\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.8717 - accuracy: 0.4041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226ebb43ec8>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.40934065934065933\n",
      "Tasa de aciertos balanceada regresión logística: 0.16\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  3  0  0]\n",
      " [ 3  0  4  4  2  0]\n",
      " [12  0 54 80  6  0]\n",
      " [ 8  2 57 94  5  0]\n",
      " [ 2  1 12 10  1  0]\n",
      " [ 0  0  2  2  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.42      0.36      0.38       152\n",
      "         4.0       0.49      0.57      0.52       166\n",
      "         5.0       0.07      0.04      0.05        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.41       364\n",
      "   macro avg       0.16      0.16      0.16       364\n",
      "weighted avg       0.40      0.41      0.40       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_305 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_306 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,548\n",
      "Trainable params: 5,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 3ms/step - loss: 918.7396 - accuracy: 0.3924\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 533.2288 - accuracy: 0.3931\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 411.5471 - accuracy: 0.3904\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 358.2084 - accuracy: 0.3821\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 325.2278 - accuracy: 0.3973\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 302.2430 - accuracy: 0.3897\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 286.4399 - accuracy: 0.3883\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 270.8274 - accuracy: 0.3911\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 255.8354 - accuracy: 0.3890\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 241.7256 - accuracy: 0.3890\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 229.4872 - accuracy: 0.3869\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 219.3228 - accuracy: 0.3897\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 208.9518 - accuracy: 0.3814\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 201.8041 - accuracy: 0.3911\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 194.2545 - accuracy: 0.3808\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 190.7710 - accuracy: 0.3801\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 185.3314 - accuracy: 0.3677\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 180.7494 - accuracy: 0.3766\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 176.9160 - accuracy: 0.3725\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 173.7949 - accuracy: 0.3588\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 168.9601 - accuracy: 0.3656\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 166.3902 - accuracy: 0.3739\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 162.1433 - accuracy: 0.3691\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 158.5258 - accuracy: 0.3649\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 154.8053 - accuracy: 0.3615\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 152.5575 - accuracy: 0.3615\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 149.8657 - accuracy: 0.3636\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 148.0422 - accuracy: 0.3608\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 143.4876 - accuracy: 0.3704\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 141.3388 - accuracy: 0.3553\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 138.0273 - accuracy: 0.3684\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 135.6172 - accuracy: 0.3629\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 133.2009 - accuracy: 0.3588\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 130.3268 - accuracy: 0.3698\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 128.4464 - accuracy: 0.3361\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 126.2182 - accuracy: 0.3643\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 124.7746 - accuracy: 0.3588\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 122.7536 - accuracy: 0.3505\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 120.8493 - accuracy: 0.3677\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 118.8305 - accuracy: 0.3759\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 117.4360 - accuracy: 0.3691\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 115.3387 - accuracy: 0.3801\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 113.8575 - accuracy: 0.3684\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 111.6061 - accuracy: 0.3725\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 110.3711 - accuracy: 0.3649\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 108.7656 - accuracy: 0.3890\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 107.9189 - accuracy: 0.3643\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 106.7344 - accuracy: 0.3649\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 105.4613 - accuracy: 0.3649\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 104.0181 - accuracy: 0.3814\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 102.5594 - accuracy: 0.3842\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 101.5772 - accuracy: 0.3753\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 100.9815 - accuracy: 0.3629\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 99.3880 - accuracy: 0.3794\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 98.1299 - accuracy: 0.3821\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 97.3162 - accuracy: 0.3636\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 95.9796 - accuracy: 0.3732\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 94.8633 - accuracy: 0.3773\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 93.9202 - accuracy: 0.3801\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 92.7128 - accuracy: 0.3801\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 92.1474 - accuracy: 0.3821\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 90.4694 - accuracy: 0.3739\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 89.6230 - accuracy: 0.3643\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 88.5081 - accuracy: 0.3746\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 88.0693 - accuracy: 0.3890\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.7016 - accuracy: 0.3684\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.0846 - accuracy: 0.3629\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.9210 - accuracy: 0.3739\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 84.3675 - accuracy: 0.3691\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.9399 - accuracy: 0.3739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.5355 - accuracy: 0.3766\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.0949 - accuracy: 0.3711\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.2676 - accuracy: 0.3595\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.3859 - accuracy: 0.3801\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 79.9257 - accuracy: 0.3622\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 79.2793 - accuracy: 0.3663\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 78.5592 - accuracy: 0.3670\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 77.9917 - accuracy: 0.3725\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 77.4461 - accuracy: 0.3649\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 76.8475 - accuracy: 0.3801\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 76.2682 - accuracy: 0.3649\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 75.7612 - accuracy: 0.3629\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 75.1674 - accuracy: 0.3704\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 74.4631 - accuracy: 0.3739\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.1875 - accuracy: 0.3739\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 73.6595 - accuracy: 0.3649\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 72.9392 - accuracy: 0.3656\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 72.4241 - accuracy: 0.3773\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 72.1433 - accuracy: 0.3835\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 71.3076 - accuracy: 0.3725\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 71.0492 - accuracy: 0.3835\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 70.4050 - accuracy: 0.3691\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 70.3925 - accuracy: 0.3704\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 69.6048 - accuracy: 0.3766\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 69.3249 - accuracy: 0.3808\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 69.0247 - accuracy: 0.3704\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 68.4159 - accuracy: 0.3698\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 68.3653 - accuracy: 0.3718\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 67.4450 - accuracy: 0.3773\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 66.8973 - accuracy: 0.3732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226ebef5748>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3983516483516483\n",
      "Tasa de aciertos balanceada regresión logística: 0.16\n",
      "Matriz de confusión:\n",
      "[[ 0  0  2  0  1  0]\n",
      " [ 1  1  6  5  0  0]\n",
      " [ 2  2 74 72  2  0]\n",
      " [ 1  4 90 70  1  0]\n",
      " [ 1  1 10 14  0  0]\n",
      " [ 0  0  2  2  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.12      0.08      0.10        13\n",
      "         3.0       0.40      0.49      0.44       152\n",
      "         4.0       0.43      0.42      0.43       166\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.40       364\n",
      "   macro avg       0.16      0.16      0.16       364\n",
      "weighted avg       0.37      0.40      0.38       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_310 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_312 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,026\n",
      "Trainable params: 2,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 4ms/step - loss: 808.0886 - accuracy: 0.1615\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 110.3650 - accuracy: 0.3347\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.3143 - accuracy: 0.3883\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 21.6112 - accuracy: 0.4089\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.6316 - accuracy: 0.4254\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.9778 - accuracy: 0.4302\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1492 - accuracy: 0.4330\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8808 - accuracy: 0.4351\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0752 - accuracy: 0.4357\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5587 - accuracy: 0.4364\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1114 - accuracy: 0.4371\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7957 - accuracy: 0.4371\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5440 - accuracy: 0.4378\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3150 - accuracy: 0.4385\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1260 - accuracy: 0.4392\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9513 - accuracy: 0.4392\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8010 - accuracy: 0.4399\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6597 - accuracy: 0.4399\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5192 - accuracy: 0.4399\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3805 - accuracy: 0.4399\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2439 - accuracy: 0.4392\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1081 - accuracy: 0.4399\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9742 - accuracy: 0.4399\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9037 - accuracy: 0.4399\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8972 - accuracy: 0.4399\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8912 - accuracy: 0.4399\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8877 - accuracy: 0.4392\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8818 - accuracy: 0.4392\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8777 - accuracy: 0.4399\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8738 - accuracy: 0.4399\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8699 - accuracy: 0.4399\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8662 - accuracy: 0.4399\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8624 - accuracy: 0.4399\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8588 - accuracy: 0.4399\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8554 - accuracy: 0.4399\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8526 - accuracy: 0.4399\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8506 - accuracy: 0.4399\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8488 - accuracy: 0.4399\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8470 - accuracy: 0.4399\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8452 - accuracy: 0.4399\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8434 - accuracy: 0.4399\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8417 - accuracy: 0.4399\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8400 - accuracy: 0.4399\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8383 - accuracy: 0.4399\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8366 - accuracy: 0.4399\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8349 - accuracy: 0.4399\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8333 - accuracy: 0.4399\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8316 - accuracy: 0.4399\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8300 - accuracy: 0.4399\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8284 - accuracy: 0.4399\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8268 - accuracy: 0.4399\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8252 - accuracy: 0.4399\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8237 - accuracy: 0.4399\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8221 - accuracy: 0.4399\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8206 - accuracy: 0.4399\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8191 - accuracy: 0.4399\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8176 - accuracy: 0.4399\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8161 - accuracy: 0.4399\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8146 - accuracy: 0.4399\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8132 - accuracy: 0.4399\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8118 - accuracy: 0.4399\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8104 - accuracy: 0.4399\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8090 - accuracy: 0.4399\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8077 - accuracy: 0.4399\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8064 - accuracy: 0.4399\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8052 - accuracy: 0.4399\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8040 - accuracy: 0.4399\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8029 - accuracy: 0.4399\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8018 - accuracy: 0.4399\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8007 - accuracy: 0.4399\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7996 - accuracy: 0.4399\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7986 - accuracy: 0.4399\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7976 - accuracy: 0.4399\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7965 - accuracy: 0.4399\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7955 - accuracy: 0.4399\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7945 - accuracy: 0.4399\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7935 - accuracy: 0.4399\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7925 - accuracy: 0.4399\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7915 - accuracy: 0.4399\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7906 - accuracy: 0.4399\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7896 - accuracy: 0.4399\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7886 - accuracy: 0.4399\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7877 - accuracy: 0.4399\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7867 - accuracy: 0.4399\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7858 - accuracy: 0.4399\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7848 - accuracy: 0.4399\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7839 - accuracy: 0.4399\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7830 - accuracy: 0.4399\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7820 - accuracy: 0.4399\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7811 - accuracy: 0.4399\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7802 - accuracy: 0.4399\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7793 - accuracy: 0.4399\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7784 - accuracy: 0.4399\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7775 - accuracy: 0.4399\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7766 - accuracy: 0.4399\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7757 - accuracy: 0.4399\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7749 - accuracy: 0.4399\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7740 - accuracy: 0.4399\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7731 - accuracy: 0.4399\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7722 - accuracy: 0.4399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226ed2893c8>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4175824175824176\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  3  0  0]\n",
      " [ 3  0  4  4  2  0]\n",
      " [12  0 54 80  6  0]\n",
      " [ 8  2 57 94  5  0]\n",
      " [ 2  1 12 10  1  0]\n",
      " [ 0  0  2  2  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.42      1.00      0.59       152\n",
      "         4.0       0.00      0.00      0.00       166\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42       364\n",
      "   macro avg       0.07      0.17      0.10       364\n",
      "weighted avg       0.17      0.42      0.25       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_315 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_316 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_318 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,657\n",
      "Trainable params: 21,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 4ms/step - loss: 10.9765 - accuracy: 0.0646\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5418 - accuracy: 0.0646\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9360 - accuracy: 0.0646\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9360 - accuracy: 0.0646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226e5e12788>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.07142857142857142\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   3   0]\n",
      " [  0   0   0   0  13   0]\n",
      " [  0   0   0   0 152   0]\n",
      " [  0   0   0   0 166   0]\n",
      " [  0   0   0   0  26   0]\n",
      " [  0   0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.00      0.00      0.00       152\n",
      "         4.0       0.00      0.00      0.00       166\n",
      "         5.0       0.07      1.00      0.13        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.07       364\n",
      "   macro avg       0.01      0.17      0.02       364\n",
      "weighted avg       0.01      0.07      0.01       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_320 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,831\n",
      "Trainable params: 9,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6382 - accuracy: 0.0687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226ebece688>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.03571428571428571\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   3   0   0   0   0]\n",
      " [  0  13   0   0   0   0]\n",
      " [  0 152   0   0   0   0]\n",
      " [  0 166   0   0   0   0]\n",
      " [  0  26   0   0   0   0]\n",
      " [  0   4   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.04      1.00      0.07        13\n",
      "         3.0       0.00      0.00      0.00       152\n",
      "         4.0       0.00      0.00      0.00       166\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.04       364\n",
      "   macro avg       0.01      0.17      0.01       364\n",
      "weighted avg       0.00      0.04      0.00       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_325 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_328 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,127\n",
      "Trainable params: 3,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3035 - accuracy: 0.2337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226dab1ccc8>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.10164835164835165\n",
      "Tasa de aciertos balanceada regresión logística: 0.04\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   3   0]\n",
      " [  0   0   0   0  13   0]\n",
      " [  0   0   0   0 152   0]\n",
      " [  0   0   0   0 166   0]\n",
      " [  0   0   0   0  26   0]\n",
      " [  0   0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.00      0.00      0.00       152\n",
      "         4.0       0.51      0.22      0.31       166\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.10       364\n",
      "   macro avg       0.07      0.03      0.04       364\n",
      "weighted avg       0.23      0.10      0.14       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_330 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,719\n",
      "Trainable params: 12,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 6.2556 - accuracy: 0.2598\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0033 - accuracy: 0.3457\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8871 - accuracy: 0.3526\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6089 - accuracy: 0.3629\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5871 - accuracy: 0.3636\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6312 - accuracy: 0.3608\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2910 - accuracy: 0.3773\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0768 - accuracy: 0.3560\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2188 - accuracy: 0.3773\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7655 - accuracy: 0.3326\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6792 - accuracy: 0.3478\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6529 - accuracy: 0.3519\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6538 - accuracy: 0.3491\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6206 - accuracy: 0.3526\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7885 - accuracy: 0.3704\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9586 - accuracy: 0.3794\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1333 - accuracy: 0.4089\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9240 - accuracy: 0.3863\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7430 - accuracy: 0.3670\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9524 - accuracy: 0.3863\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0044 - accuracy: 0.3869\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5466 - accuracy: 0.3017\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5000 - accuracy: 0.3058\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5100 - accuracy: 0.3203\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5098 - accuracy: 0.3230\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5097 - accuracy: 0.3230\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5094 - accuracy: 0.3237\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4946 - accuracy: 0.3244\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4938 - accuracy: 0.3251\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4937 - accuracy: 0.3251\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4932 - accuracy: 0.3244\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4931 - accuracy: 0.3251\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4930 - accuracy: 0.3251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226eeda5048>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.22527472527472528\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  2   0   1   0   0   0]\n",
      " [  5   0   8   0   0   0]\n",
      " [ 72   0  80   0   0   0]\n",
      " [ 65   0 101   0   0   0]\n",
      " [ 12   0  14   0   0   0]\n",
      " [  3   0   1   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      0.67      0.02         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.39      0.53      0.45       152\n",
      "         4.0       0.00      0.00      0.00       166\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.23       364\n",
      "   macro avg       0.07      0.20      0.08       364\n",
      "weighted avg       0.16      0.23      0.19       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_340 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_342 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_343 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_344 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_345 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_346 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_348 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_349 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,111\n",
      "Trainable params: 6,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 3ms/step - loss: 14.9759 - accuracy: 0.0715\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0103 - accuracy: 0.0687\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.0103 - accuracy: 0.0687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226f02bf708>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.03571428571428571\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   3   0   0   0   0]\n",
      " [  0  13   0   0   0   0]\n",
      " [  0 152   0   0   0   0]\n",
      " [  0 166   0   0   0   0]\n",
      " [  0  26   0   0   0   0]\n",
      " [  0   4   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.04      1.00      0.07        13\n",
      "         3.0       0.00      0.00      0.00       152\n",
      "         4.0       0.00      0.00      0.00       166\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.04       364\n",
      "   macro avg       0.01      0.17      0.01       364\n",
      "weighted avg       0.00      0.04      0.00       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_350 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_351 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_352 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_353 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_354 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_355 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_356 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_357 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_358 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,161\n",
      "Trainable params: 2,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 3ms/step - loss: 2.3918 - accuracy: 0.0969\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1553 - accuracy: 0.0227\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2309 - accuracy: 0.0247\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5832 - accuracy: 0.0467\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5935 - accuracy: 0.0405\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5507 - accuracy: 0.0405\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4886 - accuracy: 0.0481\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6010 - accuracy: 0.0419\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5056 - accuracy: 0.0392\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2669 - accuracy: 0.0241\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0979 - accuracy: 0.0213\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0610 - accuracy: 0.0165\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9928 - accuracy: 0.0082\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0027\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9638 - accuracy: 0.0034\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9641 - accuracy: 0.0034\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9637 - accuracy: 0.0034\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9638 - accuracy: 0.0041\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9642 - accuracy: 0.0027\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9641 - accuracy: 0.0027\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9642 - accuracy: 0.0027\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9648 - accuracy: 0.0027\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9644 - accuracy: 0.0027\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9640 - accuracy: 0.0027\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9641 - accuracy: 0.0027\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9642 - accuracy: 0.0027\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9639 - accuracy: 0.0027\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9637 - accuracy: 0.0027\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9642 - accuracy: 0.0027\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9642 - accuracy: 0.0027\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9639 - accuracy: 0.0027\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0027\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9643 - accuracy: 0.0027\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9642 - accuracy: 0.0027\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9642 - accuracy: 0.0027\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9641 - accuracy: 0.0027\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9641 - accuracy: 0.0027\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9641 - accuracy: 0.0027\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9642 - accuracy: 0.0027\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9642 - accuracy: 0.0027\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9642 - accuracy: 0.0027\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9642 - accuracy: 0.0027\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9641 - accuracy: 0.0027\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9641 - accuracy: 0.0027\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9640 - accuracy: 0.0027\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9638 - accuracy: 0.0027\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9643 - accuracy: 0.0021\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9643 - accuracy: 0.0021\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9637 - accuracy: 0.0021\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9631 - accuracy: 0.0027\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9641 - accuracy: 0.0021\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9639 - accuracy: 0.0027\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9645 - accuracy: 0.0021\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9643 - accuracy: 0.0021\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9639 - accuracy: 0.0027\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9645 - accuracy: 0.0021\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9645 - accuracy: 0.0021\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9645 - accuracy: 0.0014\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9643 - accuracy: 0.0021\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9643 - accuracy: 0.0021\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9643 - accuracy: 0.0021\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9643 - accuracy: 0.0021\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9643 - accuracy: 0.0021\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9643 - accuracy: 0.0021\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9638 - accuracy: 0.0027\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226f178ebc8>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.06318681318681318\n",
      "Tasa de aciertos balanceada regresión logística: 0.02\n",
      "Matriz de confusión:\n",
      "[[  2   0   1   0   0   0]\n",
      " [  5   0   8   0   0   0]\n",
      " [ 72   0  80   0   0   0]\n",
      " [ 65   0 101   0   0   0]\n",
      " [ 12   0  14   0   0   0]\n",
      " [  3   0   1   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        13\n",
      "         3.0       0.48      0.09      0.15       152\n",
      "         4.0       0.47      0.05      0.10       166\n",
      "         5.0       0.00      0.00      0.00        26\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.06       364\n",
      "   macro avg       0.14      0.02      0.04       364\n",
      "weighted avg       0.42      0.06      0.11       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERVALO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.440633</td>\n",
       "      <td>0.424802</td>\n",
       "      <td>0.424802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.424802</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.422164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071240</td>\n",
       "      <td>0.007916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.406332</td>\n",
       "      <td>0.300792</td>\n",
       "      <td>0.419525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.071240</td>\n",
       "      <td>0.424802</td>\n",
       "      <td>0.234828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.424802</td>\n",
       "      <td>0.424802</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.440633     0.424802     0.424802\n",
       "Experimento 2- RELU+ADAM         0.424802     0.005277     0.422164\n",
       "Experimento 3- RELU+ADAM         0.000000     0.071240     0.007916\n",
       "Experimento 1- RELU+ADAGRAD      0.406332     0.300792     0.419525\n",
       "Experimento 2- RELU+ADAGRAD      0.071240     0.424802     0.234828\n",
       "Experimento 3- RELU+ADAGRAD      0.424802     0.424802     0.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['100 Neuronas'] = None\n",
    "df1['64 Neuronas'] = None\n",
    "df1['32 Neuronas'] = None\n",
    "df1.loc['Experimento 1- RELU+ADAM'] = [0.44063324538258575,0.42480211081794195,0.42480211081794195]\n",
    "df1.loc['Experimento 2- RELU+ADAM'] = [0.42480211081794195,0.005277044854881266,0.42216358839050133]\n",
    "df1.loc['Experimento 3- RELU+ADAM'] = [0.0,0.0712401055408971,0.0079155672823219]\n",
    "df1.loc['Experimento 1- RELU+ADAGRAD'] =[0.40633245382585753,0.3007915567282322,0.41952506596306066]\n",
    "df1.loc['Experimento 2- RELU+ADAGRAD'] =[0.0712401055408971,0.42480211081794195,0.23482849604221637]\n",
    "df1.loc['Experimento 3- RELU+ADAGRAD'] = [0.42480211081794195,0.42480211081794195,0.0]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.407609</td>\n",
       "      <td>0.421196</td>\n",
       "      <td>0.421196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.453804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081522</td>\n",
       "      <td>0.421196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.334239</td>\n",
       "      <td>0.220109</td>\n",
       "      <td>0.413043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.078804</td>\n",
       "      <td>0.076087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.407609     0.421196     0.421196\n",
       "Experimento 2- RELU+ADAM         0.130435     0.163043     0.453804\n",
       "Experimento 3- RELU+ADAM         0.000000     0.081522     0.421196\n",
       "Experimento 1- RELU+ADAGRAD      0.334239     0.220109     0.413043\n",
       "Experimento 2- RELU+ADAGRAD      0.152174     0.078804     0.076087\n",
       "Experimento 3- RELU+ADAGRAD      0.021739     0.358696     0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['100 Neuronas'] = None\n",
    "df2['64 Neuronas'] = None\n",
    "df2['32 Neuronas'] = None\n",
    "df2.loc['Experimento 1- RELU+ADAM'] = [0.4076086956521739,0.421195652173913,0.421195652173913]\n",
    "df2.loc['Experimento 2- RELU+ADAM'] =[0.13043478260869565,0.16304347826086957,0.453804347826087]\n",
    "df2.loc['Experimento 3- RELU+ADAM'] = [0.0,0.08152173913043478,0.421195652173913]\n",
    "df2.loc['Experimento 1- RELU+ADAGRAD'] = [0.3342391304347826,0.22010869565217392,0.41304347826086957]\n",
    "df2.loc['Experimento 2- RELU+ADAGRAD'] = [0.15217391304347827,0.07880434782608696,0.07608695652173914]\n",
    "df2.loc['Experimento 3- RELU+ADAGRAD'] = [0.021739130434782608,0.358695652173913,0.0]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.417582</td>\n",
       "      <td>0.417582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.016484</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.409341</td>\n",
       "      <td>0.398352</td>\n",
       "      <td>0.417582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.101648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.225275</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.063187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.406593     0.417582     0.417582\n",
       "Experimento 2- RELU+ADAM         0.016484     0.071429     0.002747\n",
       "Experimento 3- RELU+ADAM         0.010989     0.010989     0.071429\n",
       "Experimento 1- RELU+ADAGRAD      0.409341     0.398352     0.417582\n",
       "Experimento 2- RELU+ADAGRAD      0.071429     0.035714     0.101648\n",
       "Experimento 3- RELU+ADAGRAD      0.225275     0.035714     0.063187"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame()\n",
    "df3['100 Neuronas'] = None\n",
    "df3['64 Neuronas'] = None\n",
    "df3['32 Neuronas'] = None\n",
    "df3.loc['Experimento 1- RELU+ADAM'] = [0.4065934065934066,0.4175824175824176,0.4175824175824176]\n",
    "df3.loc['Experimento 2- RELU+ADAM'] = [0.016483516483516484,0.07142857142857142,0.0027472527472527475]\n",
    "df3.loc['Experimento 3- RELU+ADAM'] = [0.01098901098901099,0.01098901098901099,0.07142857142857142]\n",
    "df3.loc['Experimento 1- RELU+ADAGRAD'] = [0.40934065934065933,0.3983516483516483,0.4175824175824176]\n",
    "df3.loc['Experimento 2- RELU+ADAGRAD'] = [0.07142857142857142,0.03571428571428571,0.10164835164835165]\n",
    "df3.loc['Experimento 3- RELU+ADAGRAD'] = [0.22527472527472528,0.03571428571428571,0.06318681318681318]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20c02f56308>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,20))\n",
    "fig.add_subplot(2,2,1)\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 1')\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM' ,color ='red')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 2')\n",
    "fig.add_subplot(2,2,3)\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 3')\n",
    "plt.legend(bbox_to_anchor = (1.05, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run 1dia-porintervalos2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix,balanced_accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subida(list):\n",
    "    resultado = []\n",
    "    for i in range(1,len(list)):\n",
    "        if  (list)[i] > (list)[i-1]:\n",
    "            resultado.append(1)\n",
    "        else:\n",
    "            resultado.append(0)\n",
    "    return resultado\n",
    "\n",
    "def acierto(list1,list2):\n",
    "    sum = 0\n",
    "    for i in range(0,len(list1)):\n",
    "        if(list1[i]==list2[i]):\n",
    "            sum = sum +1\n",
    "    a = sum/len(list1)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 11, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_360 (Dense)           (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_361 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_362 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_363 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_364 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,965\n",
      "Trainable params: 8,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 3s 4ms/step - loss: 465.4540 - accuracy: 0.3175\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 73.3451 - accuracy: 0.3201\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 42.0299 - accuracy: 0.3300\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 37.5054 - accuracy: 0.3307\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 31.9299 - accuracy: 0.3089\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 34.4675 - accuracy: 0.3162\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 26.5452 - accuracy: 0.3360\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 27.1845 - accuracy: 0.3525\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 21.1406 - accuracy: 0.3426\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.0837 - accuracy: 0.3399\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 20.1049 - accuracy: 0.3281\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 21.3820 - accuracy: 0.3228\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 24.3633 - accuracy: 0.3347\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 17.1568 - accuracy: 0.3307\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 19.2807 - accuracy: 0.3254\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 25.2649 - accuracy: 0.3195\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 17.7786 - accuracy: 0.3320\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.4111 - accuracy: 0.3545\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 14.1096 - accuracy: 0.3465\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.9909 - accuracy: 0.3716\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 14.4528 - accuracy: 0.3347\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 14.3226 - accuracy: 0.3479\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.4839 - accuracy: 0.3406\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 11.5847 - accuracy: 0.3690\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.5362 - accuracy: 0.3261\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.2227 - accuracy: 0.3446\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 11.5724 - accuracy: 0.3584\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.2230 - accuracy: 0.3465\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.6388 - accuracy: 0.3578\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.4687 - accuracy: 0.3492\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.5019 - accuracy: 0.3413\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.4249 - accuracy: 0.3465\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.5906 - accuracy: 0.3294\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.7023 - accuracy: 0.3439\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1500 - accuracy: 0.3300\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1503 - accuracy: 0.3630\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.5756 - accuracy: 0.3597\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.3249 - accuracy: 0.3690\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.2487 - accuracy: 0.3657\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.2523 - accuracy: 0.3571\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7315 - accuracy: 0.3254\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.8736 - accuracy: 0.3518\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.1857 - accuracy: 0.3604\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.2387 - accuracy: 0.3360\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.4823 - accuracy: 0.3373\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.3137 - accuracy: 0.3769\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.0126 - accuracy: 0.3380\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.4178 - accuracy: 0.3439\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.2194 - accuracy: 0.3215\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.0326 - accuracy: 0.3578\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.3933 - accuracy: 0.3294\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.0946 - accuracy: 0.3881\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.6299 - accuracy: 0.3419\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.6535 - accuracy: 0.3650\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.0806 - accuracy: 0.3314\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.6504 - accuracy: 0.3465\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.2960 - accuracy: 0.3465\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.0745 - accuracy: 0.3571\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.7291 - accuracy: 0.3690\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.6246 - accuracy: 0.3657\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.9039 - accuracy: 0.3545\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.9375 - accuracy: 0.3954\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.9775 - accuracy: 0.3861\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.6080 - accuracy: 0.3815\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.8023 - accuracy: 0.3611\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.8154 - accuracy: 0.3941\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.6367 - accuracy: 0.3558\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.4036 - accuracy: 0.3941\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.5860 - accuracy: 0.3947\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2431 - accuracy: 0.3789\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9641 - accuracy: 0.3881\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.6723 - accuracy: 0.3413\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.5185 - accuracy: 0.3657\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.3837 - accuracy: 0.3584\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.5486 - accuracy: 0.3703\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2828 - accuracy: 0.3947\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2324 - accuracy: 0.3710\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.8677 - accuracy: 0.4119\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.1977 - accuracy: 0.3670\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1279 - accuracy: 0.4092\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9129 - accuracy: 0.3934\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6714 - accuracy: 0.3868\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7781 - accuracy: 0.3802\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.3866 - accuracy: 0.3703\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.4088 - accuracy: 0.3736\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.4535 - accuracy: 0.3591\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.7479 - accuracy: 0.3842\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8544 - accuracy: 0.3954\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6272 - accuracy: 0.4020\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6326 - accuracy: 0.4053\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0540 - accuracy: 0.4026\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2094 - accuracy: 0.3677\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.6449 - accuracy: 0.3670\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9827 - accuracy: 0.3828\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4989 - accuracy: 0.4059\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0468 - accuracy: 0.3868\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9285 - accuracy: 0.3921\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.7693 - accuracy: 0.3967\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6780 - accuracy: 0.3947\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0602 - accuracy: 0.3762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226f398cb88>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.25065963060686014\n",
      "Tasa de aciertos balanceada regresión logística: 0.19\n",
      "Matriz de confusión:\n",
      "[[  0   2   0   1   0]\n",
      " [  0  32   1  60   0]\n",
      " [  0  66   0 112   0]\n",
      " [  0  38   0  63   0]\n",
      " [  0   1   0   3   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.23      0.34      0.28        93\n",
      "         3.0       0.00      0.00      0.00       178\n",
      "         4.0       0.26      0.62      0.37       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.25       379\n",
      "   macro avg       0.10      0.19      0.13       379\n",
      "weighted avg       0.13      0.25      0.17       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_365 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_366 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_368 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_369 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,012\n",
      "Trainable params: 4,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 3s 4ms/step - loss: 2129.7700 - accuracy: 0.3248\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 160.6343 - accuracy: 0.3307\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 93.9271 - accuracy: 0.3254\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 67.5536 - accuracy: 0.3254\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 58.2109 - accuracy: 0.3135\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 47.4969 - accuracy: 0.3267\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 21.4921 - accuracy: 0.2964\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 12.3644 - accuracy: 0.2944\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.4454 - accuracy: 0.2825\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.7994 - accuracy: 0.2660\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7803 - accuracy: 0.3584\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.6834 - accuracy: 0.3426\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.8829 - accuracy: 0.3439\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.3243 - accuracy: 0.3340\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.9766 - accuracy: 0.3340\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.1249 - accuracy: 0.3366\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7566 - accuracy: 0.2851\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6672 - accuracy: 0.2832\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6134 - accuracy: 0.4317\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5794 - accuracy: 0.4317\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5503 - accuracy: 0.4310\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5248 - accuracy: 0.4310\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.5018 - accuracy: 0.4310\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4813 - accuracy: 0.4310\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4625 - accuracy: 0.4310\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4454 - accuracy: 0.4317\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.4302 - accuracy: 0.4317\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4162 - accuracy: 0.4317\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4032 - accuracy: 0.4317\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3920 - accuracy: 0.4310\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3807 - accuracy: 0.4317\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3706 - accuracy: 0.4310\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3613 - accuracy: 0.4317\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3526 - accuracy: 0.4317\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3447 - accuracy: 0.4317\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3376 - accuracy: 0.4310\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.3314 - accuracy: 0.4317\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.3252 - accuracy: 0.4304\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3186 - accuracy: 0.4317\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3132 - accuracy: 0.4317\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3085 - accuracy: 0.4317\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3033 - accuracy: 0.4317\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2990 - accuracy: 0.4317\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2950 - accuracy: 0.4317\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.2910 - accuracy: 0.4317\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2871 - accuracy: 0.4317\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2841 - accuracy: 0.4310\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2813 - accuracy: 0.4310\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2786 - accuracy: 0.4310\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.2754 - accuracy: 0.4317\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.2729 - accuracy: 0.4310\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2705 - accuracy: 0.4317\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2688 - accuracy: 0.4310\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2665 - accuracy: 0.4310\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2641 - accuracy: 0.4310\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2617 - accuracy: 0.4317\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2598 - accuracy: 0.4317\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2590 - accuracy: 0.4304\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2575 - accuracy: 0.4317\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2555 - accuracy: 0.4310\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2542 - accuracy: 0.4310\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2524 - accuracy: 0.4310\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2510 - accuracy: 0.4310\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2500 - accuracy: 0.4310\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2488 - accuracy: 0.4310\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2477 - accuracy: 0.4310\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2467 - accuracy: 0.4310\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2456 - accuracy: 0.4310\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2447 - accuracy: 0.4310\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2438 - accuracy: 0.4310\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2429 - accuracy: 0.4310\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2421 - accuracy: 0.4310\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2413 - accuracy: 0.4310\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2406 - accuracy: 0.4310\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2399 - accuracy: 0.4310\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.2392 - accuracy: 0.4310\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 1.2386 - accuracy: 0.4310\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2381 - accuracy: 0.4310\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2374 - accuracy: 0.4310\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2369 - accuracy: 0.4310\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2363 - accuracy: 0.4310\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2358 - accuracy: 0.4310\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2353 - accuracy: 0.4310\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2348 - accuracy: 0.4310\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2344 - accuracy: 0.4310\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2339 - accuracy: 0.4310\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2335 - accuracy: 0.4310\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2331 - accuracy: 0.4310\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2328 - accuracy: 0.4310\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2324 - accuracy: 0.4310\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2321 - accuracy: 0.4310\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2317 - accuracy: 0.4310\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2314 - accuracy: 0.4310\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2310 - accuracy: 0.4310\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2307 - accuracy: 0.4310\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2305 - accuracy: 0.4310\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2301 - accuracy: 0.4310\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2299 - accuracy: 0.4310\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.2296 - accuracy: 0.4310\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2293 - accuracy: 0.4310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226b777e0c8>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.46965699208443273\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0]\n",
      " [  0   0  93   0   0]\n",
      " [  0   0 178   0   0]\n",
      " [  0   0 101   0   0]\n",
      " [  0   0   4   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        93\n",
      "         3.0       0.47      1.00      0.64       178\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.47       379\n",
      "   macro avg       0.09      0.20      0.13       379\n",
      "weighted avg       0.22      0.47      0.30       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_370 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_371 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_372 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_373 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_374 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,258\n",
      "Trainable params: 1,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 3s 3ms/step - loss: 1573.2500 - accuracy: 0.1076\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 112.5396 - accuracy: 0.3314\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 74.5942 - accuracy: 0.3452\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 40.9934 - accuracy: 0.3353\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 44.6194 - accuracy: 0.3591\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 32.7946 - accuracy: 0.3518\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 29.4010 - accuracy: 0.3386\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 21.0135 - accuracy: 0.3683\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 16.8698 - accuracy: 0.3597\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 26.7303 - accuracy: 0.3459\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.0977 - accuracy: 0.3452\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 17.2768 - accuracy: 0.3677\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 21.7558 - accuracy: 0.3353\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 18.3482 - accuracy: 0.3512\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 18.7741 - accuracy: 0.3360\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 20.3156 - accuracy: 0.3485\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.9408 - accuracy: 0.3644\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.5922 - accuracy: 0.3624\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.3214 - accuracy: 0.3320\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.0704 - accuracy: 0.3551\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2306 - accuracy: 0.3492\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.4476 - accuracy: 0.3373\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5730 - accuracy: 0.3564\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.1738 - accuracy: 0.3551\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.1787 - accuracy: 0.3538\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 13.3067 - accuracy: 0.3393\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.1513 - accuracy: 0.3307\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.1870 - accuracy: 0.3446\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.3155 - accuracy: 0.3611\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.2029 - accuracy: 0.3208\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.2666 - accuracy: 0.3637\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.6393 - accuracy: 0.3512\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.2251 - accuracy: 0.3116\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.1999 - accuracy: 0.3465\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1693 - accuracy: 0.3644\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.6530 - accuracy: 0.3406\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.9436 - accuracy: 0.3413\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.1122 - accuracy: 0.3386\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.8173 - accuracy: 0.3307\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.5998 - accuracy: 0.3406\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.6580 - accuracy: 0.3498\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.8222 - accuracy: 0.3624\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.6820 - accuracy: 0.3591\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.0807 - accuracy: 0.3564\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2346 - accuracy: 0.3432\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 13.9684 - accuracy: 0.3261\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.5171 - accuracy: 0.3485\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.4148 - accuracy: 0.3459\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.6294 - accuracy: 0.3386\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.5797 - accuracy: 0.3538\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.4112 - accuracy: 0.3512\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.7392 - accuracy: 0.3663\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0782 - accuracy: 0.3630\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.6262 - accuracy: 0.3518\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.6456 - accuracy: 0.3380\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.5554 - accuracy: 0.3571\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.5444 - accuracy: 0.3492\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 11.2521 - accuracy: 0.3512\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0782 - accuracy: 0.3426\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.5582 - accuracy: 0.3538\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.6800 - accuracy: 0.3366\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.9734 - accuracy: 0.3578\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.8102 - accuracy: 0.3637\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.1638 - accuracy: 0.3281\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.2138 - accuracy: 0.3327\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.6615 - accuracy: 0.3413\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.6035 - accuracy: 0.3637\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.2768 - accuracy: 0.3446\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 10.3929 - accuracy: 0.3241\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.7358 - accuracy: 0.3749\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.2789 - accuracy: 0.3492\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.4018 - accuracy: 0.3538\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 7.4924 - accuracy: 0.3571\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 6.6842 - accuracy: 0.3399\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.9526 - accuracy: 0.3749\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5729 - accuracy: 0.3446\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.5985 - accuracy: 0.3927\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7501 - accuracy: 0.3650\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.2682 - accuracy: 0.3512\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.9329 - accuracy: 0.3571\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7964 - accuracy: 0.3683\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.8435 - accuracy: 0.3406\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.4702 - accuracy: 0.3525\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.8079 - accuracy: 0.3485\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.3088 - accuracy: 0.3696\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5846 - accuracy: 0.3624\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.9064 - accuracy: 0.3597\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.5201 - accuracy: 0.3452\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.6381 - accuracy: 0.3512\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.2888 - accuracy: 0.3611\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.7451 - accuracy: 0.3624\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.3118 - accuracy: 0.3683\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5824 - accuracy: 0.3446\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.7439 - accuracy: 0.3644\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.4092 - accuracy: 0.3492\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.3201 - accuracy: 0.3485\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.4965 - accuracy: 0.3432\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7676 - accuracy: 0.3380\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.3754 - accuracy: 0.3756\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.6545 - accuracy: 0.3426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226f3a40948>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.39577836411609496\n",
      "Tasa de aciertos balanceada regresión logística: 0.21\n",
      "Matriz de confusión:\n",
      "[[  0   2   0   1   0]\n",
      " [  0  32   1  60   0]\n",
      " [  0  66   0 112   0]\n",
      " [  0  38   0  63   0]\n",
      " [  0   1   0   3   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.25      0.41      0.31        93\n",
      "         3.0       0.49      0.63      0.55       178\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.40       379\n",
      "   macro avg       0.15      0.21      0.17       379\n",
      "weighted avg       0.29      0.40      0.34       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 11, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_375 (Dense)           (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_376 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_378 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,257\n",
      "Trainable params: 19,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 3s 4ms/step - loss: 11.1913 - accuracy: 0.0092\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.2671 - accuracy: 0.0092\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226f370ddc8>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0]\n",
      " [ 93   0   0   0   0   0]\n",
      " [178   0   0   0   0   0]\n",
      " [101   0   0   0   0   0]\n",
      " [  4   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       3.0\n",
      "         2.0       0.00      0.00      0.00      93.0\n",
      "         3.0       0.00      0.00      0.00     178.0\n",
      "         4.0       0.00      0.00      0.00     101.0\n",
      "         5.0       0.00      0.00      0.00       4.0\n",
      "\n",
      "    accuracy                           0.00     379.0\n",
      "   macro avg       0.00      0.00      0.00     379.0\n",
      "weighted avg       0.00      0.00      0.00     379.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_380 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_381 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_382 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_383 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_384 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,295\n",
      "Trainable params: 8,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 5s 4ms/step - loss: 8.2782 - accuracy: 0.2614\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226f5dc9108>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.24538258575197888\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   3   0   0   0]\n",
      " [  0  93   0   0   0]\n",
      " [  0 178   0   0   0]\n",
      " [  0 101   0   0   0]\n",
      " [  0   4   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.25      1.00      0.39        93\n",
      "         3.0       0.00      0.00      0.00       178\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.25       379\n",
      "   macro avg       0.05      0.20      0.08       379\n",
      "weighted avg       0.06      0.25      0.10       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_385 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_386 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_387 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_388 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_389 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,359\n",
      "Trainable params: 2,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.5229 - accuracy: 0.0178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226eed4fe08>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.010554089709762533\n",
      "Tasa de aciertos balanceada regresión logística: 0.23\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0]\n",
      " [ 93   0   0   0   0   0]\n",
      " [178   0   0   0   0   0]\n",
      " [101   0   0   0   0   0]\n",
      " [  4   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      0.67      0.02         3\n",
      "         2.0       0.00      0.00      0.00        93\n",
      "         3.0       0.00      0.00      0.00       178\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.01      0.50      0.03         4\n",
      "\n",
      "    accuracy                           0.01       379\n",
      "   macro avg       0.00      0.23      0.01       379\n",
      "weighted avg       0.00      0.01      0.00       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 11, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_390 (Dense)           (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_391 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_392 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_393 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_394 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_395 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_396 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_397 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_398 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_399 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,319\n",
      "Trainable params: 10,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 8.3172 - accuracy: 0.2455\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.2681 - accuracy: 0.2475\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.2681 - accuracy: 0.2475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226f6e56508>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.26649076517150394\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   3   0]\n",
      " [  0   0   0  93   0]\n",
      " [  0   0   0 178   0]\n",
      " [  0   0   0 101   0]\n",
      " [  0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        93\n",
      "         3.0       0.00      0.00      0.00       178\n",
      "         4.0       0.27      1.00      0.42       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.27       379\n",
      "   macro avg       0.05      0.20      0.08       379\n",
      "weighted avg       0.07      0.27      0.11       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_400 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_401 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_402 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_403 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_404 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_405 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_406 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_407 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_408 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_409 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,575\n",
      "Trainable params: 4,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 6s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10.1526 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226f8454888>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   3]\n",
      " [  0   0   0   0   0  93]\n",
      " [  0   0   0   0   0 178]\n",
      " [  0   0   0   0   0 101]\n",
      " [  0   0   0   0   0   4]\n",
      " [  0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       3.0\n",
      "         2.0       0.00      0.00      0.00      93.0\n",
      "         3.0       0.00      0.00      0.00     178.0\n",
      "         4.0       0.00      0.00      0.00     101.0\n",
      "         5.0       0.00      0.00      0.00       4.0\n",
      "         6.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00     379.0\n",
      "   macro avg       0.00      0.00      0.00     379.0\n",
      "weighted avg       0.00      0.00      0.00     379.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_410 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_411 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_412 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_413 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_414 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_415 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_416 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_417 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_418 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_419 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 6s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226f88d79c8>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   3   0]\n",
      " [  0   0   0  93   0]\n",
      " [  0   0   0 178   0]\n",
      " [  0   0   0 101   0]\n",
      " [  0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       3.0\n",
      "         2.0       0.00      0.00      0.00      93.0\n",
      "         3.0       0.00      0.00      0.00     178.0\n",
      "         4.0       0.00      0.00      0.00     101.0\n",
      "         5.0       0.00      0.00      0.00       4.0\n",
      "\n",
      "    accuracy                           0.00     379.0\n",
      "   macro avg       0.00      0.00      0.00     379.0\n",
      "weighted avg       0.00      0.00      0.00     379.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_420 (Dense)           (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_421 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_422 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_423 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_424 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,965\n",
      "Trainable params: 8,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 4s 5ms/step - loss: 2550.7627 - accuracy: 0.1696\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 564.8150 - accuracy: 0.2409\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 359.0127 - accuracy: 0.2436\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 242.8000 - accuracy: 0.2937\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 154.6691 - accuracy: 0.3162\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 97.7177 - accuracy: 0.3234\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 89.5521 - accuracy: 0.3234\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 85.0314 - accuracy: 0.3505\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 78.3073 - accuracy: 0.3281\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 77.2710 - accuracy: 0.3406\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 73.7918 - accuracy: 0.3432\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 69.2829 - accuracy: 0.3505\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 68.3186 - accuracy: 0.3426\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 65.3399 - accuracy: 0.3538\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 65.4089 - accuracy: 0.3314\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 62.6921 - accuracy: 0.3479\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 61.0782 - accuracy: 0.3254\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 58.8031 - accuracy: 0.3419\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 57.4160 - accuracy: 0.3386\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 57.0481 - accuracy: 0.3333\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 54.9427 - accuracy: 0.3512\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 53.0504 - accuracy: 0.3300\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 51.2971 - accuracy: 0.3452\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 51.0295 - accuracy: 0.3373\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 49.9119 - accuracy: 0.3373\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 48.1654 - accuracy: 0.3380\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 46.7615 - accuracy: 0.3439\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 44.5789 - accuracy: 0.3393\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 44.7397 - accuracy: 0.3479\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 42.6196 - accuracy: 0.3485\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 42.5404 - accuracy: 0.3399\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 41.1471 - accuracy: 0.3393\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 40.1725 - accuracy: 0.3472\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 40.0353 - accuracy: 0.3241\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 38.4525 - accuracy: 0.3426\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 38.2334 - accuracy: 0.3386\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 37.5373 - accuracy: 0.3386\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 37.2486 - accuracy: 0.3465\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 36.5524 - accuracy: 0.3426\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 36.5954 - accuracy: 0.3419\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 35.1917 - accuracy: 0.3347\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 35.3715 - accuracy: 0.3419\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 34.7453 - accuracy: 0.3498\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 35.3683 - accuracy: 0.3419\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 34.9951 - accuracy: 0.3274\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 34.0489 - accuracy: 0.3327\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 32.8626 - accuracy: 0.3413\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 32.8152 - accuracy: 0.3472\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 32.2992 - accuracy: 0.3505\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 32.9433 - accuracy: 0.3452\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 31.5772 - accuracy: 0.3446\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 31.0631 - accuracy: 0.3386\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 30.6281 - accuracy: 0.3413\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 30.1554 - accuracy: 0.3221\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 30.2440 - accuracy: 0.3439\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 29.3933 - accuracy: 0.3432\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 29.9819 - accuracy: 0.3327\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 29.6772 - accuracy: 0.3399\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 29.1844 - accuracy: 0.3327\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 28.3874 - accuracy: 0.3545\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 28.5724 - accuracy: 0.3472\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 27.8369 - accuracy: 0.3472\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 28.6506 - accuracy: 0.3393\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 27.5665 - accuracy: 0.3353\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 27.3604 - accuracy: 0.3135\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 27.2535 - accuracy: 0.3538\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 26.1324 - accuracy: 0.3215\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 26.4537 - accuracy: 0.3340\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 26.2162 - accuracy: 0.3419\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 25.7103 - accuracy: 0.3446\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 24.6513 - accuracy: 0.3347\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 25.5616 - accuracy: 0.3234\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 25.3513 - accuracy: 0.3333\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 24.9732 - accuracy: 0.3314\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 24.3951 - accuracy: 0.3373\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 23.8610 - accuracy: 0.3373\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 24.1964 - accuracy: 0.3439\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 23.5829 - accuracy: 0.3162\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 23.5858 - accuracy: 0.3393\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 23.4236 - accuracy: 0.3274\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 23.1482 - accuracy: 0.3320\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 22.7901 - accuracy: 0.3472\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 23.0810 - accuracy: 0.3215\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 22.2878 - accuracy: 0.3366\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 22.4854 - accuracy: 0.3215\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 22.1838 - accuracy: 0.3446\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 22.1276 - accuracy: 0.3399\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 22.0876 - accuracy: 0.3380\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 21.6666 - accuracy: 0.3320\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 21.0232 - accuracy: 0.3360\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 21.2116 - accuracy: 0.3347\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.7327 - accuracy: 0.3373\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 21.1181 - accuracy: 0.3413\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.9668 - accuracy: 0.3406\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.7326 - accuracy: 0.3347\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 20.6986 - accuracy: 0.3333\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.2364 - accuracy: 0.3294\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 20.0474 - accuracy: 0.3386\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 19.7215 - accuracy: 0.3479\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 19.5251 - accuracy: 0.3465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226f9f49848>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3720316622691293\n",
      "Tasa de aciertos balanceada regresión logística: 0.19\n",
      "Matriz de confusión:\n",
      "[[  0   0   1   2   0   0]\n",
      " [  0  10  58  23   0   2]\n",
      " [  0  24 111  40   3   0]\n",
      " [  0  20  60  20   1   0]\n",
      " [  0   0   3   1   0   0]\n",
      " [  0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.19      0.11      0.14        93\n",
      "         3.0       0.48      0.62      0.54       178\n",
      "         4.0       0.23      0.20      0.21       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.37       379\n",
      "   macro avg       0.15      0.15      0.15       379\n",
      "weighted avg       0.33      0.37      0.34       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_425 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_426 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_427 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_428 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_429 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,012\n",
      "Trainable params: 4,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 4s 3ms/step - loss: 754.2634 - accuracy: 0.3102\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 208.8138 - accuracy: 0.3314\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 131.6618 - accuracy: 0.2957\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 112.9727 - accuracy: 0.3083\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 100.1439 - accuracy: 0.3089\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 93.2305 - accuracy: 0.2964\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 87.8293 - accuracy: 0.2898\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 81.7000 - accuracy: 0.3234\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 78.0423 - accuracy: 0.2917\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 74.9009 - accuracy: 0.2858\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 72.5111 - accuracy: 0.2990\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 69.3148 - accuracy: 0.2970\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 67.5196 - accuracy: 0.2911\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 65.4860 - accuracy: 0.2964\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 62.4451 - accuracy: 0.2983\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 62.1251 - accuracy: 0.2904\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 61.8922 - accuracy: 0.2746\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 59.7782 - accuracy: 0.3043\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 58.2239 - accuracy: 0.3003\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 57.1042 - accuracy: 0.2977\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 54.7854 - accuracy: 0.2950\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 54.1694 - accuracy: 0.2970\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 53.4344 - accuracy: 0.2983\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 51.8219 - accuracy: 0.3003\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 50.2859 - accuracy: 0.2911\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 50.6928 - accuracy: 0.2964\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 49.1650 - accuracy: 0.2957\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 47.7116 - accuracy: 0.2970\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 47.4760 - accuracy: 0.3056\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 48.4990 - accuracy: 0.3096\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 46.5415 - accuracy: 0.3089\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 45.3695 - accuracy: 0.2983\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 44.7547 - accuracy: 0.3135\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 44.3266 - accuracy: 0.3201\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 44.3735 - accuracy: 0.3056\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 43.1779 - accuracy: 0.3076\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 43.9812 - accuracy: 0.3030\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 42.0865 - accuracy: 0.3208\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 41.9437 - accuracy: 0.3201\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 40.9493 - accuracy: 0.3162\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 40.7396 - accuracy: 0.3175\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 40.6932 - accuracy: 0.3149\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 40.3037 - accuracy: 0.3261\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 39.9715 - accuracy: 0.3089\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 38.9336 - accuracy: 0.3314\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 38.8283 - accuracy: 0.3083\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 38.4367 - accuracy: 0.3228\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 37.8728 - accuracy: 0.3254\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 37.5057 - accuracy: 0.3234\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 37.6051 - accuracy: 0.3195\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 37.3565 - accuracy: 0.3069\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 37.2516 - accuracy: 0.3135\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 36.3751 - accuracy: 0.3182\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 36.2066 - accuracy: 0.3083\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 35.5865 - accuracy: 0.3234\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 35.4071 - accuracy: 0.3195\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 34.9666 - accuracy: 0.3182\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 34.4413 - accuracy: 0.3221\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 34.9515 - accuracy: 0.3162\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 34.7279 - accuracy: 0.3228\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 34.2329 - accuracy: 0.3221\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 34.8020 - accuracy: 0.3135\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 33.7600 - accuracy: 0.3155\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 33.1264 - accuracy: 0.3267\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 33.0918 - accuracy: 0.3175\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 32.8491 - accuracy: 0.3340\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 32.9137 - accuracy: 0.3281\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 32.2333 - accuracy: 0.3274\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 32.2523 - accuracy: 0.3300\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 31.2652 - accuracy: 0.3221\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 31.8723 - accuracy: 0.3274\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 31.1725 - accuracy: 0.3314\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 31.6536 - accuracy: 0.3201\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 30.8985 - accuracy: 0.3366\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 30.7402 - accuracy: 0.3168\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 30.4242 - accuracy: 0.3373\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 30.0622 - accuracy: 0.3294\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 29.9809 - accuracy: 0.3314\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 30.0779 - accuracy: 0.3307\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 30.1102 - accuracy: 0.3168\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 29.1145 - accuracy: 0.3419\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 28.9882 - accuracy: 0.3287\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 29.2444 - accuracy: 0.3234\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 28.9998 - accuracy: 0.3380\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 29.0749 - accuracy: 0.3281\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 28.5886 - accuracy: 0.3386\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 29.1460 - accuracy: 0.3393\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 28.6255 - accuracy: 0.3281\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 28.2746 - accuracy: 0.3168\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 28.5832 - accuracy: 0.3188\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 28.1598 - accuracy: 0.3307\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 28.0457 - accuracy: 0.3267\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 28.3305 - accuracy: 0.3175\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 27.5616 - accuracy: 0.3347\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 27.6495 - accuracy: 0.3188\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 27.5834 - accuracy: 0.3162\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 27.6070 - accuracy: 0.3234\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 27.1976 - accuracy: 0.3267\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 27.4347 - accuracy: 0.3149\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 27.1005 - accuracy: 0.3254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226fa315188>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.40369393139841686\n",
      "Tasa de aciertos balanceada regresión logística: 0.22\n",
      "Matriz de confusión:\n",
      "[[  0   0   2   1   0]\n",
      " [  1  29  41  21   1]\n",
      " [  4  43 102  27   2]\n",
      " [  4  31  44  22   0]\n",
      " [  0   1   2   1   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.28      0.31      0.29        93\n",
      "         3.0       0.53      0.57      0.55       178\n",
      "         4.0       0.31      0.22      0.25       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.40       379\n",
      "   macro avg       0.22      0.22      0.22       379\n",
      "weighted avg       0.40      0.40      0.40       379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_430 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_431 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_432 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_433 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_434 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,258\n",
      "Trainable params: 1,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 4s 4ms/step - loss: 1903.1793 - accuracy: 0.0436\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 591.4845 - accuracy: 0.2594\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 241.8898 - accuracy: 0.3683\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 108.7795 - accuracy: 0.3670\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 68.3861 - accuracy: 0.3195\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 51.9566 - accuracy: 0.2871\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 41.8384 - accuracy: 0.2838\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 34.8924 - accuracy: 0.2891\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 29.8134 - accuracy: 0.2917\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 25.8295 - accuracy: 0.2871\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 22.7890 - accuracy: 0.2891\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 20.4632 - accuracy: 0.2858\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 18.4851 - accuracy: 0.2898\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16.9538 - accuracy: 0.2779\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 15.5785 - accuracy: 0.2739\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 14.4909 - accuracy: 0.2772\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13.5451 - accuracy: 0.2792\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 12.6236 - accuracy: 0.2799\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 11.9187 - accuracy: 0.2832\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 11.2823 - accuracy: 0.2838\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.6872 - accuracy: 0.2812\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 10.4082 - accuracy: 0.2838\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.9711 - accuracy: 0.2818\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.7322 - accuracy: 0.2812\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.5102 - accuracy: 0.2779\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2768 - accuracy: 0.2779\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.0180 - accuracy: 0.2766\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.7307 - accuracy: 0.2746\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.6265 - accuracy: 0.2779\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.4456 - accuracy: 0.2752\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.2223 - accuracy: 0.2772\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.1185 - accuracy: 0.2759\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.8568 - accuracy: 0.2779\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.7287 - accuracy: 0.2785\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.5994 - accuracy: 0.2792\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.4714 - accuracy: 0.2792\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.3784 - accuracy: 0.2792\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 7.2203 - accuracy: 0.2772\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.1491 - accuracy: 0.2792\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.0866 - accuracy: 0.2792\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.9747 - accuracy: 0.2785\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.8725 - accuracy: 0.3393\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.8287 - accuracy: 0.4244\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.6669 - accuracy: 0.4251\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.6074 - accuracy: 0.4251\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.4974 - accuracy: 0.4244\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.4110 - accuracy: 0.4238\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.3493 - accuracy: 0.4244\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.3051 - accuracy: 0.4257\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.2198 - accuracy: 0.4257\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1661 - accuracy: 0.4277\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.0715 - accuracy: 0.4257\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.0025 - accuracy: 0.4264\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.9728 - accuracy: 0.4284\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8836 - accuracy: 0.4264\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.8179 - accuracy: 0.4244\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.8047 - accuracy: 0.4257\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7577 - accuracy: 0.4264\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.6628 - accuracy: 0.4277\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5916 - accuracy: 0.4277\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.5283 - accuracy: 0.4257\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.4716 - accuracy: 0.4264\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.4340 - accuracy: 0.4264\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.3859 - accuracy: 0.4257\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.3878 - accuracy: 0.4277\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.2539 - accuracy: 0.4277\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 5.2719 - accuracy: 0.4271\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.1541 - accuracy: 0.4290\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.1150 - accuracy: 0.4290\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.0601 - accuracy: 0.4271\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.0089 - accuracy: 0.4284\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.9026 - accuracy: 0.4290\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.9113 - accuracy: 0.4277\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.8630 - accuracy: 0.4290\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8329 - accuracy: 0.4277\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7535 - accuracy: 0.4297\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.7004 - accuracy: 0.4284\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.6615 - accuracy: 0.4284\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.5979 - accuracy: 0.4277\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.6171 - accuracy: 0.4284\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5914 - accuracy: 0.4284\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5514 - accuracy: 0.4284\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.4854 - accuracy: 0.4284\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.5420 - accuracy: 0.4290\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.4327 - accuracy: 0.4297\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.4159 - accuracy: 0.4277\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.3182 - accuracy: 0.4277\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.3612 - accuracy: 0.4290\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.3028 - accuracy: 0.4290\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.2096 - accuracy: 0.4290\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.1926 - accuracy: 0.4297\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.1186 - accuracy: 0.4297\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.1318 - accuracy: 0.4297\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.0878 - accuracy: 0.4297\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.0116 - accuracy: 0.4297\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.0224 - accuracy: 0.4304\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.0018 - accuracy: 0.4297\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.9019 - accuracy: 0.4290\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.9519 - accuracy: 0.4284\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.7771 - accuracy: 0.4297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226fb6a4b08>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.40633245382585753\n",
      "Tasa de aciertos balanceada regresión logística: 0.17\n",
      "Matriz de confusión:\n",
      "[[  0   0   1   2   0   0]\n",
      " [  0  10  58  23   0   2]\n",
      " [  0  24 111  40   3   0]\n",
      " [  0  20  60  20   1   0]\n",
      " [  0   0   3   1   0   0]\n",
      " [  0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        93\n",
      "         3.0       0.49      0.87      0.63       178\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.41       379\n",
      "   macro avg       0.08      0.14      0.10       379\n",
      "weighted avg       0.23      0.41      0.29       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_435 (Dense)           (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_436 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_437 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_438 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_439 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,257\n",
      "Trainable params: 19,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 4s 4ms/step - loss: 8.5108 - accuracy: 0.2772\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 8.6535 - accuracy: 0.2785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226fc9d3748>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.2717678100263852\n",
      "Tasa de aciertos balanceada regresión logística: 0.21\n",
      "Matriz de confusión:\n",
      "[[  0   1   0   2   0]\n",
      " [  0  48   0  45   0]\n",
      " [  0 102   0  76   0]\n",
      " [  0  46   0  55   0]\n",
      " [  0   3   0   1   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.24      0.52      0.33        93\n",
      "         3.0       0.00      0.00      0.00       178\n",
      "         4.0       0.31      0.54      0.39       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.27       379\n",
      "   macro avg       0.11      0.21      0.14       379\n",
      "weighted avg       0.14      0.27      0.19       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_440 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_441 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_442 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_443 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_444 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,295\n",
      "Trainable params: 8,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 4s 4ms/step - loss: 8.9207 - accuracy: 0.0218\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.2514 - accuracy: 0.0231\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.2514 - accuracy: 0.0231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226fcca2408>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.15567282321899736\n",
      "Tasa de aciertos balanceada regresión logística: 0.07\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [  2   0   0   1   0   0   0]\n",
      " [ 63   0   0  30   0   0   0]\n",
      " [119   0   0  59   0   0   0]\n",
      " [ 64   0   0  36   0   0   1]\n",
      " [  4   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        93\n",
      "         3.0       0.47      0.33      0.39       178\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.16       379\n",
      "   macro avg       0.07      0.05      0.06       379\n",
      "weighted avg       0.22      0.16      0.18       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_445 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_446 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_447 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_448 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_449 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,359\n",
      "Trainable params: 2,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 4s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 9.1815 - accuracy: 0.4304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226fe0c81c8>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.46965699208443273\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   1   0   2   0]\n",
      " [  0  48   0  45   0]\n",
      " [  0 102   0  76   0]\n",
      " [  0  46   0  55   0]\n",
      " [  0   3   0   1   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        93\n",
      "         3.0       0.47      1.00      0.64       178\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.47       379\n",
      "   macro avg       0.09      0.20      0.13       379\n",
      "weighted avg       0.22      0.47      0.30       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_450 (Dense)           (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_451 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_452 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_453 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_454 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_455 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_456 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_457 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_458 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_459 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,319\n",
      "Trainable params: 10,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 5s 4ms/step - loss: 6.4121 - accuracy: 0.0066\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3.5578 - accuracy: 0.0033\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3.5578 - accuracy: 0.0033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226fe48f288>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.005277044854881266\n",
      "Tasa de aciertos balanceada regresión logística: 0.13\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0]\n",
      " [  1   2   0   0   0   0]\n",
      " [ 61  32   0   0   0   0]\n",
      " [135  43   0   0   0   0]\n",
      " [ 73  28   0   0   0   0]\n",
      " [  3   1   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.02      0.67      0.04         3\n",
      "         2.0       0.00      0.00      0.00        93\n",
      "         3.0       0.00      0.00      0.00       178\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.01       379\n",
      "   macro avg       0.00      0.11      0.01       379\n",
      "weighted avg       0.00      0.01      0.00       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX1)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_460 (Dense)           (None, 64)                768       \n",
      "                                                                 \n",
      " dense_461 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_462 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_463 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_464 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_465 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_466 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_467 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_468 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_469 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,575\n",
      "Trainable params: 4,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 6s 4ms/step - loss: 2.0289 - accuracy: 0.2475\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0246 - accuracy: 0.2475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226ff964d48>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.26649076517150394\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   3   0]\n",
      " [  0   0   0  93   0]\n",
      " [  0   0   0 178   0]\n",
      " [  0   0   0 101   0]\n",
      " [  0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        93\n",
      "         3.0       0.00      0.00      0.00       178\n",
      "         4.0       0.27      1.00      0.42       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.27       379\n",
      "   macro avg       0.05      0.20      0.08       379\n",
      "weighted avg       0.07      0.27      0.11       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX1)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_470 (Dense)           (None, 32)                384       \n",
      "                                                                 \n",
      " dense_471 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_472 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_473 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_474 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_475 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_476 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_477 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_478 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_479 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 6s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7589 - accuracy: 0.2825\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.7589 - accuracy: 0.2825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226ffea9888>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX1, trainy1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.24538258575197888\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0]\n",
      " [  1   2   0   0   0   0]\n",
      " [ 61  32   0   0   0   0]\n",
      " [135  43   0   0   0   0]\n",
      " [ 73  28   0   0   0   0]\n",
      " [  3   1   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.25      1.00      0.39        93\n",
      "         3.0       0.00      0.00      0.00       178\n",
      "         4.0       0.00      0.00      0.00       101\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.25       379\n",
      "   macro avg       0.05      0.20      0.08       379\n",
      "weighted avg       0.06      0.25      0.10       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX1)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion1 = confusion_matrix(testy1, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy1))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))\n",
    "print(classification_report(testy1, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 21, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_480 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_481 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_482 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_483 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_484 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,965\n",
      "Trainable params: 9,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 4ms/step - loss: 573.5116 - accuracy: 0.3114\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 108.2072 - accuracy: 0.3141\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.1973 - accuracy: 0.3542\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 93.0461 - accuracy: 0.3515\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 77.8668 - accuracy: 0.3358\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 66.3254 - accuracy: 0.3583\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 58.8816 - accuracy: 0.3521\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 73.2217 - accuracy: 0.3120\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 55.1688 - accuracy: 0.3406\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 42.4272 - accuracy: 0.3447\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 52.2285 - accuracy: 0.3229\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.5808 - accuracy: 0.3426\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 34.1227 - accuracy: 0.3596\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.3043 - accuracy: 0.3372\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 29.0347 - accuracy: 0.3385\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.0589 - accuracy: 0.3447\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 21.5400 - accuracy: 0.3474\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.1450 - accuracy: 0.3317\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.7171 - accuracy: 0.3372\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.3950 - accuracy: 0.3365\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.0085 - accuracy: 0.3188\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.2074 - accuracy: 0.3562\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.4212 - accuracy: 0.3562\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.5324 - accuracy: 0.3494\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.3637 - accuracy: 0.3202\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.9463 - accuracy: 0.3474\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.9297 - accuracy: 0.3481\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5236 - accuracy: 0.3331\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.6503 - accuracy: 0.3433\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 18.2226 - accuracy: 0.3297\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.6936 - accuracy: 0.3637\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4197 - accuracy: 0.3603\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.5772 - accuracy: 0.3787\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.2162 - accuracy: 0.3521\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4016 - accuracy: 0.3549\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.5433 - accuracy: 0.3521\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6916 - accuracy: 0.3617\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0709 - accuracy: 0.3372\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.4127 - accuracy: 0.3610\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3380 - accuracy: 0.3685\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2452 - accuracy: 0.3331\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.1183 - accuracy: 0.3447\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.5774 - accuracy: 0.3508\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8308 - accuracy: 0.3467\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.0292 - accuracy: 0.3440\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 10.3463 - accuracy: 0.3283\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.7846 - accuracy: 0.3433\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.8974 - accuracy: 0.3419\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.3119 - accuracy: 0.3338\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.8876 - accuracy: 0.3399\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.9816 - accuracy: 0.3596\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.9662 - accuracy: 0.3392\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.1601 - accuracy: 0.3664\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9932 - accuracy: 0.3630\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.8145 - accuracy: 0.3657\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.5771 - accuracy: 0.3562\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8381 - accuracy: 0.3623\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6739 - accuracy: 0.3753\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.4033 - accuracy: 0.3385\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.7891 - accuracy: 0.3746\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.1260 - accuracy: 0.3712\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4718 - accuracy: 0.3780\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4249 - accuracy: 0.3678\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0619 - accuracy: 0.3317\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8876 - accuracy: 0.3610\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8649 - accuracy: 0.3453\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8034 - accuracy: 0.3596\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.4937 - accuracy: 0.3732\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.0320 - accuracy: 0.3678\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8277 - accuracy: 0.3521\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5550 - accuracy: 0.3583\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5793 - accuracy: 0.3555\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2114 - accuracy: 0.3542\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5503 - accuracy: 0.3705\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7399 - accuracy: 0.3753\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.0510 - accuracy: 0.3807\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.4693 - accuracy: 0.3596\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2649 - accuracy: 0.3630\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.4859 - accuracy: 0.3671\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2942 - accuracy: 0.3719\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9705 - accuracy: 0.3440\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5092 - accuracy: 0.3657\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.2093 - accuracy: 0.3467\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.2425 - accuracy: 0.3800\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7260 - accuracy: 0.3549\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5193 - accuracy: 0.3474\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6817 - accuracy: 0.3800\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.0298 - accuracy: 0.3943\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.3634 - accuracy: 0.3644\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9584 - accuracy: 0.3780\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2753 - accuracy: 0.3610\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8116 - accuracy: 0.3487\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.0408 - accuracy: 0.3725\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8153 - accuracy: 0.3821\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1081 - accuracy: 0.3861\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.3302 - accuracy: 0.3610\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.5864 - accuracy: 0.3494\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.5083 - accuracy: 0.3827\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8432 - accuracy: 0.3719\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0497 - accuracy: 0.4242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226812aa4c8>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.45108695652173914\n",
      "Tasa de aciertos balanceada regresión logística: 0.19\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0]\n",
      " [  0   2  86   0   0]\n",
      " [  0  10 164   0   0]\n",
      " [  0   3  96   0   0]\n",
      " [  0   0   4   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.13      0.02      0.04        88\n",
      "         3.0       0.46      0.94      0.62       174\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.45       368\n",
      "   macro avg       0.12      0.19      0.13       368\n",
      "weighted avg       0.25      0.45      0.30       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_485 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_486 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_487 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_488 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_489 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,652\n",
      "Trainable params: 4,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 4ms/step - loss: 272.2463 - accuracy: 0.3379\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 92.5761 - accuracy: 0.2944\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 48.3127 - accuracy: 0.2542\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 33.0720 - accuracy: 0.3182\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 34.5092 - accuracy: 0.3950\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.1288 - accuracy: 0.4174\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 17.9302 - accuracy: 0.4269\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4999 - accuracy: 0.4310\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0035 - accuracy: 0.4283\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8636 - accuracy: 0.4310\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7093 - accuracy: 0.4317\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6558 - accuracy: 0.4303\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6056 - accuracy: 0.4310\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5691 - accuracy: 0.4317\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5373 - accuracy: 0.4310\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5127 - accuracy: 0.4310\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4930 - accuracy: 0.4310\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4752 - accuracy: 0.4317\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4592 - accuracy: 0.4317\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4445 - accuracy: 0.4317\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4308 - accuracy: 0.4317\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4182 - accuracy: 0.4317\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4066 - accuracy: 0.4317\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3959 - accuracy: 0.4317\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.3857 - accuracy: 0.4317\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3764 - accuracy: 0.4317\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3677 - accuracy: 0.4317\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3596 - accuracy: 0.4317\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3522 - accuracy: 0.4317\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3451 - accuracy: 0.4317\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3386 - accuracy: 0.4317\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3325 - accuracy: 0.4317\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3268 - accuracy: 0.4317\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3215 - accuracy: 0.4317\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3165 - accuracy: 0.4317\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3119 - accuracy: 0.4317\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3075 - accuracy: 0.4317\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3034 - accuracy: 0.4317\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2996 - accuracy: 0.4317\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2961 - accuracy: 0.4317\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2926 - accuracy: 0.4317\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2898 - accuracy: 0.4317\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2865 - accuracy: 0.4317\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2841 - accuracy: 0.4317\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2814 - accuracy: 0.4317\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2789 - accuracy: 0.4317\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2765 - accuracy: 0.4317\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2743 - accuracy: 0.4317\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2721 - accuracy: 0.4317\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2701 - accuracy: 0.4317\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2682 - accuracy: 0.4317\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2664 - accuracy: 0.4317\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2647 - accuracy: 0.4317\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2630 - accuracy: 0.4317\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2615 - accuracy: 0.4317\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2600 - accuracy: 0.4317\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2587 - accuracy: 0.4317\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2574 - accuracy: 0.4317\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2560 - accuracy: 0.4317\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2548 - accuracy: 0.4317\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2537 - accuracy: 0.4317\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2526 - accuracy: 0.4317\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2516 - accuracy: 0.4317\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2505 - accuracy: 0.4317\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2496 - accuracy: 0.4317\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2487 - accuracy: 0.4317\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2478 - accuracy: 0.4317\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2470 - accuracy: 0.4317\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2462 - accuracy: 0.4317\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2454 - accuracy: 0.4317\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2447 - accuracy: 0.4317\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2439 - accuracy: 0.4317\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2433 - accuracy: 0.4317\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2426 - accuracy: 0.4317\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2420 - accuracy: 0.4317\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2414 - accuracy: 0.4317\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2407 - accuracy: 0.4317\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2402 - accuracy: 0.4317\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2396 - accuracy: 0.4317\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2391 - accuracy: 0.4317\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2387 - accuracy: 0.4317\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2381 - accuracy: 0.4317\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2376 - accuracy: 0.4317\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2371 - accuracy: 0.4317\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2367 - accuracy: 0.4317\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2363 - accuracy: 0.4317\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2359 - accuracy: 0.4317\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2355 - accuracy: 0.4317\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2351 - accuracy: 0.4317\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2347 - accuracy: 0.4317\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2343 - accuracy: 0.4317\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2339 - accuracy: 0.4317\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2336 - accuracy: 0.4317\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2332 - accuracy: 0.4317\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2330 - accuracy: 0.4317\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2326 - accuracy: 0.4317\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2324 - accuracy: 0.4317\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2320 - accuracy: 0.4317\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2317 - accuracy: 0.4317\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2314 - accuracy: 0.4317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226827645c8>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.47282608695652173\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0]\n",
      " [  0   0  88   0   0]\n",
      " [  0   0 174   0   0]\n",
      " [  0   0  99   0   0]\n",
      " [  0   0   4   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        88\n",
      "         3.0       0.47      1.00      0.64       174\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.47       368\n",
      "   macro avg       0.09      0.20      0.13       368\n",
      "weighted avg       0.22      0.47      0.30       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_490 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_491 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_492 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_493 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_494 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,578\n",
      "Trainable params: 1,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 8s 4ms/step - loss: 230.3073 - accuracy: 0.2665\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.4741 - accuracy: 0.2658\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 19.9200 - accuracy: 0.2678\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5260 - accuracy: 0.2808\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1207 - accuracy: 0.2808\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7052 - accuracy: 0.2808\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6663 - accuracy: 0.2808\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6319 - accuracy: 0.3059\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6032 - accuracy: 0.3603\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5750 - accuracy: 0.4324\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5498 - accuracy: 0.4324\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5266 - accuracy: 0.4324\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5053 - accuracy: 0.4324\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4856 - accuracy: 0.4324\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4674 - accuracy: 0.4324\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4507 - accuracy: 0.4324\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4352 - accuracy: 0.4324\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4210 - accuracy: 0.4324\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4076 - accuracy: 0.4324\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.3954 - accuracy: 0.4324\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3840 - accuracy: 0.4324\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3733 - accuracy: 0.4324\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3670 - accuracy: 0.4317\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3551 - accuracy: 0.4324\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3461 - accuracy: 0.4324\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3382 - accuracy: 0.4324\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3311 - accuracy: 0.4324\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3242 - accuracy: 0.4324\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3180 - accuracy: 0.4324\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3121 - accuracy: 0.4324\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.3096 - accuracy: 0.4324\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3018 - accuracy: 0.4324\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2969 - accuracy: 0.4324\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2997 - accuracy: 0.4324\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2932 - accuracy: 0.4317\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2860 - accuracy: 0.4324\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2815 - accuracy: 0.4324\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2782 - accuracy: 0.4324\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2751 - accuracy: 0.4324\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2724 - accuracy: 0.4324\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2695 - accuracy: 0.4324\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2670 - accuracy: 0.4324\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2646 - accuracy: 0.4324\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2625 - accuracy: 0.4324\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2603 - accuracy: 0.4324\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2584 - accuracy: 0.4324\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2565 - accuracy: 0.4324\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2549 - accuracy: 0.4324\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2532 - accuracy: 0.4324\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2517 - accuracy: 0.4324\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2502 - accuracy: 0.4324\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2489 - accuracy: 0.4324\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2476 - accuracy: 0.4324\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2464 - accuracy: 0.4324\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2452 - accuracy: 0.4324\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2442 - accuracy: 0.4324\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2432 - accuracy: 0.4324\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2422 - accuracy: 0.4324\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2413 - accuracy: 0.4324\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2404 - accuracy: 0.4324\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2396 - accuracy: 0.4324\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2388 - accuracy: 0.4324\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2382 - accuracy: 0.4324\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2374 - accuracy: 0.4324\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2368 - accuracy: 0.4324\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2361 - accuracy: 0.4324\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2355 - accuracy: 0.4324\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2349 - accuracy: 0.4324\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2343 - accuracy: 0.4324\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2338 - accuracy: 0.4324\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2333 - accuracy: 0.4324\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2328 - accuracy: 0.4324\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2324 - accuracy: 0.4324\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2319 - accuracy: 0.4324\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2315 - accuracy: 0.4324\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2311 - accuracy: 0.4324\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2307 - accuracy: 0.4324\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2303 - accuracy: 0.4324\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2300 - accuracy: 0.4324\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2297 - accuracy: 0.4324\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2293 - accuracy: 0.4324\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2290 - accuracy: 0.4324\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2288 - accuracy: 0.4324\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2284 - accuracy: 0.4324\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2282 - accuracy: 0.4324\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2278 - accuracy: 0.4324\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2276 - accuracy: 0.4324\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2273 - accuracy: 0.4324\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2270 - accuracy: 0.4324\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2269 - accuracy: 0.4324\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2266 - accuracy: 0.4324\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2263 - accuracy: 0.4324\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2261 - accuracy: 0.4324\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2260 - accuracy: 0.4324\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2257 - accuracy: 0.4324\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2256 - accuracy: 0.4324\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2253 - accuracy: 0.4324\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2251 - accuracy: 0.4324\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2249 - accuracy: 0.4324\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2248 - accuracy: 0.4324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22682b33748>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.47282608695652173\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0]\n",
      " [  0   2  86   0   0]\n",
      " [  0  10 164   0   0]\n",
      " [  0   3  96   0   0]\n",
      " [  0   0   4   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        88\n",
      "         3.0       0.47      1.00      0.64       174\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.47       368\n",
      "   macro avg       0.09      0.20      0.13       368\n",
      "weighted avg       0.22      0.47      0.30       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 21, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_495 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_496 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_497 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_498 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_499 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,257\n",
      "Trainable params: 20,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 9.1774 - accuracy: 0.0476\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.3116 - accuracy: 0.1781\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2330 - accuracy: 0.1835\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8240 - accuracy: 0.1645\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.0224 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1181 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226fe491f08>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0]\n",
      " [ 88   0   0   0   0   0]\n",
      " [174   0   0   0   0   0]\n",
      " [ 99   0   0   0   0   0]\n",
      " [  4   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       3.0\n",
      "         2.0       0.00      0.00      0.00      88.0\n",
      "         3.0       0.00      0.00      0.00     174.0\n",
      "         4.0       0.00      0.00      0.00      99.0\n",
      "         5.0       0.00      0.00      0.00       4.0\n",
      "\n",
      "    accuracy                           0.00     368.0\n",
      "   macro avg       0.00      0.00      0.00     368.0\n",
      "weighted avg       0.00      0.00      0.00     368.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_500 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_501 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_502 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_503 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_504 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,935\n",
      "Trainable params: 8,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5962 - accuracy: 0.1074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226eed81088>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.19293478260869565\n",
      "Tasa de aciertos balanceada regresión logística: 0.21\n",
      "Matriz de confusión:\n",
      "[[ 1  0  0  2  0]\n",
      " [32  0  0 56  0]\n",
      " [76  0  0 98  0]\n",
      " [29  0  0 70  0]\n",
      " [ 2  0  0  2  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      0.33      0.01         3\n",
      "         2.0       0.00      0.00      0.00        88\n",
      "         3.0       0.00      0.00      0.00       174\n",
      "         4.0       0.31      0.71      0.43        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.19       368\n",
      "   macro avg       0.06      0.21      0.09       368\n",
      "weighted avg       0.08      0.19      0.12       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_505 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_506 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_507 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_508 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_509 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,679\n",
      "Trainable params: 2,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 5ms/step - loss: 12.8096 - accuracy: 0.0027\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.2409 - accuracy: 6.7981e-04\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0339 - accuracy: 6.7981e-04\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.9543 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22685246808>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0]\n",
      " [ 88   0   0   0   0   0]\n",
      " [174   0   0   0   0   0]\n",
      " [ 99   0   0   0   0   0]\n",
      " [  4   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       3.0\n",
      "         2.0       0.00      0.00      0.00      88.0\n",
      "         3.0       0.00      0.00      0.00     174.0\n",
      "         4.0       0.00      0.00      0.00      99.0\n",
      "         5.0       0.00      0.00      0.00       4.0\n",
      "\n",
      "    accuracy                           0.00     368.0\n",
      "   macro avg       0.00      0.00      0.00     368.0\n",
      "weighted avg       0.00      0.00      0.00     368.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 21, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_510 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_511 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_512 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_513 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_514 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_515 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_516 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_517 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_518 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_519 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,319\n",
      "Trainable params: 11,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 3ms/step - loss: 6.0036 - accuracy: 0.2672\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0245\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.3612 - accuracy: 0.0224\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3612 - accuracy: 0.0224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226855a1248>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.008152173913043478\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  3   0   0   0   0]\n",
      " [ 88   0   0   0   0]\n",
      " [174   0   0   0   0]\n",
      " [ 99   0   0   0   0]\n",
      " [  4   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      1.00      0.02         3\n",
      "         2.0       0.00      0.00      0.00        88\n",
      "         3.0       0.00      0.00      0.00       174\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.01       368\n",
      "   macro avg       0.00      0.20      0.00       368\n",
      "weighted avg       0.00      0.01      0.00       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_520 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_521 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_522 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_523 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_524 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_525 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_526 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_527 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_528 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_529 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,215\n",
      "Trainable params: 5,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 5s 5ms/step - loss: 4.3566 - accuracy: 0.3909\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.8008 - accuracy: 0.4276\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6487 - accuracy: 0.4317\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6487 - accuracy: 0.4317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22686c0b1c8>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.47282608695652173\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0]\n",
      " [  0   0  88   0   0]\n",
      " [  0   0 174   0   0]\n",
      " [  0   0  99   0   0]\n",
      " [  0   0   4   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        88\n",
      "         3.0       0.47      1.00      0.64       174\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.47       368\n",
      "   macro avg       0.09      0.20      0.13       368\n",
      "weighted avg       0.22      0.47      0.30       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_530 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_531 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_532 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_533 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_534 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_535 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_536 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_537 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_538 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_539 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,713\n",
      "Trainable params: 1,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 5s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0668 - accuracy: 0.0231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2268815b748>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.008152173913043478\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  3   0   0   0   0]\n",
      " [ 88   0   0   0   0]\n",
      " [174   0   0   0   0]\n",
      " [ 99   0   0   0   0]\n",
      " [  4   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      1.00      0.02         3\n",
      "         2.0       0.00      0.00      0.00        88\n",
      "         3.0       0.00      0.00      0.00       174\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.01       368\n",
      "   macro avg       0.00      0.20      0.00       368\n",
      "weighted avg       0.00      0.01      0.00       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_540 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_541 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_542 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_543 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_544 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,965\n",
      "Trainable params: 9,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 3ms/step - loss: 2317.6985 - accuracy: 0.2121\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 244.8121 - accuracy: 0.3018\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 198.7353 - accuracy: 0.3263\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 171.5054 - accuracy: 0.3338\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 157.7351 - accuracy: 0.3304\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 146.6799 - accuracy: 0.3182\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 134.4601 - accuracy: 0.3236\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 124.0612 - accuracy: 0.3195\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 116.2270 - accuracy: 0.3385\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 110.3182 - accuracy: 0.3168\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 104.3966 - accuracy: 0.3222\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 101.4422 - accuracy: 0.3202\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 93.9410 - accuracy: 0.3290\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 92.9935 - accuracy: 0.2991\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 89.6331 - accuracy: 0.3134\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 83.9440 - accuracy: 0.3182\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.9317 - accuracy: 0.3290\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 78.9969 - accuracy: 0.3209\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 75.1882 - accuracy: 0.3154\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 72.0341 - accuracy: 0.3209\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 66.9231 - accuracy: 0.3297\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 65.5032 - accuracy: 0.3249\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 66.3912 - accuracy: 0.3243\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.3638 - accuracy: 0.3188\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 63.9695 - accuracy: 0.3345\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 62.5437 - accuracy: 0.3080\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 60.9764 - accuracy: 0.3290\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 60.5647 - accuracy: 0.3141\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 59.0124 - accuracy: 0.3331\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.4709 - accuracy: 0.3209\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 57.1870 - accuracy: 0.3229\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 56.4713 - accuracy: 0.3270\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 56.1028 - accuracy: 0.3290\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 54.2875 - accuracy: 0.3263\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 55.8673 - accuracy: 0.3215\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 54.3905 - accuracy: 0.3351\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 53.8453 - accuracy: 0.3134\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 53.5226 - accuracy: 0.3236\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 52.4030 - accuracy: 0.3372\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 52.3396 - accuracy: 0.3229\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.7652 - accuracy: 0.3107\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 50.2444 - accuracy: 0.3236\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 49.3119 - accuracy: 0.3290\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 49.5850 - accuracy: 0.3249\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 48.8689 - accuracy: 0.3215\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 49.3892 - accuracy: 0.3277\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 48.7017 - accuracy: 0.3080\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.3231 - accuracy: 0.3297\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 47.5144 - accuracy: 0.3215\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.8689 - accuracy: 0.3161\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 47.3365 - accuracy: 0.3073\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 46.1343 - accuracy: 0.3175\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.2343 - accuracy: 0.3134\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 45.5075 - accuracy: 0.3256\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.7308 - accuracy: 0.3277\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.9267 - accuracy: 0.3080\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.9646 - accuracy: 0.3086\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.6665 - accuracy: 0.3236\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.1596 - accuracy: 0.3311\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.3037 - accuracy: 0.3317\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 42.6553 - accuracy: 0.3209\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 43.2713 - accuracy: 0.3066\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.5766 - accuracy: 0.3141\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.0315 - accuracy: 0.3175\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.8510 - accuracy: 0.3141\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.1106 - accuracy: 0.3195\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.6089 - accuracy: 0.2998\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.5739 - accuracy: 0.3120\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 40.9834 - accuracy: 0.3148\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.5062 - accuracy: 0.3209\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 40.8299 - accuracy: 0.3114\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 40.4092 - accuracy: 0.3032\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 40.5537 - accuracy: 0.3209\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.6739 - accuracy: 0.3114\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 38.9182 - accuracy: 0.3222\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 40.8406 - accuracy: 0.3182\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 40.3717 - accuracy: 0.3134\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 39.3045 - accuracy: 0.3351\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.0818 - accuracy: 0.3127\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 39.5778 - accuracy: 0.3107\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 39.1931 - accuracy: 0.3066\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.7734 - accuracy: 0.3114\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 39.1645 - accuracy: 0.3161\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.8601 - accuracy: 0.3086\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 38.9726 - accuracy: 0.3120\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.0778 - accuracy: 0.3039\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 38.6309 - accuracy: 0.3175\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 38.0070 - accuracy: 0.3168\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 39.2649 - accuracy: 0.3100\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 37.8050 - accuracy: 0.3100\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.7074 - accuracy: 0.3018\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.4327 - accuracy: 0.2978\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 38.0126 - accuracy: 0.3243\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 37.0941 - accuracy: 0.3161\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.1192 - accuracy: 0.3107\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.8766 - accuracy: 0.3148\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 37.6327 - accuracy: 0.3120\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 37.5501 - accuracy: 0.3005\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 37.2040 - accuracy: 0.3249\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 36.7185 - accuracy: 0.3222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226885bd788>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3532608695652174\n",
      "Tasa de aciertos balanceada regresión logística: 0.19\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0  2  1  0  0]\n",
      " [ 1  3 37 44  3  0]\n",
      " [ 2  7 73 89  3  0]\n",
      " [ 1  7 46 41  4  0]\n",
      " [ 0  0  3  1  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.23      0.42      0.30        88\n",
      "         3.0       0.51      0.51      0.51       174\n",
      "         4.0       0.40      0.04      0.07        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.35       368\n",
      "   macro avg       0.19      0.16      0.15       368\n",
      "weighted avg       0.40      0.35      0.33       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_545 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_546 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_547 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_548 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_549 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,652\n",
      "Trainable params: 4,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 3ms/step - loss: 711.8263 - accuracy: 0.2067\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 310.6029 - accuracy: 0.3093\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 260.3042 - accuracy: 0.3501\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 232.3268 - accuracy: 0.3705\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 209.2770 - accuracy: 0.3691\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 191.4738 - accuracy: 0.3508\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 175.8135 - accuracy: 0.3725\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 159.7101 - accuracy: 0.3413\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 142.3952 - accuracy: 0.3487\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 121.0320 - accuracy: 0.3460\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 107.7690 - accuracy: 0.3664\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 99.0550 - accuracy: 0.3657\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 92.7707 - accuracy: 0.3521\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.6065 - accuracy: 0.3481\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.0748 - accuracy: 0.3596\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.6567 - accuracy: 0.3528\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 76.4459 - accuracy: 0.3542\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.9451 - accuracy: 0.3535\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.4806 - accuracy: 0.3542\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.7960 - accuracy: 0.3494\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 65.4085 - accuracy: 0.3467\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 63.0283 - accuracy: 0.3569\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 61.0497 - accuracy: 0.3542\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 59.4489 - accuracy: 0.3630\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 57.8806 - accuracy: 0.3569\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 55.4888 - accuracy: 0.3617\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.8631 - accuracy: 0.3678\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 51.6672 - accuracy: 0.3793\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 50.0887 - accuracy: 0.3759\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 48.4304 - accuracy: 0.4092\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.5837 - accuracy: 0.3916\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.4758 - accuracy: 0.4011\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.6389 - accuracy: 0.3882\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.8356 - accuracy: 0.4045\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.1317 - accuracy: 0.3936\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.5836 - accuracy: 0.3943\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 43.0532 - accuracy: 0.3997\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.2880 - accuracy: 0.3936\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.9149 - accuracy: 0.3902\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.2749 - accuracy: 0.3861\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.0690 - accuracy: 0.3889\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 40.5843 - accuracy: 0.3916\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 40.0629 - accuracy: 0.3821\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.1554 - accuracy: 0.3909\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.1156 - accuracy: 0.3929\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.2379 - accuracy: 0.3753\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.1003 - accuracy: 0.3766\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 37.7167 - accuracy: 0.3902\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 37.0916 - accuracy: 0.3916\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.7363 - accuracy: 0.3705\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.4187 - accuracy: 0.3909\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.0855 - accuracy: 0.3895\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 35.7689 - accuracy: 0.3895\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 35.8904 - accuracy: 0.3909\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 35.5368 - accuracy: 0.3882\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 35.1286 - accuracy: 0.3895\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.8285 - accuracy: 0.3780\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 34.6149 - accuracy: 0.3943\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 34.1239 - accuracy: 0.3902\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 34.0131 - accuracy: 0.3916\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.5433 - accuracy: 0.3943\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 33.4492 - accuracy: 0.3956\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 33.3531 - accuracy: 0.3841\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.8504 - accuracy: 0.3923\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.8110 - accuracy: 0.3787\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.4354 - accuracy: 0.3868\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.3902 - accuracy: 0.4011\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.9177 - accuracy: 0.3861\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.7646 - accuracy: 0.3984\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.9459 - accuracy: 0.3882\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.4042 - accuracy: 0.3943\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.3840 - accuracy: 0.3895\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 31.2648 - accuracy: 0.3895\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.8373 - accuracy: 0.3861\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.6912 - accuracy: 0.3827\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.4616 - accuracy: 0.3909\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.2911 - accuracy: 0.3929\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.1964 - accuracy: 0.3943\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.9972 - accuracy: 0.3997\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.6911 - accuracy: 0.3997\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.9879 - accuracy: 0.3936\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.4310 - accuracy: 0.3963\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.3731 - accuracy: 0.3895\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.1922 - accuracy: 0.3943\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.9902 - accuracy: 0.4024\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.9756 - accuracy: 0.4058\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 28.8417 - accuracy: 0.3977\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.5525 - accuracy: 0.3997\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.6757 - accuracy: 0.3977\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.2777 - accuracy: 0.3848\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.3174 - accuracy: 0.4018\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.1823 - accuracy: 0.3943\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.1456 - accuracy: 0.3997\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.9185 - accuracy: 0.3916\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.6621 - accuracy: 0.4188\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.8734 - accuracy: 0.3943\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.5483 - accuracy: 0.4045\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 27.6015 - accuracy: 0.3956\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.2817 - accuracy: 0.3990\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.1932 - accuracy: 0.3950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2268991b708>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.35597826086956524\n",
      "Tasa de aciertos balanceada regresión logística: 0.21\n",
      "Matriz de confusión:\n",
      "[[ 0  1  1  1  0]\n",
      " [ 0 34 33 21  0]\n",
      " [ 1 64 73 36  0]\n",
      " [ 1 38 36 24  0]\n",
      " [ 0  1  3  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.25      0.39      0.30        88\n",
      "         3.0       0.50      0.42      0.46       174\n",
      "         4.0       0.29      0.24      0.27        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.36       368\n",
      "   macro avg       0.21      0.21      0.20       368\n",
      "weighted avg       0.37      0.36      0.36       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_550 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_551 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_552 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_553 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_554 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,578\n",
      "Trainable params: 1,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 2ms/step - loss: 3266.9116 - accuracy: 0.3447\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 882.6623 - accuracy: 0.2495\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 285.9243 - accuracy: 0.2998\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 146.9100 - accuracy: 0.2923\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.0156 - accuracy: 0.2882\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.5040 - accuracy: 0.2848\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.1924 - accuracy: 0.2835\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.8746 - accuracy: 0.2842\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.7465 - accuracy: 0.2862\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1961 - accuracy: 0.2828\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3189 - accuracy: 0.2828\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3617 - accuracy: 0.2814\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3468 - accuracy: 0.2801\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7554 - accuracy: 0.2801\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9545 - accuracy: 0.2808\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5379 - accuracy: 0.2814\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1629 - accuracy: 0.2801\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8381 - accuracy: 0.2801\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6383 - accuracy: 0.2801\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4484 - accuracy: 0.2801\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2568 - accuracy: 0.2801\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1293 - accuracy: 0.2808\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0727 - accuracy: 0.2801\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0211 - accuracy: 0.2808\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0164 - accuracy: 0.2808\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0123 - accuracy: 0.2808\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0082 - accuracy: 0.2808\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0042 - accuracy: 0.2808\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0002 - accuracy: 0.2808\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9964 - accuracy: 0.2808\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9928 - accuracy: 0.2808\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9890 - accuracy: 0.2808\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9853 - accuracy: 0.2808\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9823 - accuracy: 0.2808\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9792 - accuracy: 0.2808\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9762 - accuracy: 0.2808\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9731 - accuracy: 0.2808\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9702 - accuracy: 0.2808\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9672 - accuracy: 0.2808\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9642 - accuracy: 0.2808\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9611 - accuracy: 0.2808\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9584 - accuracy: 0.2808\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9555 - accuracy: 0.2808\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9526 - accuracy: 0.2808\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9497 - accuracy: 0.2808\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9469 - accuracy: 0.2808\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9440 - accuracy: 0.2808\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9413 - accuracy: 0.2808\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9385 - accuracy: 0.2808\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9357 - accuracy: 0.2808\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9330 - accuracy: 0.2808\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9303 - accuracy: 0.2808\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9277 - accuracy: 0.2808\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9252 - accuracy: 0.3562\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9228 - accuracy: 0.4324\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9206 - accuracy: 0.4324\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9185 - accuracy: 0.4324\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9165 - accuracy: 0.4324\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9144 - accuracy: 0.4324\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9122 - accuracy: 0.4324\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9103 - accuracy: 0.4324\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9081 - accuracy: 0.4324\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9060 - accuracy: 0.4324\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9040 - accuracy: 0.4324\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9019 - accuracy: 0.4324\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9000 - accuracy: 0.4324\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8979 - accuracy: 0.4324\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8959 - accuracy: 0.4324\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8940 - accuracy: 0.4324\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8920 - accuracy: 0.4324\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8900 - accuracy: 0.4324\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8880 - accuracy: 0.4324\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8860 - accuracy: 0.4324\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8840 - accuracy: 0.4324\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8820 - accuracy: 0.4324\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8801 - accuracy: 0.4324\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8781 - accuracy: 0.4324\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8762 - accuracy: 0.4324\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8742 - accuracy: 0.4324\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8724 - accuracy: 0.4324\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8705 - accuracy: 0.4324\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8686 - accuracy: 0.4324\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8667 - accuracy: 0.4324\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8648 - accuracy: 0.4324\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8630 - accuracy: 0.4324\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8611 - accuracy: 0.4324\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8592 - accuracy: 0.4324\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8573 - accuracy: 0.4324\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8555 - accuracy: 0.4324\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8538 - accuracy: 0.4324\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8521 - accuracy: 0.4324\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8509 - accuracy: 0.4324\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8499 - accuracy: 0.4324\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8489 - accuracy: 0.4324\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8479 - accuracy: 0.4324\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8469 - accuracy: 0.4324\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8459 - accuracy: 0.4324\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8449 - accuracy: 0.4324\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8439 - accuracy: 0.4324\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8430 - accuracy: 0.4324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22689cb3348>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.47282608695652173\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0  2  1  0  0]\n",
      " [ 1  3 37 44  3  0]\n",
      " [ 2  7 73 89  3  0]\n",
      " [ 1  7 46 41  4  0]\n",
      " [ 0  0  3  1  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        88\n",
      "         3.0       0.47      1.00      0.64       174\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.47       368\n",
      "   macro avg       0.09      0.20      0.13       368\n",
      "weighted avg       0.22      0.47      0.30       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_555 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_556 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_557 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_558 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_559 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,257\n",
      "Trainable params: 20,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 3ms/step - loss: 12.9037 - accuracy: 0.1815\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5942 - accuracy: 0.1768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22689ff5b08>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.08967391304347826\n",
      "Tasa de aciertos balanceada regresión logística: 0.07\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 2  0  0  0  1  0]\n",
      " [51  0  0  0 37  0]\n",
      " [93  0  0  0 81  0]\n",
      " [66  0  0  0 33  0]\n",
      " [ 2  0  0  0  2  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        88\n",
      "         3.0       0.00      0.00      0.00       174\n",
      "         4.0       0.21      0.33      0.26        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.09       368\n",
      "   macro avg       0.04      0.06      0.04       368\n",
      "weighted avg       0.06      0.09      0.07       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_560 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_561 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_562 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_563 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_564 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,935\n",
      "Trainable params: 8,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 15.3475 - accuracy: 0.0156\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3130 - accuracy: 0.0156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2268b419508>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.010869565217391304\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   3]\n",
      " [  0   0   0   0  88]\n",
      " [  0   0   0   0 174]\n",
      " [  0   0   0   0  99]\n",
      " [  0   0   0   0   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        88\n",
      "         3.0       0.00      0.00      0.00       174\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.01      1.00      0.02         4\n",
      "\n",
      "    accuracy                           0.01       368\n",
      "   macro avg       0.00      0.20      0.00       368\n",
      "weighted avg       0.00      0.01      0.00       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_565 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_566 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_567 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_568 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_569 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,679\n",
      "Trainable params: 2,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 7.4548 - accuracy: 0.0156\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.6587 - accuracy: 0.0156\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4877 - accuracy: 0.0156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2268c7da448>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.010869565217391304\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 2  0  0  0  1  0]\n",
      " [51  0  0  0 37  0]\n",
      " [93  0  0  0 81  0]\n",
      " [66  0  0  0 33  0]\n",
      " [ 2  0  0  0  2  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        88\n",
      "         3.0       0.00      0.00      0.00       174\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.01      1.00      0.02         4\n",
      "\n",
      "    accuracy                           0.01       368\n",
      "   macro avg       0.00      0.20      0.00       368\n",
      "weighted avg       0.00      0.01      0.00       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_570 (Dense)           (None, 100)               2200      \n",
      "                                                                 \n",
      " dense_571 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_572 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_573 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_574 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_575 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_576 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_577 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_578 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_579 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,319\n",
      "Trainable params: 11,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 4ms/step - loss: 12.1282 - accuracy: 0.0163\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.7594 - accuracy: 0.0184\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3182 - accuracy: 0.0184\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4717 - accuracy: 0.0197\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.4803 - accuracy: 0.0204\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6888 - accuracy: 0.0211\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.6065 - accuracy: 0.0197\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8602 - accuracy: 0.0197\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.6667 - accuracy: 0.0204\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7162 - accuracy: 0.0197\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7063 - accuracy: 0.0197\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.0197\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7169 - accuracy: 0.0197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2268cb83dc8>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.005434782608695652\n",
      "Tasa de aciertos balanceada regresión logística: 0.13\n",
      "Matriz de confusión:\n",
      "[[  2   0   0   0   1]\n",
      " [ 81   0   0   0   7]\n",
      " [148   0   0   0  26]\n",
      " [ 93   0   0   0   6]\n",
      " [  4   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      0.67      0.01         3\n",
      "         2.0       0.00      0.00      0.00        88\n",
      "         3.0       0.00      0.00      0.00       174\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.01       368\n",
      "   macro avg       0.00      0.13      0.00       368\n",
      "weighted avg       0.00      0.01      0.00       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX2)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_580 (Dense)           (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_581 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_582 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_583 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_584 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_585 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_586 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_587 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_588 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_589 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,215\n",
      "Trainable params: 5,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 3ms/step - loss: 6.8712 - accuracy: 0.3107\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7173 - accuracy: 0.4344\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.1283 - accuracy: 0.4317\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4247 - accuracy: 0.4269\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7532 - accuracy: 0.4181\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7936 - accuracy: 0.4181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2268e051608>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.391304347826087\n",
      "Tasa de aciertos balanceada regresión logística: 0.18\n",
      "Matriz de confusión:\n",
      "[[  0   0   2   0   1]\n",
      " [  0   0  56  12  20]\n",
      " [  0   0 124  25  25]\n",
      " [  0   0  60  20  19]\n",
      " [  0   0   4   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        88\n",
      "         3.0       0.50      0.71      0.59       174\n",
      "         4.0       0.35      0.20      0.26        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.39       368\n",
      "   macro avg       0.17      0.18      0.17       368\n",
      "weighted avg       0.33      0.39      0.35       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX2)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_590 (Dense)           (None, 32)                704       \n",
      "                                                                 \n",
      " dense_591 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_592 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_593 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_594 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_595 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_596 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_597 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_598 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_599 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,713\n",
      "Trainable params: 1,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 9.1915 - accuracy: 0.4310\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1621 - accuracy: 0.4317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2268f5a8648>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX2, trainy2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.47282608695652173\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  2   0   0   0   1]\n",
      " [ 81   0   0   0   7]\n",
      " [148   0   0   0  26]\n",
      " [ 93   0   0   0   6]\n",
      " [  4   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        88\n",
      "         3.0       0.47      1.00      0.64       174\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.47       368\n",
      "   macro avg       0.09      0.20      0.13       368\n",
      "weighted avg       0.22      0.47      0.30       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX2)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion2 = confusion_matrix(testy2, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy2))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))\n",
    "print(classification_report(testy2, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de datos 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 35, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_600 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_601 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_602 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_603 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_604 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,365\n",
      "Trainable params: 11,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 762.5217 - accuracy: 0.3107\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 187.8952 - accuracy: 0.3395\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 105.6597 - accuracy: 0.3608\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 94.3633 - accuracy: 0.3533\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 93.7104 - accuracy: 0.3354\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.9006 - accuracy: 0.3491\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.5915 - accuracy: 0.3677\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.6252 - accuracy: 0.3381\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.6085 - accuracy: 0.3443\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.7921 - accuracy: 0.3223\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.4826 - accuracy: 0.3643\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.3532 - accuracy: 0.3649\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.7329 - accuracy: 0.3759\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.1651 - accuracy: 0.3766\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.7334 - accuracy: 0.3615\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.8828 - accuracy: 0.3574\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 33.0115 - accuracy: 0.3574\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.9191 - accuracy: 0.3704\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.9750 - accuracy: 0.3636\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.3283 - accuracy: 0.3677\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.0631 - accuracy: 0.3636\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.6059 - accuracy: 0.3546\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.5659 - accuracy: 0.3615\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.8744 - accuracy: 0.3732\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.1785 - accuracy: 0.3595\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.7081 - accuracy: 0.3622\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.3194 - accuracy: 0.3601\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.2310 - accuracy: 0.3533\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.8523 - accuracy: 0.3416\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.3123 - accuracy: 0.3911\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.2398 - accuracy: 0.3388\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.3483 - accuracy: 0.3326\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.8055 - accuracy: 0.3677\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.2409 - accuracy: 0.3629\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.6869 - accuracy: 0.3787\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7148 - accuracy: 0.3753\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.8160 - accuracy: 0.3732\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6858 - accuracy: 0.3746\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6731 - accuracy: 0.3478\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.5167 - accuracy: 0.3808\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.4816 - accuracy: 0.3478\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9175 - accuracy: 0.3643\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0901 - accuracy: 0.3670\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.9134 - accuracy: 0.3443\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6266 - accuracy: 0.3354\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.3402 - accuracy: 0.3491\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.7966 - accuracy: 0.3533\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.1835 - accuracy: 0.3450\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8154 - accuracy: 0.3595\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4749 - accuracy: 0.3457\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6754 - accuracy: 0.3684\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.1616 - accuracy: 0.3560\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9082 - accuracy: 0.3649\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2289 - accuracy: 0.3794\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9402 - accuracy: 0.3780\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8077 - accuracy: 0.3808\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3898 - accuracy: 0.3842\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0766 - accuracy: 0.4199\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.2147 - accuracy: 0.3918\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1850 - accuracy: 0.3828\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7614 - accuracy: 0.4021\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7590 - accuracy: 0.3924\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3871 - accuracy: 0.3443\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3074 - accuracy: 0.3711\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5572 - accuracy: 0.3636\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5765 - accuracy: 0.3766\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9193 - accuracy: 0.3794\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7115 - accuracy: 0.3814\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4653 - accuracy: 0.3835\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1262 - accuracy: 0.3704\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9034 - accuracy: 0.3897\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2978 - accuracy: 0.3595\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4059 - accuracy: 0.3856\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5579 - accuracy: 0.3966\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4480 - accuracy: 0.4144\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6347 - accuracy: 0.3876\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9366 - accuracy: 0.3746\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8615 - accuracy: 0.3959\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3157 - accuracy: 0.3794\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8888 - accuracy: 0.4007\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1830 - accuracy: 0.3924\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2550 - accuracy: 0.3828\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4265 - accuracy: 0.4227\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7895 - accuracy: 0.3993\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0738 - accuracy: 0.3849\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8576 - accuracy: 0.4007\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0347 - accuracy: 0.3979\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5539 - accuracy: 0.4405\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8297 - accuracy: 0.3869\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3587 - accuracy: 0.3856\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1712 - accuracy: 0.3959\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1714 - accuracy: 0.4027\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8887 - accuracy: 0.4206\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3088 - accuracy: 0.3753\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1056 - accuracy: 0.3897\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7321 - accuracy: 0.3601\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3942 - accuracy: 0.3643\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7397 - accuracy: 0.3691\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5712 - accuracy: 0.3595\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5648 - accuracy: 0.3485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226e6135408>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.30494505494505497\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   3   0]\n",
      " [  0   2  15  69   0]\n",
      " [  0   4  26 142   0]\n",
      " [  0   0  16  83   0]\n",
      " [  0   0   2   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.33      0.02      0.04        86\n",
      "         3.0       0.44      0.15      0.23       172\n",
      "         4.0       0.28      0.84      0.42        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.30       364\n",
      "   macro avg       0.21      0.20      0.14       364\n",
      "weighted avg       0.36      0.30      0.23       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_605 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_606 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_607 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_608 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_609 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,548\n",
      "Trainable params: 5,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 637.1234 - accuracy: 0.2591\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 78.0537 - accuracy: 0.3203\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 42.6475 - accuracy: 0.3340\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.1308 - accuracy: 0.3368\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.8484 - accuracy: 0.3457\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6334 - accuracy: 0.3416\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.8285 - accuracy: 0.3622\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.4796 - accuracy: 0.3443\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4449 - accuracy: 0.3704\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8090 - accuracy: 0.3553\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5553 - accuracy: 0.3326\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1938 - accuracy: 0.3464\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.0537 - accuracy: 0.3533\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8173 - accuracy: 0.3704\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7563 - accuracy: 0.3560\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9727 - accuracy: 0.3649\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4814 - accuracy: 0.3677\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.6501 - accuracy: 0.3430\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.6625 - accuracy: 0.3753\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4472 - accuracy: 0.3409\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0596 - accuracy: 0.3718\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0507 - accuracy: 0.3306\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0878 - accuracy: 0.3588\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7087 - accuracy: 0.3649\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.1295 - accuracy: 0.3704\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4119 - accuracy: 0.3464\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6770 - accuracy: 0.3409\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.9028 - accuracy: 0.3711\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8792 - accuracy: 0.3567\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2911 - accuracy: 0.3450\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1327 - accuracy: 0.3656\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.1822 - accuracy: 0.3505\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0433 - accuracy: 0.3464\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9160 - accuracy: 0.3299\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1075 - accuracy: 0.3512\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.9582 - accuracy: 0.3684\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9694 - accuracy: 0.3794\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3876 - accuracy: 0.3711\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8524 - accuracy: 0.3615\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.9896 - accuracy: 0.3746\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1021 - accuracy: 0.3711\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8925 - accuracy: 0.3491\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3991 - accuracy: 0.3773\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9057 - accuracy: 0.4027\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8654 - accuracy: 0.4082\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6470 - accuracy: 0.4158\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7522 - accuracy: 0.3959\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8009 - accuracy: 0.4062\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5301 - accuracy: 0.4144\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6256 - accuracy: 0.4144\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5705 - accuracy: 0.4364\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5247 - accuracy: 0.4247\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5070 - accuracy: 0.4330\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4808 - accuracy: 0.4337\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4579 - accuracy: 0.4337\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4382 - accuracy: 0.4337\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4206 - accuracy: 0.4337\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4053 - accuracy: 0.4337\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3915 - accuracy: 0.4337\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3792 - accuracy: 0.4337\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3680 - accuracy: 0.4337\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3580 - accuracy: 0.4337\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3488 - accuracy: 0.4337\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3405 - accuracy: 0.4337\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3331 - accuracy: 0.4337\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3260 - accuracy: 0.4337\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3196 - accuracy: 0.4337\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3136 - accuracy: 0.4337\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.3077 - accuracy: 0.4337\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3028 - accuracy: 0.4337\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2980 - accuracy: 0.4337\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2938 - accuracy: 0.4337\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2900 - accuracy: 0.4337\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2865 - accuracy: 0.4337\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2827 - accuracy: 0.4337\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2789 - accuracy: 0.4337\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2758 - accuracy: 0.4337\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2729 - accuracy: 0.4337\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2704 - accuracy: 0.4337\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2686 - accuracy: 0.4337\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2661 - accuracy: 0.4337\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2638 - accuracy: 0.4337\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2617 - accuracy: 0.4337\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2598 - accuracy: 0.4337\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2579 - accuracy: 0.4337\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2560 - accuracy: 0.4337\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2544 - accuracy: 0.4337\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2528 - accuracy: 0.4337\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2513 - accuracy: 0.4337\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2499 - accuracy: 0.4337\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2486 - accuracy: 0.4337\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2473 - accuracy: 0.4337\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2461 - accuracy: 0.4337\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2450 - accuracy: 0.4337\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2436 - accuracy: 0.4337\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2416 - accuracy: 0.4337\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2426 - accuracy: 0.4337\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2409 - accuracy: 0.4337\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2400 - accuracy: 0.4337\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2393 - accuracy: 0.4337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22690e22248>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4725274725274725\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0]\n",
      " [  0   0  86   0   0]\n",
      " [  0   0 172   0   0]\n",
      " [  0   0  99   0   0]\n",
      " [  0   0   4   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        86\n",
      "         3.0       0.47      1.00      0.64       172\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.47       364\n",
      "   macro avg       0.09      0.20      0.13       364\n",
      "weighted avg       0.22      0.47      0.30       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_610 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_611 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_612 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_613 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_614 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,026\n",
      "Trainable params: 2,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 278.2749 - accuracy: 0.2241\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.0565 - accuracy: 0.2832\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.2791 - accuracy: 0.3478\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5174 - accuracy: 0.3945\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4058 - accuracy: 0.4103\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6676 - accuracy: 0.4330\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5930 - accuracy: 0.4309\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5344 - accuracy: 0.4254\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5022 - accuracy: 0.4254\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4680 - accuracy: 0.4213\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4430 - accuracy: 0.4261\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4125 - accuracy: 0.4289\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4296 - accuracy: 0.4179\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3808 - accuracy: 0.4247\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3631 - accuracy: 0.4227\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3507 - accuracy: 0.4227\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3774 - accuracy: 0.4158\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3267 - accuracy: 0.4234\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3186 - accuracy: 0.4247\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3098 - accuracy: 0.4316\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3089 - accuracy: 0.4247\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2966 - accuracy: 0.4296\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2900 - accuracy: 0.4220\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2861 - accuracy: 0.4206\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2799 - accuracy: 0.4289\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2751 - accuracy: 0.4282\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2732 - accuracy: 0.4220\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2694 - accuracy: 0.4282\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2846 - accuracy: 0.4213\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3397 - accuracy: 0.4296\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2587 - accuracy: 0.4261\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2547 - accuracy: 0.4302\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2514 - accuracy: 0.4227\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2500 - accuracy: 0.4261\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2481 - accuracy: 0.4296\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2471 - accuracy: 0.4302\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2449 - accuracy: 0.4261\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2467 - accuracy: 0.4282\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2429 - accuracy: 0.4268\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2422 - accuracy: 0.4296\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2451 - accuracy: 0.4247\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2413 - accuracy: 0.4206\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2425 - accuracy: 0.4261\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2438 - accuracy: 0.4323\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2377 - accuracy: 0.4254\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2333 - accuracy: 0.4357\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2327 - accuracy: 0.4357\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2326 - accuracy: 0.4344\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2318 - accuracy: 0.4344\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2315 - accuracy: 0.4337\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2307 - accuracy: 0.4337\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2301 - accuracy: 0.4337\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2298 - accuracy: 0.4337\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2292 - accuracy: 0.4337\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2287 - accuracy: 0.4337\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2283 - accuracy: 0.4337\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2278 - accuracy: 0.4337\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2275 - accuracy: 0.4337\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2271 - accuracy: 0.4337\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2268 - accuracy: 0.4337\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2265 - accuracy: 0.4337\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2261 - accuracy: 0.4337\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2259 - accuracy: 0.4337\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2255 - accuracy: 0.4337\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2252 - accuracy: 0.4337\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2250 - accuracy: 0.4337\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2247 - accuracy: 0.4337\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2246 - accuracy: 0.4337\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2243 - accuracy: 0.4337\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2240 - accuracy: 0.4337\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2240 - accuracy: 0.4337\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2235 - accuracy: 0.4337\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2234 - accuracy: 0.4337\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2232 - accuracy: 0.4337\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2230 - accuracy: 0.4337\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2229 - accuracy: 0.4337\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2227 - accuracy: 0.4337\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2226 - accuracy: 0.4337\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2224 - accuracy: 0.4337\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2222 - accuracy: 0.4337\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2221 - accuracy: 0.4337\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2219 - accuracy: 0.4337\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2218 - accuracy: 0.4337\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2217 - accuracy: 0.4337\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2216 - accuracy: 0.4337\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2215 - accuracy: 0.4337\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2214 - accuracy: 0.4337\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2214 - accuracy: 0.4337\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2212 - accuracy: 0.4337\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2210 - accuracy: 0.4337\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2210 - accuracy: 0.4337\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2208 - accuracy: 0.4337\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2210 - accuracy: 0.4337\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2205 - accuracy: 0.4337\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2206 - accuracy: 0.4337\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2203 - accuracy: 0.4337\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2203 - accuracy: 0.4337\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2202 - accuracy: 0.4337\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2203 - accuracy: 0.4337\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2202 - accuracy: 0.4337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22692130b88>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4725274725274725\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   3   0]\n",
      " [  0   2  15  69   0]\n",
      " [  0   4  26 142   0]\n",
      " [  0   0  16  83   0]\n",
      " [  0   0   2   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        86\n",
      "         3.0       0.47      1.00      0.64       172\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.47       364\n",
      "   macro avg       0.09      0.20      0.13       364\n",
      "weighted avg       0.22      0.47      0.30       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 35, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_615 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_616 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_617 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_618 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_619 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,657\n",
      "Trainable params: 21,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 14.5716 - accuracy: 0.0529\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.1703 - accuracy: 0.0282\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.4911 - accuracy: 0.2096\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1080 - accuracy: 0.2488\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.1080 - accuracy: 0.2488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226925de048>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.27197802197802196\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   3   0]\n",
      " [  0   0   0  86   0]\n",
      " [  0   0   0 172   0]\n",
      " [  0   0   0  99   0]\n",
      " [  0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        86\n",
      "         3.0       0.00      0.00      0.00       172\n",
      "         4.0       0.27      1.00      0.43        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.27       364\n",
      "   macro avg       0.05      0.20      0.09       364\n",
      "weighted avg       0.07      0.27      0.12       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_620 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_621 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_622 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_623 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_624 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,831\n",
      "Trainable params: 9,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 6s 4ms/step - loss: 4.6305 - accuracy: 0.2515\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5156 - accuracy: 0.2735\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5273 - accuracy: 0.2742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22693992888>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.16758241758241757\n",
      "Tasa de aciertos balanceada regresión logística: 0.21\n",
      "Matriz de confusión:\n",
      "[[  1   2   0   0   0]\n",
      " [ 26  60   0   0   0]\n",
      " [ 42 130   0   0   0]\n",
      " [ 30  69   0   0   0]\n",
      " [  1   3   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      0.33      0.02         3\n",
      "         2.0       0.23      0.70      0.34        86\n",
      "         3.0       0.00      0.00      0.00       172\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.17       364\n",
      "   macro avg       0.05      0.21      0.07       364\n",
      "weighted avg       0.05      0.17      0.08       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_625 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_626 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_627 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_628 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_629 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,127\n",
      "Trainable params: 3,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 1.9054 - accuracy: 0.2667\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9152 - accuracy: 0.2722\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9121 - accuracy: 0.2763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2268f491588>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.23626373626373626\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   3   0]\n",
      " [  0   0   0  86   0]\n",
      " [  0   0   0 172   0]\n",
      " [  0   0   0  99   0]\n",
      " [  0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.24      1.00      0.38        86\n",
      "         3.0       0.00      0.00      0.00       172\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.24       364\n",
      "   macro avg       0.05      0.20      0.08       364\n",
      "weighted avg       0.06      0.24      0.09       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(neurons, output_size, activation_fun,loss_fun,optimizer_fun):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim = 35, activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/2), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/3), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/4), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/5), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/6), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/7), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/8), activation=activation_fun))\n",
    "    model.add(Dense(round(neurons/9), activation=activation_fun))\n",
    "    model.add(Dense(7, activation=activation_fun))\n",
    "    model.compile(loss=loss_fun, optimizer=optimizer_fun, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_630 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_631 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_632 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_633 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_634 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_635 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_636 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_637 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_638 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_639 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,719\n",
      "Trainable params: 12,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 5s 5ms/step - loss: 13.9548 - accuracy: 0.0234\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.9370 - accuracy: 0.0234\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9370 - accuracy: 0.0234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22688121a08>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.008241758241758242\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  3   0   0   0   0]\n",
      " [ 86   0   0   0   0]\n",
      " [172   0   0   0   0]\n",
      " [ 99   0   0   0   0]\n",
      " [  4   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      1.00      0.02         3\n",
      "         2.0       0.00      0.00      0.00        86\n",
      "         3.0       0.00      0.00      0.00       172\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.01       364\n",
      "   macro avg       0.00      0.20      0.00       364\n",
      "weighted avg       0.00      0.01      0.00       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_640 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_641 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_642 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_643 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_644 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_645 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_646 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_647 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_648 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_649 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,111\n",
      "Trainable params: 6,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 5s 5ms/step - loss: 12.2513 - accuracy: 0.0158\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5099 - accuracy: 0.0158\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.5102 - accuracy: 0.0158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22694c422c8>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.01098901098901099\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   3]\n",
      " [  0   0   0   0  86]\n",
      " [  0   0   0   0 172]\n",
      " [  0   0   0   0  99]\n",
      " [  0   0   0   0   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        86\n",
      "         3.0       0.00      0.00      0.00       172\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.01      1.00      0.02         4\n",
      "\n",
      "    accuracy                           0.01       364\n",
      "   macro avg       0.00      0.20      0.00       364\n",
      "weighted avg       0.00      0.01      0.00       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_650 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_651 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_652 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_653 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_654 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_655 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_656 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_657 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_658 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_659 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,161\n",
      "Trainable params: 2,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 5s 5ms/step - loss: 3.5742 - accuracy: 0.0990\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5538 - accuracy: 0.0371\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.0195 - accuracy: 0.0055\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9864 - accuracy: 0.0021\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9876 - accuracy: 0.0014\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9557 - accuracy: 0.0014\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9459 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22697369488>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adam')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  3   0   0   0   0]\n",
      " [ 86   0   0   0   0]\n",
      " [172   0   0   0   0]\n",
      " [ 99   0   0   0   0]\n",
      " [  4   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       3.0\n",
      "         2.0       0.00      0.00      0.00      86.0\n",
      "         3.0       0.00      0.00      0.00     172.0\n",
      "         4.0       0.00      0.00      0.00      99.0\n",
      "         5.0       0.00      0.00      0.00       4.0\n",
      "\n",
      "    accuracy                           0.00     364.0\n",
      "   macro avg       0.00      0.00      0.00     364.0\n",
      "weighted avg       0.00      0.00      0.00     364.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense RELU+ADAGRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 1: Modelo con 5 capas, dividiendo las neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_660 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_661 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_662 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_663 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_664 (Dense)           (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,365\n",
      "Trainable params: 11,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 3ms/step - loss: 156.8297 - accuracy: 0.3656\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 69.7577 - accuracy: 0.3464\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 55.9716 - accuracy: 0.3443\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 52.2409 - accuracy: 0.3615\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 47.9835 - accuracy: 0.3732\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.5963 - accuracy: 0.3904\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 40.3603 - accuracy: 0.3849\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.6058 - accuracy: 0.3794\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 36.8429 - accuracy: 0.3780\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 35.8030 - accuracy: 0.3698\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 33.5762 - accuracy: 0.3869\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.2134 - accuracy: 0.3938\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 31.6585 - accuracy: 0.3979\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.9559 - accuracy: 0.3938\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 29.2945 - accuracy: 0.3842\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 28.2438 - accuracy: 0.4000\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 27.7404 - accuracy: 0.4069\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 27.0818 - accuracy: 0.3828\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 26.1696 - accuracy: 0.3979\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.4684 - accuracy: 0.4027\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 25.1733 - accuracy: 0.4027\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.0829 - accuracy: 0.4048\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.9443 - accuracy: 0.3883\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.1978 - accuracy: 0.4131\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.6590 - accuracy: 0.4021\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.2077 - accuracy: 0.3979\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 21.2628 - accuracy: 0.4186\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.3121 - accuracy: 0.3931\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.6502 - accuracy: 0.3993\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.0505 - accuracy: 0.4041\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.2066 - accuracy: 0.3986\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.8720 - accuracy: 0.3979\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.3484 - accuracy: 0.3911\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 18.5882 - accuracy: 0.4034\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.6383 - accuracy: 0.4021\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 18.2298 - accuracy: 0.4000\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 17.5277 - accuracy: 0.4062\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 17.3938 - accuracy: 0.4076\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.9990 - accuracy: 0.3938\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 17.0351 - accuracy: 0.4062\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 17.0389 - accuracy: 0.4034\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.4033 - accuracy: 0.4027\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.3017 - accuracy: 0.3897\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.1063 - accuracy: 0.3938\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.7167 - accuracy: 0.4021\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.4286 - accuracy: 0.3938\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 14.9241 - accuracy: 0.4055\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6365 - accuracy: 0.4021\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.6864 - accuracy: 0.4062\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2858 - accuracy: 0.3938\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.2225 - accuracy: 0.3931\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.0887 - accuracy: 0.3979\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.8917 - accuracy: 0.4021\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7625 - accuracy: 0.3814\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5727 - accuracy: 0.3938\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1223 - accuracy: 0.4000\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2385 - accuracy: 0.3986\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.0061 - accuracy: 0.3945\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9972 - accuracy: 0.3856\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5407 - accuracy: 0.3904\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.6848 - accuracy: 0.4069\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9139 - accuracy: 0.3993\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.4215 - accuracy: 0.3959\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5147 - accuracy: 0.3814\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.3293 - accuracy: 0.4007\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0968 - accuracy: 0.3924\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9382 - accuracy: 0.3856\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0331 - accuracy: 0.3849\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9676 - accuracy: 0.3869\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0751 - accuracy: 0.3890\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.8239 - accuracy: 0.4000\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.5916 - accuracy: 0.3842\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4975 - accuracy: 0.3973\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4239 - accuracy: 0.3869\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.5488 - accuracy: 0.3959\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.4317 - accuracy: 0.4076\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.5889 - accuracy: 0.3794\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.4268 - accuracy: 0.3911\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.1615 - accuracy: 0.3876\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4102 - accuracy: 0.4041\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8551 - accuracy: 0.3986\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9875 - accuracy: 0.3952\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.1042 - accuracy: 0.3945\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.8392 - accuracy: 0.4007\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9722 - accuracy: 0.3931\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.9952 - accuracy: 0.4027\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.7694 - accuracy: 0.3924\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.7441 - accuracy: 0.3931\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.6463 - accuracy: 0.4069\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7702 - accuracy: 0.3918\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.5427 - accuracy: 0.4034\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.5932 - accuracy: 0.4007\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5979 - accuracy: 0.3801\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.5000 - accuracy: 0.4027\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4011 - accuracy: 0.3966\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3551 - accuracy: 0.4027\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.2896 - accuracy: 0.4041\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4827 - accuracy: 0.3979\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.5112 - accuracy: 0.3918\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.0729 - accuracy: 0.4021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226987d1188>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model1(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.31043956043956045\n",
      "Tasa de aciertos balanceada regresión logística: 0.21\n",
      "Matriz de confusión:\n",
      "[[ 0  1  0  2  0]\n",
      " [ 1 62 14  8  1]\n",
      " [ 5 96 41 26  4]\n",
      " [ 4 68 17 10  0]\n",
      " [ 0  3  1  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.27      0.72      0.39        86\n",
      "         3.0       0.56      0.24      0.33       172\n",
      "         4.0       0.22      0.10      0.14        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.31       364\n",
      "   macro avg       0.21      0.21      0.17       364\n",
      "weighted avg       0.39      0.31      0.29       364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_665 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_666 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_667 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_668 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_669 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,548\n",
      "Trainable params: 5,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 3s 4ms/step - loss: 1563.2166 - accuracy: 0.2914\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 486.5482 - accuracy: 0.3340\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 367.3941 - accuracy: 0.3113\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 313.4383 - accuracy: 0.3141\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 279.8051 - accuracy: 0.3155\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 252.3424 - accuracy: 0.3086\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 232.9038 - accuracy: 0.3189\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 220.5393 - accuracy: 0.3162\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 208.5566 - accuracy: 0.3113\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 200.3648 - accuracy: 0.3237\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 192.4139 - accuracy: 0.3299\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 183.9209 - accuracy: 0.3320\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 177.8359 - accuracy: 0.3271\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 172.3149 - accuracy: 0.3326\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 166.4608 - accuracy: 0.3443\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 162.9660 - accuracy: 0.3230\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 159.1619 - accuracy: 0.3375\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 153.8508 - accuracy: 0.3560\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 150.6892 - accuracy: 0.3368\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 146.4114 - accuracy: 0.3464\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 143.4508 - accuracy: 0.3485\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 140.9490 - accuracy: 0.3533\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 138.7226 - accuracy: 0.3402\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 135.2444 - accuracy: 0.3409\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 133.9777 - accuracy: 0.3395\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 131.5525 - accuracy: 0.3340\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 127.8309 - accuracy: 0.3299\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 127.0010 - accuracy: 0.3430\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 124.4844 - accuracy: 0.3485\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 123.0751 - accuracy: 0.3443\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 119.9125 - accuracy: 0.3361\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 118.2743 - accuracy: 0.3320\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 115.8902 - accuracy: 0.3457\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 115.3879 - accuracy: 0.3464\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 114.0939 - accuracy: 0.3340\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 110.9836 - accuracy: 0.3423\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 110.7677 - accuracy: 0.3485\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 109.8742 - accuracy: 0.3402\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 107.5122 - accuracy: 0.3313\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 105.6458 - accuracy: 0.3519\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 104.9737 - accuracy: 0.3560\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 103.8848 - accuracy: 0.3409\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 103.0336 - accuracy: 0.3471\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 101.7967 - accuracy: 0.3601\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 98.9801 - accuracy: 0.3533\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 98.6321 - accuracy: 0.3574\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 97.6632 - accuracy: 0.3546\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 95.9506 - accuracy: 0.3553\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 95.5134 - accuracy: 0.3526\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 94.5455 - accuracy: 0.3519\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 92.7610 - accuracy: 0.3485\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 92.5604 - accuracy: 0.3553\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 90.3084 - accuracy: 0.3505\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 91.0946 - accuracy: 0.3457\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 88.5362 - accuracy: 0.3636\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 87.1210 - accuracy: 0.3595\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.9593 - accuracy: 0.3560\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 85.7703 - accuracy: 0.3670\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 85.4482 - accuracy: 0.3588\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.2150 - accuracy: 0.3574\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.6375 - accuracy: 0.3601\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.4778 - accuracy: 0.3615\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.8310 - accuracy: 0.3643\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.0011 - accuracy: 0.3546\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.3926 - accuracy: 0.3560\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 78.6159 - accuracy: 0.3574\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.0622 - accuracy: 0.3608\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.6000 - accuracy: 0.3608\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 76.1664 - accuracy: 0.3704\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 76.0607 - accuracy: 0.3649\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 74.9429 - accuracy: 0.3615\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.5189 - accuracy: 0.3546\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.0289 - accuracy: 0.3629\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.5141 - accuracy: 0.3491\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.4939 - accuracy: 0.3485\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.3111 - accuracy: 0.3581\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.1511 - accuracy: 0.3629\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.7136 - accuracy: 0.3656\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.3793 - accuracy: 0.3512\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.0232 - accuracy: 0.3636\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.2735 - accuracy: 0.3464\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 69.1431 - accuracy: 0.3595\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 69.8330 - accuracy: 0.3553\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.5455 - accuracy: 0.3629\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.3367 - accuracy: 0.3636\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.5252 - accuracy: 0.3567\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.8214 - accuracy: 0.3601\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.8294 - accuracy: 0.3643\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.5632 - accuracy: 0.3677\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.9195 - accuracy: 0.3491\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.3580 - accuracy: 0.3485\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.7300 - accuracy: 0.3526\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.4542 - accuracy: 0.3629\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.5175 - accuracy: 0.3615\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.5231 - accuracy: 0.3691\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.1701 - accuracy: 0.3691\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.6942 - accuracy: 0.3512\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.9530 - accuracy: 0.3601\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.6329 - accuracy: 0.3725\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.1314 - accuracy: 0.3498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22698b610c8>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model1(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.3241758241758242\n",
      "Tasa de aciertos balanceada regresión logística: 0.18\n",
      "Matriz de confusión:\n",
      "[[ 0  0  2  1  0]\n",
      " [14 22 31 19  0]\n",
      " [17 50 76 27  2]\n",
      " [11 30 38 20  0]\n",
      " [ 0  1  2  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.21      0.26      0.23        86\n",
      "         3.0       0.51      0.44      0.47       172\n",
      "         4.0       0.29      0.20      0.24        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.32       364\n",
      "   macro avg       0.20      0.18      0.19       364\n",
      "weighted avg       0.37      0.32      0.34       364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_670 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_671 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_672 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_673 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_674 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,026\n",
      "Trainable params: 2,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 8855.1562 - accuracy: 0.2790\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3954.8096 - accuracy: 0.2687\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2742.8484 - accuracy: 0.1485\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2334.6899 - accuracy: 0.1395\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2045.4622 - accuracy: 0.1340\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1816.1951 - accuracy: 0.1271\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1632.5262 - accuracy: 0.1072\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1486.1127 - accuracy: 0.1079\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1370.9390 - accuracy: 0.1065\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1269.1854 - accuracy: 0.1031\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1179.9940 - accuracy: 0.1010\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1098.7979 - accuracy: 0.1058\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1029.4006 - accuracy: 0.0921\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 966.9439 - accuracy: 0.0962\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 910.1775 - accuracy: 0.0976\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 858.4052 - accuracy: 0.0948\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 811.4464 - accuracy: 0.0942\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 768.2709 - accuracy: 0.0948\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 729.3821 - accuracy: 0.0955\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 694.4185 - accuracy: 0.0907\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 664.5887 - accuracy: 0.0880\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 637.2584 - accuracy: 0.0832\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 612.8716 - accuracy: 0.0866\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 590.7421 - accuracy: 0.0797\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 570.2678 - accuracy: 0.0790\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 550.5337 - accuracy: 0.0804\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 532.3047 - accuracy: 0.0784\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 515.9766 - accuracy: 0.0797\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 500.6396 - accuracy: 0.0797\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 485.6663 - accuracy: 0.0784\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 471.8607 - accuracy: 0.0770\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 458.7240 - accuracy: 0.0770\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 446.3379 - accuracy: 0.0770\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 434.2664 - accuracy: 0.0770\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 422.5315 - accuracy: 0.0784\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 411.7038 - accuracy: 0.0790\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 400.8219 - accuracy: 0.0777\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 390.3672 - accuracy: 0.0784\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 380.1923 - accuracy: 0.0784\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 370.7978 - accuracy: 0.0880\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 361.9811 - accuracy: 0.0832\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 353.0542 - accuracy: 0.0859\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 344.7302 - accuracy: 0.0866\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 336.4357 - accuracy: 0.0893\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 328.6711 - accuracy: 0.0866\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 320.7688 - accuracy: 0.0948\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 313.6707 - accuracy: 0.0921\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 306.2642 - accuracy: 0.0969\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 299.0959 - accuracy: 0.0935\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 291.4736 - accuracy: 0.0962\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 283.9055 - accuracy: 0.1003\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 275.8250 - accuracy: 0.1003\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 267.5287 - accuracy: 0.1045\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 258.3707 - accuracy: 0.1072\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 249.0416 - accuracy: 0.1093\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 239.3625 - accuracy: 0.1127\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 229.4477 - accuracy: 0.1134\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 219.4555 - accuracy: 0.1196\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 209.5279 - accuracy: 0.1127\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 198.5588 - accuracy: 0.1196\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 187.6753 - accuracy: 0.1155\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 177.4352 - accuracy: 0.1134\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 167.4216 - accuracy: 0.1003\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 158.9213 - accuracy: 0.1127\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 151.4796 - accuracy: 0.1155\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 145.0655 - accuracy: 0.1120\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 139.3965 - accuracy: 0.1168\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 133.9970 - accuracy: 0.1182\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 129.3291 - accuracy: 0.1148\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 124.6799 - accuracy: 0.1216\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 120.4946 - accuracy: 0.1175\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 116.3806 - accuracy: 0.1203\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 112.5276 - accuracy: 0.1244\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 108.8500 - accuracy: 0.1210\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 105.0685 - accuracy: 0.1237\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 101.2577 - accuracy: 0.1244\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 97.5517 - accuracy: 0.1285\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 94.0208 - accuracy: 0.1306\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.4984 - accuracy: 0.1313\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.1178 - accuracy: 0.1299\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 83.7789 - accuracy: 0.1313\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.5121 - accuracy: 0.1375\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.2149 - accuracy: 0.1381\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.9865 - accuracy: 0.1375\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.7114 - accuracy: 0.1381\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 67.5800 - accuracy: 0.1340\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.3339 - accuracy: 0.1436\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.3677 - accuracy: 0.1464\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.3486 - accuracy: 0.1478\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.2704 - accuracy: 0.1505\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.3577 - accuracy: 0.1581\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.4081 - accuracy: 0.1643\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.6379 - accuracy: 0.1656\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.9997 - accuracy: 0.1759\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.6485 - accuracy: 0.1849\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.4597 - accuracy: 0.1986\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.4307 - accuracy: 0.2069\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.5278 - accuracy: 0.2172\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.7373 - accuracy: 0.2247\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.1648 - accuracy: 0.2488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22699f3e388>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model1(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.18681318681318682\n",
      "Tasa de aciertos balanceada regresión logística: 0.12\n",
      "Matriz de confusión:\n",
      "[[ 0  1  0  2  0]\n",
      " [ 1 62 14  8  1]\n",
      " [ 5 96 41 26  4]\n",
      " [ 4 68 17 10  0]\n",
      " [ 0  3  1  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.20      0.37      0.26        86\n",
      "         3.0       0.45      0.21      0.29       172\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.19       364\n",
      "   macro avg       0.11      0.10      0.09       364\n",
      "weighted avg       0.26      0.19      0.20       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTO 2:  Modelo con 5 capas, mismas neuronas cada 2 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_675 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_676 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_677 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_678 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_679 (Dense)           (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,657\n",
      "Trainable params: 21,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 2ms/step - loss: 9.5214 - accuracy: 6.8729e-04\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5073 - accuracy: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2269a2a0188>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model2(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   3]\n",
      " [  4   0   0   0   0  82]\n",
      " [ 14   0   0   0   0 158]\n",
      " [  9   0   0   0   0  90]\n",
      " [  0   0   0   0   0   4]\n",
      " [  0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       3.0\n",
      "         2.0       0.00      0.00      0.00      86.0\n",
      "         3.0       0.00      0.00      0.00     172.0\n",
      "         4.0       0.00      0.00      0.00      99.0\n",
      "         5.0       0.00      0.00      0.00       4.0\n",
      "         6.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00     364.0\n",
      "   macro avg       0.00      0.00      0.00     364.0\n",
      "weighted avg       0.00      0.00      0.00     364.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_680 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_681 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_682 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_683 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_684 (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,831\n",
      "Trainable params: 9,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 5s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5958 - accuracy: 0.0151\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5958 - accuracy: 0.0151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2269b6672c8>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model2(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.005494505494505495\n",
      "Tasa de aciertos balanceada regresión logística: 0.12\n",
      "Matriz de confusión:\n",
      "[[ 1  0  0  0  2  0]\n",
      " [22  0  0  0 39 25]\n",
      " [62  0  0  0 57 53]\n",
      " [24  0  0  0 38 37]\n",
      " [ 1  0  0  0  1  2]\n",
      " [ 0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.01      0.33      0.02         3\n",
      "         2.0       0.00      0.00      0.00        86\n",
      "         3.0       0.00      0.00      0.00       172\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.01      0.25      0.01         4\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.01       364\n",
      "   macro avg       0.00      0.10      0.01       364\n",
      "weighted avg       0.00      0.01      0.00       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_685 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_686 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_687 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_688 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_689 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,127\n",
      "Trainable params: 3,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 5s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.6511 - accuracy: 6.8729e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2269ba4b588>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model2(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.0\n",
      "Tasa de aciertos balanceada regresión logística: 0.00\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   0   0   3]\n",
      " [  4   0   0   0   0  82]\n",
      " [ 14   0   0   0   0 158]\n",
      " [  9   0   0   0   0  90]\n",
      " [  0   0   0   0   0   4]\n",
      " [  0   0   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       3.0\n",
      "         2.0       0.00      0.00      0.00      86.0\n",
      "         3.0       0.00      0.00      0.00     172.0\n",
      "         4.0       0.00      0.00      0.00      99.0\n",
      "         5.0       0.00      0.00      0.00       4.0\n",
      "\n",
      "    accuracy                           0.00     364.0\n",
      "   macro avg       0.00      0.00      0.00     364.0\n",
      "weighted avg       0.00      0.00      0.00     364.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3: Modelo 10 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 100 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_690 (Dense)           (None, 100)               3600      \n",
      "                                                                 \n",
      " dense_691 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_692 (Dense)           (None, 33)                1683      \n",
      "                                                                 \n",
      " dense_693 (Dense)           (None, 25)                850       \n",
      "                                                                 \n",
      " dense_694 (Dense)           (None, 20)                520       \n",
      "                                                                 \n",
      " dense_695 (Dense)           (None, 17)                357       \n",
      "                                                                 \n",
      " dense_696 (Dense)           (None, 14)                252       \n",
      "                                                                 \n",
      " dense_697 (Dense)           (None, 12)                180       \n",
      "                                                                 \n",
      " dense_698 (Dense)           (None, 11)                143       \n",
      "                                                                 \n",
      " dense_699 (Dense)           (None, 7)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,719\n",
      "Trainable params: 12,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 6s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.8628 - accuracy: 0.2488\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.8628 - accuracy: 0.2488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2269ce169c8>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense100 = build_model3(100,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense100.summary()\n",
    "modeldense100.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.27197802197802196\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   3   0]\n",
      " [  0   0   0  86   0]\n",
      " [  0   0   0 172   0]\n",
      " [  0   0   0  99   0]\n",
      " [  0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        86\n",
      "         3.0       0.00      0.00      0.00       172\n",
      "         4.0       0.27      1.00      0.43        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.27       364\n",
      "   macro avg       0.05      0.20      0.09       364\n",
      "weighted avg       0.07      0.27      0.12       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense100 = modeldense100.predict(testX3)\n",
    "y_preddense100 =  y_preddense100.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense100, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense100)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 64 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_700 (Dense)           (None, 64)                2304      \n",
      "                                                                 \n",
      " dense_701 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_702 (Dense)           (None, 21)                693       \n",
      "                                                                 \n",
      " dense_703 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_704 (Dense)           (None, 13)                221       \n",
      "                                                                 \n",
      " dense_705 (Dense)           (None, 11)                154       \n",
      "                                                                 \n",
      " dense_706 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_707 (Dense)           (None, 8)                 80        \n",
      "                                                                 \n",
      " dense_708 (Dense)           (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_709 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,111\n",
      "Trainable params: 6,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 7s 5ms/step - loss: 7.4107 - accuracy: 0.4158\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5179 - accuracy: 0.4330\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3452 - accuracy: 0.4330\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.3550 - accuracy: 0.4330\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3447 - accuracy: 0.4330\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3453 - accuracy: 0.4330\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3449 - accuracy: 0.4330\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3450 - accuracy: 0.4330\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3449 - accuracy: 0.4330\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3445 - accuracy: 0.4330\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3441 - accuracy: 0.4330\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3434 - accuracy: 0.4330\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.3432 - accuracy: 0.4330\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3342 - accuracy: 0.4330\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.3342 - accuracy: 0.4330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2269d31c788>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense64 = build_model3(64,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense64.summary()\n",
    "modeldense64.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.4725274725274725\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   3   0   0]\n",
      " [  0   0  86   0   0]\n",
      " [  0   0 172   0   0]\n",
      " [  0   0  99   0   0]\n",
      " [  0   0   4   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        86\n",
      "         3.0       0.47      1.00      0.64       172\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.47       364\n",
      "   macro avg       0.09      0.20      0.13       364\n",
      "weighted avg       0.22      0.47      0.30       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense64 = modeldense64.predict(testX3)\n",
    "y_preddense64 =  y_preddense64.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense64)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense64, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense64)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo 32 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_710 (Dense)           (None, 32)                1152      \n",
      "                                                                 \n",
      " dense_711 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_712 (Dense)           (None, 11)                187       \n",
      "                                                                 \n",
      " dense_713 (Dense)           (None, 8)                 96        \n",
      "                                                                 \n",
      " dense_714 (Dense)           (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_715 (Dense)           (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_716 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_717 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_718 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_719 (Dense)           (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,161\n",
      "Trainable params: 2,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 8s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.5564 - accuracy: 0.0158\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5564 - accuracy: 0.0158\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5564 - accuracy: 0.0158\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5564 - accuracy: 0.0158\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5564 - accuracy: 0.0158\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5564 - accuracy: 0.0158\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5564 - accuracy: 0.0158\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5564 - accuracy: 0.0158\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.5564 - accuracy: 0.0158\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5564 - accuracy: 0.0158\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5564 - accuracy: 0.0158\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5564 - accuracy: 0.0158\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5564 - accuracy: 0.0158\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.5565 - accuracy: 0.0158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2269e7cb4c8>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldense32 = build_model3(32,1,'relu','sparse_categorical_crossentropy','adagrad')\n",
    "modeldense32.summary()\n",
    "modeldense32.fit(trainX3, trainy3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: {:.2f} 0.01098901098901099\n",
      "Tasa de aciertos balanceada regresión logística: 0.20\n",
      "Matriz de confusión:\n",
      "[[  0   0   0   3   0]\n",
      " [  0   0   0  86   0]\n",
      " [  0   0   0 172   0]\n",
      " [  0   0   0  99   0]\n",
      " [  0   0   0   4   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         3\n",
      "         2.0       0.00      0.00      0.00        86\n",
      "         3.0       0.00      0.00      0.00       172\n",
      "         4.0       0.00      0.00      0.00        99\n",
      "         5.0       0.01      1.00      0.02         4\n",
      "\n",
      "    accuracy                           0.01       364\n",
      "   macro avg       0.00      0.20      0.00       364\n",
      "weighted avg       0.00      0.01      0.00       364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_preddense32 = modeldense32.predict(testX3)\n",
    "y_preddense32 =  y_preddense32.argmax(axis=-1)\n",
    "confusion3 = confusion_matrix(testy3, y_preddense100)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\", acierto(y_preddense32, testy3))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_preddense32)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))\n",
    "print(classification_report(testy3, y_preddense32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERVALO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.250660</td>\n",
       "      <td>0.469657</td>\n",
       "      <td>0.395778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245383</td>\n",
       "      <td>0.010554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.266491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.372032</td>\n",
       "      <td>0.403694</td>\n",
       "      <td>0.406332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.271768</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>0.469657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.266491</td>\n",
       "      <td>0.245383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.250660     0.469657     0.395778\n",
       "Experimento 2- RELU+ADAM         0.000000     0.245383     0.010554\n",
       "Experimento 3- RELU+ADAM         0.266491     0.000000     0.000000\n",
       "Experimento 1- RELU+ADAGRAD      0.372032     0.403694     0.406332\n",
       "Experimento 2- RELU+ADAGRAD      0.271768     0.155673     0.469657\n",
       "Experimento 3- RELU+ADAGRAD      0.005277     0.266491     0.245383"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['100 Neuronas'] = None\n",
    "df1['64 Neuronas'] = None\n",
    "df1['32 Neuronas'] = None\n",
    "df1.loc['Experimento 1- RELU+ADAM'] = [0.25065963060686014,0.46965699208443273,0.39577836411609496]\n",
    "df1.loc['Experimento 2- RELU+ADAM'] = [0.0,0.24538258575197888,0.010554089709762533]\n",
    "df1.loc['Experimento 3- RELU+ADAM'] = [0.26649076517150394,0.0,0.0]\n",
    "df1.loc['Experimento 1- RELU+ADAGRAD'] =[0.3720316622691293,0.40369393139841686,0.40633245382585753]\n",
    "df1.loc['Experimento 2- RELU+ADAGRAD'] =[0.2717678100263852,0.15567282321899736,0.46965699208443273]\n",
    "df1.loc['Experimento 3- RELU+ADAGRAD'] = [0.005277044854881266,0.26649076517150394,0.24538258575197888]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.451087</td>\n",
       "      <td>0.472826</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192935</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.472826</td>\n",
       "      <td>0.008152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.353261</td>\n",
       "      <td>0.355978</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.089674</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.451087     0.472826     0.472826\n",
       "Experimento 2- RELU+ADAM         0.000000     0.192935     0.000000\n",
       "Experimento 3- RELU+ADAM         0.008152     0.472826     0.008152\n",
       "Experimento 1- RELU+ADAGRAD      0.353261     0.355978     0.472826\n",
       "Experimento 2- RELU+ADAGRAD      0.089674     0.010870     0.010870\n",
       "Experimento 3- RELU+ADAGRAD      0.005435     0.391304     0.472826"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['100 Neuronas'] = None\n",
    "df2['64 Neuronas'] = None\n",
    "df2['32 Neuronas'] = None\n",
    "df2.loc['Experimento 1- RELU+ADAM'] = [0.45108695652173914,0.47282608695652173,0.47282608695652173]\n",
    "df2.loc['Experimento 2- RELU+ADAM'] =[0.0,0.19293478260869565,0.0]\n",
    "df2.loc['Experimento 3- RELU+ADAM'] = [0.008152173913043478,0.47282608695652173,0.008152173913043478]\n",
    "df2.loc['Experimento 1- RELU+ADAGRAD'] = [0.3532608695652174,0.35597826086956524,0.47282608695652173]\n",
    "df2.loc['Experimento 2- RELU+ADAGRAD'] = [0.08967391304347826,0.010869565217391304,0.010869565217391304]\n",
    "df2.loc['Experimento 3- RELU+ADAGRAD'] = [0.005434782608695652,0.391304347826087,0.47282608695652173]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100 Neuronas</th>\n",
       "      <th>64 Neuronas</th>\n",
       "      <th>32 Neuronas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAM</th>\n",
       "      <td>0.304945</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.472527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAM</th>\n",
       "      <td>0.271978</td>\n",
       "      <td>0.167582</td>\n",
       "      <td>0.236264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAM</th>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 1- RELU+ADAGRAD</th>\n",
       "      <td>0.310440</td>\n",
       "      <td>0.324176</td>\n",
       "      <td>0.186813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 2- RELU+ADAGRAD</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experimento 3- RELU+ADAGRAD</th>\n",
       "      <td>0.271978</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.010989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             100 Neuronas  64 Neuronas  32 Neuronas\n",
       "Experimento 1- RELU+ADAM         0.304945     0.472527     0.472527\n",
       "Experimento 2- RELU+ADAM         0.271978     0.167582     0.236264\n",
       "Experimento 3- RELU+ADAM         0.008242     0.010989     0.000000\n",
       "Experimento 1- RELU+ADAGRAD      0.310440     0.324176     0.186813\n",
       "Experimento 2- RELU+ADAGRAD      0.000000     0.005495     0.000000\n",
       "Experimento 3- RELU+ADAGRAD      0.271978     0.472527     0.010989"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame()\n",
    "df3['100 Neuronas'] = None\n",
    "df3['64 Neuronas'] = None\n",
    "df3['32 Neuronas'] = None\n",
    "df3.loc['Experimento 1- RELU+ADAM'] = [0.30494505494505497,0.4725274725274725,0.4725274725274725]\n",
    "df3.loc['Experimento 2- RELU+ADAM'] = [0.27197802197802196,0.16758241758241757,0.23626373626373626]\n",
    "df3.loc['Experimento 3- RELU+ADAM'] = [0.008241758241758242,0.01098901098901099,0.0]\n",
    "df3.loc['Experimento 1- RELU+ADAGRAD'] = [0.31043956043956045,0.3241758241758242,0.18681318681318682]\n",
    "df3.loc['Experimento 2- RELU+ADAGRAD'] = [0.0,0.005494505494505495,0.0]\n",
    "df3.loc['Experimento 3- RELU+ADAGRAD'] = [0.27197802197802196,0.4725274725274725,0.01098901098901099]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20c03188c88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,20))\n",
    "fig.add_subplot(2,2,1)\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df1.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df1.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df1.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 1')\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM' ,color ='red')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df2.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df2.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df2.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 2')\n",
    "fig.add_subplot(2,2,3)\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAM'],'o-',label ='Experimento 1- RELU+ADAM',color ='red')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAM'],'o-',label ='Experimento 2- RELU+ADAM',color ='olive')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAM'],'o-',label ='Experimento 3- RELU+ADAM',color ='cyan')\n",
    "plt.plot(df3.loc['Experimento 1- RELU+ADAGRAD'],'o-',label ='Experimento 1- RELU+ADAGRAD',color ='purple')\n",
    "plt.plot(df3.loc['Experimento 2- RELU+ADAGRAD'],'o-',label ='Experimento 2- RELU+ADAGRAD',color ='orange')\n",
    "plt.plot(df3.loc['Experimento 3- RELU+ADAGRAD'],'o-',label ='Experimento 3- RELU+ADAGRAD',color ='yellow')\n",
    "plt.title('Conjunto de datos 3')\n",
    "plt.legend(bbox_to_anchor = (1.05, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
