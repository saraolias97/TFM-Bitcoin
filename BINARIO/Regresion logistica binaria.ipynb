{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,balanced_accuracy_score,f1_score,classification_report,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acierto(list1,list2):\n",
    "    sum = 0\n",
    "    for i in range(0,len(list1)):\n",
    "        if(list1[i]==list2[i]):\n",
    "            sum = sum +1\n",
    "    a = sum/len(list1[i])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasa de aciertos balanceada (balanced accuracy)\n",
    "\n",
    "Recordemos que existe otra medida combinada, la precisión balanceada. En este caso combina la sensibilidad o recall y la exhaustividad. Una forma más intuitiva de ver esta métrica es como la media de las tasas de aciertos calculadas sobre las clases positiva y negativa respectivamente.\n",
    "\n",
    "\n",
    "$$B_{acc} =\\frac{Sensibility + Especificity}{2} = \\frac{\\frac{TP}{TP+FN} + \\frac{TN}{FP+TN}}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medida F1\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{F1} = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Es mejor la medida F1 o la tasa de aciertos balanceada?\n",
    "Aqui para escribir: https://datascience.stackexchange.com/questions/73974/balanced-accuracy-vs-f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIARIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run Datos-1diaBINARIO.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 1: MODELO BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.49\n",
      "Tasa de aciertos balanceada regresión logística: 0.50\n",
      "Medida F1 regresión logística: 0.54\n",
      "Matriz de confusión:\n",
      "[[ 74 125]\n",
      " [ 67 111]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 1\n",
    "# -------------------------------------------------------------------\n",
    "logreg1 = LogisticRegression(max_iter=10000).fit(trainX1, trainy1)\n",
    "pred_logreg1 = logreg1.predict(testX1)\n",
    "confusion1 = confusion_matrix(testy1, pred_logreg1)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg1.score(testX1, testy1)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, pred_logreg1)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy1, pred_logreg1)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.50\n",
      "Tasa de aciertos balanceada regresión logística: 0.50\n",
      "Medida F1 regresión logística: 0.52\n",
      "Matriz de confusión:\n",
      "[[ 83 112]\n",
      " [ 72  99]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 2\n",
    "# -------------------------------------------------------------------\n",
    "logreg2 = LogisticRegression(max_iter=10000).fit(trainX2, trainy2)\n",
    "pred_logreg2 = logreg2.predict(testX2)\n",
    "confusion2 = confusion_matrix(testy2, pred_logreg2)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg2.score(testX2, testy2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, pred_logreg2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, pred_logreg2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.49\n",
      "Tasa de aciertos balanceada regresión logística: 0.50\n",
      "Medida F1 regresión logística: 0.54\n",
      "Matriz de confusión:\n",
      "[[ 73 121]\n",
      " [ 62 106]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 3\n",
    "# -------------------------------------------------------------------\n",
    "logreg3 = LogisticRegression(max_iter=10000).fit(trainX3, trainy3)\n",
    "pred_logreg3 = logreg3.predict(testX3)\n",
    "confusion = confusion_matrix(testy3, pred_logreg3)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg3.score(testX3, testy3)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, pred_logreg3)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy3, pred_logreg3)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 1: GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 1\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid1 = LogisticRegression()\n",
    "parameters1 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"none\",\"l2\"]}\n",
    "grid1 = GridSearchCV(modelgrid1,parameters1, cv=None).fit(trainX1, trainy1)\n",
    "grid1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrgrid1 = LogisticRegression(C=0.001).fit(trainX1, trainy1)\n",
    "y_predg1 = lrgrid1.predict(testX1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.49\n",
      "Tasa de aciertos balanceada regresión logística: 0.50\n",
      "Medida F1 regresión logística: 0.54\n",
      "Matriz de confusión:\n",
      "[[ 74 125]\n",
      " [ 67 111]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid1 = lrgrid1.predict(testX1)\n",
    "confusiong1 = confusion_matrix(testy1, pred_lrgrid1)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid1.score(testX1, testy1)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, pred_logreg1)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy1, pred_logreg1)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, penalty='none')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 2\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid2 = LogisticRegression()\n",
    "parameters2 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"none\",\"l2\"]}\n",
    "grid2 = GridSearchCV(modelgrid2,parameters2, cv=None).fit(trainX2, trainy2)\n",
    "grid2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lrgrid2 = LogisticRegression(C=0.001, penalty='none').fit(trainX2, trainy2)\n",
    "y_predg2 = lrgrid2.predict(testX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.51\n",
      "Tasa de aciertos balanceada regresión logística: 0.50\n",
      "Medida F1 regresión logística: 0.52\n",
      "Matriz de confusión:\n",
      "[[ 83 112]\n",
      " [ 69 102]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid2 = lrgrid2.predict(testX2)\n",
    "confusiong2 = confusion_matrix(testy2, pred_lrgrid2)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid2.score(testX2, testy2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, pred_logreg2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, pred_logreg2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.52595156        nan 0.52318339        nan 0.52387543\n",
      "        nan 0.52041522        nan 0.52525952        nan 0.52387543\n",
      "        nan 0.52110727]\n",
      "  category=UserWarning\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 3\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid3 = LogisticRegression()\n",
    "parameters3 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\",None]}\n",
    "grid3 = GridSearchCV(modelgrid3,parameters3, cv=None).fit(trainX3, trainy3)\n",
    "grid3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lrgrid3 = LogisticRegression(C=0.001).fit(trainX3, trainy3)\n",
    "y_predg3 = lrgrid3.predict(testX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.49\n",
      "Tasa de aciertos balanceada regresión logística: 0.50\n",
      "Medida F1 regresión logística: 0.54\n",
      "Matriz de confusión:\n",
      "[[ 68 126]\n",
      " [ 58 110]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid3 = lrgrid3.predict(testX3)\n",
    "confusiong3 = confusion_matrix(testy3, pred_lrgrid3)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid3.score(testX3, testy3)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, pred_logreg3)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy3, pred_logreg3)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejora Modelo Base - Datos 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando la incertidumbre en las predicciones: umbrales y curvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comenzar podemos ver como la proporción de datos entre la clase de bajada y la de subida es mas o menos de un 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    880\n",
       "1.0    947\n",
       "Name: Subida, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy2.value_counts() + trainy2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El clasificador no solamente hacen predicciones de la clase, sino que suelen proporcionar un grado de certidumbre en la predicción que realizan.Para regresión logística el grado de certidumbre se da en forma de probabilidad (un valor entre 0 y 1). En ese caso, el método `predict` devolverá la clase positiva si la probabilidad está por encima de 0.5, y la clase negativa en caso contrario.\n",
    "\n",
    "En ambos casos existen unos valores por defecto del _umbral_ en la incertidumbre, a partir del cual decidimos clasificar un ejemplo como de la clase positiva; vamos a tomar umbrales diferentes (tanto al alza como a la baja) para considerar que un ejemplo está en la dicha clase. Podríamos así ser más o menos estrictos a la hora de la clasificación. Y esto influiría indudablemente en las métricas definidas anteriormente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Baja       0.54      0.43      0.47       195\n",
      "        Sube       0.47      0.58      0.52       171\n",
      "\n",
      "    accuracy                           0.50       366\n",
      "   macro avg       0.50      0.50      0.50       366\n",
      "weighted avg       0.50      0.50      0.49       366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testy2, pred_logreg2,target_names=[\"Baja\", \"Sube\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[ 83 112]\n",
      " [ 72  99]]\n"
     ]
    }
   ],
   "source": [
    "confusion2 = confusion_matrix(testy2, pred_logreg2)\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que el recall de subida es muy bajo, si va a subir, queremos que la predicción sea mejor, por lo que podemos bajar el umbral un poco, para ver como se comporta el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lower_threshold2 = logreg2.decision_function(testX2) > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos balanceada regresión logística: 0.51\n",
      "Tasa de aciertos balanceada regresión logística: 0.51\n",
      "Medida F1 regresión logística: 0.49\n",
      "Matriz de confusión:\n",
      "[[103  92]\n",
      " [ 86  85]]\n"
     ]
    }
   ],
   "source": [
    "confusiongumbral = confusion_matrix(testy2, y_pred_lower_threshold2)\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(accuracy_score(testy2, y_pred_lower_threshold2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_pred_lower_threshold2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, y_pred_lower_threshold2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiongumbral))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver cómo cambian los valores de precision ($p$)  y recall ($r$) con los distintos umbrales, y eso se hace de mánera gráfica con lo que se conoce como _curva precision-recall_ o _curva PR_:  es la curva que describen todos los puntos $(p,r)$ que se obtienen si vamos variando el umbral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: -0.941. (P,R)=(0.47,1.00)\n",
      "Umbral: -0.854. (P,R)=(0.47,0.99)\n",
      "Umbral: -0.839. (P,R)=(0.46,0.99)\n",
      "Umbral: -0.838. (P,R)=(0.47,0.99)\n",
      "Umbral: -0.727. (P,R)=(0.47,0.99)\n",
      "Umbral: -0.694. (P,R)=(0.47,0.99)\n",
      "Umbral: -0.694. (P,R)=(0.47,0.98)\n",
      "Umbral: -0.687. (P,R)=(0.47,0.98)\n",
      "Umbral: -0.643. (P,R)=(0.47,0.98)\n",
      "Umbral: -0.628. (P,R)=(0.47,0.98)\n",
      "Umbral: -0.628. (P,R)=(0.47,0.98)\n",
      "Umbral: -0.601. (P,R)=(0.47,0.98)\n",
      "Umbral: -0.597. (P,R)=(0.47,0.98)\n",
      "Umbral: -0.594. (P,R)=(0.47,0.97)\n",
      "Umbral: -0.587. (P,R)=(0.47,0.96)\n",
      "Umbral: -0.556. (P,R)=(0.47,0.96)\n",
      "Umbral: -0.553. (P,R)=(0.47,0.96)\n",
      "Umbral: -0.546. (P,R)=(0.47,0.96)\n",
      "Umbral: -0.544. (P,R)=(0.47,0.96)\n",
      "Umbral: -0.542. (P,R)=(0.47,0.96)\n",
      "Umbral: -0.529. (P,R)=(0.47,0.95)\n",
      "Umbral: -0.520. (P,R)=(0.47,0.95)\n",
      "Umbral: -0.518. (P,R)=(0.47,0.95)\n",
      "Umbral: -0.517. (P,R)=(0.47,0.95)\n",
      "Umbral: -0.513. (P,R)=(0.47,0.94)\n",
      "Umbral: -0.502. (P,R)=(0.47,0.94)\n",
      "Umbral: -0.487. (P,R)=(0.47,0.93)\n",
      "Umbral: -0.479. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.471. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.466. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.460. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.457. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.452. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.452. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.452. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.447. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.440. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.436. (P,R)=(0.47,0.90)\n",
      "Umbral: -0.435. (P,R)=(0.47,0.89)\n",
      "Umbral: -0.426. (P,R)=(0.47,0.89)\n",
      "Umbral: -0.417. (P,R)=(0.47,0.89)\n",
      "Umbral: -0.415. (P,R)=(0.47,0.89)\n",
      "Umbral: -0.410. (P,R)=(0.47,0.89)\n",
      "Umbral: -0.406. (P,R)=(0.47,0.89)\n",
      "Umbral: -0.388. (P,R)=(0.47,0.88)\n",
      "Umbral: -0.379. (P,R)=(0.47,0.88)\n",
      "Umbral: -0.377. (P,R)=(0.47,0.88)\n",
      "Umbral: -0.377. (P,R)=(0.47,0.88)\n",
      "Umbral: -0.373. (P,R)=(0.47,0.87)\n",
      "Umbral: -0.372. (P,R)=(0.47,0.87)\n",
      "Umbral: -0.372. (P,R)=(0.47,0.87)\n",
      "Umbral: -0.355. (P,R)=(0.47,0.87)\n",
      "Umbral: -0.340. (P,R)=(0.47,0.87)\n",
      "Umbral: -0.339. (P,R)=(0.47,0.87)\n",
      "Umbral: -0.333. (P,R)=(0.47,0.87)\n",
      "Umbral: -0.332. (P,R)=(0.47,0.86)\n",
      "Umbral: -0.329. (P,R)=(0.47,0.86)\n",
      "Umbral: -0.328. (P,R)=(0.47,0.85)\n",
      "Umbral: -0.328. (P,R)=(0.47,0.85)\n",
      "Umbral: -0.323. (P,R)=(0.47,0.85)\n",
      "Umbral: -0.323. (P,R)=(0.47,0.85)\n",
      "Umbral: -0.322. (P,R)=(0.47,0.84)\n",
      "Umbral: -0.316. (P,R)=(0.47,0.84)\n",
      "Umbral: -0.310. (P,R)=(0.47,0.84)\n",
      "Umbral: -0.310. (P,R)=(0.47,0.83)\n",
      "Umbral: -0.305. (P,R)=(0.47,0.83)\n",
      "Umbral: -0.302. (P,R)=(0.47,0.83)\n",
      "Umbral: -0.302. (P,R)=(0.47,0.83)\n",
      "Umbral: -0.300. (P,R)=(0.48,0.83)\n",
      "Umbral: -0.300. (P,R)=(0.48,0.83)\n",
      "Umbral: -0.291. (P,R)=(0.48,0.82)\n",
      "Umbral: -0.286. (P,R)=(0.47,0.82)\n",
      "Umbral: -0.286. (P,R)=(0.47,0.81)\n",
      "Umbral: -0.283. (P,R)=(0.47,0.81)\n",
      "Umbral: -0.268. (P,R)=(0.47,0.81)\n",
      "Umbral: -0.265. (P,R)=(0.47,0.80)\n",
      "Umbral: -0.263. (P,R)=(0.47,0.80)\n",
      "Umbral: -0.261. (P,R)=(0.47,0.80)\n",
      "Umbral: -0.260. (P,R)=(0.47,0.80)\n",
      "Umbral: -0.250. (P,R)=(0.47,0.80)\n",
      "Umbral: -0.250. (P,R)=(0.48,0.80)\n",
      "Umbral: -0.249. (P,R)=(0.47,0.79)\n",
      "Umbral: -0.248. (P,R)=(0.48,0.79)\n",
      "Umbral: -0.247. (P,R)=(0.47,0.78)\n",
      "Umbral: -0.242. (P,R)=(0.47,0.78)\n",
      "Umbral: -0.238. (P,R)=(0.47,0.77)\n",
      "Umbral: -0.237. (P,R)=(0.47,0.77)\n",
      "Umbral: -0.232. (P,R)=(0.47,0.77)\n",
      "Umbral: -0.229. (P,R)=(0.47,0.76)\n",
      "Umbral: -0.226. (P,R)=(0.47,0.76)\n",
      "Umbral: -0.226. (P,R)=(0.47,0.75)\n",
      "Umbral: -0.224. (P,R)=(0.47,0.75)\n",
      "Umbral: -0.218. (P,R)=(0.47,0.75)\n",
      "Umbral: -0.217. (P,R)=(0.47,0.75)\n",
      "Umbral: -0.209. (P,R)=(0.47,0.74)\n",
      "Umbral: -0.200. (P,R)=(0.46,0.74)\n",
      "Umbral: -0.196. (P,R)=(0.46,0.73)\n",
      "Umbral: -0.185. (P,R)=(0.46,0.73)\n",
      "Umbral: -0.183. (P,R)=(0.46,0.73)\n",
      "Umbral: -0.183. (P,R)=(0.46,0.73)\n",
      "Umbral: -0.171. (P,R)=(0.46,0.72)\n",
      "Umbral: -0.168. (P,R)=(0.46,0.72)\n",
      "Umbral: -0.168. (P,R)=(0.47,0.72)\n",
      "Umbral: -0.164. (P,R)=(0.47,0.72)\n",
      "Umbral: -0.163. (P,R)=(0.47,0.71)\n",
      "Umbral: -0.158. (P,R)=(0.46,0.71)\n",
      "Umbral: -0.155. (P,R)=(0.47,0.71)\n",
      "Umbral: -0.153. (P,R)=(0.46,0.70)\n",
      "Umbral: -0.150. (P,R)=(0.47,0.70)\n",
      "Umbral: -0.132. (P,R)=(0.46,0.70)\n",
      "Umbral: -0.128. (P,R)=(0.46,0.69)\n",
      "Umbral: -0.127. (P,R)=(0.46,0.69)\n",
      "Umbral: -0.125. (P,R)=(0.46,0.69)\n",
      "Umbral: -0.124. (P,R)=(0.47,0.69)\n",
      "Umbral: -0.121. (P,R)=(0.47,0.69)\n",
      "Umbral: -0.118. (P,R)=(0.47,0.68)\n",
      "Umbral: -0.117. (P,R)=(0.46,0.68)\n",
      "Umbral: -0.115. (P,R)=(0.46,0.67)\n",
      "Umbral: -0.104. (P,R)=(0.46,0.67)\n",
      "Umbral: -0.096. (P,R)=(0.47,0.67)\n",
      "Umbral: -0.095. (P,R)=(0.46,0.67)\n",
      "Umbral: -0.091. (P,R)=(0.46,0.66)\n",
      "Umbral: -0.090. (P,R)=(0.46,0.66)\n",
      "Umbral: -0.087. (P,R)=(0.47,0.66)\n",
      "Umbral: -0.085. (P,R)=(0.47,0.66)\n",
      "Umbral: -0.081. (P,R)=(0.47,0.66)\n",
      "Umbral: -0.080. (P,R)=(0.47,0.65)\n",
      "Umbral: -0.078. (P,R)=(0.46,0.65)\n",
      "Umbral: -0.076. (P,R)=(0.47,0.65)\n",
      "Umbral: -0.073. (P,R)=(0.47,0.65)\n",
      "Umbral: -0.072. (P,R)=(0.47,0.65)\n",
      "Umbral: -0.071. (P,R)=(0.47,0.64)\n",
      "Umbral: -0.070. (P,R)=(0.47,0.64)\n",
      "Umbral: -0.070. (P,R)=(0.47,0.64)\n",
      "Umbral: -0.063. (P,R)=(0.47,0.64)\n",
      "Umbral: -0.059. (P,R)=(0.48,0.64)\n",
      "Umbral: -0.059. (P,R)=(0.47,0.64)\n",
      "Umbral: -0.059. (P,R)=(0.47,0.63)\n",
      "Umbral: -0.057. (P,R)=(0.47,0.63)\n",
      "Umbral: -0.052. (P,R)=(0.47,0.63)\n",
      "Umbral: -0.052. (P,R)=(0.47,0.62)\n",
      "Umbral: -0.050. (P,R)=(0.47,0.61)\n",
      "Umbral: -0.048. (P,R)=(0.47,0.61)\n",
      "Umbral: -0.046. (P,R)=(0.47,0.61)\n",
      "Umbral: -0.042. (P,R)=(0.47,0.61)\n",
      "Umbral: -0.041. (P,R)=(0.47,0.60)\n",
      "Umbral: -0.037. (P,R)=(0.46,0.60)\n",
      "Umbral: -0.036. (P,R)=(0.46,0.59)\n",
      "Umbral: -0.022. (P,R)=(0.46,0.59)\n",
      "Umbral: -0.021. (P,R)=(0.46,0.58)\n",
      "Umbral: -0.014. (P,R)=(0.46,0.58)\n",
      "Umbral: -0.013. (P,R)=(0.47,0.58)\n",
      "Umbral: -0.013. (P,R)=(0.47,0.58)\n",
      "Umbral: -0.011. (P,R)=(0.47,0.58)\n",
      "Umbral: -0.001. (P,R)=(0.47,0.58)\n",
      "Umbral: 0.000. (P,R)=(0.47,0.58)\n",
      "Umbral: 0.006. (P,R)=(0.47,0.58)\n",
      "Umbral: 0.009. (P,R)=(0.47,0.58)\n",
      "Umbral: 0.009. (P,R)=(0.47,0.57)\n",
      "Umbral: 0.009. (P,R)=(0.47,0.57)\n",
      "Umbral: 0.013. (P,R)=(0.47,0.57)\n",
      "Umbral: 0.015. (P,R)=(0.47,0.57)\n",
      "Umbral: 0.017. (P,R)=(0.48,0.57)\n",
      "Umbral: 0.024. (P,R)=(0.47,0.56)\n",
      "Umbral: 0.025. (P,R)=(0.48,0.56)\n",
      "Umbral: 0.028. (P,R)=(0.47,0.56)\n",
      "Umbral: 0.030. (P,R)=(0.47,0.56)\n",
      "Umbral: 0.030. (P,R)=(0.47,0.55)\n",
      "Umbral: 0.031. (P,R)=(0.47,0.54)\n",
      "Umbral: 0.032. (P,R)=(0.47,0.54)\n",
      "Umbral: 0.032. (P,R)=(0.47,0.54)\n",
      "Umbral: 0.039. (P,R)=(0.47,0.54)\n",
      "Umbral: 0.042. (P,R)=(0.47,0.54)\n",
      "Umbral: 0.042. (P,R)=(0.48,0.54)\n",
      "Umbral: 0.043. (P,R)=(0.48,0.54)\n",
      "Umbral: 0.049. (P,R)=(0.48,0.53)\n",
      "Umbral: 0.051. (P,R)=(0.48,0.53)\n",
      "Umbral: 0.063. (P,R)=(0.48,0.53)\n",
      "Umbral: 0.067. (P,R)=(0.48,0.53)\n",
      "Umbral: 0.071. (P,R)=(0.48,0.53)\n",
      "Umbral: 0.076. (P,R)=(0.48,0.52)\n",
      "Umbral: 0.077. (P,R)=(0.48,0.51)\n",
      "Umbral: 0.080. (P,R)=(0.48,0.51)\n",
      "Umbral: 0.080. (P,R)=(0.48,0.51)\n",
      "Umbral: 0.080. (P,R)=(0.48,0.51)\n",
      "Umbral: 0.087. (P,R)=(0.49,0.51)\n",
      "Umbral: 0.088. (P,R)=(0.49,0.51)\n",
      "Umbral: 0.088. (P,R)=(0.49,0.51)\n",
      "Umbral: 0.089. (P,R)=(0.48,0.50)\n",
      "Umbral: 0.107. (P,R)=(0.48,0.50)\n",
      "Umbral: 0.115. (P,R)=(0.48,0.49)\n",
      "Umbral: 0.116. (P,R)=(0.47,0.49)\n",
      "Umbral: 0.119. (P,R)=(0.47,0.48)\n",
      "Umbral: 0.119. (P,R)=(0.47,0.47)\n",
      "Umbral: 0.123. (P,R)=(0.47,0.47)\n",
      "Umbral: 0.134. (P,R)=(0.47,0.47)\n",
      "Umbral: 0.139. (P,R)=(0.47,0.47)\n",
      "Umbral: 0.141. (P,R)=(0.47,0.47)\n",
      "Umbral: 0.143. (P,R)=(0.48,0.47)\n",
      "Umbral: 0.146. (P,R)=(0.47,0.46)\n",
      "Umbral: 0.157. (P,R)=(0.47,0.46)\n",
      "Umbral: 0.159. (P,R)=(0.47,0.45)\n",
      "Umbral: 0.160. (P,R)=(0.46,0.44)\n",
      "Umbral: 0.161. (P,R)=(0.47,0.44)\n",
      "Umbral: 0.163. (P,R)=(0.47,0.44)\n",
      "Umbral: 0.165. (P,R)=(0.47,0.44)\n",
      "Umbral: 0.167. (P,R)=(0.47,0.44)\n",
      "Umbral: 0.167. (P,R)=(0.47,0.43)\n",
      "Umbral: 0.173. (P,R)=(0.47,0.43)\n",
      "Umbral: 0.173. (P,R)=(0.46,0.43)\n",
      "Umbral: 0.180. (P,R)=(0.46,0.42)\n",
      "Umbral: 0.182. (P,R)=(0.46,0.42)\n",
      "Umbral: 0.183. (P,R)=(0.46,0.42)\n",
      "Umbral: 0.187. (P,R)=(0.46,0.42)\n",
      "Umbral: 0.200. (P,R)=(0.46,0.41)\n",
      "Umbral: 0.210. (P,R)=(0.46,0.41)\n",
      "Umbral: 0.214. (P,R)=(0.46,0.40)\n",
      "Umbral: 0.219. (P,R)=(0.46,0.40)\n",
      "Umbral: 0.219. (P,R)=(0.46,0.40)\n",
      "Umbral: 0.219. (P,R)=(0.46,0.39)\n",
      "Umbral: 0.220. (P,R)=(0.46,0.39)\n",
      "Umbral: 0.223. (P,R)=(0.46,0.39)\n",
      "Umbral: 0.232. (P,R)=(0.45,0.38)\n",
      "Umbral: 0.236. (P,R)=(0.45,0.37)\n",
      "Umbral: 0.236. (P,R)=(0.45,0.37)\n",
      "Umbral: 0.240. (P,R)=(0.45,0.37)\n",
      "Umbral: 0.246. (P,R)=(0.46,0.37)\n",
      "Umbral: 0.248. (P,R)=(0.45,0.37)\n",
      "Umbral: 0.250. (P,R)=(0.45,0.36)\n",
      "Umbral: 0.251. (P,R)=(0.45,0.36)\n",
      "Umbral: 0.251. (P,R)=(0.45,0.36)\n",
      "Umbral: 0.261. (P,R)=(0.44,0.35)\n",
      "Umbral: 0.267. (P,R)=(0.45,0.35)\n",
      "Umbral: 0.267. (P,R)=(0.44,0.35)\n",
      "Umbral: 0.268. (P,R)=(0.44,0.34)\n",
      "Umbral: 0.272. (P,R)=(0.44,0.34)\n",
      "Umbral: 0.284. (P,R)=(0.45,0.34)\n",
      "Umbral: 0.288. (P,R)=(0.44,0.33)\n",
      "Umbral: 0.289. (P,R)=(0.44,0.33)\n",
      "Umbral: 0.292. (P,R)=(0.44,0.33)\n",
      "Umbral: 0.294. (P,R)=(0.44,0.32)\n",
      "Umbral: 0.296. (P,R)=(0.43,0.32)\n",
      "Umbral: 0.301. (P,R)=(0.43,0.31)\n",
      "Umbral: 0.303. (P,R)=(0.42,0.30)\n",
      "Umbral: 0.306. (P,R)=(0.43,0.30)\n",
      "Umbral: 0.313. (P,R)=(0.42,0.30)\n",
      "Umbral: 0.317. (P,R)=(0.42,0.30)\n",
      "Umbral: 0.319. (P,R)=(0.42,0.29)\n",
      "Umbral: 0.326. (P,R)=(0.42,0.29)\n",
      "Umbral: 0.332. (P,R)=(0.41,0.28)\n",
      "Umbral: 0.334. (P,R)=(0.41,0.28)\n",
      "Umbral: 0.337. (P,R)=(0.41,0.27)\n",
      "Umbral: 0.339. (P,R)=(0.40,0.27)\n",
      "Umbral: 0.347. (P,R)=(0.41,0.27)\n",
      "Umbral: 0.349. (P,R)=(0.41,0.27)\n",
      "Umbral: 0.351. (P,R)=(0.41,0.27)\n",
      "Umbral: 0.357. (P,R)=(0.42,0.27)\n",
      "Umbral: 0.361. (P,R)=(0.42,0.27)\n",
      "Umbral: 0.364. (P,R)=(0.42,0.26)\n",
      "Umbral: 0.365. (P,R)=(0.41,0.26)\n",
      "Umbral: 0.368. (P,R)=(0.41,0.25)\n",
      "Umbral: 0.384. (P,R)=(0.41,0.25)\n",
      "Umbral: 0.387. (P,R)=(0.41,0.25)\n",
      "Umbral: 0.387. (P,R)=(0.41,0.25)\n",
      "Umbral: 0.393. (P,R)=(0.41,0.25)\n",
      "Umbral: 0.397. (P,R)=(0.42,0.25)\n",
      "Umbral: 0.400. (P,R)=(0.41,0.24)\n",
      "Umbral: 0.417. (P,R)=(0.41,0.24)\n",
      "Umbral: 0.418. (P,R)=(0.42,0.24)\n",
      "Umbral: 0.420. (P,R)=(0.42,0.24)\n",
      "Umbral: 0.434. (P,R)=(0.43,0.24)\n",
      "Umbral: 0.440. (P,R)=(0.43,0.24)\n",
      "Umbral: 0.442. (P,R)=(0.43,0.23)\n",
      "Umbral: 0.443. (P,R)=(0.43,0.23)\n",
      "Umbral: 0.445. (P,R)=(0.43,0.23)\n",
      "Umbral: 0.457. (P,R)=(0.43,0.23)\n",
      "Umbral: 0.463. (P,R)=(0.42,0.22)\n",
      "Umbral: 0.466. (P,R)=(0.42,0.22)\n",
      "Umbral: 0.469. (P,R)=(0.42,0.22)\n",
      "Umbral: 0.469. (P,R)=(0.43,0.22)\n",
      "Umbral: 0.476. (P,R)=(0.43,0.22)\n",
      "Umbral: 0.477. (P,R)=(0.44,0.22)\n",
      "Umbral: 0.479. (P,R)=(0.44,0.22)\n",
      "Umbral: 0.484. (P,R)=(0.45,0.22)\n",
      "Umbral: 0.489. (P,R)=(0.45,0.22)\n",
      "Umbral: 0.491. (P,R)=(0.44,0.21)\n",
      "Umbral: 0.504. (P,R)=(0.45,0.21)\n",
      "Umbral: 0.506. (P,R)=(0.44,0.20)\n",
      "Umbral: 0.508. (P,R)=(0.45,0.20)\n",
      "Umbral: 0.509. (P,R)=(0.45,0.20)\n",
      "Umbral: 0.511. (P,R)=(0.46,0.20)\n",
      "Umbral: 0.511. (P,R)=(0.45,0.20)\n",
      "Umbral: 0.514. (P,R)=(0.46,0.20)\n",
      "Umbral: 0.519. (P,R)=(0.47,0.20)\n",
      "Umbral: 0.520. (P,R)=(0.46,0.19)\n",
      "Umbral: 0.528. (P,R)=(0.46,0.19)\n",
      "Umbral: 0.529. (P,R)=(0.47,0.19)\n",
      "Umbral: 0.532. (P,R)=(0.48,0.19)\n",
      "Umbral: 0.541. (P,R)=(0.47,0.19)\n",
      "Umbral: 0.544. (P,R)=(0.48,0.19)\n",
      "Umbral: 0.547. (P,R)=(0.47,0.18)\n",
      "Umbral: 0.559. (P,R)=(0.46,0.18)\n",
      "Umbral: 0.568. (P,R)=(0.45,0.17)\n",
      "Umbral: 0.577. (P,R)=(0.46,0.17)\n",
      "Umbral: 0.578. (P,R)=(0.47,0.17)\n",
      "Umbral: 0.579. (P,R)=(0.48,0.17)\n",
      "Umbral: 0.587. (P,R)=(0.48,0.17)\n",
      "Umbral: 0.590. (P,R)=(0.47,0.16)\n",
      "Umbral: 0.592. (P,R)=(0.47,0.16)\n",
      "Umbral: 0.592. (P,R)=(0.47,0.16)\n",
      "Umbral: 0.604. (P,R)=(0.48,0.16)\n",
      "Umbral: 0.617. (P,R)=(0.47,0.15)\n",
      "Umbral: 0.619. (P,R)=(0.48,0.15)\n",
      "Umbral: 0.621. (P,R)=(0.49,0.15)\n",
      "Umbral: 0.621. (P,R)=(0.50,0.15)\n",
      "Umbral: 0.627. (P,R)=(0.49,0.15)\n",
      "Umbral: 0.633. (P,R)=(0.50,0.15)\n",
      "Umbral: 0.660. (P,R)=(0.49,0.14)\n",
      "Umbral: 0.666. (P,R)=(0.50,0.14)\n",
      "Umbral: 0.674. (P,R)=(0.51,0.14)\n",
      "Umbral: 0.681. (P,R)=(0.50,0.13)\n",
      "Umbral: 0.695. (P,R)=(0.49,0.13)\n",
      "Umbral: 0.697. (P,R)=(0.48,0.12)\n",
      "Umbral: 0.701. (P,R)=(0.47,0.12)\n",
      "Umbral: 0.704. (P,R)=(0.45,0.11)\n",
      "Umbral: 0.704. (P,R)=(0.44,0.11)\n",
      "Umbral: 0.715. (P,R)=(0.42,0.10)\n",
      "Umbral: 0.734. (P,R)=(0.44,0.10)\n",
      "Umbral: 0.746. (P,R)=(0.42,0.09)\n",
      "Umbral: 0.760. (P,R)=(0.43,0.09)\n",
      "Umbral: 0.771. (P,R)=(0.44,0.09)\n",
      "Umbral: 0.781. (P,R)=(0.46,0.09)\n",
      "Umbral: 0.793. (P,R)=(0.47,0.09)\n",
      "Umbral: 0.799. (P,R)=(0.45,0.09)\n",
      "Umbral: 0.816. (P,R)=(0.44,0.08)\n",
      "Umbral: 0.836. (P,R)=(0.42,0.08)\n",
      "Umbral: 0.837. (P,R)=(0.43,0.08)\n",
      "Umbral: 0.839. (P,R)=(0.41,0.07)\n",
      "Umbral: 0.844. (P,R)=(0.39,0.06)\n",
      "Umbral: 0.857. (P,R)=(0.37,0.06)\n",
      "Umbral: 0.859. (P,R)=(0.35,0.05)\n",
      "Umbral: 0.867. (P,R)=(0.32,0.05)\n",
      "Umbral: 0.885. (P,R)=(0.33,0.05)\n",
      "Umbral: 0.889. (P,R)=(0.35,0.05)\n",
      "Umbral: 0.900. (P,R)=(0.36,0.05)\n",
      "Umbral: 0.943. (P,R)=(0.38,0.05)\n",
      "Umbral: 0.950. (P,R)=(0.40,0.05)\n",
      "Umbral: 0.963. (P,R)=(0.37,0.04)\n",
      "Umbral: 0.977. (P,R)=(0.39,0.04)\n",
      "Umbral: 0.997. (P,R)=(0.41,0.04)\n",
      "Umbral: 1.011. (P,R)=(0.44,0.04)\n",
      "Umbral: 1.016. (P,R)=(0.47,0.04)\n",
      "Umbral: 1.044. (P,R)=(0.50,0.04)\n",
      "Umbral: 1.048. (P,R)=(0.54,0.04)\n",
      "Umbral: 1.085. (P,R)=(0.50,0.04)\n",
      "Umbral: 1.122. (P,R)=(0.55,0.04)\n",
      "Umbral: 1.123. (P,R)=(0.60,0.04)\n",
      "Umbral: 1.140. (P,R)=(0.67,0.04)\n",
      "Umbral: 1.168. (P,R)=(0.75,0.04)\n",
      "Umbral: 1.217. (P,R)=(0.86,0.04)\n",
      "Umbral: 1.263. (P,R)=(0.83,0.03)\n",
      "Umbral: 1.324. (P,R)=(0.80,0.02)\n",
      "Umbral: 1.429. (P,R)=(0.75,0.02)\n",
      "Umbral: 1.477. (P,R)=(1.00,0.02)\n",
      "Umbral: 1.609. (P,R)=(1.00,0.01)\n",
      "Umbral: 1.849. (P,R)=(1.00,0.01)\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve( testy2, logreg2.decision_function(testX2))\n",
    "for u,p,r in zip(thresholds,precision,recall):\n",
    "    print(\"Umbral: {:.3f}. (P,R)=({:.2f},{:.2f})\".format(u,p,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Curva PR')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(testy2, logreg2.decision_function(testX2))\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10, label=\"umbral cero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.plot(precision, recall)\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Curva PR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Curva ROC (Receiver Operating Characteristics) y AUC (area under curve)\n",
    "\n",
    "Otra curva que se usa muy frecuentemente para analizar el comportamiento de clasificadores binarios, y especialmente en problemas en el que las clases no están equilibradas, es la curva ROC (siglas de _Receiver Operating Characteristics_). La idea es similar a la de la curva PR, pero en este caso la curva se forma con los puntos $(FPR,TPR)$ que se generan variando el umbral. Aquí $TPR$ es _true positive rate_ y es otro nombre para _recall_; y $FPR$ es _false Postive rate_ y se defina como la tasa de error que tiene el clasificador en el conjunto de ejemplos negativos. Es decir:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Curva ROC')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(testy2, logreg2.decision_function(testX2))\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=7,label=\"umbral cero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.legend(loc=4)\n",
    "plt.title(\"Curva ROC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La gráfica empieza cuando todo se clasifica como negativo y acaba cuando todo lo clasifica como positivo. Podemos observar que el mejor umbral, porque en el ninguna de las dos métricas(TPR,FPR) es muy baja, va a ser el umbral 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HORARIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "run Datos-1horaBINARIO.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 1: MODELO BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.53\n",
      "Tasa de aciertos balanceada regresión logística: 0.53\n",
      "Medida F1 regresión logística: 0.61\n",
      "Matriz de confusión:\n",
      "[[1515 3035]\n",
      " [1211 3260]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 1\n",
    "# -------------------------------------------------------------------\n",
    "logreg1 = LogisticRegression(max_iter=10000).fit(trainX1, trainy1)\n",
    "pred_logreg1 = logreg1.predict(testX1)\n",
    "confusion1 = confusion_matrix(testy1, pred_logreg1)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg1.score(testX1, testy1)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, pred_logreg1)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy1, pred_logreg1)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.54\n",
      "Tasa de aciertos balanceada regresión logística: 0.54\n",
      "Medida F1 regresión logística: 0.60\n",
      "Matriz de confusión:\n",
      "[[1673 2871]\n",
      " [1306 3160]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 2\n",
    "# -------------------------------------------------------------------\n",
    "logreg2 = LogisticRegression(max_iter=10000).fit(trainX2, trainy2)\n",
    "pred_logreg2 = logreg2.predict(testX2)\n",
    "confusion2 = confusion_matrix(testy2, pred_logreg2)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg2.score(testX2, testy2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, pred_logreg2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, pred_logreg2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.54\n",
      "Tasa de aciertos balanceada regresión logística: 0.54\n",
      "Medida F1 regresión logística: 0.57\n",
      "Matriz de confusión:\n",
      "[[2079 2464]\n",
      " [1673 2790]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 3\n",
    "# -------------------------------------------------------------------\n",
    "logreg3 = LogisticRegression(max_iter=10000).fit(trainX3, trainy3)\n",
    "pred_logreg3 = logreg3.predict(testX3)\n",
    "confusion = confusion_matrix(testy3, pred_logreg3)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg3.score(testX3, testy3)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, pred_logreg3)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy3, pred_logreg3)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 1: GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 1\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid1 = LogisticRegression()\n",
    "parameters1 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"none\",\"l2\"]}\n",
    "grid1 = GridSearchCV(modelgrid1,parameters1, cv=None).fit(trainX1, trainy1)\n",
    "grid1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrgrid1 = LogisticRegression(C=0.1).fit(trainX1, trainy1)\n",
    "y_predg1 = lrgrid1.predict(testX1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.53\n",
      "Tasa de aciertos balanceada regresión logística: 0.53\n",
      "Medida F1 regresión logística: 0.61\n",
      "Matriz de confusión:\n",
      "[[1515 3035]\n",
      " [1211 3260]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid1 = lrgrid1.predict(testX1)\n",
    "confusiong1 = confusion_matrix(testy1, pred_lrgrid1)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid1.score(testX1, testy1)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, pred_logreg1)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy1, pred_logreg1)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 2\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid2 = LogisticRegression()\n",
    "parameters2 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"none\",\"l2\",]}\n",
    "grid2 = GridSearchCV(modelgrid2,parameters2, cv=None).fit(trainX2, trainy2)\n",
    "grid2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lrgrid2 = LogisticRegression(C=0.001).fit(trainX2, trainy2)\n",
    "y_predg2 = lrgrid2.predict(testX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.54\n",
      "Tasa de aciertos balanceada regresión logística: 0.54\n",
      "Medida F1 regresión logística: 0.60\n",
      "Matriz de confusión:\n",
      "[[1694 2850]\n",
      " [1327 3139]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid2 = lrgrid2.predict(testX2)\n",
    "confusiong2 = confusion_matrix(testy2, pred_lrgrid2)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid2.score(testX2, testy2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, pred_logreg2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, pred_logreg2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.53704547        nan        nan 0.53751751        nan\n",
      "        nan 0.53443606        nan        nan 0.53604611        nan\n",
      "        nan 0.53810021        nan        nan 0.53754517        nan\n",
      "        nan 0.53651809        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 3\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid3 = LogisticRegression()\n",
    "parameters3 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\",None]}\n",
    "grid3 = GridSearchCV(modelgrid3,parameters3, cv=None).fit(trainX3, trainy3)\n",
    "grid3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lrgrid3 = LogisticRegression(C=10.0).fit(trainX3, trainy3)\n",
    "y_predg3 = lrgrid3.predict(testX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.53\n",
      "Tasa de aciertos balanceada regresión logística: 0.54\n",
      "Medida F1 regresión logística: 0.57\n",
      "Matriz de confusión:\n",
      "[[1553 2990]\n",
      " [1251 3212]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid3 = lrgrid3.predict(testX3)\n",
    "confusiong3 = confusion_matrix(testy3, pred_lrgrid3)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid3.score(testX3, testy3)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, pred_logreg3)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy3, pred_logreg3)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejora Modelo Base- Conjunto de datos 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando la incertidumbre en las predicciones: umbrales y curvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    22051\n",
       "1.0    22998\n",
       "Name: Subida, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy2.value_counts() + trainy2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Baja       0.56      0.37      0.44      4544\n",
      "        Sube       0.52      0.71      0.60      4466\n",
      "\n",
      "    accuracy                           0.54      9010\n",
      "   macro avg       0.54      0.54      0.52      9010\n",
      "weighted avg       0.54      0.54      0.52      9010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testy2, pred_logreg2,target_names=[\"Baja\", \"Sube\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[1673 2871]\n",
      " [1306 3160]]\n"
     ]
    }
   ],
   "source": [
    "confusion2 = confusion_matrix(testy2, pred_logreg2)\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lower_threshold2 = logreg2.decision_function(testX2) > 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos balanceada regresión logística: 0.54\n",
      "Tasa de aciertos balanceada regresión logística: 0.54\n",
      "Medida F1 regresión logística: 0.60\n",
      "Matriz de confusión:\n",
      "[[1679 2865]\n",
      " [1314 3152]]\n"
     ]
    }
   ],
   "source": [
    "confusiongumbral = confusion_matrix(testy2, y_pred_lower_threshold2)\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(accuracy_score(testy2, y_pred_lower_threshold2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_pred_lower_threshold2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, y_pred_lower_threshold2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiongumbral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: -1.086. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.920. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.918. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.906. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.903. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.857. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.848. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.843. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.841. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.802. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.802. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.795. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.791. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.791. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.784. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.762. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.758. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.737. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.708. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.700. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.678. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.669. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.662. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.661. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.655. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.646. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.642. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.642. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.636. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.628. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.616. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.615. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.613. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.612. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.600. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.598. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.597. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.595. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.583. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.580. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.580. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.578. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.577. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.575. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.571. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.569. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.561. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.559. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.551. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.544. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.540. (P,R)=(0.50,1.00)\n",
      "Umbral: -0.536. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.535. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.529. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.525. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.523. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.520. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.517. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.512. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.505. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.497. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.497. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.496. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.494. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.492. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.488. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.477. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.474. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.473. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.471. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.464. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.464. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.459. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.458. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.455. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.455. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.454. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.451. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.449. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.448. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.445. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.445. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.444. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.443. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.442. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.440. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.439. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.438. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.437. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.435. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.433. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.430. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.428. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.427. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.425. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.423. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.423. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.419. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.419. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.419. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.419. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.418. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.417. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.416. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.411. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.410. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.410. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.409. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.409. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.409. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.408. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.406. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.403. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.403. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.403. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.401. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.399. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.397. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.396. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.395. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.394. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.390. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.390. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.389. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.389. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.389. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.388. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.388. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.388. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.387. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.387. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.385. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.385. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.384. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.384. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.383. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.381. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.380. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.380. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.379. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.377. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.376. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.374. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.371. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.370. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.369. (P,R)=(0.50,0.99)\n",
      "Umbral: -0.367. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.366. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.363. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.360. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.360. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.359. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.358. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.357. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.357. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.357. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.355. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.355. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.352. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.352. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.351. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.350. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.349. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.349. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.348. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.348. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.347. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.347. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.347. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.346. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.346. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.345. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.345. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.344. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.344. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.344. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.344. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.343. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.342. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.342. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.340. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.340. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.340. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.340. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.335. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.335. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.335. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.334. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.334. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.333. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.333. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.332. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.331. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.330. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.329. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.328. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.327. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.327. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.326. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.326. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.325. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.325. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.325. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.324. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.324. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.324. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.322. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.321. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.319. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.319. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.318. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.318. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.318. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.317. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.317. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.316. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.315. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.315. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.314. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.312. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.312. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.312. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.309. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.308. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.308. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.307. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.305. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.304. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.304. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.303. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.303. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.303. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.302. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.302. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.301. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.300. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.300. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.299. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.298. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.298. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.297. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.296. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.296. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.296. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.296. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.296. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.295. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.293. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.293. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.292. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.292. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.292. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.292. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.292. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.291. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.291. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.291. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.290. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.289. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.288. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.288. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.285. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.282. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.282. (P,R)=(0.50,0.98)\n",
      "Umbral: -0.281. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.281. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.281. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.281. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.281. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.280. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.279. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.279. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.278. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.278. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.277. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.276. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.276. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.276. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.276. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.276. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.275. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.275. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.274. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.273. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.273. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.273. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.272. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.271. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.271. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.271. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.270. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.270. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.268. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.268. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.267. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.266. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.266. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.265. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.265. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.265. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.265. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.264. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.262. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.262. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.262. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.262. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.262. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.261. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.260. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.260. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.259. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.259. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.259. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.258. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.257. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.256. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.256. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.256. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.256. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.255. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.255. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.255. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.255. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.255. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.254. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.254. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.254. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.254. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.253. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.253. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.253. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.252. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.252. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.251. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.251. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.251. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.251. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.251. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.251. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.250. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.250. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.250. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.250. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.250. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.250. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.248. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.248. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.248. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.247. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.247. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.247. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.247. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.247. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.247. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.246. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.246. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.245. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.245. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.244. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.244. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.244. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.244. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.243. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.243. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.243. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.242. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.242. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.241. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.241. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.240. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.240. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.240. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.240. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.239. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.239. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.238. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.238. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.238. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.238. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.238. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.238. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.237. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.237. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.235. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.235. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.235. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.235. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.235. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.234. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.234. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.234. (P,R)=(0.50,0.97)\n",
      "Umbral: -0.234. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.233. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.233. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.232. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.232. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.232. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.232. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.232. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.232. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.232. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.231. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.231. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.231. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.231. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.231. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.230. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.230. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.230. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.230. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.230. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.229. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.229. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.229. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.229. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.229. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.228. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.228. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.228. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.228. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.227. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.227. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.227. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.227. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.227. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.227. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.227. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.226. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.226. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.226. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.225. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.225. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.225. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.225. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.224. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.224. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.224. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.224. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.224. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.224. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.224. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.223. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.223. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.223. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.222. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.222. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.221. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.221. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.221. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.221. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.220. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.220. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.219. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.219. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.218. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.218. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.218. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.218. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.217. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.217. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.217. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.217. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.217. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.217. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.216. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.216. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.216. (P,R)=(0.50,0.96)\n",
      "Umbral: -0.215. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.215. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.215. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.215. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.214. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.214. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.214. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.213. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.213. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.213. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.212. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.212. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.212. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.211. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.211. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.211. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.211. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.211. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.210. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.210. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.210. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.210. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.210. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.209. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.209. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.209. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.209. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.209. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.208. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.208. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.208. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.208. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.207. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.207. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.207. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.206. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.206. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.206. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.205. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.205. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.204. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.204. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.204. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.203. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.203. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.203. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.202. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.202. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.202. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.202. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.202. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.201. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.201. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.200. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.200. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.200. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.200. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.200. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.200. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.200. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.200. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.199. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.199. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.199. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.199. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.199. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.198. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.197. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.197. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.197. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.196. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.196. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.196. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.196. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.195. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.195. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.194. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.194. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.194. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.192. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.192. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.192. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.192. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.191. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.191. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.191. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.191. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.191. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.191. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.191. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.190. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.190. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.190. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.190. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.190. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.190. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.189. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.189. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.189. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.189. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.189. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.189. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.189. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.189. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.188. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.188. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.188. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.188. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.188. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.188. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.188. (P,R)=(0.50,0.95)\n",
      "Umbral: -0.188. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.187. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.187. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.187. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.187. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.187. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.187. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.187. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.187. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.186. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.186. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.186. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.186. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.186. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.186. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.186. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.186. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.186. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.185. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.185. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.185. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.185. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.184. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.184. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.184. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.184. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.183. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.183. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.183. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.183. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.183. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.183. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.183. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.183. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.183. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.182. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.182. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.182. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.182. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.182. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.182. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.181. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.181. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.181. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.181. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.180. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.180. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.180. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.180. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.180. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.180. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.180. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.179. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.179. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.179. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.179. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.179. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.178. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.178. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.178. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.178. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.178. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.177. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.177. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.177. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.177. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.176. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.176. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.176. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.176. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.176. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.176. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.176. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.175. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.175. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.175. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.175. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.175. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.174. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.174. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.174. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.174. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.174. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.174. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.174. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.174. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.173. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.173. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.173. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.173. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.173. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.173. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.173. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.173. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.173. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.172. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.172. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.172. (P,R)=(0.50,0.94)\n",
      "Umbral: -0.172. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.172. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.172. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.172. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.171. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.171. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.171. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.171. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.171. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.170. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.170. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.170. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.170. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.170. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.170. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.169. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.169. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.169. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.169. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.169. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.169. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.168. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.168. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.168. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.168. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.168. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.167. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.167. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.167. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.167. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.166. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.166. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.166. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.166. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.166. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.166. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.166. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.166. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.165. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.165. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.165. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.165. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.165. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.165. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.165. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.165. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.164. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.164. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.164. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.164. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.164. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.164. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.164. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.163. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.163. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.163. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.163. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.163. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.163. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.163. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.162. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.162. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.162. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.162. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.162. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.162. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.162. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.162. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.162. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.161. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.161. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.161. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.161. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.161. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.161. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.161. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.161. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.161. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.161. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.160. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.160. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.160. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.160. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.160. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.160. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.159. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.159. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.159. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.159. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.159. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.159. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.159. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.158. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.158. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.158. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.158. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.158. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.157. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.157. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.157. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.157. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.157. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.157. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.157. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.156. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.156. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.156. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.156. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.156. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.156. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.156. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.156. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.156. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.156. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.155. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.155. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.155. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.155. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.155. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.154. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.154. (P,R)=(0.50,0.93)\n",
      "Umbral: -0.154. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.154. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.154. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.154. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.154. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.154. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.153. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.153. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.153. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.153. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.153. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.153. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.152. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.152. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.152. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.152. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.152. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.152. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.152. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.152. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.151. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.151. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.151. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.151. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.151. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.150. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.150. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.150. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.150. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.150. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.149. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.149. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.149. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.149. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.149. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.149. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.148. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.148. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.148. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.148. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.148. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.148. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.148. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.148. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.147. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.147. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.147. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.147. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.147. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.147. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.147. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.147. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.146. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.146. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.146. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.146. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.146. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.145. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.145. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.145. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.145. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.145. (P,R)=(0.50,0.92)\n",
      "Umbral: -0.144. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.144. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.144. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.144. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.143. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.143. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.143. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.143. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.143. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.143. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.143. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.142. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.142. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.142. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.142. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.142. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.142. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.142. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.142. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.142. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.142. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.142. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.142. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.141. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.141. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.141. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.141. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.141. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.141. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.141. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.140. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.140. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.140. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.140. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.140. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.140. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.140. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.140. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.140. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.139. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.139. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.139. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.139. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.139. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.139. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.138. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.138. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.138. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.138. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.138. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.138. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.138. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.138. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.137. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.137. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.137. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.137. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.137. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.137. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.136. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.136. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.136. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.136. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.136. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.136. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.136. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.136. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.136. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.136. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.136. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.136. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.135. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.135. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.135. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.135. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.135. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.134. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.134. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.134. (P,R)=(0.51,0.92)\n",
      "Umbral: -0.133. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.133. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.133. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.132. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.132. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.132. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.132. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.132. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.132. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.132. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.132. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.132. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.131. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.131. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.131. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.131. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.131. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.131. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.131. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.131. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.131. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.131. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.130. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.130. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.130. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.130. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.130. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.130. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.130. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.130. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.130. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.130. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.130. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.130. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.129. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.129. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.129. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.129. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.129. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.129. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.129. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.129. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.129. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.128. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.128. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.128. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.128. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.128. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.128. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.128. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.128. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.128. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.127. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.127. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.127. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.127. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.127. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.127. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.127. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.127. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.127. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.127. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.126. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.126. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.126. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.126. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.126. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.126. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.126. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.125. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.125. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.125. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.125. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.125. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.124. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.124. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.124. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.124. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.124. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.124. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.124. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.124. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.124. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.124. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.124. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.124. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.124. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.123. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.123. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.123. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.123. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.123. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.123. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.123. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.123. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.123. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.123. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.122. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.122. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.122. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.122. (P,R)=(0.51,0.91)\n",
      "Umbral: -0.122. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.122. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.122. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.122. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.122. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.121. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.121. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.121. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.121. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.121. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.121. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.121. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.121. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.121. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.120. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.120. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.120. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.120. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.120. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.120. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.120. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.120. (P,R)=(0.51,0.90)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: -0.120. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.120. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.120. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.120. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.120. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.119. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.119. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.119. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.119. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.119. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.119. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.119. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.119. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.119. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.118. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.118. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.118. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.118. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.118. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.118. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.118. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.118. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.118. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.118. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.117. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.116. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.116. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.116. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.116. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.116. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.116. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.116. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.115. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.115. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.115. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.115. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.115. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.115. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.114. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.114. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.114. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.114. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.114. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.114. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.114. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.114. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.114. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.114. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.114. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.114. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.113. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.113. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.113. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.112. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.112. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.112. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.112. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.111. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.111. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.111. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.111. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.111. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.111. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.110. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.110. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.110. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.110. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.110. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.110. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.110. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.110. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.110. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.110. (P,R)=(0.51,0.90)\n",
      "Umbral: -0.110. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.110. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.109. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.109. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.109. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.109. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.109. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.109. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.109. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.109. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.109. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.108. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.108. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.108. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.108. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.108. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.108. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.108. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.108. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.108. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.108. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.108. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.108. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.107. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.107. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.107. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.107. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.107. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.107. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.107. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.107. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.107. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.107. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.107. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.107. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.107. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.106. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.106. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.106. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.106. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.106. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.106. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.106. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.106. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.106. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.106. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.105. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.104. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.103. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.102. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.101. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.101. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.101. (P,R)=(0.51,0.89)\n",
      "Umbral: -0.101. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.101. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.101. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.101. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.101. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.101. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.101. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.100. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.100. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.100. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.100. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.100. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.100. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.100. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.100. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.100. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.100. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.099. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.099. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.099. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.099. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.099. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.099. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.099. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.099. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.099. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.098. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.097. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.097. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.097. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.097. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.097. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.097. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.097. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.097. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.097. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.096. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.095. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.095. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.095. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.095. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.095. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.095. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.095. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.095. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.094. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.094. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.094. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.094. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.094. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.094. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.094. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.094. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.094. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.094. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.094. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.093. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.093. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.093. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.093. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.093. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.093. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.093. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.093. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.092. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.092. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.092. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.092. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.092. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.092. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.092. (P,R)=(0.51,0.88)\n",
      "Umbral: -0.092. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.092. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.092. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.092. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.092. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.091. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.090. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.090. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.090. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.090. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.090. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.090. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.090. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.090. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.090. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.089. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.088. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.088. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.088. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.088. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.088. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.088. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.088. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.088. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.088. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.088. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.088. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.088. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.087. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.086. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.87)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.085. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.084. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.084. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.084. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.084. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.084. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.084. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.084. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.084. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.084. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.083. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.082. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.082. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.082. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.082. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.082. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.082. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.082. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.082. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.082. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.082. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.082. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.082. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.081. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.081. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.081. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.081. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.081. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.081. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.081. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.081. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.081. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.080. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.080. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.080. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.080. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.080. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.080. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.080. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.080. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.080. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.080. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.080. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.080. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.080. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.079. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.079. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.079. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.079. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.079. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.079. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.079. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.079. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.079. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.079. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.079. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.079. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.079. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.078. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.078. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.078. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.078. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.078. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.078. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.078. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.078. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.078. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.077. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.077. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.077. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.077. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.077. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.077. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.077. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.077. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.077. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.077. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.077. (P,R)=(0.51,0.86)\n",
      "Umbral: -0.077. (P,R)=(0.51,0.85)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: -0.077. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.077. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.076. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.075. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.075. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.075. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.075. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.075. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.075. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.075. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.075. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.075. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.075. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.075. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.075. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.075. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.074. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.074. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.074. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.074. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.074. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.074. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.074. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.074. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.074. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.074. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.074. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.074. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.073. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.073. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.073. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.073. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.073. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.073. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.073. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.073. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.073. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.073. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.073. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.073. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.073. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.072. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.072. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.072. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.072. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.072. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.072. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.072. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.072. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.072. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.072. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.072. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.071. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.85)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.070. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.069. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.068. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.067. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.067. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.067. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.067. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.067. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.067. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.067. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.067. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.067. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.067. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.067. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.066. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.065. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.065. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.065. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.065. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.065. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.065. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.065. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.065. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.065. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.065. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.064. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.064. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.064. (P,R)=(0.51,0.84)\n",
      "Umbral: -0.064. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.064. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.064. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.064. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.064. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.064. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.064. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.064. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.064. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.064. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.063. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.063. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.063. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.063. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.063. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.063. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.063. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.063. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.063. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.062. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.062. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.062. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.062. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.062. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.062. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.062. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.062. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.062. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.062. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.061. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.060. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.059. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.83)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.058. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.057. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.057. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.057. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.057. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.057. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.057. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.057. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.057. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.057. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.057. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.057. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.056. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.056. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.056. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.056. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.056. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.056. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.056. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.056. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.056. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.056. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.055. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.82)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.054. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.053. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.052. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.051. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.051. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.051. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.051. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.051. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.051. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.051. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.051. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.051. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.051. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.051. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.051. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.050. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.049. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.048. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.048. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.048. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.048. (P,R)=(0.51,0.81)\n",
      "Umbral: -0.048. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.048. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.048. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.048. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.048. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.048. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.048. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.048. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.047. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.046. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.045. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.044. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.044. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.044. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.044. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.044. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.044. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.044. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.044. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.044. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.044. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.043. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.80)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.042. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.041. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.040. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.039. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.039. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.039. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.039. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.039. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.039. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.039. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.039. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.039. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.039. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.038. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.79)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.037. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.036. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.035. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.034. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.51,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.52,0.78)\n",
      "Umbral: -0.033. (P,R)=(0.52,0.78)\n",
      "Umbral: -0.032. (P,R)=(0.52,0.78)\n",
      "Umbral: -0.032. (P,R)=(0.52,0.78)\n",
      "Umbral: -0.032. (P,R)=(0.52,0.78)\n",
      "Umbral: -0.032. (P,R)=(0.52,0.78)\n",
      "Umbral: -0.032. (P,R)=(0.52,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.52,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.52,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.52,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.52,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.52,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.52,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.032. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.52,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.031. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.030. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.77)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.029. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.51,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.028. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.027. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.026. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.025. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.024. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.023. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.76)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.022. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.021. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.020. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.019. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.018. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.75)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.017. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.016. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.015. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.014. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.013. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.74)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.012. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.011. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.010. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.009. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.008. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.73)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.007. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.006. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.005. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.004. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.72)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.003. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.002. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.000. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.71)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.001. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.002. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.003. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.53,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.53,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.53,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.53,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.53,0.70)\n",
      "Umbral: 0.004. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.004. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.004. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.005. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.006. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.007. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.52,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.69)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.008. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.009. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.010. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.011. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.68)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.012. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.013. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.014. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.015. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.67)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.016. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.017. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.018. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.019. (P,R)=(0.53,0.66)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.020. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.021. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.022. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.65)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.023. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.024. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.025. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.026. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.64)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.027. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.028. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.029. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.63)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.030. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.031. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.032. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.62)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.033. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.034. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.61)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.035. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.036. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.037. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.60)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.039. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.040. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.041. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.59)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.042. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.043. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.044. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.58)\n",
      "Umbral: 0.045. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.046. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.047. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.048. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.57)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.049. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.050. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.051. (P,R)=(0.53,0.56)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.052. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.053. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.55)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.054. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.055. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.056. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.54)\n",
      "Umbral: 0.057. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.058. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.059. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.53)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.060. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.061. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.062. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.063. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.52)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.064. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.065. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.51)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.066. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.067. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.068. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.069. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.50)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.070. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.071. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.072. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.54,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.54,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.54,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.54,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.54,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.49)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.073. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.073. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.073. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.54,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.074. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.075. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.48)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.076. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.077. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.078. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.47)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.079. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.080. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.081. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.54,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.54,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.54,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.54,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.53,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.54,0.46)\n",
      "Umbral: 0.082. (P,R)=(0.54,0.46)\n",
      "Umbral: 0.083. (P,R)=(0.54,0.46)\n",
      "Umbral: 0.083. (P,R)=(0.54,0.46)\n",
      "Umbral: 0.083. (P,R)=(0.54,0.46)\n",
      "Umbral: 0.083. (P,R)=(0.54,0.46)\n",
      "Umbral: 0.083. (P,R)=(0.54,0.46)\n",
      "Umbral: 0.083. (P,R)=(0.54,0.46)\n",
      "Umbral: 0.083. (P,R)=(0.54,0.46)\n",
      "Umbral: 0.083. (P,R)=(0.54,0.45)\n",
      "Umbral: 0.083. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.083. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.083. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.083. (P,R)=(0.54,0.45)\n",
      "Umbral: 0.083. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.083. (P,R)=(0.54,0.45)\n",
      "Umbral: 0.083. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.083. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.083. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.083. (P,R)=(0.54,0.45)\n",
      "Umbral: 0.083. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.083. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.54,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.084. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.085. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.45)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.086. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.087. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.088. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.44)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.089. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.090. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.091. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.092. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.43)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.093. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.094. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.53,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.095. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.096. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: 0.097. (P,R)=(0.54,0.42)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.097. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.098. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.099. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.100. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.41)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.101. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.102. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.103. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.104. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.40)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.105. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.106. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.107. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.108. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.109. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.109. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.109. (P,R)=(0.54,0.39)\n",
      "Umbral: 0.109. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.109. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.109. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.109. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.109. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.109. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.109. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.110. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.111. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.112. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.38)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.113. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.114. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.115. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.116. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.37)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.117. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.118. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.119. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.120. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.36)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.121. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.122. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.123. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.124. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.35)\n",
      "Umbral: 0.125. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.126. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.127. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.128. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.129. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.34)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.130. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.131. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.132. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.133. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.33)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.134. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.135. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.136. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.137. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.32)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.138. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.139. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.140. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.140. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.140. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.140. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.140. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.140. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.140. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.140. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.140. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.140. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.140. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.140. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.140. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.141. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.55,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.55,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.55,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.55,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.55,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.55,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.55,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.142. (P,R)=(0.55,0.31)\n",
      "Umbral: 0.143. (P,R)=(0.55,0.31)\n",
      "Umbral: 0.143. (P,R)=(0.55,0.31)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.143. (P,R)=(0.55,0.31)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.31)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.143. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.144. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.144. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.144. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.144. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.144. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.144. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.144. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.144. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.144. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.145. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.54,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.55,0.30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: 0.146. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.146. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.147. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.148. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.30)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.149. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.150. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.151. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.152. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.152. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.152. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.152. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.152. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.152. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.152. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.152. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.152. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.152. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.152. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.153. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.153. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.153. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.153. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.153. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.153. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.153. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.153. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.153. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.153. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.153. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.153. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.153. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.29)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.154. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.155. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.155. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.155. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.155. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.155. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.155. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.155. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.155. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.155. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.155. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.155. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.155. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.155. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.156. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.156. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.156. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.156. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.156. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.156. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.156. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.156. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.156. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.156. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.156. (P,R)=(0.54,0.28)\n",
      "Umbral: 0.156. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.54,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.157. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.158. (P,R)=(0.55,0.28)\n",
      "Umbral: 0.159. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.159. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.159. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.159. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.159. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.159. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.159. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.159. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.159. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.159. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.159. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.159. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.159. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.160. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.160. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.160. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.160. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.160. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.160. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.160. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.160. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.160. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.160. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.160. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.160. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.160. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.161. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.161. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.161. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.161. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.161. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.161. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.161. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.161. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.161. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.161. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.161. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.161. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.162. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.162. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.162. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.162. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.162. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.162. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.162. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.162. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.162. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.162. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.162. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.162. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.163. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.54,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.27)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.164. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.165. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.165. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.165. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.165. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.165. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.165. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.165. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.165. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.165. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.166. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.166. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.166. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.166. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.166. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.166. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.166. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.166. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.166. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.166. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.166. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.167. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.167. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.167. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.167. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.167. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.167. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.167. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.167. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.167. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.167. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.167. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.167. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.168. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.168. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.168. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.168. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.168. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.168. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.168. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.168. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.168. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.168. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.168. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.168. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.55,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.169. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.26)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.170. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.171. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.171. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.171. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.171. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.171. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.171. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.171. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.171. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.171. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.171. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.171. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.171. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.172. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.173. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.173. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.173. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.173. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.173. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.173. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.173. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.173. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.173. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.173. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.173. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.173. (P,R)=(0.55,0.25)\n",
      "Umbral: 0.173. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.174. (P,R)=(0.55,0.25)\n",
      "Umbral: 0.174. (P,R)=(0.55,0.25)\n",
      "Umbral: 0.174. (P,R)=(0.55,0.25)\n",
      "Umbral: 0.174. (P,R)=(0.55,0.25)\n",
      "Umbral: 0.174. (P,R)=(0.55,0.25)\n",
      "Umbral: 0.174. (P,R)=(0.55,0.25)\n",
      "Umbral: 0.174. (P,R)=(0.55,0.25)\n",
      "Umbral: 0.174. (P,R)=(0.55,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.55,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.55,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.175. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.176. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.176. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.176. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.176. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.176. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.176. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.176. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.176. (P,R)=(0.54,0.25)\n",
      "Umbral: 0.177. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.177. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.177. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.177. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.177. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.177. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.177. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.177. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.177. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.177. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.178. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.178. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.178. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.178. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.178. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.178. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.178. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.178. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.179. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.55,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.180. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.181. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.181. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.181. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.181. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.181. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.181. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.181. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.181. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.181. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.181. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.181. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.182. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.24)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.183. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.184. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.185. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.185. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.185. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.185. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.185. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.185. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.185. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.185. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.185. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.185. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.185. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.185. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.186. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.187. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.187. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.187. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.187. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.187. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.187. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.187. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.187. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.187. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.187. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.188. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.188. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.188. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.188. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.188. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.188. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.188. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.188. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.188. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.188. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.188. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.188. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.188. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.189. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.189. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.189. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.189. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.189. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.189. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.189. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.189. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.189. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.189. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.189. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.189. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.189. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.190. (P,R)=(0.54,0.23)\n",
      "Umbral: 0.190. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.190. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.190. (P,R)=(0.55,0.23)\n",
      "Umbral: 0.190. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.190. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.190. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.190. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.190. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.190. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.190. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.190. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.191. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.191. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.191. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.191. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.191. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.191. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.191. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.191. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.191. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.191. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.191. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.191. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.192. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.192. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.192. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.192. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.192. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.192. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.192. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.192. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.193. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.193. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.193. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.193. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.193. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.193. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.193. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.193. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.193. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.193. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.193. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.193. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.193. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.194. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.194. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.194. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.194. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.194. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.194. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.194. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.194. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.194. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.194. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.194. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.194. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.195. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.195. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.195. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.195. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.195. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.195. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.195. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.195. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.195. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.195. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.195. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.195. (P,R)=(0.54,0.22)\n",
      "Umbral: 0.196. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.196. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.196. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.196. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.196. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.196. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.196. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.196. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.196. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.196. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.196. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.196. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.196. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.22)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.197. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.198. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.199. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.200. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.200. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.200. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.200. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.200. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.200. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.200. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.200. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.200. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.200. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.200. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.200. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.201. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.201. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.201. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.201. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.201. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.201. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.201. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.201. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.201. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.201. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.201. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.201. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.201. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.202. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.202. (P,R)=(0.54,0.21)\n",
      "Umbral: 0.202. (P,R)=(0.54,0.21)\n",
      "Umbral: 0.202. (P,R)=(0.54,0.21)\n",
      "Umbral: 0.202. (P,R)=(0.55,0.21)\n",
      "Umbral: 0.203. (P,R)=(0.54,0.21)\n",
      "Umbral: 0.203. (P,R)=(0.54,0.21)\n",
      "Umbral: 0.203. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.203. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.203. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.203. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.203. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.203. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.203. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.203. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.203. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.204. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.205. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.205. (P,R)=(0.54,0.20)\n",
      "Umbral: 0.205. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.205. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.205. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.205. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.205. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.205. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.205. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.206. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.206. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.206. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.206. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.206. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.206. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.206. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.206. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.206. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.206. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.206. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.206. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.206. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.207. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.207. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.207. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.207. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.207. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.207. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.207. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.207. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.207. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.207. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.207. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.207. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.207. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.208. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.208. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.208. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.208. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.208. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.208. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.208. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.208. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.208. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.208. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.208. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.20)\n",
      "Umbral: 0.209. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.210. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.210. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.210. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.210. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.210. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.210. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.210. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.210. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.210. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.210. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.210. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.210. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.210. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.211. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.211. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.211. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.211. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.211. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.211. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.211. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.211. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.211. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.212. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.213. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.213. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.213. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.213. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.213. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.213. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.213. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.213. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.213. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.213. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.214. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.214. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.214. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.214. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.214. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.214. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.214. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.214. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.214. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.214. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.215. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.215. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.215. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.215. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.215. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.215. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.215. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.215. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.215. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.215. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.216. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.216. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.216. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.216. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.216. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.216. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.216. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.216. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.216. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.216. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.19)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.217. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.218. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.218. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.218. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.218. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.218. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.218. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.218. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.218. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.218. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.218. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.219. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.219. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.219. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.219. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.219. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.219. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.220. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.220. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.220. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.220. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.220. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.220. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.220. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.220. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.220. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.220. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.221. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.221. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.221. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.221. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.221. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.221. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.221. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.54,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.54,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.54,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.54,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.222. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.223. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.223. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.223. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.223. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.223. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.223. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.223. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.223. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.223. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.223. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.223. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.223. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.223. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.224. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.224. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.224. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.224. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.224. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.224. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.224. (P,R)=(0.55,0.18)\n",
      "Umbral: 0.224. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.224. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.224. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.224. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.225. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.226. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.226. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.226. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.226. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.226. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.226. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.226. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.226. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.226. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.227. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.227. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.227. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.227. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.227. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.227. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.227. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.227. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.227. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.227. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.228. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.228. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.228. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.228. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.228. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.228. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.228. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.228. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.228. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.228. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.229. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.229. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.229. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.229. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.229. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.229. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.229. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.229. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.230. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.230. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.230. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.230. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.230. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.230. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.230. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.230. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.231. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.231. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.231. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.231. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.231. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.231. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.231. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.231. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.231. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.231. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.231. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.231. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.231. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.232. (P,R)=(0.55,0.17)\n",
      "Umbral: 0.232. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.232. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.232. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.232. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.232. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.232. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.232. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.232. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.233. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.233. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.233. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.233. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.233. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.233. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.233. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.233. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.233. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.233. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.233. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.233. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.233. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.234. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.234. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.234. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.234. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.234. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.234. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.234. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.234. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.234. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.234. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.234. (P,R)=(0.55,0.16)\n",
      "Umbral: 0.235. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.235. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.235. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.235. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.235. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.235. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.235. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.236. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.236. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.236. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.236. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.236. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.237. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.237. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.237. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.237. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.237. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.237. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.238. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.238. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.238. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.238. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.238. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.238. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.239. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.239. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.239. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.239. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.239. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.239. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.239. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.239. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.240. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.240. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.240. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.240. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.240. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.240. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.240. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.240. (P,R)=(0.54,0.16)\n",
      "Umbral: 0.241. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.241. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.241. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.241. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.241. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.241. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.241. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.241. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.241. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.241. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.241. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.241. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.242. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.242. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.242. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.242. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.243. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.243. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.243. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.243. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.243. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.243. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.244. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.244. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.244. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.244. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.244. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.244. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.244. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.244. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.244. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.245. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.245. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.245. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.245. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.245. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.245. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.245. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.245. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.246. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.246. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.246. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.247. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.247. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.247. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.247. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.247. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.247. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.247. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.247. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.247. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.247. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.247. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.248. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.248. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.248. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.248. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.248. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.248. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.248. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.248. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.248. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.248. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.249. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.249. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.249. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.249. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.249. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.249. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.249. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.249. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.249. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.249. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.249. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.250. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.250. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.250. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.250. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.250. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.250. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.250. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.250. (P,R)=(0.54,0.15)\n",
      "Umbral: 0.250. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.250. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.251. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.251. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.251. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.251. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.251. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.251. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.251. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.251. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.251. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.252. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.252. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.252. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.252. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.252. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.252. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.252. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.252. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.252. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.253. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.253. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.253. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.253. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.253. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.253. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.254. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.254. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.254. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.254. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.254. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.254. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.254. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.254. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.254. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.254. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.255. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.255. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.255. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.255. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.255. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.255. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.255. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.255. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.255. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.255. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.256. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.256. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.256. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.256. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.256. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.256. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.256. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.256. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.256. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.256. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.257. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.257. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.257. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.258. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.258. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.258. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.258. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.259. (P,R)=(0.54,0.14)\n",
      "Umbral: 0.259. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.259. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.259. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.259. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.259. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.259. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.259. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.260. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.260. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.260. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.260. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.260. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.260. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.260. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.261. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.261. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.261. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.261. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.261. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.262. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.262. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.262. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.262. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.262. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.262. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.262. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.262. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.263. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.263. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.263. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.264. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.264. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.264. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.264. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.264. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.264. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.264. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.264. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.264. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.264. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.264. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.265. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.265. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.265. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.265. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.265. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.265. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.265. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.265. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.265. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.266. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.266. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.266. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.266. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.266. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.266. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.266. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.266. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.267. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.267. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.267. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.267. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.267. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.267. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.267. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.267. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.268. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.268. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.268. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.268. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.268. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.268. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.268. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.268. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.268. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.269. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.269. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.269. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.269. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.269. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.270. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.270. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.270. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.270. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.270. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.270. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.270. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.270. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.270. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.270. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.271. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.271. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.271. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.271. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.271. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.271. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.271. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.271. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.272. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.272. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.272. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.272. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.272. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.272. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.272. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.273. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.273. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.273. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.273. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.273. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.273. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.273. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.274. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.274. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.274. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.274. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.275. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.275. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.275. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.275. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.275. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.276. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.276. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.276. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.276. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.276. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.276. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.276. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.276. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.277. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.277. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.277. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.277. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.277. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.277. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.277. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.278. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.279. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.279. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.279. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.279. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.279. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.279. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.280. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.280. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.280. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.280. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.280. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.281. (P,R)=(0.53,0.11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: 0.281. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.281. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.281. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.281. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.281. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.281. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.282. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.282. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.282. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.282. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.282. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.282. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.283. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.283. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.283. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.283. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.283. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.283. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.283. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.283. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.284. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.284. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.284. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.285. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.285. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.285. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.285. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.285. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.285. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.286. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.286. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.286. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.286. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.286. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.287. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.287. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.287. (P,R)=(0.54,0.11)\n",
      "Umbral: 0.287. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.287. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.288. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.288. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.288. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.288. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.288. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.288. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.288. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.289. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.289. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.289. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.289. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.289. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.289. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.289. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.290. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.290. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.290. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.290. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.290. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.290. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.290. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.291. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.291. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.291. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.291. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.291. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.291. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.291. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.292. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.292. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.292. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.292. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.292. (P,R)=(0.53,0.11)\n",
      "Umbral: 0.292. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.292. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.292. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.293. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.293. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.293. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.293. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.293. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.293. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.293. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.293. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.293. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.293. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.293. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.293. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.294. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.294. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.294. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.294. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.294. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.294. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.294. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.295. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.295. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.295. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.295. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.295. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.296. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.296. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.296. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.296. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.296. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.296. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.296. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.296. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.296. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.296. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.297. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.297. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.297. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.297. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.297. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.297. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.297. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.297. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.297. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.297. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.297. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.297. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.298. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.298. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.298. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.299. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.299. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.299. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.299. (P,R)=(0.54,0.10)\n",
      "Umbral: 0.299. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.299. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.299. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.299. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.299. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.300. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.300. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.300. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.300. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.300. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.300. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.300. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.300. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.301. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.302. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.302. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.302. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.303. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.303. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.303. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.303. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.303. (P,R)=(0.53,0.10)\n",
      "Umbral: 0.303. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.304. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.304. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.304. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.304. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.305. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.305. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.305. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.305. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.305. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.305. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.306. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.306. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.306. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.306. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.306. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.307. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.307. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.307. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.307. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.307. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.307. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.308. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.308. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.308. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.308. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.308. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.309. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.309. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.309. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.309. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.310. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.310. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.311. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.311. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.311. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.312. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.312. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.313. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.313. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.314. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.314. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.314. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.314. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.315. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.315. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.315. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.315. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.315. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.315. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.315. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.316. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.316. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.316. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.316. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.316. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.316. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.316. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.316. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.316. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.316. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.316. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.317. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.317. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.318. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.318. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.318. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.318. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.319. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.319. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.319. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.320. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.320. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.320. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.320. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.321. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.321. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.321. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.322. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.322. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.322. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.322. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.322. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.322. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.322. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.323. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.323. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.323. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.323. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.323. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.324. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.324. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.324. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.324. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.325. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.325. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.325. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.325. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.325. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.326. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.326. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.326. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.327. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.327. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.327. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.327. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.327. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.328. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.328. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.328. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.329. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.329. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.330. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.330. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.330. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.330. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.330. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.331. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.331. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.331. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.331. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.333. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.333. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.333. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.333. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.334. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.334. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.334. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.334. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.334. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.334. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.335. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.336. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.336. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.336. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.336. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.336. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.337. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.337. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.337. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.337. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.337. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.338. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.338. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.339. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.340. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.340. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.340. (P,R)=(0.54,0.08)\n",
      "Umbral: 0.341. (P,R)=(0.54,0.08)\n",
      "Umbral: 0.341. (P,R)=(0.54,0.08)\n",
      "Umbral: 0.341. (P,R)=(0.54,0.08)\n",
      "Umbral: 0.341. (P,R)=(0.54,0.08)\n",
      "Umbral: 0.342. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.342. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.343. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.343. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.343. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.344. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.344. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.344. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.345. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.345. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.345. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.345. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.346. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.346. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.346. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.346. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.346. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.347. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.347. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.347. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.347. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.347. (P,R)=(0.53,0.08)\n",
      "Umbral: 0.347. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.348. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.348. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.348. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.348. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.349. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.349. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.349. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.350. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.350. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.350. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.350. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.350. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.350. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.351. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.351. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.352. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.352. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.352. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.352. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.352. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.352. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.352. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.352. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.352. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.353. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.353. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.354. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.354. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.354. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.354. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.355. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.355. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.355. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.355. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.355. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.355. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.356. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.356. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.356. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.358. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.359. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.359. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.359. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.360. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.361. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.361. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.361. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.362. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.362. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.362. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.362. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.362. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.362. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.363. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.363. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.363. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.363. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.363. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.364. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.364. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.365. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.365. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.365. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.365. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.365. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.366. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.366. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.366. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.366. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.367. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.367. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.367. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.367. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.367. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.367. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.367. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.367. (P,R)=(0.53,0.07)\n",
      "Umbral: 0.368. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.368. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.368. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.368. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.368. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.369. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.369. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.370. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.371. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.371. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.371. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.371. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.372. (P,R)=(0.54,0.07)\n",
      "Umbral: 0.372. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.372. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.372. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.372. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.373. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.373. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.373. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.373. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.374. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.374. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.374. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.374. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.374. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.374. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.374. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.376. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.376. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.376. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.376. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.377. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.377. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.377. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.377. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.378. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.378. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.379. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.379. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.379. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.380. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.381. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.381. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.381. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.381. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.381. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.381. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.382. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.382. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.382. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.383. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.383. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.383. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.384. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.384. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.384. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.384. (P,R)=(0.52,0.06)\n",
      "Umbral: 0.384. (P,R)=(0.52,0.06)\n",
      "Umbral: 0.385. (P,R)=(0.52,0.06)\n",
      "Umbral: 0.385. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.386. (P,R)=(0.52,0.06)\n",
      "Umbral: 0.386. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.386. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.386. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.387. (P,R)=(0.52,0.06)\n",
      "Umbral: 0.388. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.389. (P,R)=(0.52,0.06)\n",
      "Umbral: 0.389. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.389. (P,R)=(0.52,0.06)\n",
      "Umbral: 0.389. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.389. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.389. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.390. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.390. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.390. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.390. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.390. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.391. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.392. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.392. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.392. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.392. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.392. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.393. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.393. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.393. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.393. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.393. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.393. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.393. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.394. (P,R)=(0.53,0.06)\n",
      "Umbral: 0.394. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.394. (P,R)=(0.54,0.06)\n",
      "Umbral: 0.395. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.395. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.395. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.395. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.395. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.396. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.397. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.397. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.398. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.398. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.398. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.398. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.399. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.399. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.399. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.401. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.401. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.401. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.401. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.402. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.403. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.404. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.404. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.404. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.405. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.405. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.405. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.405. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.406. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.408. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.408. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.408. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.409. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.409. (P,R)=(0.54,0.05)\n",
      "Umbral: 0.410. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.410. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.411. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.412. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.412. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.413. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.413. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.414. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.414. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.414. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.415. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.415. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.415. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.416. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.417. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.417. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.418. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.418. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.419. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.419. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.419. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.420. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.420. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.420. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.421. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.421. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.421. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.421. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.422. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.422. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.423. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.423. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.424. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.425. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.425. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.425. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.426. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.426. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.426. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.427. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.427. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.428. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.428. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.428. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.428. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.428. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.429. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.430. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.430. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.430. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.431. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.431. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.431. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.431. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.431. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.432. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.432. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.432. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.434. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.434. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.435. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.435. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.436. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.436. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.436. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.437. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.439. (P,R)=(0.54,0.04)\n",
      "Umbral: 0.439. (P,R)=(0.54,0.04)\n",
      "Umbral: 0.440. (P,R)=(0.54,0.04)\n",
      "Umbral: 0.440. (P,R)=(0.54,0.04)\n",
      "Umbral: 0.441. (P,R)=(0.54,0.04)\n",
      "Umbral: 0.441. (P,R)=(0.54,0.04)\n",
      "Umbral: 0.442. (P,R)=(0.54,0.04)\n",
      "Umbral: 0.442. (P,R)=(0.54,0.04)\n",
      "Umbral: 0.443. (P,R)=(0.54,0.04)\n",
      "Umbral: 0.444. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.444. (P,R)=(0.54,0.04)\n",
      "Umbral: 0.444. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.444. (P,R)=(0.54,0.04)\n",
      "Umbral: 0.444. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.445. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.445. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.445. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.447. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.447. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.447. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.448. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.448. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.450. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.450. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.451. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.453. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.454. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.455. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.455. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.455. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.456. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.456. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.457. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.457. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.458. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.459. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.459. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.459. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.459. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.459. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.460. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.461. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.462. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.462. (P,R)=(0.53,0.04)\n",
      "Umbral: 0.463. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.465. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.465. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.466. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.467. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.468. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.468. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.468. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.469. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.470. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.470. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.470. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.471. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.471. (P,R)=(0.52,0.04)\n",
      "Umbral: 0.472. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.472. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.472. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.473. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.473. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.473. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.474. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.474. (P,R)=(0.51,0.03)\n",
      "Umbral: 0.475. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.476. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.476. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.480. (P,R)=(0.51,0.03)\n",
      "Umbral: 0.480. (P,R)=(0.52,0.03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: 0.480. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.484. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.484. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.484. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.486. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.486. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.487. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.487. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.488. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.488. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.488. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.488. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.488. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.489. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.490. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.491. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.491. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.491. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.492. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.492. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.492. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.493. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.493. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.493. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.494. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.496. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.497. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.497. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.498. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.499. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.499. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.501. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.504. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.505. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.505. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.506. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.507. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.507. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.507. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.509. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.510. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.510. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.510. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.510. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.512. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.513. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.513. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.516. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.516. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.517. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.517. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.519. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.522. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.523. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.524. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.526. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.527. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.527. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.529. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.530. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.531. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.532. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.536. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.536. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.536. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.537. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.542. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.542. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.543. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.544. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.544. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.545. (P,R)=(0.53,0.03)\n",
      "Umbral: 0.545. (P,R)=(0.52,0.03)\n",
      "Umbral: 0.545. (P,R)=(0.52,0.02)\n",
      "Umbral: 0.546. (P,R)=(0.52,0.02)\n",
      "Umbral: 0.546. (P,R)=(0.52,0.02)\n",
      "Umbral: 0.550. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.551. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.552. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.553. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.555. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.555. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.557. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.561. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.561. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.564. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.565. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.565. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.565. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.566. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.566. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.567. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.568. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.569. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.569. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.571. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.571. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.572. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.581. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.582. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.584. (P,R)=(0.52,0.02)\n",
      "Umbral: 0.584. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.584. (P,R)=(0.52,0.02)\n",
      "Umbral: 0.585. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.586. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.587. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.588. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.590. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.592. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.594. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.594. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.595. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.595. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.596. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.597. (P,R)=(0.51,0.02)\n",
      "Umbral: 0.598. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.598. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.599. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.599. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.601. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.601. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.602. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.606. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.608. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.611. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.613. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.616. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.620. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.622. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.622. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.623. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.624. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.626. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.627. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.628. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.631. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.633. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.634. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.635. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.636. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.638. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.639. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.639. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.642. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.642. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.643. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.643. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.645. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.647. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.648. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.648. (P,R)=(0.49,0.02)\n",
      "Umbral: 0.649. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.650. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.651. (P,R)=(0.50,0.01)\n",
      "Umbral: 0.651. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.656. (P,R)=(0.50,0.01)\n",
      "Umbral: 0.657. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.657. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.658. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.658. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.660. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.660. (P,R)=(0.50,0.01)\n",
      "Umbral: 0.661. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.662. (P,R)=(0.50,0.01)\n",
      "Umbral: 0.664. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.666. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.667. (P,R)=(0.48,0.01)\n",
      "Umbral: 0.668. (P,R)=(0.48,0.01)\n",
      "Umbral: 0.669. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.669. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.672. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.676. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.676. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.678. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.681. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.686. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.686. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.687. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.690. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.693. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.695. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.695. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.696. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.698. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.699. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.700. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.702. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.705. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.707. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.709. (P,R)=(0.45,0.01)\n",
      "Umbral: 0.710. (P,R)=(0.45,0.01)\n",
      "Umbral: 0.715. (P,R)=(0.44,0.01)\n",
      "Umbral: 0.717. (P,R)=(0.45,0.01)\n",
      "Umbral: 0.717. (P,R)=(0.44,0.01)\n",
      "Umbral: 0.721. (P,R)=(0.43,0.01)\n",
      "Umbral: 0.723. (P,R)=(0.44,0.01)\n",
      "Umbral: 0.723. (P,R)=(0.43,0.01)\n",
      "Umbral: 0.726. (P,R)=(0.43,0.01)\n",
      "Umbral: 0.730. (P,R)=(0.43,0.01)\n",
      "Umbral: 0.731. (P,R)=(0.44,0.01)\n",
      "Umbral: 0.734. (P,R)=(0.43,0.01)\n",
      "Umbral: 0.734. (P,R)=(0.44,0.01)\n",
      "Umbral: 0.738. (P,R)=(0.44,0.01)\n",
      "Umbral: 0.738. (P,R)=(0.45,0.01)\n",
      "Umbral: 0.739. (P,R)=(0.45,0.01)\n",
      "Umbral: 0.740. (P,R)=(0.44,0.01)\n",
      "Umbral: 0.741. (P,R)=(0.45,0.01)\n",
      "Umbral: 0.746. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.746. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.749. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.753. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.753. (P,R)=(0.48,0.01)\n",
      "Umbral: 0.755. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.755. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.761. (P,R)=(0.50,0.01)\n",
      "Umbral: 0.761. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.772. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.773. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.777. (P,R)=(0.50,0.01)\n",
      "Umbral: 0.778. (P,R)=(0.51,0.01)\n",
      "Umbral: 0.786. (P,R)=(0.52,0.01)\n",
      "Umbral: 0.787. (P,R)=(0.51,0.01)\n",
      "Umbral: 0.788. (P,R)=(0.52,0.01)\n",
      "Umbral: 0.789. (P,R)=(0.51,0.01)\n",
      "Umbral: 0.796. (P,R)=(0.50,0.01)\n",
      "Umbral: 0.797. (P,R)=(0.51,0.01)\n",
      "Umbral: 0.801. (P,R)=(0.50,0.01)\n",
      "Umbral: 0.802. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.804. (P,R)=(0.48,0.01)\n",
      "Umbral: 0.806. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.808. (P,R)=(0.48,0.01)\n",
      "Umbral: 0.809. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.817. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.823. (P,R)=(0.45,0.01)\n",
      "Umbral: 0.825. (P,R)=(0.46,0.01)\n",
      "Umbral: 0.828. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.835. (P,R)=(0.48,0.01)\n",
      "Umbral: 0.843. (P,R)=(0.47,0.01)\n",
      "Umbral: 0.850. (P,R)=(0.48,0.01)\n",
      "Umbral: 0.855. (P,R)=(0.49,0.01)\n",
      "Umbral: 0.860. (P,R)=(0.50,0.01)\n",
      "Umbral: 0.860. (P,R)=(0.51,0.01)\n",
      "Umbral: 0.864. (P,R)=(0.50,0.00)\n",
      "Umbral: 0.871. (P,R)=(0.51,0.00)\n",
      "Umbral: 0.880. (P,R)=(0.50,0.00)\n",
      "Umbral: 0.881. (P,R)=(0.49,0.00)\n",
      "Umbral: 0.881. (P,R)=(0.50,0.00)\n",
      "Umbral: 0.882. (P,R)=(0.49,0.00)\n",
      "Umbral: 0.889. (P,R)=(0.47,0.00)\n",
      "Umbral: 0.906. (P,R)=(0.46,0.00)\n",
      "Umbral: 0.907. (P,R)=(0.44,0.00)\n",
      "Umbral: 0.913. (P,R)=(0.46,0.00)\n",
      "Umbral: 0.918. (P,R)=(0.47,0.00)\n",
      "Umbral: 0.933. (P,R)=(0.45,0.00)\n",
      "Umbral: 0.934. (P,R)=(0.44,0.00)\n",
      "Umbral: 0.954. (P,R)=(0.45,0.00)\n",
      "Umbral: 0.954. (P,R)=(0.47,0.00)\n",
      "Umbral: 0.957. (P,R)=(0.48,0.00)\n",
      "Umbral: 0.961. (P,R)=(0.46,0.00)\n",
      "Umbral: 0.980. (P,R)=(0.44,0.00)\n",
      "Umbral: 0.993. (P,R)=(0.42,0.00)\n",
      "Umbral: 0.995. (P,R)=(0.44,0.00)\n",
      "Umbral: 1.006. (P,R)=(0.46,0.00)\n",
      "Umbral: 1.006. (P,R)=(0.48,0.00)\n",
      "Umbral: 1.011. (P,R)=(0.50,0.00)\n",
      "Umbral: 1.025. (P,R)=(0.52,0.00)\n",
      "Umbral: 1.035. (P,R)=(0.50,0.00)\n",
      "Umbral: 1.041. (P,R)=(0.53,0.00)\n",
      "Umbral: 1.049. (P,R)=(0.56,0.00)\n",
      "Umbral: 1.060. (P,R)=(0.53,0.00)\n",
      "Umbral: 1.102. (P,R)=(0.50,0.00)\n",
      "Umbral: 1.134. (P,R)=(0.53,0.00)\n",
      "Umbral: 1.136. (P,R)=(0.57,0.00)\n",
      "Umbral: 1.138. (P,R)=(0.54,0.00)\n",
      "Umbral: 1.188. (P,R)=(0.50,0.00)\n",
      "Umbral: 1.188. (P,R)=(0.45,0.00)\n",
      "Umbral: 1.194. (P,R)=(0.40,0.00)\n",
      "Umbral: 1.210. (P,R)=(0.44,0.00)\n",
      "Umbral: 1.251. (P,R)=(0.38,0.00)\n",
      "Umbral: 1.287. (P,R)=(0.43,0.00)\n",
      "Umbral: 1.305. (P,R)=(0.50,0.00)\n",
      "Umbral: 1.327. (P,R)=(0.40,0.00)\n",
      "Umbral: 1.335. (P,R)=(0.25,0.00)\n",
      "Umbral: 1.525. (P,R)=(0.33,0.00)\n",
      "Umbral: 1.582. (P,R)=(0.50,0.00)\n",
      "Umbral: 1.618. (P,R)=(0.00,0.00)\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve( testy2, logreg2.decision_function(testX2))\n",
    "for u,p,r in zip(thresholds,precision,recall):\n",
    "    print(\"Umbral: {:.3f}. (P,R)=({:.2f},{:.2f})\".format(u,p,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Curva PR')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(testy2, logreg2.decision_function(testX2))\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10, label=\"umbral cero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.plot(precision, recall)\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Curva PR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Curva ROC')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(testy2, logreg2.decision_function(testX2))\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=7,label=\"umbral cero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.legend(loc=4)\n",
    "plt.title(\"Curva ROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 DIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "run Datos-5diasBINARIO.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 1: MODELO BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.47\n",
      "Tasa de aciertos balanceada regresión logística: 0.49\n",
      "Medida F1 regresión logística: 0.58\n",
      "Matriz de confusión:\n",
      "[[ 44 155]\n",
      " [ 43 134]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 1\n",
    "# -------------------------------------------------------------------\n",
    "logreg1 = LogisticRegression(max_iter=10000).fit(trainX1, trainy1)\n",
    "pred_logreg1 = logreg1.predict(testX1)\n",
    "confusion1 = confusion_matrix(testy1, pred_logreg1)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg1.score(testX1, testy1)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, pred_logreg1)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy1, pred_logreg1)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.51\n",
      "Tasa de aciertos balanceada regresión logística: 0.52\n",
      "Medida F1 regresión logística: 0.56\n",
      "Matriz de confusión:\n",
      "[[ 74 120]\n",
      " [ 58 112]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 2\n",
    "# -------------------------------------------------------------------\n",
    "logreg2 = LogisticRegression(max_iter=10000).fit(trainX2, trainy2)\n",
    "pred_logreg2 = logreg2.predict(testX2)\n",
    "confusion2 = confusion_matrix(testy2, pred_logreg2)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg2.score(testX2, testy2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, pred_logreg2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, pred_logreg2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.52\n",
      "Tasa de aciertos balanceada regresión logística: 0.52\n",
      "Medida F1 regresión logística: 0.50\n",
      "Matriz de confusión:\n",
      "[[97 93]\n",
      " [81 88]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 3\n",
    "# -------------------------------------------------------------------\n",
    "logreg3 = LogisticRegression(max_iter=10000).fit(trainX3, trainy3)\n",
    "pred_logreg3 = logreg3.predict(testX3)\n",
    "confusion = confusion_matrix(testy3, pred_logreg3)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg3.score(testX3, testy3)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, pred_logreg3)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy3, pred_logreg3)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 1: GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, penalty='none')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 1\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid1 = LogisticRegression()\n",
    "parameters1 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"none\",\"l2\"]}\n",
    "grid1 = GridSearchCV(modelgrid1,parameters1, cv=None).fit(trainX1, trainy1)\n",
    "grid1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    }
   ],
   "source": [
    "lrgrid1 = LogisticRegression(C=0.001, penalty='none').fit(trainX1, trainy1)\n",
    "y_predg1 = lrgrid1.predict(testX1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.47\n",
      "Tasa de aciertos balanceada regresión logística: 0.49\n",
      "Medida F1 regresión logística: 0.58\n",
      "Matriz de confusión:\n",
      "[[ 44 155]\n",
      " [ 43 134]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid1 = lrgrid1.predict(testX1)\n",
    "confusiong1 = confusion_matrix(testy1, pred_lrgrid1)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid1.score(testX1, testy1)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, pred_logreg1)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy1, pred_logreg1)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 2\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid2 = LogisticRegression()\n",
    "parameters2 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"none\",\"l2\"]}\n",
    "grid2 = GridSearchCV(modelgrid2,parameters2, cv=None).fit(trainX2, trainy2)\n",
    "grid2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lrgrid2 = LogisticRegression(C=0.001).fit(trainX2, trainy2)\n",
    "y_predg2 = lrgrid2.predict(testX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.54\n",
      "Tasa de aciertos balanceada regresión logística: 0.52\n",
      "Medida F1 regresión logística: 0.56\n",
      "Matriz de confusión:\n",
      "[[ 75 119]\n",
      " [ 50 120]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid2 = lrgrid2.predict(testX2)\n",
    "confusiong2 = confusion_matrix(testy2, pred_lrgrid2)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid2.score(testX2, testy2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, pred_logreg2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, pred_logreg2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.52577913        nan 0.516732          nan 0.52230207        nan\n",
      " 0.5243854         nan 0.52021148        nan 0.52300377        nan\n",
      " 0.51672958        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 3\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid3 = LogisticRegression()\n",
    "parameters3 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\",None]}\n",
    "grid3 = GridSearchCV(modelgrid3,parameters3, cv=None).fit(trainX3, trainy3)\n",
    "grid3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lrgrid3 = LogisticRegression(C=0.001).fit(trainX3, trainy3)\n",
    "y_predg3 = lrgrid3.predict(testX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.50\n",
      "Tasa de aciertos balanceada regresión logística: 0.52\n",
      "Medida F1 regresión logística: 0.50\n",
      "Matriz de confusión:\n",
      "[[ 73 117]\n",
      " [ 64 105]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid3 = lrgrid3.predict(testX3)\n",
    "confusiong3 = confusion_matrix(testy3, pred_lrgrid3)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid3.score(testX3, testy3)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, pred_logreg3)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy3, pred_logreg3)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejora Modelo GridSearch- Conjunto de datos 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando la incertidumbre en las predicciones: umbrales y curvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    877\n",
       "1.0    942\n",
       "Name: Subida, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy2.value_counts() + trainy2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Baja       0.60      0.39      0.47       194\n",
      "        Sube       0.50      0.71      0.59       170\n",
      "\n",
      "    accuracy                           0.54       364\n",
      "   macro avg       0.55      0.55      0.53       364\n",
      "weighted avg       0.55      0.54      0.52       364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testy2, pred_lrgrid2,target_names=[\"Baja\", \"Sube\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[ 75 119]\n",
      " [ 50 120]]\n"
     ]
    }
   ],
   "source": [
    "confusion2 = confusion_matrix(testy2, pred_lrgrid2)\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lower_threshold2 = lrgrid2.decision_function(testX2) > 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos balanceada regresión logística: 0.54\n",
      "Tasa de aciertos balanceada regresión logística: 0.55\n",
      "Medida F1 regresión logística: 0.59\n",
      "Matriz de confusión:\n",
      "[[ 75 119]\n",
      " [ 50 120]]\n"
     ]
    }
   ],
   "source": [
    "confusiongumbral = confusion_matrix(testy2, y_pred_lower_threshold2)\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(accuracy_score(testy2, y_pred_lower_threshold2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_pred_lower_threshold2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, y_pred_lower_threshold2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiongumbral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: -0.740. (P,R)=(0.47,1.00)\n",
      "Umbral: -0.715. (P,R)=(0.47,0.99)\n",
      "Umbral: -0.625. (P,R)=(0.47,0.99)\n",
      "Umbral: -0.615. (P,R)=(0.46,0.98)\n",
      "Umbral: -0.596. (P,R)=(0.46,0.98)\n",
      "Umbral: -0.583. (P,R)=(0.46,0.98)\n",
      "Umbral: -0.568. (P,R)=(0.46,0.98)\n",
      "Umbral: -0.552. (P,R)=(0.46,0.97)\n",
      "Umbral: -0.545. (P,R)=(0.46,0.96)\n",
      "Umbral: -0.513. (P,R)=(0.46,0.96)\n",
      "Umbral: -0.481. (P,R)=(0.46,0.96)\n",
      "Umbral: -0.478. (P,R)=(0.46,0.96)\n",
      "Umbral: -0.467. (P,R)=(0.46,0.96)\n",
      "Umbral: -0.438. (P,R)=(0.47,0.96)\n",
      "Umbral: -0.432. (P,R)=(0.47,0.96)\n",
      "Umbral: -0.425. (P,R)=(0.47,0.96)\n",
      "Umbral: -0.416. (P,R)=(0.47,0.95)\n",
      "Umbral: -0.415. (P,R)=(0.47,0.95)\n",
      "Umbral: -0.374. (P,R)=(0.47,0.95)\n",
      "Umbral: -0.369. (P,R)=(0.47,0.94)\n",
      "Umbral: -0.364. (P,R)=(0.47,0.94)\n",
      "Umbral: -0.357. (P,R)=(0.46,0.94)\n",
      "Umbral: -0.356. (P,R)=(0.46,0.93)\n",
      "Umbral: -0.353. (P,R)=(0.46,0.93)\n",
      "Umbral: -0.346. (P,R)=(0.47,0.93)\n",
      "Umbral: -0.345. (P,R)=(0.47,0.93)\n",
      "Umbral: -0.339. (P,R)=(0.47,0.93)\n",
      "Umbral: -0.326. (P,R)=(0.47,0.93)\n",
      "Umbral: -0.325. (P,R)=(0.47,0.93)\n",
      "Umbral: -0.312. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.306. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.299. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.293. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.285. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.284. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.281. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.276. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.269. (P,R)=(0.48,0.91)\n",
      "Umbral: -0.265. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.256. (P,R)=(0.48,0.91)\n",
      "Umbral: -0.255. (P,R)=(0.47,0.90)\n",
      "Umbral: -0.254. (P,R)=(0.47,0.89)\n",
      "Umbral: -0.250. (P,R)=(0.47,0.89)\n",
      "Umbral: -0.249. (P,R)=(0.47,0.89)\n",
      "Umbral: -0.244. (P,R)=(0.47,0.89)\n",
      "Umbral: -0.241. (P,R)=(0.47,0.89)\n",
      "Umbral: -0.239. (P,R)=(0.48,0.89)\n",
      "Umbral: -0.237. (P,R)=(0.47,0.88)\n",
      "Umbral: -0.228. (P,R)=(0.48,0.88)\n",
      "Umbral: -0.228. (P,R)=(0.47,0.88)\n",
      "Umbral: -0.225. (P,R)=(0.47,0.87)\n",
      "Umbral: -0.221. (P,R)=(0.47,0.86)\n",
      "Umbral: -0.213. (P,R)=(0.47,0.86)\n",
      "Umbral: -0.210. (P,R)=(0.47,0.86)\n",
      "Umbral: -0.210. (P,R)=(0.47,0.85)\n",
      "Umbral: -0.203. (P,R)=(0.47,0.85)\n",
      "Umbral: -0.202. (P,R)=(0.47,0.85)\n",
      "Umbral: -0.201. (P,R)=(0.47,0.85)\n",
      "Umbral: -0.199. (P,R)=(0.48,0.85)\n",
      "Umbral: -0.194. (P,R)=(0.47,0.85)\n",
      "Umbral: -0.188. (P,R)=(0.47,0.84)\n",
      "Umbral: -0.174. (P,R)=(0.47,0.84)\n",
      "Umbral: -0.169. (P,R)=(0.47,0.84)\n",
      "Umbral: -0.168. (P,R)=(0.47,0.83)\n",
      "Umbral: -0.165. (P,R)=(0.47,0.83)\n",
      "Umbral: -0.154. (P,R)=(0.47,0.83)\n",
      "Umbral: -0.149. (P,R)=(0.47,0.82)\n",
      "Umbral: -0.144. (P,R)=(0.47,0.82)\n",
      "Umbral: -0.142. (P,R)=(0.47,0.82)\n",
      "Umbral: -0.140. (P,R)=(0.47,0.82)\n",
      "Umbral: -0.139. (P,R)=(0.47,0.82)\n",
      "Umbral: -0.138. (P,R)=(0.47,0.81)\n",
      "Umbral: -0.138. (P,R)=(0.47,0.81)\n",
      "Umbral: -0.132. (P,R)=(0.48,0.81)\n",
      "Umbral: -0.132. (P,R)=(0.47,0.81)\n",
      "Umbral: -0.123. (P,R)=(0.48,0.81)\n",
      "Umbral: -0.123. (P,R)=(0.48,0.81)\n",
      "Umbral: -0.122. (P,R)=(0.48,0.80)\n",
      "Umbral: -0.121. (P,R)=(0.47,0.79)\n",
      "Umbral: -0.118. (P,R)=(0.48,0.79)\n",
      "Umbral: -0.115. (P,R)=(0.47,0.79)\n",
      "Umbral: -0.112. (P,R)=(0.48,0.79)\n",
      "Umbral: -0.112. (P,R)=(0.48,0.79)\n",
      "Umbral: -0.111. (P,R)=(0.48,0.79)\n",
      "Umbral: -0.106. (P,R)=(0.48,0.78)\n",
      "Umbral: -0.102. (P,R)=(0.48,0.78)\n",
      "Umbral: -0.101. (P,R)=(0.48,0.78)\n",
      "Umbral: -0.099. (P,R)=(0.48,0.78)\n",
      "Umbral: -0.098. (P,R)=(0.48,0.77)\n",
      "Umbral: -0.088. (P,R)=(0.48,0.77)\n",
      "Umbral: -0.088. (P,R)=(0.48,0.77)\n",
      "Umbral: -0.085. (P,R)=(0.48,0.76)\n",
      "Umbral: -0.084. (P,R)=(0.48,0.76)\n",
      "Umbral: -0.081. (P,R)=(0.48,0.76)\n",
      "Umbral: -0.075. (P,R)=(0.48,0.76)\n",
      "Umbral: -0.068. (P,R)=(0.48,0.75)\n",
      "Umbral: -0.067. (P,R)=(0.48,0.75)\n",
      "Umbral: -0.063. (P,R)=(0.48,0.75)\n",
      "Umbral: -0.061. (P,R)=(0.48,0.75)\n",
      "Umbral: -0.061. (P,R)=(0.48,0.75)\n",
      "Umbral: -0.059. (P,R)=(0.48,0.74)\n",
      "Umbral: -0.058. (P,R)=(0.48,0.74)\n",
      "Umbral: -0.058. (P,R)=(0.48,0.74)\n",
      "Umbral: -0.057. (P,R)=(0.48,0.73)\n",
      "Umbral: -0.056. (P,R)=(0.47,0.72)\n",
      "Umbral: -0.053. (P,R)=(0.48,0.72)\n",
      "Umbral: -0.053. (P,R)=(0.48,0.72)\n",
      "Umbral: -0.050. (P,R)=(0.48,0.72)\n",
      "Umbral: -0.043. (P,R)=(0.48,0.72)\n",
      "Umbral: -0.041. (P,R)=(0.48,0.72)\n",
      "Umbral: -0.034. (P,R)=(0.49,0.72)\n",
      "Umbral: -0.034. (P,R)=(0.49,0.72)\n",
      "Umbral: -0.031. (P,R)=(0.49,0.72)\n",
      "Umbral: -0.031. (P,R)=(0.49,0.72)\n",
      "Umbral: -0.028. (P,R)=(0.49,0.71)\n",
      "Umbral: -0.025. (P,R)=(0.48,0.71)\n",
      "Umbral: -0.021. (P,R)=(0.49,0.71)\n",
      "Umbral: -0.011. (P,R)=(0.49,0.71)\n",
      "Umbral: -0.010. (P,R)=(0.49,0.71)\n",
      "Umbral: -0.008. (P,R)=(0.49,0.71)\n",
      "Umbral: -0.006. (P,R)=(0.49,0.71)\n",
      "Umbral: -0.004. (P,R)=(0.50,0.71)\n",
      "Umbral: -0.001. (P,R)=(0.50,0.71)\n",
      "Umbral: -0.000. (P,R)=(0.50,0.71)\n",
      "Umbral: 0.001. (P,R)=(0.50,0.71)\n",
      "Umbral: 0.002. (P,R)=(0.50,0.71)\n",
      "Umbral: 0.005. (P,R)=(0.50,0.70)\n",
      "Umbral: 0.008. (P,R)=(0.50,0.69)\n",
      "Umbral: 0.009. (P,R)=(0.50,0.69)\n",
      "Umbral: 0.010. (P,R)=(0.50,0.69)\n",
      "Umbral: 0.012. (P,R)=(0.51,0.69)\n",
      "Umbral: 0.016. (P,R)=(0.51,0.69)\n",
      "Umbral: 0.016. (P,R)=(0.51,0.69)\n",
      "Umbral: 0.020. (P,R)=(0.50,0.68)\n",
      "Umbral: 0.023. (P,R)=(0.50,0.68)\n",
      "Umbral: 0.029. (P,R)=(0.50,0.68)\n",
      "Umbral: 0.031. (P,R)=(0.50,0.67)\n",
      "Umbral: 0.033. (P,R)=(0.50,0.66)\n",
      "Umbral: 0.035. (P,R)=(0.50,0.66)\n",
      "Umbral: 0.039. (P,R)=(0.50,0.65)\n",
      "Umbral: 0.041. (P,R)=(0.50,0.65)\n",
      "Umbral: 0.041. (P,R)=(0.50,0.65)\n",
      "Umbral: 0.046. (P,R)=(0.49,0.64)\n",
      "Umbral: 0.047. (P,R)=(0.49,0.64)\n",
      "Umbral: 0.047. (P,R)=(0.49,0.64)\n",
      "Umbral: 0.053. (P,R)=(0.49,0.63)\n",
      "Umbral: 0.054. (P,R)=(0.49,0.62)\n",
      "Umbral: 0.055. (P,R)=(0.49,0.62)\n",
      "Umbral: 0.057. (P,R)=(0.48,0.61)\n",
      "Umbral: 0.058. (P,R)=(0.49,0.61)\n",
      "Umbral: 0.058. (P,R)=(0.49,0.61)\n",
      "Umbral: 0.060. (P,R)=(0.49,0.61)\n",
      "Umbral: 0.062. (P,R)=(0.49,0.61)\n",
      "Umbral: 0.073. (P,R)=(0.50,0.61)\n",
      "Umbral: 0.074. (P,R)=(0.49,0.61)\n",
      "Umbral: 0.076. (P,R)=(0.49,0.60)\n",
      "Umbral: 0.076. (P,R)=(0.49,0.59)\n",
      "Umbral: 0.077. (P,R)=(0.49,0.59)\n",
      "Umbral: 0.080. (P,R)=(0.48,0.58)\n",
      "Umbral: 0.081. (P,R)=(0.49,0.58)\n",
      "Umbral: 0.081. (P,R)=(0.49,0.58)\n",
      "Umbral: 0.082. (P,R)=(0.49,0.58)\n",
      "Umbral: 0.085. (P,R)=(0.49,0.58)\n",
      "Umbral: 0.087. (P,R)=(0.49,0.58)\n",
      "Umbral: 0.088. (P,R)=(0.49,0.58)\n",
      "Umbral: 0.089. (P,R)=(0.49,0.57)\n",
      "Umbral: 0.092. (P,R)=(0.49,0.57)\n",
      "Umbral: 0.095. (P,R)=(0.49,0.56)\n",
      "Umbral: 0.096. (P,R)=(0.49,0.56)\n",
      "Umbral: 0.097. (P,R)=(0.48,0.55)\n",
      "Umbral: 0.098. (P,R)=(0.49,0.55)\n",
      "Umbral: 0.098. (P,R)=(0.48,0.55)\n",
      "Umbral: 0.098. (P,R)=(0.48,0.54)\n",
      "Umbral: 0.102. (P,R)=(0.48,0.54)\n",
      "Umbral: 0.103. (P,R)=(0.48,0.54)\n",
      "Umbral: 0.112. (P,R)=(0.48,0.53)\n",
      "Umbral: 0.112. (P,R)=(0.48,0.52)\n",
      "Umbral: 0.114. (P,R)=(0.47,0.52)\n",
      "Umbral: 0.116. (P,R)=(0.47,0.51)\n",
      "Umbral: 0.117. (P,R)=(0.47,0.51)\n",
      "Umbral: 0.122. (P,R)=(0.46,0.50)\n",
      "Umbral: 0.130. (P,R)=(0.47,0.50)\n",
      "Umbral: 0.130. (P,R)=(0.46,0.49)\n",
      "Umbral: 0.131. (P,R)=(0.47,0.49)\n",
      "Umbral: 0.132. (P,R)=(0.46,0.49)\n",
      "Umbral: 0.134. (P,R)=(0.47,0.49)\n",
      "Umbral: 0.134. (P,R)=(0.46,0.48)\n",
      "Umbral: 0.137. (P,R)=(0.46,0.48)\n",
      "Umbral: 0.141. (P,R)=(0.46,0.47)\n",
      "Umbral: 0.141. (P,R)=(0.45,0.46)\n",
      "Umbral: 0.142. (P,R)=(0.45,0.46)\n",
      "Umbral: 0.143. (P,R)=(0.45,0.46)\n",
      "Umbral: 0.145. (P,R)=(0.45,0.45)\n",
      "Umbral: 0.152. (P,R)=(0.45,0.45)\n",
      "Umbral: 0.153. (P,R)=(0.46,0.45)\n",
      "Umbral: 0.155. (P,R)=(0.45,0.45)\n",
      "Umbral: 0.155. (P,R)=(0.46,0.45)\n",
      "Umbral: 0.159. (P,R)=(0.46,0.45)\n",
      "Umbral: 0.162. (P,R)=(0.46,0.45)\n",
      "Umbral: 0.164. (P,R)=(0.46,0.44)\n",
      "Umbral: 0.169. (P,R)=(0.46,0.44)\n",
      "Umbral: 0.174. (P,R)=(0.46,0.44)\n",
      "Umbral: 0.178. (P,R)=(0.45,0.43)\n",
      "Umbral: 0.178. (P,R)=(0.46,0.43)\n",
      "Umbral: 0.192. (P,R)=(0.45,0.42)\n",
      "Umbral: 0.195. (P,R)=(0.46,0.42)\n",
      "Umbral: 0.198. (P,R)=(0.45,0.42)\n",
      "Umbral: 0.198. (P,R)=(0.46,0.42)\n",
      "Umbral: 0.198. (P,R)=(0.46,0.42)\n",
      "Umbral: 0.199. (P,R)=(0.46,0.42)\n",
      "Umbral: 0.210. (P,R)=(0.46,0.42)\n",
      "Umbral: 0.210. (P,R)=(0.46,0.41)\n",
      "Umbral: 0.216. (P,R)=(0.46,0.41)\n",
      "Umbral: 0.217. (P,R)=(0.45,0.40)\n",
      "Umbral: 0.221. (P,R)=(0.46,0.40)\n",
      "Umbral: 0.222. (P,R)=(0.46,0.40)\n",
      "Umbral: 0.230. (P,R)=(0.46,0.40)\n",
      "Umbral: 0.236. (P,R)=(0.46,0.39)\n",
      "Umbral: 0.240. (P,R)=(0.46,0.39)\n",
      "Umbral: 0.241. (P,R)=(0.47,0.39)\n",
      "Umbral: 0.241. (P,R)=(0.46,0.39)\n",
      "Umbral: 0.242. (P,R)=(0.46,0.38)\n",
      "Umbral: 0.243. (P,R)=(0.46,0.38)\n",
      "Umbral: 0.244. (P,R)=(0.46,0.38)\n",
      "Umbral: 0.244. (P,R)=(0.45,0.37)\n",
      "Umbral: 0.244. (P,R)=(0.45,0.36)\n",
      "Umbral: 0.245. (P,R)=(0.45,0.36)\n",
      "Umbral: 0.246. (P,R)=(0.46,0.36)\n",
      "Umbral: 0.249. (P,R)=(0.45,0.36)\n",
      "Umbral: 0.253. (P,R)=(0.45,0.35)\n",
      "Umbral: 0.257. (P,R)=(0.45,0.35)\n",
      "Umbral: 0.257. (P,R)=(0.45,0.35)\n",
      "Umbral: 0.259. (P,R)=(0.46,0.35)\n",
      "Umbral: 0.260. (P,R)=(0.46,0.35)\n",
      "Umbral: 0.263. (P,R)=(0.46,0.35)\n",
      "Umbral: 0.268. (P,R)=(0.45,0.34)\n",
      "Umbral: 0.270. (P,R)=(0.45,0.34)\n",
      "Umbral: 0.272. (P,R)=(0.44,0.33)\n",
      "Umbral: 0.276. (P,R)=(0.45,0.33)\n",
      "Umbral: 0.281. (P,R)=(0.44,0.32)\n",
      "Umbral: 0.281. (P,R)=(0.44,0.32)\n",
      "Umbral: 0.282. (P,R)=(0.43,0.31)\n",
      "Umbral: 0.291. (P,R)=(0.44,0.31)\n",
      "Umbral: 0.310. (P,R)=(0.43,0.31)\n",
      "Umbral: 0.311. (P,R)=(0.44,0.31)\n",
      "Umbral: 0.312. (P,R)=(0.43,0.30)\n",
      "Umbral: 0.315. (P,R)=(0.43,0.29)\n",
      "Umbral: 0.315. (P,R)=(0.42,0.29)\n",
      "Umbral: 0.317. (P,R)=(0.43,0.29)\n",
      "Umbral: 0.318. (P,R)=(0.43,0.29)\n",
      "Umbral: 0.318. (P,R)=(0.42,0.28)\n",
      "Umbral: 0.321. (P,R)=(0.43,0.28)\n",
      "Umbral: 0.322. (P,R)=(0.43,0.28)\n",
      "Umbral: 0.324. (P,R)=(0.43,0.28)\n",
      "Umbral: 0.326. (P,R)=(0.43,0.28)\n",
      "Umbral: 0.335. (P,R)=(0.44,0.28)\n",
      "Umbral: 0.339. (P,R)=(0.44,0.28)\n",
      "Umbral: 0.339. (P,R)=(0.44,0.28)\n",
      "Umbral: 0.343. (P,R)=(0.45,0.28)\n",
      "Umbral: 0.343. (P,R)=(0.45,0.28)\n",
      "Umbral: 0.345. (P,R)=(0.45,0.27)\n",
      "Umbral: 0.346. (P,R)=(0.45,0.27)\n",
      "Umbral: 0.352. (P,R)=(0.45,0.26)\n",
      "Umbral: 0.353. (P,R)=(0.45,0.26)\n",
      "Umbral: 0.355. (P,R)=(0.44,0.26)\n",
      "Umbral: 0.362. (P,R)=(0.45,0.26)\n",
      "Umbral: 0.365. (P,R)=(0.44,0.25)\n",
      "Umbral: 0.366. (P,R)=(0.44,0.25)\n",
      "Umbral: 0.373. (P,R)=(0.43,0.24)\n",
      "Umbral: 0.376. (P,R)=(0.43,0.24)\n",
      "Umbral: 0.379. (P,R)=(0.43,0.24)\n",
      "Umbral: 0.381. (P,R)=(0.42,0.23)\n",
      "Umbral: 0.382. (P,R)=(0.43,0.23)\n",
      "Umbral: 0.383. (P,R)=(0.43,0.23)\n",
      "Umbral: 0.397. (P,R)=(0.44,0.23)\n",
      "Umbral: 0.397. (P,R)=(0.43,0.22)\n",
      "Umbral: 0.399. (P,R)=(0.44,0.22)\n",
      "Umbral: 0.405. (P,R)=(0.43,0.22)\n",
      "Umbral: 0.405. (P,R)=(0.42,0.21)\n",
      "Umbral: 0.407. (P,R)=(0.42,0.21)\n",
      "Umbral: 0.408. (P,R)=(0.41,0.20)\n",
      "Umbral: 0.413. (P,R)=(0.41,0.20)\n",
      "Umbral: 0.415. (P,R)=(0.42,0.20)\n",
      "Umbral: 0.418. (P,R)=(0.41,0.19)\n",
      "Umbral: 0.418. (P,R)=(0.42,0.19)\n",
      "Umbral: 0.422. (P,R)=(0.41,0.19)\n",
      "Umbral: 0.423. (P,R)=(0.42,0.19)\n",
      "Umbral: 0.425. (P,R)=(0.41,0.18)\n",
      "Umbral: 0.439. (P,R)=(0.40,0.18)\n",
      "Umbral: 0.443. (P,R)=(0.41,0.18)\n",
      "Umbral: 0.444. (P,R)=(0.41,0.18)\n",
      "Umbral: 0.447. (P,R)=(0.42,0.18)\n",
      "Umbral: 0.452. (P,R)=(0.42,0.18)\n",
      "Umbral: 0.457. (P,R)=(0.41,0.17)\n",
      "Umbral: 0.462. (P,R)=(0.42,0.17)\n",
      "Umbral: 0.470. (P,R)=(0.43,0.17)\n",
      "Umbral: 0.471. (P,R)=(0.43,0.17)\n",
      "Umbral: 0.475. (P,R)=(0.44,0.17)\n",
      "Umbral: 0.475. (P,R)=(0.45,0.17)\n",
      "Umbral: 0.475. (P,R)=(0.45,0.17)\n",
      "Umbral: 0.478. (P,R)=(0.44,0.16)\n",
      "Umbral: 0.484. (P,R)=(0.45,0.16)\n",
      "Umbral: 0.490. (P,R)=(0.44,0.16)\n",
      "Umbral: 0.492. (P,R)=(0.45,0.16)\n",
      "Umbral: 0.498. (P,R)=(0.44,0.15)\n",
      "Umbral: 0.498. (P,R)=(0.45,0.15)\n",
      "Umbral: 0.511. (P,R)=(0.46,0.15)\n",
      "Umbral: 0.514. (P,R)=(0.45,0.15)\n",
      "Umbral: 0.518. (P,R)=(0.45,0.15)\n",
      "Umbral: 0.526. (P,R)=(0.46,0.15)\n",
      "Umbral: 0.529. (P,R)=(0.47,0.15)\n",
      "Umbral: 0.534. (P,R)=(0.48,0.15)\n",
      "Umbral: 0.541. (P,R)=(0.49,0.15)\n",
      "Umbral: 0.541. (P,R)=(0.50,0.15)\n",
      "Umbral: 0.542. (P,R)=(0.51,0.15)\n",
      "Umbral: 0.545. (P,R)=(0.52,0.15)\n",
      "Umbral: 0.549. (P,R)=(0.51,0.14)\n",
      "Umbral: 0.559. (P,R)=(0.52,0.14)\n",
      "Umbral: 0.563. (P,R)=(0.53,0.14)\n",
      "Umbral: 0.567. (P,R)=(0.55,0.14)\n",
      "Umbral: 0.574. (P,R)=(0.53,0.14)\n",
      "Umbral: 0.576. (P,R)=(0.52,0.13)\n",
      "Umbral: 0.586. (P,R)=(0.51,0.12)\n",
      "Umbral: 0.587. (P,R)=(0.50,0.12)\n",
      "Umbral: 0.588. (P,R)=(0.51,0.12)\n",
      "Umbral: 0.590. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.596. (P,R)=(0.51,0.11)\n",
      "Umbral: 0.596. (P,R)=(0.50,0.11)\n",
      "Umbral: 0.598. (P,R)=(0.51,0.11)\n",
      "Umbral: 0.611. (P,R)=(0.50,0.10)\n",
      "Umbral: 0.616. (P,R)=(0.48,0.09)\n",
      "Umbral: 0.621. (P,R)=(0.47,0.09)\n",
      "Umbral: 0.626. (P,R)=(0.48,0.09)\n",
      "Umbral: 0.626. (P,R)=(0.50,0.09)\n",
      "Umbral: 0.639. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.644. (P,R)=(0.54,0.09)\n",
      "Umbral: 0.651. (P,R)=(0.52,0.08)\n",
      "Umbral: 0.671. (P,R)=(0.54,0.08)\n",
      "Umbral: 0.704. (P,R)=(0.52,0.08)\n",
      "Umbral: 0.708. (P,R)=(0.54,0.08)\n",
      "Umbral: 0.714. (P,R)=(0.57,0.08)\n",
      "Umbral: 0.715. (P,R)=(0.59,0.08)\n",
      "Umbral: 0.741. (P,R)=(0.62,0.08)\n",
      "Umbral: 0.746. (P,R)=(0.60,0.07)\n",
      "Umbral: 0.766. (P,R)=(0.58,0.06)\n",
      "Umbral: 0.771. (P,R)=(0.56,0.06)\n",
      "Umbral: 0.794. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.810. (P,R)=(0.56,0.05)\n",
      "Umbral: 0.853. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.857. (P,R)=(0.50,0.04)\n",
      "Umbral: 0.860. (P,R)=(0.54,0.04)\n",
      "Umbral: 0.880. (P,R)=(0.50,0.04)\n",
      "Umbral: 0.886. (P,R)=(0.55,0.04)\n",
      "Umbral: 0.892. (P,R)=(0.60,0.04)\n",
      "Umbral: 0.898. (P,R)=(0.56,0.03)\n",
      "Umbral: 0.925. (P,R)=(0.50,0.02)\n",
      "Umbral: 0.987. (P,R)=(0.43,0.02)\n",
      "Umbral: 0.992. (P,R)=(0.33,0.01)\n",
      "Umbral: 1.038. (P,R)=(0.20,0.01)\n",
      "Umbral: 1.100. (P,R)=(0.25,0.01)\n",
      "Umbral: 1.147. (P,R)=(0.33,0.01)\n",
      "Umbral: 1.223. (P,R)=(0.50,0.01)\n",
      "Umbral: 1.598. (P,R)=(0.00,0.00)\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve( testy2, lrgrid2.decision_function(testX2))\n",
    "for u,p,r in zip(thresholds,precision,recall):\n",
    "    print(\"Umbral: {:.3f}. (P,R)=({:.2f},{:.2f})\".format(u,p,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Curva PR')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(testy2, lrgrid2.decision_function(testX2))\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10, label=\"umbral cero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.plot(precision, recall)\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Curva PR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Curva ROC')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(testy2, lrgrid2.decision_function(testX2))\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=7,label=\"umbral cero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.legend(loc=4)\n",
    "plt.title(\"Curva ROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 DIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "run Datos-10diasBINARIO.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 1: MODELO BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.49\n",
      "Tasa de aciertos balanceada regresión logística: 0.51\n",
      "Medida F1 regresión logística: 0.61\n",
      "Matriz de confusión:\n",
      "[[ 37 162]\n",
      " [ 28 148]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 1\n",
    "# -------------------------------------------------------------------\n",
    "logreg1 = LogisticRegression(max_iter=10000).fit(trainX1, trainy1)\n",
    "pred_logreg1 = logreg1.predict(testX1)\n",
    "confusion1 = confusion_matrix(testy1, pred_logreg1)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg1.score(testX1, testy1)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, pred_logreg1)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy1, pred_logreg1)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.48\n",
      "Tasa de aciertos balanceada regresión logística: 0.49\n",
      "Medida F1 regresión logística: 0.53\n",
      "Matriz de confusión:\n",
      "[[ 66 125]\n",
      " [ 64 107]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 2\n",
    "# -------------------------------------------------------------------\n",
    "logreg2 = LogisticRegression(max_iter=10000).fit(trainX2, trainy2)\n",
    "pred_logreg2 = logreg2.predict(testX2)\n",
    "confusion2 = confusion_matrix(testy2, pred_logreg2)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg2.score(testX2, testy2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, pred_logreg2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, pred_logreg2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.51\n",
      "Tasa de aciertos balanceada regresión logística: 0.50\n",
      "Medida F1 regresión logística: 0.39\n",
      "Matriz de confusión:\n",
      "[[124  63]\n",
      " [113  56]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 3\n",
    "# -------------------------------------------------------------------\n",
    "logreg3 = LogisticRegression(max_iter=10000).fit(trainX3, trainy3)\n",
    "pred_logreg3 = logreg3.predict(testX3)\n",
    "confusion = confusion_matrix(testy3, pred_logreg3)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg3.score(testX3, testy3)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, pred_logreg3)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy3, pred_logreg3)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 1: GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, penalty='none')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 1\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid1 = LogisticRegression()\n",
    "parameters1 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"none\",\"l2\"]}\n",
    "grid1 = GridSearchCV(modelgrid1,parameters1, cv=None).fit(trainX1, trainy1)\n",
    "grid1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    }
   ],
   "source": [
    "lrgrid1 = LogisticRegression(C=0.001, penalty='none').fit(trainX1, trainy1)\n",
    "y_predg1 = lrgrid1.predict(testX1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.49\n",
      "Tasa de aciertos balanceada regresión logística: 0.51\n",
      "Medida F1 regresión logística: 0.61\n",
      "Matriz de confusión:\n",
      "[[ 37 162]\n",
      " [ 28 148]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid1 = lrgrid1.predict(testX1)\n",
    "confusiong1 = confusion_matrix(testy1, pred_lrgrid1)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid1.score(testX1, testy1)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, pred_logreg1)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy1, pred_logreg1)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 2\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid2 = LogisticRegression()\n",
    "parameters2 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"none\",\"l2\"]}\n",
    "grid2 = GridSearchCV(modelgrid2,parameters2, cv=None).fit(trainX2, trainy2)\n",
    "grid2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lrgrid2 = LogisticRegression(C=0.01, penalty='none').fit(trainX2, trainy2)\n",
    "y_predg2 = lrgrid2.predict(testX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.52\n",
      "Tasa de aciertos balanceada regresión logística: 0.49\n",
      "Medida F1 regresión logística: 0.53\n",
      "Matriz de confusión:\n",
      "[[ 77 114]\n",
      " [ 61 110]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid2 = lrgrid2.predict(testX2)\n",
    "confusiong2 = confusion_matrix(testy2, pred_lrgrid2)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid2.score(testX2, testy2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, pred_logreg2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, pred_logreg2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.51616259        nan 0.51897208        nan 0.52319002        nan\n",
      " 0.52108475        nan 0.51897702        nan 0.51968372        nan\n",
      " 0.52038547        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 3\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid3 = LogisticRegression()\n",
    "parameters3 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\",None]}\n",
    "grid3 = GridSearchCV(modelgrid3,parameters3, cv=None).fit(trainX3, trainy3)\n",
    "grid3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lrgrid3 = LogisticRegression(C=0.1).fit(trainX3, trainy3)\n",
    "y_predg3 = lrgrid3.predict(testX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.51\n",
      "Tasa de aciertos balanceada regresión logística: 0.50\n",
      "Medida F1 regresión logística: 0.39\n",
      "Matriz de confusión:\n",
      "[[110  77]\n",
      " [ 98  71]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid3 = lrgrid3.predict(testX3)\n",
    "confusiong3 = confusion_matrix(testy3, pred_lrgrid3)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid3.score(testX3, testy3)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, pred_logreg3)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy3, pred_logreg3)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejora Modelo GridSearch - Datos 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando la incertidumbre en las predicciones: umbrales y curvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    871\n",
       "1.0    938\n",
       "Name: Subida, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy2.value_counts() + trainy2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Baja       0.51      0.35      0.41       191\n",
      "        Sube       0.46      0.63      0.53       171\n",
      "\n",
      "    accuracy                           0.48       362\n",
      "   macro avg       0.48      0.49      0.47       362\n",
      "weighted avg       0.49      0.48      0.47       362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testy2, pred_logreg2,target_names=[\"Baja\", \"Sube\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[ 66 125]\n",
      " [ 64 107]]\n"
     ]
    }
   ],
   "source": [
    "confusion2 = confusion_matrix(testy2, pred_logreg2)\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lower_threshold2 = lrgrid2.decision_function(testX2) > 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos balanceada regresión logística: 0.52\n",
      "Tasa de aciertos balanceada regresión logística: 0.53\n",
      "Medida F1 regresión logística: 0.55\n",
      "Matriz de confusión:\n",
      "[[ 82 109]\n",
      " [ 64 107]]\n"
     ]
    }
   ],
   "source": [
    "confusiongumbral = confusion_matrix(testy2, y_pred_lower_threshold2)\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(accuracy_score(testy2, y_pred_lower_threshold2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, y_pred_lower_threshold2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, y_pred_lower_threshold2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiongumbral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: -1.562. (P,R)=(0.47,1.00)\n",
      "Umbral: -0.875. (P,R)=(0.47,0.99)\n",
      "Umbral: -0.596. (P,R)=(0.47,0.99)\n",
      "Umbral: -0.587. (P,R)=(0.47,0.99)\n",
      "Umbral: -0.534. (P,R)=(0.47,0.99)\n",
      "Umbral: -0.532. (P,R)=(0.47,0.99)\n",
      "Umbral: -0.532. (P,R)=(0.47,0.98)\n",
      "Umbral: -0.509. (P,R)=(0.47,0.98)\n",
      "Umbral: -0.498. (P,R)=(0.47,0.98)\n",
      "Umbral: -0.496. (P,R)=(0.48,0.98)\n",
      "Umbral: -0.494. (P,R)=(0.48,0.98)\n",
      "Umbral: -0.489. (P,R)=(0.48,0.98)\n",
      "Umbral: -0.484. (P,R)=(0.48,0.98)\n",
      "Umbral: -0.458. (P,R)=(0.48,0.97)\n",
      "Umbral: -0.453. (P,R)=(0.47,0.96)\n",
      "Umbral: -0.435. (P,R)=(0.48,0.96)\n",
      "Umbral: -0.433. (P,R)=(0.47,0.96)\n",
      "Umbral: -0.411. (P,R)=(0.47,0.95)\n",
      "Umbral: -0.411. (P,R)=(0.47,0.95)\n",
      "Umbral: -0.396. (P,R)=(0.48,0.95)\n",
      "Umbral: -0.388. (P,R)=(0.48,0.95)\n",
      "Umbral: -0.383. (P,R)=(0.48,0.95)\n",
      "Umbral: -0.377. (P,R)=(0.48,0.95)\n",
      "Umbral: -0.373. (P,R)=(0.47,0.94)\n",
      "Umbral: -0.366. (P,R)=(0.47,0.94)\n",
      "Umbral: -0.340. (P,R)=(0.47,0.93)\n",
      "Umbral: -0.332. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.331. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.323. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.320. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.319. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.319. (P,R)=(0.47,0.92)\n",
      "Umbral: -0.319. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.318. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.317. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.316. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.313. (P,R)=(0.48,0.91)\n",
      "Umbral: -0.301. (P,R)=(0.47,0.90)\n",
      "Umbral: -0.294. (P,R)=(0.48,0.90)\n",
      "Umbral: -0.285. (P,R)=(0.48,0.90)\n",
      "Umbral: -0.280. (P,R)=(0.48,0.90)\n",
      "Umbral: -0.274. (P,R)=(0.48,0.90)\n",
      "Umbral: -0.272. (P,R)=(0.48,0.90)\n",
      "Umbral: -0.271. (P,R)=(0.48,0.90)\n",
      "Umbral: -0.268. (P,R)=(0.48,0.89)\n",
      "Umbral: -0.264. (P,R)=(0.48,0.89)\n",
      "Umbral: -0.264. (P,R)=(0.48,0.89)\n",
      "Umbral: -0.256. (P,R)=(0.48,0.89)\n",
      "Umbral: -0.255. (P,R)=(0.48,0.88)\n",
      "Umbral: -0.245. (P,R)=(0.48,0.88)\n",
      "Umbral: -0.243. (P,R)=(0.48,0.87)\n",
      "Umbral: -0.236. (P,R)=(0.48,0.87)\n",
      "Umbral: -0.231. (P,R)=(0.48,0.87)\n",
      "Umbral: -0.225. (P,R)=(0.48,0.87)\n",
      "Umbral: -0.223. (P,R)=(0.48,0.87)\n",
      "Umbral: -0.220. (P,R)=(0.48,0.87)\n",
      "Umbral: -0.219. (P,R)=(0.48,0.87)\n",
      "Umbral: -0.218. (P,R)=(0.48,0.86)\n",
      "Umbral: -0.216. (P,R)=(0.48,0.85)\n",
      "Umbral: -0.214. (P,R)=(0.48,0.85)\n",
      "Umbral: -0.211. (P,R)=(0.48,0.85)\n",
      "Umbral: -0.211. (P,R)=(0.48,0.84)\n",
      "Umbral: -0.207. (P,R)=(0.48,0.84)\n",
      "Umbral: -0.207. (P,R)=(0.48,0.84)\n",
      "Umbral: -0.205. (P,R)=(0.48,0.84)\n",
      "Umbral: -0.205. (P,R)=(0.48,0.84)\n",
      "Umbral: -0.200. (P,R)=(0.48,0.84)\n",
      "Umbral: -0.195. (P,R)=(0.48,0.83)\n",
      "Umbral: -0.194. (P,R)=(0.48,0.82)\n",
      "Umbral: -0.192. (P,R)=(0.48,0.82)\n",
      "Umbral: -0.185. (P,R)=(0.48,0.81)\n",
      "Umbral: -0.184. (P,R)=(0.48,0.81)\n",
      "Umbral: -0.182. (P,R)=(0.48,0.81)\n",
      "Umbral: -0.180. (P,R)=(0.48,0.81)\n",
      "Umbral: -0.178. (P,R)=(0.48,0.80)\n",
      "Umbral: -0.177. (P,R)=(0.47,0.80)\n",
      "Umbral: -0.173. (P,R)=(0.48,0.80)\n",
      "Umbral: -0.170. (P,R)=(0.48,0.80)\n",
      "Umbral: -0.169. (P,R)=(0.48,0.80)\n",
      "Umbral: -0.164. (P,R)=(0.48,0.79)\n",
      "Umbral: -0.159. (P,R)=(0.48,0.78)\n",
      "Umbral: -0.155. (P,R)=(0.48,0.78)\n",
      "Umbral: -0.150. (P,R)=(0.47,0.78)\n",
      "Umbral: -0.149. (P,R)=(0.48,0.78)\n",
      "Umbral: -0.147. (P,R)=(0.48,0.78)\n",
      "Umbral: -0.147. (P,R)=(0.48,0.78)\n",
      "Umbral: -0.144. (P,R)=(0.48,0.78)\n",
      "Umbral: -0.142. (P,R)=(0.48,0.77)\n",
      "Umbral: -0.141. (P,R)=(0.48,0.77)\n",
      "Umbral: -0.141. (P,R)=(0.48,0.77)\n",
      "Umbral: -0.140. (P,R)=(0.48,0.77)\n",
      "Umbral: -0.133. (P,R)=(0.48,0.76)\n",
      "Umbral: -0.133. (P,R)=(0.48,0.76)\n",
      "Umbral: -0.126. (P,R)=(0.48,0.76)\n",
      "Umbral: -0.125. (P,R)=(0.49,0.76)\n",
      "Umbral: -0.125. (P,R)=(0.48,0.75)\n",
      "Umbral: -0.116. (P,R)=(0.48,0.75)\n",
      "Umbral: -0.106. (P,R)=(0.48,0.75)\n",
      "Umbral: -0.102. (P,R)=(0.48,0.75)\n",
      "Umbral: -0.100. (P,R)=(0.48,0.74)\n",
      "Umbral: -0.095. (P,R)=(0.48,0.74)\n",
      "Umbral: -0.093. (P,R)=(0.48,0.74)\n",
      "Umbral: -0.087. (P,R)=(0.48,0.74)\n",
      "Umbral: -0.083. (P,R)=(0.48,0.73)\n",
      "Umbral: -0.083. (P,R)=(0.48,0.73)\n",
      "Umbral: -0.081. (P,R)=(0.48,0.73)\n",
      "Umbral: -0.081. (P,R)=(0.48,0.73)\n",
      "Umbral: -0.078. (P,R)=(0.48,0.72)\n",
      "Umbral: -0.073. (P,R)=(0.48,0.71)\n",
      "Umbral: -0.071. (P,R)=(0.48,0.71)\n",
      "Umbral: -0.071. (P,R)=(0.48,0.71)\n",
      "Umbral: -0.069. (P,R)=(0.48,0.70)\n",
      "Umbral: -0.058. (P,R)=(0.48,0.70)\n",
      "Umbral: -0.053. (P,R)=(0.48,0.70)\n",
      "Umbral: -0.050. (P,R)=(0.48,0.69)\n",
      "Umbral: -0.042. (P,R)=(0.48,0.69)\n",
      "Umbral: -0.042. (P,R)=(0.48,0.69)\n",
      "Umbral: -0.041. (P,R)=(0.48,0.68)\n",
      "Umbral: -0.040. (P,R)=(0.48,0.68)\n",
      "Umbral: -0.038. (P,R)=(0.48,0.68)\n",
      "Umbral: -0.037. (P,R)=(0.48,0.68)\n",
      "Umbral: -0.036. (P,R)=(0.49,0.68)\n",
      "Umbral: -0.033. (P,R)=(0.49,0.68)\n",
      "Umbral: -0.029. (P,R)=(0.49,0.68)\n",
      "Umbral: -0.029. (P,R)=(0.49,0.68)\n",
      "Umbral: -0.023. (P,R)=(0.49,0.68)\n",
      "Umbral: -0.023. (P,R)=(0.49,0.68)\n",
      "Umbral: -0.022. (P,R)=(0.49,0.67)\n",
      "Umbral: -0.022. (P,R)=(0.49,0.67)\n",
      "Umbral: -0.021. (P,R)=(0.49,0.67)\n",
      "Umbral: -0.019. (P,R)=(0.50,0.67)\n",
      "Umbral: -0.016. (P,R)=(0.49,0.67)\n",
      "Umbral: -0.013. (P,R)=(0.49,0.66)\n",
      "Umbral: -0.010. (P,R)=(0.49,0.66)\n",
      "Umbral: -0.009. (P,R)=(0.49,0.65)\n",
      "Umbral: -0.008. (P,R)=(0.49,0.65)\n",
      "Umbral: -0.006. (P,R)=(0.49,0.65)\n",
      "Umbral: -0.003. (P,R)=(0.49,0.65)\n",
      "Umbral: 0.004. (P,R)=(0.49,0.64)\n",
      "Umbral: 0.005. (P,R)=(0.49,0.64)\n",
      "Umbral: 0.005. (P,R)=(0.50,0.64)\n",
      "Umbral: 0.005. (P,R)=(0.50,0.64)\n",
      "Umbral: 0.006. (P,R)=(0.50,0.64)\n",
      "Umbral: 0.007. (P,R)=(0.50,0.64)\n",
      "Umbral: 0.007. (P,R)=(0.50,0.64)\n",
      "Umbral: 0.008. (P,R)=(0.50,0.63)\n",
      "Umbral: 0.013. (P,R)=(0.50,0.63)\n",
      "Umbral: 0.014. (P,R)=(0.49,0.62)\n",
      "Umbral: 0.021. (P,R)=(0.50,0.62)\n",
      "Umbral: 0.021. (P,R)=(0.49,0.61)\n",
      "Umbral: 0.025. (P,R)=(0.50,0.61)\n",
      "Umbral: 0.026. (P,R)=(0.49,0.61)\n",
      "Umbral: 0.036. (P,R)=(0.49,0.60)\n",
      "Umbral: 0.038. (P,R)=(0.49,0.60)\n",
      "Umbral: 0.040. (P,R)=(0.49,0.60)\n",
      "Umbral: 0.042. (P,R)=(0.49,0.59)\n",
      "Umbral: 0.048. (P,R)=(0.49,0.59)\n",
      "Umbral: 0.051. (P,R)=(0.49,0.58)\n",
      "Umbral: 0.051. (P,R)=(0.49,0.58)\n",
      "Umbral: 0.052. (P,R)=(0.49,0.58)\n",
      "Umbral: 0.057. (P,R)=(0.49,0.57)\n",
      "Umbral: 0.057. (P,R)=(0.49,0.57)\n",
      "Umbral: 0.059. (P,R)=(0.48,0.57)\n",
      "Umbral: 0.063. (P,R)=(0.49,0.57)\n",
      "Umbral: 0.066. (P,R)=(0.49,0.57)\n",
      "Umbral: 0.066. (P,R)=(0.49,0.56)\n",
      "Umbral: 0.066. (P,R)=(0.48,0.56)\n",
      "Umbral: 0.071. (P,R)=(0.48,0.55)\n",
      "Umbral: 0.071. (P,R)=(0.48,0.55)\n",
      "Umbral: 0.073. (P,R)=(0.49,0.55)\n",
      "Umbral: 0.074. (P,R)=(0.48,0.54)\n",
      "Umbral: 0.080. (P,R)=(0.48,0.54)\n",
      "Umbral: 0.080. (P,R)=(0.48,0.53)\n",
      "Umbral: 0.084. (P,R)=(0.48,0.53)\n",
      "Umbral: 0.093. (P,R)=(0.48,0.53)\n",
      "Umbral: 0.094. (P,R)=(0.48,0.53)\n",
      "Umbral: 0.099. (P,R)=(0.48,0.52)\n",
      "Umbral: 0.105. (P,R)=(0.48,0.51)\n",
      "Umbral: 0.106. (P,R)=(0.48,0.51)\n",
      "Umbral: 0.106. (P,R)=(0.48,0.51)\n",
      "Umbral: 0.107. (P,R)=(0.48,0.51)\n",
      "Umbral: 0.112. (P,R)=(0.49,0.51)\n",
      "Umbral: 0.113. (P,R)=(0.49,0.51)\n",
      "Umbral: 0.122. (P,R)=(0.49,0.51)\n",
      "Umbral: 0.124. (P,R)=(0.48,0.50)\n",
      "Umbral: 0.124. (P,R)=(0.49,0.50)\n",
      "Umbral: 0.125. (P,R)=(0.48,0.50)\n",
      "Umbral: 0.127. (P,R)=(0.48,0.49)\n",
      "Umbral: 0.129. (P,R)=(0.48,0.49)\n",
      "Umbral: 0.130. (P,R)=(0.47,0.48)\n",
      "Umbral: 0.130. (P,R)=(0.47,0.47)\n",
      "Umbral: 0.132. (P,R)=(0.47,0.47)\n",
      "Umbral: 0.135. (P,R)=(0.48,0.47)\n",
      "Umbral: 0.141. (P,R)=(0.48,0.47)\n",
      "Umbral: 0.142. (P,R)=(0.48,0.47)\n",
      "Umbral: 0.148. (P,R)=(0.48,0.47)\n",
      "Umbral: 0.152. (P,R)=(0.48,0.47)\n",
      "Umbral: 0.153. (P,R)=(0.48,0.46)\n",
      "Umbral: 0.155. (P,R)=(0.48,0.46)\n",
      "Umbral: 0.155. (P,R)=(0.48,0.46)\n",
      "Umbral: 0.157. (P,R)=(0.48,0.46)\n",
      "Umbral: 0.158. (P,R)=(0.48,0.45)\n",
      "Umbral: 0.158. (P,R)=(0.47,0.44)\n",
      "Umbral: 0.161. (P,R)=(0.48,0.44)\n",
      "Umbral: 0.161. (P,R)=(0.48,0.44)\n",
      "Umbral: 0.162. (P,R)=(0.48,0.44)\n",
      "Umbral: 0.165. (P,R)=(0.48,0.44)\n",
      "Umbral: 0.166. (P,R)=(0.48,0.43)\n",
      "Umbral: 0.166. (P,R)=(0.47,0.43)\n",
      "Umbral: 0.173. (P,R)=(0.47,0.42)\n",
      "Umbral: 0.179. (P,R)=(0.47,0.42)\n",
      "Umbral: 0.179. (P,R)=(0.47,0.42)\n",
      "Umbral: 0.181. (P,R)=(0.47,0.41)\n",
      "Umbral: 0.181. (P,R)=(0.46,0.40)\n",
      "Umbral: 0.185. (P,R)=(0.46,0.40)\n",
      "Umbral: 0.185. (P,R)=(0.46,0.39)\n",
      "Umbral: 0.187. (P,R)=(0.45,0.39)\n",
      "Umbral: 0.191. (P,R)=(0.46,0.39)\n",
      "Umbral: 0.193. (P,R)=(0.45,0.38)\n",
      "Umbral: 0.200. (P,R)=(0.45,0.38)\n",
      "Umbral: 0.204. (P,R)=(0.46,0.38)\n",
      "Umbral: 0.206. (P,R)=(0.45,0.37)\n",
      "Umbral: 0.209. (P,R)=(0.46,0.37)\n",
      "Umbral: 0.212. (P,R)=(0.45,0.37)\n",
      "Umbral: 0.212. (P,R)=(0.46,0.37)\n",
      "Umbral: 0.212. (P,R)=(0.45,0.36)\n",
      "Umbral: 0.214. (P,R)=(0.45,0.36)\n",
      "Umbral: 0.217. (P,R)=(0.44,0.35)\n",
      "Umbral: 0.226. (P,R)=(0.45,0.35)\n",
      "Umbral: 0.228. (P,R)=(0.44,0.35)\n",
      "Umbral: 0.229. (P,R)=(0.45,0.35)\n",
      "Umbral: 0.231. (P,R)=(0.44,0.34)\n",
      "Umbral: 0.233. (P,R)=(0.44,0.33)\n",
      "Umbral: 0.234. (P,R)=(0.43,0.33)\n",
      "Umbral: 0.235. (P,R)=(0.44,0.33)\n",
      "Umbral: 0.238. (P,R)=(0.43,0.32)\n",
      "Umbral: 0.243. (P,R)=(0.43,0.32)\n",
      "Umbral: 0.247. (P,R)=(0.43,0.32)\n",
      "Umbral: 0.250. (P,R)=(0.44,0.32)\n",
      "Umbral: 0.255. (P,R)=(0.44,0.32)\n",
      "Umbral: 0.258. (P,R)=(0.44,0.32)\n",
      "Umbral: 0.268. (P,R)=(0.45,0.32)\n",
      "Umbral: 0.279. (P,R)=(0.44,0.31)\n",
      "Umbral: 0.280. (P,R)=(0.45,0.31)\n",
      "Umbral: 0.287. (P,R)=(0.44,0.30)\n",
      "Umbral: 0.290. (P,R)=(0.44,0.30)\n",
      "Umbral: 0.313. (P,R)=(0.43,0.29)\n",
      "Umbral: 0.316. (P,R)=(0.43,0.29)\n",
      "Umbral: 0.320. (P,R)=(0.43,0.29)\n",
      "Umbral: 0.326. (P,R)=(0.43,0.29)\n",
      "Umbral: 0.327. (P,R)=(0.44,0.29)\n",
      "Umbral: 0.331. (P,R)=(0.44,0.29)\n",
      "Umbral: 0.332. (P,R)=(0.45,0.29)\n",
      "Umbral: 0.334. (P,R)=(0.45,0.29)\n",
      "Umbral: 0.339. (P,R)=(0.45,0.29)\n",
      "Umbral: 0.341. (P,R)=(0.45,0.28)\n",
      "Umbral: 0.342. (P,R)=(0.45,0.28)\n",
      "Umbral: 0.345. (P,R)=(0.45,0.27)\n",
      "Umbral: 0.348. (P,R)=(0.45,0.27)\n",
      "Umbral: 0.350. (P,R)=(0.45,0.27)\n",
      "Umbral: 0.351. (P,R)=(0.45,0.27)\n",
      "Umbral: 0.357. (P,R)=(0.46,0.27)\n",
      "Umbral: 0.358. (P,R)=(0.46,0.27)\n",
      "Umbral: 0.359. (P,R)=(0.45,0.26)\n",
      "Umbral: 0.360. (P,R)=(0.46,0.26)\n",
      "Umbral: 0.367. (P,R)=(0.45,0.26)\n",
      "Umbral: 0.371. (P,R)=(0.45,0.25)\n",
      "Umbral: 0.389. (P,R)=(0.44,0.25)\n",
      "Umbral: 0.393. (P,R)=(0.45,0.25)\n",
      "Umbral: 0.395. (P,R)=(0.45,0.25)\n",
      "Umbral: 0.398. (P,R)=(0.46,0.25)\n",
      "Umbral: 0.403. (P,R)=(0.46,0.25)\n",
      "Umbral: 0.405. (P,R)=(0.47,0.25)\n",
      "Umbral: 0.406. (P,R)=(0.47,0.25)\n",
      "Umbral: 0.407. (P,R)=(0.48,0.25)\n",
      "Umbral: 0.408. (P,R)=(0.47,0.24)\n",
      "Umbral: 0.409. (P,R)=(0.48,0.24)\n",
      "Umbral: 0.409. (P,R)=(0.48,0.24)\n",
      "Umbral: 0.411. (P,R)=(0.48,0.23)\n",
      "Umbral: 0.412. (P,R)=(0.47,0.23)\n",
      "Umbral: 0.415. (P,R)=(0.48,0.23)\n",
      "Umbral: 0.418. (P,R)=(0.48,0.23)\n",
      "Umbral: 0.429. (P,R)=(0.49,0.23)\n",
      "Umbral: 0.439. (P,R)=(0.49,0.23)\n",
      "Umbral: 0.450. (P,R)=(0.50,0.23)\n",
      "Umbral: 0.457. (P,R)=(0.51,0.23)\n",
      "Umbral: 0.462. (P,R)=(0.50,0.22)\n",
      "Umbral: 0.471. (P,R)=(0.49,0.22)\n",
      "Umbral: 0.472. (P,R)=(0.50,0.22)\n",
      "Umbral: 0.475. (P,R)=(0.51,0.22)\n",
      "Umbral: 0.480. (P,R)=(0.51,0.22)\n",
      "Umbral: 0.484. (P,R)=(0.51,0.21)\n",
      "Umbral: 0.488. (P,R)=(0.50,0.20)\n",
      "Umbral: 0.491. (P,R)=(0.49,0.20)\n",
      "Umbral: 0.492. (P,R)=(0.49,0.19)\n",
      "Umbral: 0.503. (P,R)=(0.49,0.19)\n",
      "Umbral: 0.509. (P,R)=(0.50,0.19)\n",
      "Umbral: 0.516. (P,R)=(0.49,0.19)\n",
      "Umbral: 0.523. (P,R)=(0.50,0.19)\n",
      "Umbral: 0.527. (P,R)=(0.49,0.18)\n",
      "Umbral: 0.527. (P,R)=(0.48,0.18)\n",
      "Umbral: 0.528. (P,R)=(0.48,0.17)\n",
      "Umbral: 0.529. (P,R)=(0.48,0.17)\n",
      "Umbral: 0.532. (P,R)=(0.47,0.16)\n",
      "Umbral: 0.534. (P,R)=(0.47,0.16)\n",
      "Umbral: 0.539. (P,R)=(0.46,0.15)\n",
      "Umbral: 0.540. (P,R)=(0.46,0.15)\n",
      "Umbral: 0.550. (P,R)=(0.45,0.15)\n",
      "Umbral: 0.551. (P,R)=(0.46,0.15)\n",
      "Umbral: 0.553. (P,R)=(0.47,0.15)\n",
      "Umbral: 0.559. (P,R)=(0.46,0.14)\n",
      "Umbral: 0.562. (P,R)=(0.47,0.14)\n",
      "Umbral: 0.566. (P,R)=(0.48,0.14)\n",
      "Umbral: 0.567. (P,R)=(0.49,0.14)\n",
      "Umbral: 0.569. (P,R)=(0.50,0.14)\n",
      "Umbral: 0.571. (P,R)=(0.51,0.14)\n",
      "Umbral: 0.577. (P,R)=(0.52,0.14)\n",
      "Umbral: 0.578. (P,R)=(0.51,0.13)\n",
      "Umbral: 0.584. (P,R)=(0.50,0.13)\n",
      "Umbral: 0.587. (P,R)=(0.51,0.13)\n",
      "Umbral: 0.600. (P,R)=(0.52,0.13)\n",
      "Umbral: 0.601. (P,R)=(0.54,0.13)\n",
      "Umbral: 0.605. (P,R)=(0.55,0.13)\n",
      "Umbral: 0.612. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.618. (P,R)=(0.53,0.12)\n",
      "Umbral: 0.620. (P,R)=(0.54,0.12)\n",
      "Umbral: 0.622. (P,R)=(0.56,0.12)\n",
      "Umbral: 0.630. (P,R)=(0.57,0.12)\n",
      "Umbral: 0.630. (P,R)=(0.59,0.12)\n",
      "Umbral: 0.633. (P,R)=(0.58,0.11)\n",
      "Umbral: 0.641. (P,R)=(0.56,0.11)\n",
      "Umbral: 0.651. (P,R)=(0.55,0.10)\n",
      "Umbral: 0.655. (P,R)=(0.53,0.09)\n",
      "Umbral: 0.661. (P,R)=(0.55,0.09)\n",
      "Umbral: 0.669. (P,R)=(0.57,0.09)\n",
      "Umbral: 0.675. (P,R)=(0.59,0.09)\n",
      "Umbral: 0.675. (P,R)=(0.58,0.09)\n",
      "Umbral: 0.678. (P,R)=(0.56,0.08)\n",
      "Umbral: 0.690. (P,R)=(0.58,0.08)\n",
      "Umbral: 0.702. (P,R)=(0.57,0.08)\n",
      "Umbral: 0.706. (P,R)=(0.59,0.08)\n",
      "Umbral: 0.708. (P,R)=(0.57,0.07)\n",
      "Umbral: 0.710. (P,R)=(0.55,0.06)\n",
      "Umbral: 0.717. (P,R)=(0.58,0.06)\n",
      "Umbral: 0.719. (P,R)=(0.56,0.06)\n",
      "Umbral: 0.721. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.725. (P,R)=(0.50,0.05)\n",
      "Umbral: 0.727. (P,R)=(0.53,0.05)\n",
      "Umbral: 0.745. (P,R)=(0.57,0.05)\n",
      "Umbral: 0.783. (P,R)=(0.62,0.05)\n",
      "Umbral: 0.793. (P,R)=(0.67,0.05)\n",
      "Umbral: 0.803. (P,R)=(0.73,0.05)\n",
      "Umbral: 0.824. (P,R)=(0.80,0.05)\n",
      "Umbral: 0.825. (P,R)=(0.78,0.04)\n",
      "Umbral: 0.827. (P,R)=(0.75,0.04)\n",
      "Umbral: 0.834. (P,R)=(0.71,0.03)\n",
      "Umbral: 0.860. (P,R)=(0.67,0.02)\n",
      "Umbral: 0.879. (P,R)=(0.60,0.02)\n",
      "Umbral: 0.897. (P,R)=(0.50,0.01)\n",
      "Umbral: 0.954. (P,R)=(0.33,0.01)\n",
      "Umbral: 0.984. (P,R)=(0.50,0.01)\n",
      "Umbral: 0.988. (P,R)=(0.00,0.00)\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve( testy2, lrgrid2.decision_function(testX2))\n",
    "for u,p,r in zip(thresholds,precision,recall):\n",
    "    print(\"Umbral: {:.3f}. (P,R)=({:.2f},{:.2f})\".format(u,p,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Curva PR')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(testy2, logreg2.decision_function(testX2))\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10, label=\"umbral cero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.plot(precision, recall)\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Curva PR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Curva ROC')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(testy2, lrgrid2.decision_function(testX2))\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=7,label=\"umbral cero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.legend(loc=4)\n",
    "plt.title(\"Curva ROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 DIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "run Datos-20diasBINARIO.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 1: MODELO BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.49\n",
      "Tasa de aciertos balanceada regresión logística: 0.51\n",
      "Medida F1 regresión logística: 0.61\n",
      "Matriz de confusión:\n",
      "[[ 37 162]\n",
      " [ 28 148]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 1\n",
    "# -------------------------------------------------------------------\n",
    "logreg1 = LogisticRegression(max_iter=10000).fit(trainX1, trainy1)\n",
    "pred_logreg1 = logreg1.predict(testX1)\n",
    "confusion1 = confusion_matrix(testy1, pred_logreg1)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg1.score(testX1, testy1)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, pred_logreg1)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy1, pred_logreg1)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.48\n",
      "Tasa de aciertos balanceada regresión logística: 0.49\n",
      "Medida F1 regresión logística: 0.53\n",
      "Matriz de confusión:\n",
      "[[ 66 125]\n",
      " [ 64 107]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 2\n",
    "# -------------------------------------------------------------------\n",
    "logreg2 = LogisticRegression(max_iter=10000).fit(trainX2, trainy2)\n",
    "pred_logreg2 = logreg2.predict(testX2)\n",
    "confusion2 = confusion_matrix(testy2, pred_logreg2)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg2.score(testX2, testy2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, pred_logreg2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, pred_logreg2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.51\n",
      "Tasa de aciertos balanceada regresión logística: 0.50\n",
      "Medida F1 regresión logística: 0.39\n",
      "Matriz de confusión:\n",
      "[[124  63]\n",
      " [113  56]]\n"
     ]
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 3\n",
    "# -------------------------------------------------------------------\n",
    "logreg3 = LogisticRegression(max_iter=10000).fit(trainX3, trainy3)\n",
    "pred_logreg3 = logreg3.predict(testX3)\n",
    "confusion = confusion_matrix(testy3, pred_logreg3)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(logreg3.score(testX3, testy3)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, pred_logreg3)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy3, pred_logreg3)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 1: GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, penalty='none')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 1\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid1 = LogisticRegression()\n",
    "parameters1 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"none\",\"l2\"]}\n",
    "grid1 = GridSearchCV(modelgrid1,parameters1, cv=None).fit(trainX1, trainy1)\n",
    "grid1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    }
   ],
   "source": [
    "lrgrid1 = LogisticRegression(C=0.001, penalty='none').fit(trainX1, trainy1)\n",
    "y_predg1 = lrgrid1.predict(testX1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.49\n",
      "Tasa de aciertos balanceada regresión logística: 0.51\n",
      "Medida F1 regresión logística: 0.61\n",
      "Matriz de confusión:\n",
      "[[ 37 162]\n",
      " [ 28 148]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid1 = lrgrid1.predict(testX1)\n",
    "confusiong1 = confusion_matrix(testy1, pred_lrgrid1)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid1.score(testX1, testy1)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy1, pred_logreg1)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy1, pred_logreg1)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 2\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid2 = LogisticRegression()\n",
    "parameters2 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"none\",\"l2\"]}\n",
    "grid2 = GridSearchCV(modelgrid2,parameters2, cv=None).fit(trainX2, trainy2)\n",
    "grid2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lrgrid2 = LogisticRegression(C=0.01).fit(trainX2, trainy2)\n",
    "y_predg2 = lrgrid2.predict(testX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.51\n",
      "Tasa de aciertos balanceada regresión logística: 0.49\n",
      "Medida F1 regresión logística: 0.53\n",
      "Matriz de confusión:\n",
      "[[ 78 113]\n",
      " [ 65 106]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid2 = lrgrid2.predict(testX2)\n",
    "confusiong2 = confusion_matrix(testy2, pred_lrgrid2)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid2.score(testX2, testy2)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy2, pred_logreg2)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy2, pred_logreg2)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 440, in _check_solver\n",
      "    \" got %s.\" % (all_penalties, penalty))\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.51616259        nan 0.51897208        nan 0.52319002        nan\n",
      " 0.52108475        nan 0.51897702        nan 0.51968372        nan\n",
      " 0.52038547        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODELO CON EL CONJUNTO DE DATOS 3\n",
    "# -------------------------------------------------------------------\n",
    "modelgrid3 = LogisticRegression()\n",
    "parameters3 = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\",None]}\n",
    "grid3 = GridSearchCV(modelgrid3,parameters3, cv=None).fit(trainX3, trainy3)\n",
    "grid3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lrgrid3 = LogisticRegression(C=0.1).fit(trainX3, trainy3)\n",
    "y_predg3 = lrgrid3.predict(testX3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto en regresión logística: 0.51\n",
      "Tasa de aciertos balanceada regresión logística: 0.50\n",
      "Medida F1 regresión logística: 0.39\n",
      "Matriz de confusión:\n",
      "[[110  77]\n",
      " [ 98  71]]\n"
     ]
    }
   ],
   "source": [
    "pred_lrgrid3 = lrgrid3.predict(testX3)\n",
    "confusiong3 = confusion_matrix(testy3, pred_lrgrid3)\n",
    "print(\"Tasa de acierto en regresión logística: {:.2f}\".format(lrgrid3.score(testX3, testy3)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, pred_logreg3)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy3, pred_logreg3)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiong3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejora Modelo Base - Conjunto de datos 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando la incertidumbre en las predicciones: umbrales y curvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    857\n",
       "1.0    923\n",
       "Name: Subida, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy3.value_counts() + trainy3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Baja       0.52      0.66      0.58       187\n",
      "        Sube       0.47      0.33      0.39       169\n",
      "\n",
      "    accuracy                           0.51       356\n",
      "   macro avg       0.50      0.50      0.49       356\n",
      "weighted avg       0.50      0.51      0.49       356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testy3, pred_logreg3,target_names=[\"Baja\", \"Sube\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[124  63]\n",
      " [113  56]]\n"
     ]
    }
   ],
   "source": [
    "confusion3 = confusion_matrix(testy3, pred_logreg3)\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusion3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lower_threshold3 = logreg3.decision_function(testX3) < 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos balanceada regresión logística: 0.51\n",
      "Tasa de aciertos balanceada regresión logística: 0.53\n",
      "Medida F1 regresión logística: 0.62\n",
      "Matriz de confusión:\n",
      "[[ 36 151]\n",
      " [ 24 145]]\n"
     ]
    }
   ],
   "source": [
    "confusiongumbral = confusion_matrix(testy3, y_pred_lower_threshold3)\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(accuracy_score(testy3, y_pred_lower_threshold3)))\n",
    "print(\"Tasa de aciertos balanceada regresión logística: {:.2f}\".format(balanced_accuracy_score(testy3, y_pred_lower_threshold3)))\n",
    "print(\"Medida F1 regresión logística: {:.2f}\".format(f1_score(testy3, y_pred_lower_threshold3)))\n",
    "print(\"Matriz de confusión:\\n{}\".format(confusiongumbral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral: -1.866. (P,R)=(0.47,1.00)\n",
      "Umbral: -1.286. (P,R)=(0.47,0.99)\n",
      "Umbral: -1.195. (P,R)=(0.47,0.99)\n",
      "Umbral: -1.162. (P,R)=(0.48,0.99)\n",
      "Umbral: -1.086. (P,R)=(0.47,0.99)\n",
      "Umbral: -1.048. (P,R)=(0.48,0.99)\n",
      "Umbral: -1.012. (P,R)=(0.47,0.98)\n",
      "Umbral: -1.005. (P,R)=(0.48,0.98)\n",
      "Umbral: -0.947. (P,R)=(0.47,0.98)\n",
      "Umbral: -0.938. (P,R)=(0.48,0.98)\n",
      "Umbral: -0.911. (P,R)=(0.48,0.98)\n",
      "Umbral: -0.897. (P,R)=(0.48,0.97)\n",
      "Umbral: -0.892. (P,R)=(0.48,0.97)\n",
      "Umbral: -0.866. (P,R)=(0.48,0.96)\n",
      "Umbral: -0.863. (P,R)=(0.47,0.96)\n",
      "Umbral: -0.856. (P,R)=(0.47,0.95)\n",
      "Umbral: -0.849. (P,R)=(0.47,0.95)\n",
      "Umbral: -0.818. (P,R)=(0.47,0.94)\n",
      "Umbral: -0.795. (P,R)=(0.47,0.93)\n",
      "Umbral: -0.795. (P,R)=(0.47,0.93)\n",
      "Umbral: -0.789. (P,R)=(0.46,0.92)\n",
      "Umbral: -0.788. (P,R)=(0.46,0.92)\n",
      "Umbral: -0.779. (P,R)=(0.46,0.91)\n",
      "Umbral: -0.774. (P,R)=(0.46,0.91)\n",
      "Umbral: -0.759. (P,R)=(0.46,0.91)\n",
      "Umbral: -0.753. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.753. (P,R)=(0.46,0.91)\n",
      "Umbral: -0.749. (P,R)=(0.47,0.91)\n",
      "Umbral: -0.734. (P,R)=(0.46,0.90)\n",
      "Umbral: -0.692. (P,R)=(0.46,0.90)\n",
      "Umbral: -0.690. (P,R)=(0.46,0.89)\n",
      "Umbral: -0.687. (P,R)=(0.46,0.89)\n",
      "Umbral: -0.685. (P,R)=(0.46,0.88)\n",
      "Umbral: -0.681. (P,R)=(0.46,0.88)\n",
      "Umbral: -0.676. (P,R)=(0.46,0.88)\n",
      "Umbral: -0.669. (P,R)=(0.46,0.88)\n",
      "Umbral: -0.667. (P,R)=(0.46,0.87)\n",
      "Umbral: -0.665. (P,R)=(0.46,0.86)\n",
      "Umbral: -0.665. (P,R)=(0.46,0.86)\n",
      "Umbral: -0.651. (P,R)=(0.46,0.86)\n",
      "Umbral: -0.650. (P,R)=(0.46,0.86)\n",
      "Umbral: -0.650. (P,R)=(0.46,0.85)\n",
      "Umbral: -0.647. (P,R)=(0.46,0.85)\n",
      "Umbral: -0.640. (P,R)=(0.46,0.85)\n",
      "Umbral: -0.637. (P,R)=(0.46,0.85)\n",
      "Umbral: -0.619. (P,R)=(0.46,0.85)\n",
      "Umbral: -0.618. (P,R)=(0.46,0.85)\n",
      "Umbral: -0.617. (P,R)=(0.46,0.84)\n",
      "Umbral: -0.603. (P,R)=(0.46,0.84)\n",
      "Umbral: -0.598. (P,R)=(0.46,0.83)\n",
      "Umbral: -0.596. (P,R)=(0.46,0.83)\n",
      "Umbral: -0.591. (P,R)=(0.46,0.83)\n",
      "Umbral: -0.591. (P,R)=(0.46,0.82)\n",
      "Umbral: -0.589. (P,R)=(0.46,0.82)\n",
      "Umbral: -0.586. (P,R)=(0.46,0.82)\n",
      "Umbral: -0.581. (P,R)=(0.46,0.81)\n",
      "Umbral: -0.580. (P,R)=(0.45,0.80)\n",
      "Umbral: -0.579. (P,R)=(0.45,0.80)\n",
      "Umbral: -0.579. (P,R)=(0.45,0.80)\n",
      "Umbral: -0.578. (P,R)=(0.45,0.80)\n",
      "Umbral: -0.571. (P,R)=(0.46,0.80)\n",
      "Umbral: -0.567. (P,R)=(0.46,0.80)\n",
      "Umbral: -0.562. (P,R)=(0.46,0.80)\n",
      "Umbral: -0.556. (P,R)=(0.46,0.80)\n",
      "Umbral: -0.553. (P,R)=(0.46,0.79)\n",
      "Umbral: -0.551. (P,R)=(0.46,0.79)\n",
      "Umbral: -0.546. (P,R)=(0.46,0.79)\n",
      "Umbral: -0.546. (P,R)=(0.46,0.79)\n",
      "Umbral: -0.535. (P,R)=(0.46,0.78)\n",
      "Umbral: -0.532. (P,R)=(0.46,0.78)\n",
      "Umbral: -0.528. (P,R)=(0.46,0.78)\n",
      "Umbral: -0.527. (P,R)=(0.46,0.78)\n",
      "Umbral: -0.526. (P,R)=(0.46,0.78)\n",
      "Umbral: -0.525. (P,R)=(0.47,0.78)\n",
      "Umbral: -0.518. (P,R)=(0.47,0.78)\n",
      "Umbral: -0.515. (P,R)=(0.47,0.78)\n",
      "Umbral: -0.507. (P,R)=(0.47,0.78)\n",
      "Umbral: -0.503. (P,R)=(0.47,0.77)\n",
      "Umbral: -0.502. (P,R)=(0.47,0.77)\n",
      "Umbral: -0.500. (P,R)=(0.47,0.77)\n",
      "Umbral: -0.495. (P,R)=(0.47,0.77)\n",
      "Umbral: -0.490. (P,R)=(0.47,0.76)\n",
      "Umbral: -0.488. (P,R)=(0.47,0.76)\n",
      "Umbral: -0.487. (P,R)=(0.47,0.76)\n",
      "Umbral: -0.471. (P,R)=(0.47,0.75)\n",
      "Umbral: -0.468. (P,R)=(0.46,0.75)\n",
      "Umbral: -0.461. (P,R)=(0.47,0.75)\n",
      "Umbral: -0.460. (P,R)=(0.46,0.74)\n",
      "Umbral: -0.458. (P,R)=(0.47,0.74)\n",
      "Umbral: -0.458. (P,R)=(0.47,0.74)\n",
      "Umbral: -0.457. (P,R)=(0.47,0.73)\n",
      "Umbral: -0.449. (P,R)=(0.47,0.73)\n",
      "Umbral: -0.448. (P,R)=(0.47,0.73)\n",
      "Umbral: -0.445. (P,R)=(0.47,0.73)\n",
      "Umbral: -0.438. (P,R)=(0.47,0.73)\n",
      "Umbral: -0.437. (P,R)=(0.47,0.73)\n",
      "Umbral: -0.436. (P,R)=(0.47,0.72)\n",
      "Umbral: -0.435. (P,R)=(0.47,0.72)\n",
      "Umbral: -0.432. (P,R)=(0.47,0.72)\n",
      "Umbral: -0.430. (P,R)=(0.47,0.72)\n",
      "Umbral: -0.428. (P,R)=(0.47,0.72)\n",
      "Umbral: -0.425. (P,R)=(0.47,0.72)\n",
      "Umbral: -0.422. (P,R)=(0.47,0.71)\n",
      "Umbral: -0.415. (P,R)=(0.47,0.70)\n",
      "Umbral: -0.412. (P,R)=(0.47,0.70)\n",
      "Umbral: -0.411. (P,R)=(0.47,0.70)\n",
      "Umbral: -0.408. (P,R)=(0.47,0.70)\n",
      "Umbral: -0.407. (P,R)=(0.47,0.69)\n",
      "Umbral: -0.405. (P,R)=(0.47,0.69)\n",
      "Umbral: -0.405. (P,R)=(0.47,0.69)\n",
      "Umbral: -0.404. (P,R)=(0.47,0.69)\n",
      "Umbral: -0.404. (P,R)=(0.47,0.68)\n",
      "Umbral: -0.401. (P,R)=(0.47,0.68)\n",
      "Umbral: -0.401. (P,R)=(0.47,0.67)\n",
      "Umbral: -0.401. (P,R)=(0.47,0.67)\n",
      "Umbral: -0.399. (P,R)=(0.47,0.67)\n",
      "Umbral: -0.391. (P,R)=(0.47,0.67)\n",
      "Umbral: -0.386. (P,R)=(0.47,0.67)\n",
      "Umbral: -0.384. (P,R)=(0.47,0.66)\n",
      "Umbral: -0.379. (P,R)=(0.47,0.66)\n",
      "Umbral: -0.375. (P,R)=(0.47,0.66)\n",
      "Umbral: -0.373. (P,R)=(0.47,0.65)\n",
      "Umbral: -0.368. (P,R)=(0.47,0.65)\n",
      "Umbral: -0.367. (P,R)=(0.47,0.65)\n",
      "Umbral: -0.363. (P,R)=(0.47,0.64)\n",
      "Umbral: -0.354. (P,R)=(0.47,0.64)\n",
      "Umbral: -0.352. (P,R)=(0.47,0.64)\n",
      "Umbral: -0.352. (P,R)=(0.47,0.64)\n",
      "Umbral: -0.348. (P,R)=(0.47,0.63)\n",
      "Umbral: -0.346. (P,R)=(0.47,0.63)\n",
      "Umbral: -0.346. (P,R)=(0.47,0.63)\n",
      "Umbral: -0.343. (P,R)=(0.47,0.63)\n",
      "Umbral: -0.338. (P,R)=(0.47,0.62)\n",
      "Umbral: -0.336. (P,R)=(0.47,0.62)\n",
      "Umbral: -0.328. (P,R)=(0.46,0.61)\n",
      "Umbral: -0.324. (P,R)=(0.46,0.60)\n",
      "Umbral: -0.320. (P,R)=(0.46,0.60)\n",
      "Umbral: -0.310. (P,R)=(0.47,0.60)\n",
      "Umbral: -0.307. (P,R)=(0.47,0.60)\n",
      "Umbral: -0.305. (P,R)=(0.47,0.60)\n",
      "Umbral: -0.303. (P,R)=(0.47,0.60)\n",
      "Umbral: -0.301. (P,R)=(0.47,0.60)\n",
      "Umbral: -0.297. (P,R)=(0.48,0.60)\n",
      "Umbral: -0.292. (P,R)=(0.48,0.60)\n",
      "Umbral: -0.291. (P,R)=(0.48,0.60)\n",
      "Umbral: -0.286. (P,R)=(0.48,0.60)\n",
      "Umbral: -0.285. (P,R)=(0.48,0.60)\n",
      "Umbral: -0.282. (P,R)=(0.48,0.60)\n",
      "Umbral: -0.257. (P,R)=(0.48,0.59)\n",
      "Umbral: -0.249. (P,R)=(0.48,0.59)\n",
      "Umbral: -0.249. (P,R)=(0.48,0.58)\n",
      "Umbral: -0.248. (P,R)=(0.47,0.57)\n",
      "Umbral: -0.245. (P,R)=(0.47,0.57)\n",
      "Umbral: -0.244. (P,R)=(0.47,0.56)\n",
      "Umbral: -0.243. (P,R)=(0.47,0.56)\n",
      "Umbral: -0.242. (P,R)=(0.47,0.56)\n",
      "Umbral: -0.232. (P,R)=(0.47,0.55)\n",
      "Umbral: -0.230. (P,R)=(0.47,0.55)\n",
      "Umbral: -0.229. (P,R)=(0.46,0.54)\n",
      "Umbral: -0.229. (P,R)=(0.47,0.54)\n",
      "Umbral: -0.224. (P,R)=(0.46,0.54)\n",
      "Umbral: -0.222. (P,R)=(0.47,0.54)\n",
      "Umbral: -0.221. (P,R)=(0.47,0.54)\n",
      "Umbral: -0.220. (P,R)=(0.47,0.54)\n",
      "Umbral: -0.215. (P,R)=(0.47,0.53)\n",
      "Umbral: -0.214. (P,R)=(0.47,0.53)\n",
      "Umbral: -0.214. (P,R)=(0.47,0.53)\n",
      "Umbral: -0.212. (P,R)=(0.47,0.53)\n",
      "Umbral: -0.210. (P,R)=(0.47,0.52)\n",
      "Umbral: -0.205. (P,R)=(0.47,0.52)\n",
      "Umbral: -0.205. (P,R)=(0.47,0.51)\n",
      "Umbral: -0.199. (P,R)=(0.47,0.51)\n",
      "Umbral: -0.197. (P,R)=(0.47,0.51)\n",
      "Umbral: -0.196. (P,R)=(0.48,0.51)\n",
      "Umbral: -0.188. (P,R)=(0.48,0.51)\n",
      "Umbral: -0.186. (P,R)=(0.48,0.51)\n",
      "Umbral: -0.185. (P,R)=(0.47,0.50)\n",
      "Umbral: -0.185. (P,R)=(0.47,0.50)\n",
      "Umbral: -0.180. (P,R)=(0.47,0.49)\n",
      "Umbral: -0.179. (P,R)=(0.46,0.49)\n",
      "Umbral: -0.177. (P,R)=(0.46,0.48)\n",
      "Umbral: -0.173. (P,R)=(0.46,0.48)\n",
      "Umbral: -0.170. (P,R)=(0.47,0.48)\n",
      "Umbral: -0.165. (P,R)=(0.46,0.47)\n",
      "Umbral: -0.160. (P,R)=(0.46,0.47)\n",
      "Umbral: -0.159. (P,R)=(0.46,0.46)\n",
      "Umbral: -0.159. (P,R)=(0.46,0.46)\n",
      "Umbral: -0.155. (P,R)=(0.46,0.46)\n",
      "Umbral: -0.152. (P,R)=(0.46,0.46)\n",
      "Umbral: -0.152. (P,R)=(0.46,0.46)\n",
      "Umbral: -0.152. (P,R)=(0.46,0.45)\n",
      "Umbral: -0.148. (P,R)=(0.46,0.45)\n",
      "Umbral: -0.146. (P,R)=(0.46,0.44)\n",
      "Umbral: -0.143. (P,R)=(0.46,0.44)\n",
      "Umbral: -0.139. (P,R)=(0.46,0.44)\n",
      "Umbral: -0.138. (P,R)=(0.46,0.44)\n",
      "Umbral: -0.138. (P,R)=(0.46,0.44)\n",
      "Umbral: -0.134. (P,R)=(0.46,0.43)\n",
      "Umbral: -0.129. (P,R)=(0.46,0.43)\n",
      "Umbral: -0.127. (P,R)=(0.46,0.43)\n",
      "Umbral: -0.122. (P,R)=(0.46,0.43)\n",
      "Umbral: -0.122. (P,R)=(0.46,0.43)\n",
      "Umbral: -0.121. (P,R)=(0.46,0.42)\n",
      "Umbral: -0.119. (P,R)=(0.46,0.41)\n",
      "Umbral: -0.115. (P,R)=(0.45,0.41)\n",
      "Umbral: -0.112. (P,R)=(0.45,0.40)\n",
      "Umbral: -0.111. (P,R)=(0.45,0.40)\n",
      "Umbral: -0.102. (P,R)=(0.46,0.40)\n",
      "Umbral: -0.096. (P,R)=(0.46,0.40)\n",
      "Umbral: -0.096. (P,R)=(0.46,0.40)\n",
      "Umbral: -0.096. (P,R)=(0.47,0.40)\n",
      "Umbral: -0.094. (P,R)=(0.46,0.40)\n",
      "Umbral: -0.088. (P,R)=(0.46,0.39)\n",
      "Umbral: -0.079. (P,R)=(0.45,0.38)\n",
      "Umbral: -0.079. (P,R)=(0.46,0.38)\n",
      "Umbral: -0.076. (P,R)=(0.45,0.38)\n",
      "Umbral: -0.075. (P,R)=(0.46,0.38)\n",
      "Umbral: -0.073. (P,R)=(0.46,0.38)\n",
      "Umbral: -0.071. (P,R)=(0.46,0.38)\n",
      "Umbral: -0.063. (P,R)=(0.46,0.37)\n",
      "Umbral: -0.061. (P,R)=(0.46,0.37)\n",
      "Umbral: -0.058. (P,R)=(0.47,0.37)\n",
      "Umbral: -0.052. (P,R)=(0.47,0.37)\n",
      "Umbral: -0.046. (P,R)=(0.47,0.37)\n",
      "Umbral: -0.044. (P,R)=(0.47,0.37)\n",
      "Umbral: -0.039. (P,R)=(0.47,0.37)\n",
      "Umbral: -0.030. (P,R)=(0.47,0.36)\n",
      "Umbral: -0.028. (P,R)=(0.47,0.36)\n",
      "Umbral: -0.027. (P,R)=(0.47,0.36)\n",
      "Umbral: -0.024. (P,R)=(0.46,0.35)\n",
      "Umbral: -0.017. (P,R)=(0.46,0.34)\n",
      "Umbral: -0.017. (P,R)=(0.46,0.34)\n",
      "Umbral: -0.012. (P,R)=(0.46,0.34)\n",
      "Umbral: -0.010. (P,R)=(0.46,0.34)\n",
      "Umbral: -0.007. (P,R)=(0.47,0.34)\n",
      "Umbral: -0.005. (P,R)=(0.46,0.33)\n",
      "Umbral: -0.002. (P,R)=(0.47,0.33)\n",
      "Umbral: 0.001. (P,R)=(0.47,0.33)\n",
      "Umbral: 0.009. (P,R)=(0.47,0.33)\n",
      "Umbral: 0.015. (P,R)=(0.47,0.33)\n",
      "Umbral: 0.020. (P,R)=(0.47,0.32)\n",
      "Umbral: 0.025. (P,R)=(0.46,0.31)\n",
      "Umbral: 0.028. (P,R)=(0.46,0.31)\n",
      "Umbral: 0.028. (P,R)=(0.45,0.30)\n",
      "Umbral: 0.028. (P,R)=(0.46,0.30)\n",
      "Umbral: 0.028. (P,R)=(0.45,0.30)\n",
      "Umbral: 0.033. (P,R)=(0.45,0.29)\n",
      "Umbral: 0.034. (P,R)=(0.45,0.29)\n",
      "Umbral: 0.042. (P,R)=(0.44,0.28)\n",
      "Umbral: 0.042. (P,R)=(0.45,0.28)\n",
      "Umbral: 0.052. (P,R)=(0.45,0.28)\n",
      "Umbral: 0.055. (P,R)=(0.45,0.28)\n",
      "Umbral: 0.056. (P,R)=(0.44,0.27)\n",
      "Umbral: 0.057. (P,R)=(0.44,0.27)\n",
      "Umbral: 0.060. (P,R)=(0.44,0.27)\n",
      "Umbral: 0.061. (P,R)=(0.45,0.27)\n",
      "Umbral: 0.074. (P,R)=(0.45,0.27)\n",
      "Umbral: 0.075. (P,R)=(0.44,0.26)\n",
      "Umbral: 0.084. (P,R)=(0.44,0.25)\n",
      "Umbral: 0.084. (P,R)=(0.44,0.25)\n",
      "Umbral: 0.088. (P,R)=(0.44,0.25)\n",
      "Umbral: 0.088. (P,R)=(0.43,0.24)\n",
      "Umbral: 0.092. (P,R)=(0.43,0.24)\n",
      "Umbral: 0.094. (P,R)=(0.43,0.24)\n",
      "Umbral: 0.094. (P,R)=(0.42,0.23)\n",
      "Umbral: 0.096. (P,R)=(0.42,0.22)\n",
      "Umbral: 0.103. (P,R)=(0.42,0.22)\n",
      "Umbral: 0.104. (P,R)=(0.42,0.22)\n",
      "Umbral: 0.117. (P,R)=(0.41,0.21)\n",
      "Umbral: 0.118. (P,R)=(0.40,0.21)\n",
      "Umbral: 0.125. (P,R)=(0.40,0.20)\n",
      "Umbral: 0.128. (P,R)=(0.40,0.20)\n",
      "Umbral: 0.136. (P,R)=(0.39,0.20)\n",
      "Umbral: 0.143. (P,R)=(0.39,0.19)\n",
      "Umbral: 0.144. (P,R)=(0.39,0.19)\n",
      "Umbral: 0.144. (P,R)=(0.40,0.19)\n",
      "Umbral: 0.145. (P,R)=(0.40,0.19)\n",
      "Umbral: 0.145. (P,R)=(0.41,0.19)\n",
      "Umbral: 0.150. (P,R)=(0.40,0.18)\n",
      "Umbral: 0.154. (P,R)=(0.40,0.18)\n",
      "Umbral: 0.156. (P,R)=(0.39,0.18)\n",
      "Umbral: 0.157. (P,R)=(0.40,0.18)\n",
      "Umbral: 0.158. (P,R)=(0.41,0.18)\n",
      "Umbral: 0.168. (P,R)=(0.41,0.18)\n",
      "Umbral: 0.170. (P,R)=(0.40,0.17)\n",
      "Umbral: 0.174. (P,R)=(0.41,0.17)\n",
      "Umbral: 0.176. (P,R)=(0.41,0.17)\n",
      "Umbral: 0.177. (P,R)=(0.42,0.17)\n",
      "Umbral: 0.179. (P,R)=(0.43,0.17)\n",
      "Umbral: 0.185. (P,R)=(0.42,0.17)\n",
      "Umbral: 0.186. (P,R)=(0.41,0.16)\n",
      "Umbral: 0.187. (P,R)=(0.40,0.15)\n",
      "Umbral: 0.190. (P,R)=(0.39,0.15)\n",
      "Umbral: 0.197. (P,R)=(0.38,0.14)\n",
      "Umbral: 0.198. (P,R)=(0.39,0.14)\n",
      "Umbral: 0.199. (P,R)=(0.39,0.14)\n",
      "Umbral: 0.200. (P,R)=(0.40,0.14)\n",
      "Umbral: 0.203. (P,R)=(0.41,0.14)\n",
      "Umbral: 0.209. (P,R)=(0.41,0.14)\n",
      "Umbral: 0.212. (P,R)=(0.40,0.14)\n",
      "Umbral: 0.216. (P,R)=(0.41,0.14)\n",
      "Umbral: 0.218. (P,R)=(0.42,0.14)\n",
      "Umbral: 0.218. (P,R)=(0.41,0.13)\n",
      "Umbral: 0.224. (P,R)=(0.42,0.13)\n",
      "Umbral: 0.225. (P,R)=(0.42,0.13)\n",
      "Umbral: 0.234. (P,R)=(0.43,0.13)\n",
      "Umbral: 0.235. (P,R)=(0.44,0.13)\n",
      "Umbral: 0.237. (P,R)=(0.43,0.12)\n",
      "Umbral: 0.238. (P,R)=(0.44,0.12)\n",
      "Umbral: 0.247. (P,R)=(0.43,0.12)\n",
      "Umbral: 0.249. (P,R)=(0.41,0.11)\n",
      "Umbral: 0.261. (P,R)=(0.42,0.11)\n",
      "Umbral: 0.263. (P,R)=(0.41,0.11)\n",
      "Umbral: 0.264. (P,R)=(0.42,0.11)\n",
      "Umbral: 0.265. (P,R)=(0.43,0.11)\n",
      "Umbral: 0.270. (P,R)=(0.44,0.11)\n",
      "Umbral: 0.276. (P,R)=(0.45,0.11)\n",
      "Umbral: 0.278. (P,R)=(0.46,0.11)\n",
      "Umbral: 0.280. (P,R)=(0.47,0.11)\n",
      "Umbral: 0.299. (P,R)=(0.49,0.11)\n",
      "Umbral: 0.301. (P,R)=(0.47,0.10)\n",
      "Umbral: 0.326. (P,R)=(0.49,0.10)\n",
      "Umbral: 0.331. (P,R)=(0.50,0.10)\n",
      "Umbral: 0.335. (P,R)=(0.48,0.09)\n",
      "Umbral: 0.340. (P,R)=(0.47,0.09)\n",
      "Umbral: 0.345. (P,R)=(0.48,0.09)\n",
      "Umbral: 0.357. (P,R)=(0.50,0.09)\n",
      "Umbral: 0.358. (P,R)=(0.52,0.09)\n",
      "Umbral: 0.358. (P,R)=(0.54,0.09)\n",
      "Umbral: 0.372. (P,R)=(0.56,0.09)\n",
      "Umbral: 0.389. (P,R)=(0.58,0.09)\n",
      "Umbral: 0.412. (P,R)=(0.56,0.08)\n",
      "Umbral: 0.416. (P,R)=(0.58,0.08)\n",
      "Umbral: 0.428. (P,R)=(0.61,0.08)\n",
      "Umbral: 0.434. (P,R)=(0.59,0.08)\n",
      "Umbral: 0.438. (P,R)=(0.57,0.07)\n",
      "Umbral: 0.462. (P,R)=(0.60,0.07)\n",
      "Umbral: 0.468. (P,R)=(0.58,0.07)\n",
      "Umbral: 0.468. (P,R)=(0.56,0.06)\n",
      "Umbral: 0.473. (P,R)=(0.59,0.06)\n",
      "Umbral: 0.480. (P,R)=(0.56,0.05)\n",
      "Umbral: 0.482. (P,R)=(0.60,0.05)\n",
      "Umbral: 0.493. (P,R)=(0.57,0.05)\n",
      "Umbral: 0.494. (P,R)=(0.54,0.04)\n",
      "Umbral: 0.501. (P,R)=(0.58,0.04)\n",
      "Umbral: 0.506. (P,R)=(0.64,0.04)\n",
      "Umbral: 0.510. (P,R)=(0.70,0.04)\n",
      "Umbral: 0.528. (P,R)=(0.67,0.04)\n",
      "Umbral: 0.554. (P,R)=(0.62,0.03)\n",
      "Umbral: 0.575. (P,R)=(0.71,0.03)\n",
      "Umbral: 0.576. (P,R)=(0.67,0.02)\n",
      "Umbral: 0.582. (P,R)=(0.60,0.02)\n",
      "Umbral: 0.645. (P,R)=(0.75,0.02)\n",
      "Umbral: 0.666. (P,R)=(1.00,0.02)\n",
      "Umbral: 0.711. (P,R)=(1.00,0.01)\n",
      "Umbral: 0.774. (P,R)=(1.00,0.01)\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve( testy3, logreg3.decision_function(testX3))\n",
    "for u,p,r in zip(thresholds,precision,recall):\n",
    "    print(\"Umbral: {:.3f}. (P,R)=({:.2f},{:.2f})\".format(u,p,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Curva PR')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(testy3, logreg3.decision_function(testX3))\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10, label=\"umbral cero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.plot(precision, recall)\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Curva PR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Curva ROC')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(testy3, logreg3.decision_function(testX3))\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=7,label=\"umbral cero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.legend(loc=4)\n",
    "plt.title(\"Curva ROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
